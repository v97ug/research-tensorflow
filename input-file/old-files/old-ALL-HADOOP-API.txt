 AHSClient (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AHSClient (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api Class AHSClient java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.client.api.AHSClient All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Stable public abstract class AHSClient extends AbstractService Constructor Summary Constructors  Constructor and Description AHSClient(String name)  Method Summary Methods  Modifier and Type Method and Description static AHSClient createAHSClient() Create a new instance of AHSClient. abstract ApplicationAttemptReport getApplicationAttemptReport(ApplicationAttemptId applicationAttemptId)  Get a report of the given ApplicationAttempt. abstract List<ApplicationAttemptReport> getApplicationAttempts(ApplicationId applicationId)  Get a report of all (ApplicationAttempts) of Application in the cluster. abstract ApplicationReport getApplicationReport(ApplicationId appId) Get a report of the given Application. abstract List<ApplicationReport> getApplications()  Get a report (ApplicationReport) of all Applications in the cluster. abstract ContainerReport getContainerReport(ContainerId containerId)  Get a report of the given Container. abstract List<ContainerReport> getContainers(ApplicationAttemptId applicationAttemptId)  Get a report of all (Containers) of ApplicationAttempt in the cluster. Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceInit, serviceStart, serviceStop, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail AHSClient @InterfaceAudience.Private public AHSClient(String name) Method Detail createAHSClient @InterfaceAudience.Public public static AHSClient createAHSClient() Create a new instance of AHSClient. getApplicationReport public abstract ApplicationReport getApplicationReport(ApplicationId appId)                                                 throws YarnException,                                                        IOException Get a report of the given Application.    In secure mode, YARN verifies access to the application, queue  etc. before accepting the request.    If the user does not have VIEW_APP access then the following  fields in the report will be set to stubbed values:      host - set to "N/A"    RPC port - set to -1    client token - set to "N/A"    diagnostics - set to "N/A"    tracking URL - set to "N/A"    original tracking URL - set to "N/A"    resource usage report - all values are -1   Parameters:appId - ApplicationId of the application that needs a report Returns:application report Throws: YarnException IOException getApplications public abstract List<ApplicationReport> getApplications()                                                  throws YarnException,                                                         IOException  Get a report (ApplicationReport) of all Applications in the cluster.        If the user does not have VIEW_APP access for an application  then the corresponding report will be filtered as described in  getApplicationReport(ApplicationId).   Returns:a list of reports for all applications Throws: YarnException IOException getApplicationAttemptReport public abstract ApplicationAttemptReport getApplicationAttemptReport(ApplicationAttemptId applicationAttemptId)                                                               throws YarnException,                                                                      IOException  Get a report of the given ApplicationAttempt.        In secure mode, YARN verifies access to the application, queue  etc. before accepting the request.   Parameters:applicationAttemptId - ApplicationAttemptId of the application attempt that needs           a report Returns:application attempt report Throws: YarnException ApplicationAttemptNotFoundException - if application attempt          not found IOException getApplicationAttempts public abstract List<ApplicationAttemptReport> getApplicationAttempts(ApplicationId applicationId)                                                                throws YarnException,                                                                       IOException  Get a report of all (ApplicationAttempts) of Application in the cluster.   Parameters:applicationId -  Returns:a list of reports for all application attempts for specified          application Throws: YarnException IOException getContainerReport public abstract ContainerReport getContainerReport(ContainerId containerId)                                             throws YarnException,                                                    IOException  Get a report of the given Container.        In secure mode, YARN verifies access to the application, queue  etc. before accepting the request.   Parameters:containerId - ContainerId of the container that needs a report Returns:container report Throws: YarnException ContainerNotFoundException - if container not found IOException getContainers public abstract List<ContainerReport> getContainers(ApplicationAttemptId applicationAttemptId)                                              throws YarnException,                                                     IOException  Get a report of all (Containers) of ApplicationAttempt in the cluster.   Parameters:applicationAttemptId -  Returns:a list of reports of all containers for specified application          attempt Throws: YarnException IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AHSProxy (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AHSProxy (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client Class AHSProxy<T> java.lang.Object org.apache.hadoop.yarn.client.AHSProxy<T> @InterfaceAudience.Public @InterfaceStability.Evolving public class AHSProxy<T> extends Object Constructor Summary Constructors  Constructor and Description AHSProxy()  Method Summary Methods  Modifier and Type Method and Description static <T> T createAHSProxy(Configuration conf,                             Class<T> protocol,                             InetSocketAddress ahsAddress)  protected static <T> T getProxy(Configuration conf,                 Class<T> protocol,                 InetSocketAddress rmAddress)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AHSProxy public AHSProxy() Method Detail createAHSProxy public static <T> T createAHSProxy(Configuration conf,                    Class<T> protocol,                    InetSocketAddress ahsAddress)                         throws IOException Throws: IOException getProxy protected static <T> T getProxy(Configuration conf,              Class<T> protocol,              InetSocketAddress rmAddress)                      throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AMCommand (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AMCommand (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum AMCommand java.lang.Object java.lang.Enum<AMCommand> org.apache.hadoop.yarn.api.records.AMCommand All Implemented Interfaces: Serializable, Comparable<AMCommand> @InterfaceAudience.Public @InterfaceStability.Unstable public enum AMCommand extends Enum<AMCommand> Command sent by the Resource Manager to the Application Master in the   AllocateResponse See Also:AllocateResponse Enum Constant Summary Enum Constants  Enum Constant and Description AM_RESYNC Deprecated.  Sent by Resource Manager when it is out of sync with the AM and              wants the AM get back in sync.                Note: Instead of sending this command,              ApplicationMasterNotRegisteredException will be thrown              when ApplicationMaster is out of sync with ResourceManager and              ApplicationMaster is expected to re-register with RM by calling              ApplicationMasterProtocol.registerApplicationMaster(RegisterApplicationMasterRequest) AM_SHUTDOWN Deprecated.  Sent by Resource Manager when it wants the AM to shutdown.              Note: This command was earlier sent by ResourceManager to              instruct AM to shutdown if RM had restarted. Now              ApplicationAttemptNotFoundException will be thrown in case              that RM has restarted and AM is supposed to handle this              exception by shutting down itself. Method Summary Methods  Modifier and Type Method and Description static AMCommand valueOf(String name) Returns the enum constant of this type with the specified name. static AMCommand[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail AM_RESYNC public static final AMCommand AM_RESYNC Deprecated. Sent by Resource Manager when it is out of sync with the AM and              wants the AM get back in sync.                Note: Instead of sending this command,              ApplicationMasterNotRegisteredException will be thrown              when ApplicationMaster is out of sync with ResourceManager and              ApplicationMaster is expected to re-register with RM by calling              ApplicationMasterProtocol.registerApplicationMaster(RegisterApplicationMasterRequest) AM_SHUTDOWN public static final AMCommand AM_SHUTDOWN Deprecated. Sent by Resource Manager when it wants the AM to shutdown.              Note: This command was earlier sent by ResourceManager to              instruct AM to shutdown if RM had restarted. Now              ApplicationAttemptNotFoundException will be thrown in case              that RM has restarted and AM is supposed to handle this              exception by shutting down itself. Method Detail values public static AMCommand[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (AMCommand c : AMCommand.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static AMCommand valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AMRMClient (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AMRMClient (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api Class AMRMClient<T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.client.api.AMRMClient<T> All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Stable public abstract class AMRMClient<T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> extends AbstractService Constructor Summary Constructors  Modifier Constructor and Description protected  AMRMClient(String name)  Method Summary Methods  Modifier and Type Method and Description abstract void addContainerRequest(T req) Request containers for resources before calling allocate abstract AllocateResponse allocate(float progressIndicator) Request additional containers and receive new container allocations. static <T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> AMRMClient<T> createAMRMClient() Create a new instance of AMRMClient. abstract Resource getAvailableResources() Get the currently available resources in the cluster. abstract int getClusterNodeCount() Get the current number of nodes in the cluster. abstract List<? extends Collection<T>> getMatchingRequests(Priority priority,                                       String resourceName,                                       Resource capability) Get outstanding ContainerRequests matching the given   parameters. NMTokenCache getNMTokenCache() Get the NM token cache of the AMRMClient. abstract RegisterApplicationMasterResponse registerApplicationMaster(String appHostName,                                                   int appHostPort,                                                   String appTrackingUrl) Register the application master. abstract void releaseAssignedContainer(ContainerId containerId) Release containers assigned by the Resource Manager. abstract void removeContainerRequest(T req) Remove previous container request. void setNMTokenCache(NMTokenCache nmTokenCache) Set the NM token cache for the AMRMClient. abstract void unregisterApplicationMaster(FinalApplicationStatus appStatus,                                                       String appMessage,                                                       String appTrackingUrl) Unregister the application master. abstract void updateBlacklist(List<String> blacklistAdditions,                               List<String> blacklistRemovals) Update application's blacklist with addition or removal resources. void waitFor(com.google.common.base.Supplier<Boolean> check) Wait for check to return true for each 1000 ms. void waitFor(com.google.common.base.Supplier<Boolean> check,               int checkEveryMillis) Wait for check to return true for each  checkEveryMillis ms. void waitFor(com.google.common.base.Supplier<Boolean> check,               int checkEveryMillis,               int logInterval) Wait for check to return true for each  checkEveryMillis ms. Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceInit, serviceStart, serviceStop, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail AMRMClient @InterfaceAudience.Private protected AMRMClient(String name) Method Detail createAMRMClient @InterfaceAudience.Public public static <T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> AMRMClient<T> createAMRMClient() Create a new instance of AMRMClient.  For usage:    AMRMClient.<T>createAMRMClientContainerRequest()   Returns:the newly create AMRMClient instance. registerApplicationMaster public abstract RegisterApplicationMasterResponse registerApplicationMaster(String appHostName,                                                           int appHostPort,                                                           String appTrackingUrl)                                                                      throws YarnException,                                                                             IOException Register the application master. This must be called before any   other interaction Parameters:appHostName - Name of the host on which master is runningappHostPort - Port master is listening onappTrackingUrl - URL at which the master info can be seen Returns:RegisterApplicationMasterResponse Throws: YarnException IOException allocate public abstract AllocateResponse allocate(float progressIndicator)                                    throws YarnException,                                           IOException Request additional containers and receive new container allocations.  Requests made via addContainerRequest are sent to the  ResourceManager. New containers assigned to the master are  retrieved. Status of completed containers and node health updates are also  retrieved. This also doubles up as a heartbeat to the ResourceManager and  must be made periodically. The call may not always return any new  allocations of containers. App should not make concurrent allocate  requests. May cause request loss.      Note : If the user has not removed container requests that have already  been satisfied, then the re-register may end up sending the entire  container requests to the RM (including matched requests). Which would mean  the RM could end up giving it a lot of new allocated containers.   Parameters:progressIndicator - Indicates progress made by the master Returns:the response of the allocate request Throws: YarnException IOException unregisterApplicationMaster public abstract void unregisterApplicationMaster(FinalApplicationStatus appStatus,                                String appMessage,                                String appTrackingUrl)                                           throws YarnException,                                                  IOException Unregister the application master. This must be called in the end. Parameters:appStatus - Success/Failure status of the masterappMessage - Diagnostics message on failureappTrackingUrl - New URL to get master info Throws: YarnException IOException addContainerRequest public abstract void addContainerRequest(T req) Request containers for resources before calling allocate Parameters:req - Resource request removeContainerRequest public abstract void removeContainerRequest(T req) Remove previous container request. The previous container request may have   already been sent to the ResourceManager. So even after the remove request   the app must be prepared to receive an allocation for the previous request   even after the remove request Parameters:req - Resource request releaseAssignedContainer public abstract void releaseAssignedContainer(ContainerId containerId) Release containers assigned by the Resource Manager. If the app cannot use  the container or wants to give up the container then it can release them.  The app needs to make new requests for the released resource capability if  it still needs it. eg. it released non-local resources Parameters:containerId -  getAvailableResources public abstract Resource getAvailableResources() Get the currently available resources in the cluster.  A valid value is available after a call to allocate has been made Returns:Currently available resources getClusterNodeCount public abstract int getClusterNodeCount() Get the current number of nodes in the cluster.  A valid values is available after a call to allocate has been made Returns:Current number of nodes in the cluster getMatchingRequests public abstract List<? extends Collection<T>> getMatchingRequests(Priority priority,                                                 String resourceName,                                                 Resource capability) Get outstanding ContainerRequests matching the given   parameters. These ContainerRequests should have been added via  addContainerRequest earlier in the lifecycle. For performance,  the AMRMClient may return its internal collection directly without creating   a copy. Users should not perform mutable operations on the return value.  Each collection in the list contains requests with identical   Resource size that fit in the given capability. In a   collection, requests will be returned in the same order as they were added. Returns:Collection of request matching the parameters updateBlacklist public abstract void updateBlacklist(List<String> blacklistAdditions,                    List<String> blacklistRemovals) Update application's blacklist with addition or removal resources. Parameters:blacklistAdditions - list of resources which should be added to the          application blacklistblacklistRemovals - list of resources which should be removed from the          application blacklist setNMTokenCache public void setNMTokenCache(NMTokenCache nmTokenCache) Set the NM token cache for the AMRMClient. This cache must  be shared with the NMClient used to manage containers for the  AMRMClient    If a NM token cache is not set, the NMTokenCache.getSingleton()  singleton instance will be used. Parameters:nmTokenCache - the NM token cache to use. getNMTokenCache public NMTokenCache getNMTokenCache() Get the NM token cache of the AMRMClient. This cache must be  shared with the NMClient used to manage containers for the  AMRMClient.    If a NM token cache is not set, the NMTokenCache.getSingleton()  singleton instance will be used. Returns:the NM token cache. waitFor public void waitFor(com.google.common.base.Supplier<Boolean> check)              throws InterruptedException Wait for check to return true for each 1000 ms.  See also waitFor(com.google.common.base.Supplier, int)  and waitFor(com.google.common.base.Supplier, int, int) Parameters:check -  Throws: InterruptedException waitFor public void waitFor(com.google.common.base.Supplier<Boolean> check,            int checkEveryMillis)              throws InterruptedException Wait for check to return true for each  checkEveryMillis ms.  See also waitFor(com.google.common.base.Supplier, int, int) Parameters:check - user defined checkercheckEveryMillis - interval to call check Throws: InterruptedException waitFor public void waitFor(com.google.common.base.Supplier<Boolean> check,            int checkEveryMillis,            int logInterval)              throws InterruptedException Wait for check to return true for each  checkEveryMillis ms. In the main loop, this method will log  the message "waiting in main loop" for each logInterval times  iteration to confirm the thread is alive. Parameters:check - user defined checkercheckEveryMillis - interval to call checklogInterval - interval to log for each Throws: InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AMRMClientAsync (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AMRMClientAsync (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api.async Class AMRMClientAsync<T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.client.api.async.AMRMClientAsync<T> All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Stable public abstract class AMRMClientAsync<T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> extends AbstractService AMRMClientAsync handles communication with the ResourceManager  and provides asynchronous updates on events such as container allocations and  completions.  It contains a thread that sends periodic heartbeats to the  ResourceManager.    It should be used by implementing a CallbackHandler:    class MyCallbackHandler implements AMRMClientAsync.CallbackHandler {    public void onContainersAllocated(List<Container> containers) {      [run tasks on the containers]    }        public void onContainersCompleted(List<ContainerStatus> statuses) {      [update progress, check whether app is done]    }        public void onNodesUpdated(List<NodeReport> updated) {}        public void onReboot() {}  }        The client's lifecycle should be managed similarly to the following:      AMRMClientAsync asyncClient =       createAMRMClientAsync(appAttId, 1000, new MyCallbackhandler());  asyncClient.init(conf);  asyncClient.start();  RegisterApplicationMasterResponse response = asyncClient     .registerApplicationMaster(appMasterHostname, appMasterRpcPort,        appMasterTrackingUrl);  asyncClient.addContainerRequest(containerRequest);  [... wait for application to complete]  asyncClient.unregisterApplicationMaster(status, appMsg, trackingUrl);  asyncClient.stop();     Field Summary Fields  Modifier and Type Field and Description protected AMRMClient<T> client  protected org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler handler  protected AtomicInteger heartbeatIntervalMs  Constructor Summary Constructors  Modifier Constructor and Description protected  AMRMClientAsync(AMRMClient<T> client,                               int intervalMs,                               org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler callbackHandler)  protected  AMRMClientAsync(int intervalMs,                               org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler callbackHandler)  Method Summary Methods  Modifier and Type Method and Description abstract void addContainerRequest(T req) Request containers for resources before calling allocate static <T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> AMRMClientAsync<T> createAMRMClientAsync(AMRMClient<T> client,                                           int intervalMs,                                           org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler callbackHandler)  static <T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> AMRMClientAsync<T> createAMRMClientAsync(int intervalMs,                                           org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler callbackHandler)  abstract Resource getAvailableResources() Get the currently available resources in the cluster. abstract int getClusterNodeCount() Get the current number of nodes in the cluster. abstract List<? extends Collection<T>> getMatchingRequests(Priority priority,                                       String resourceName,                                       Resource capability)  abstract RegisterApplicationMasterResponse registerApplicationMaster(String appHostName,                                                   int appHostPort,                                                   String appTrackingUrl) Registers this application master with the resource manager. abstract void releaseAssignedContainer(ContainerId containerId) Release containers assigned by the Resource Manager. abstract void removeContainerRequest(T req) Remove previous container request. void setHeartbeatInterval(int interval)  abstract void unregisterApplicationMaster(FinalApplicationStatus appStatus,                                                       String appMessage,                                                       String appTrackingUrl) Unregister the application master. abstract void updateBlacklist(List<String> blacklistAdditions,                               List<String> blacklistRemovals) Update application's blacklist with addition or removal resources. void waitFor(com.google.common.base.Supplier<Boolean> check) Wait for check to return true for each 1000 ms. void waitFor(com.google.common.base.Supplier<Boolean> check,               int checkEveryMillis) Wait for check to return true for each  checkEveryMillis ms. void waitFor(com.google.common.base.Supplier<Boolean> check,               int checkEveryMillis,               int logInterval) Wait for check to return true for each  checkEveryMillis ms. Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceInit, serviceStart, serviceStop, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail client protected final AMRMClient<T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> client handler protected final org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler handler heartbeatIntervalMs protected final AtomicInteger heartbeatIntervalMs Constructor Detail AMRMClientAsync protected AMRMClientAsync(int intervalMs,                org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler callbackHandler) AMRMClientAsync @InterfaceAudience.Private protected AMRMClientAsync(AMRMClient<T> client,                                          int intervalMs,                                          org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler callbackHandler) Method Detail createAMRMClientAsync public static <T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> AMRMClientAsync<T> createAMRMClientAsync(int intervalMs,                                                                                                                  org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler callbackHandler) createAMRMClientAsync public static <T extends org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest> AMRMClientAsync<T> createAMRMClientAsync(AMRMClient<T> client,                                                                                                                  int intervalMs,                                                                                                                  org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler callbackHandler) setHeartbeatInterval public void setHeartbeatInterval(int interval) getMatchingRequests public abstract List<? extends Collection<T>> getMatchingRequests(Priority priority,                                                 String resourceName,                                                 Resource capability) registerApplicationMaster public abstract RegisterApplicationMasterResponse registerApplicationMaster(String appHostName,                                                           int appHostPort,                                                           String appTrackingUrl)                                                                      throws YarnException,                                                                             IOException Registers this application master with the resource manager. On successful  registration, starts the heartbeating thread. Throws: YarnException IOException unregisterApplicationMaster public abstract void unregisterApplicationMaster(FinalApplicationStatus appStatus,                                String appMessage,                                String appTrackingUrl)                                           throws YarnException,                                                  IOException Unregister the application master. This must be called in the end. Parameters:appStatus - Success/Failure status of the masterappMessage - Diagnostics message on failureappTrackingUrl - New URL to get master info Throws: YarnException IOException addContainerRequest public abstract void addContainerRequest(T req) Request containers for resources before calling allocate Parameters:req - Resource request removeContainerRequest public abstract void removeContainerRequest(T req) Remove previous container request. The previous container request may have   already been sent to the ResourceManager. So even after the remove request   the app must be prepared to receive an allocation for the previous request   even after the remove request Parameters:req - Resource request releaseAssignedContainer public abstract void releaseAssignedContainer(ContainerId containerId) Release containers assigned by the Resource Manager. If the app cannot use  the container or wants to give up the container then it can release them.  The app needs to make new requests for the released resource capability if  it still needs it. eg. it released non-local resources Parameters:containerId -  getAvailableResources public abstract Resource getAvailableResources() Get the currently available resources in the cluster.  A valid value is available after a call to allocate has been made Returns:Currently available resources getClusterNodeCount public abstract int getClusterNodeCount() Get the current number of nodes in the cluster.  A valid values is available after a call to allocate has been made Returns:Current number of nodes in the cluster updateBlacklist public abstract void updateBlacklist(List<String> blacklistAdditions,                    List<String> blacklistRemovals) Update application's blacklist with addition or removal resources. Parameters:blacklistAdditions - list of resources which should be added to the         application blacklistblacklistRemovals - list of resources which should be removed from the         application blacklist waitFor public void waitFor(com.google.common.base.Supplier<Boolean> check)              throws InterruptedException Wait for check to return true for each 1000 ms.  See also waitFor(com.google.common.base.Supplier, int)  and waitFor(com.google.common.base.Supplier, int, int) Parameters:check -  Throws: InterruptedException waitFor public void waitFor(com.google.common.base.Supplier<Boolean> check,            int checkEveryMillis)              throws InterruptedException Wait for check to return true for each  checkEveryMillis ms.  See also waitFor(com.google.common.base.Supplier, int, int) Parameters:check - user defined checkercheckEveryMillis - interval to call check Throws: InterruptedException waitFor public void waitFor(com.google.common.base.Supplier<Boolean> check,            int checkEveryMillis,            int logInterval)              throws InterruptedException Wait for check to return true for each  checkEveryMillis ms. In the main loop, this method will log  the message "waiting in main loop" for each logInterval times  iteration to confirm the thread is alive. Parameters:check - user defined checkercheckEveryMillis - interval to call checklogInterval - interval to log for each Throws: InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AMRMTokenIdentifier (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AMRMTokenIdentifier (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security Class AMRMTokenIdentifier java.lang.Object org.apache.hadoop.security.token.TokenIdentifier org.apache.hadoop.yarn.security.AMRMTokenIdentifier All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class AMRMTokenIdentifier extends org.apache.hadoop.security.token.TokenIdentifier AMRMTokenIdentifier is the TokenIdentifier to be used by  ApplicationMasters to authenticate to the ResourceManager. Field Summary Fields  Modifier and Type Field and Description static Text KIND_NAME  Constructor Summary Constructors  Constructor and Description AMRMTokenIdentifier()  AMRMTokenIdentifier(ApplicationAttemptId appAttemptId,                                       int masterKeyId)  Method Summary Methods  Modifier and Type Method and Description boolean equals(Object other)  int getKeyId()  Text getKind() Get the token kind org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.AMRMTokenIdentifierProto getProto()  org.apache.hadoop.security.UserGroupInformation getUser() Get the Ugi with the username encoded in the token identifier int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.security.token.TokenIdentifier getBytes, getTrackingId Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail KIND_NAME public static final Text KIND_NAME Constructor Detail AMRMTokenIdentifier public AMRMTokenIdentifier() AMRMTokenIdentifier public AMRMTokenIdentifier(ApplicationAttemptId appAttemptId,                    int masterKeyId) Method Detail write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Parameters:in - DataInput to deseriablize this object from. Throws: IOException getKind public Text getKind() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the token kind Specified by: getKind in class org.apache.hadoop.security.token.TokenIdentifier Returns:the kind of the token getUser public org.apache.hadoop.security.UserGroupInformation getUser() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the Ugi with the username encoded in the token identifier Specified by: getUser in class org.apache.hadoop.security.token.TokenIdentifier Returns:the username. null is returned if username in the identifier is          empty or null. getKeyId public int getKeyId() getProto public org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.AMRMTokenIdentifierProto getProto() hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object other) Overrides: equals in class Object toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AMRMTokenSelector (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AMRMTokenSelector (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security Class AMRMTokenSelector java.lang.Object org.apache.hadoop.yarn.security.AMRMTokenSelector All Implemented Interfaces: org.apache.hadoop.security.token.TokenSelector<AMRMTokenIdentifier> @InterfaceAudience.Public @InterfaceStability.Evolving public class AMRMTokenSelector extends Object implements org.apache.hadoop.security.token.TokenSelector<AMRMTokenIdentifier> Constructor Summary Constructors  Constructor and Description AMRMTokenSelector()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.token.Token<AMRMTokenIdentifier> selectToken(Text service,                       Collection<org.apache.hadoop.security.token.Token<? extends org.apache.hadoop.security.token.TokenIdentifier>> tokens)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AMRMTokenSelector public AMRMTokenSelector() Method Detail selectToken public org.apache.hadoop.security.token.Token<AMRMTokenIdentifier> selectToken(Text service,                                                                       Collection<org.apache.hadoop.security.token.Token<? extends org.apache.hadoop.security.token.TokenIdentifier>> tokens) Specified by: selectToken in interface org.apache.hadoop.security.token.TokenSelector<AMRMTokenIdentifier> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AbstractCounters (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AbstractCounters (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.counters Class AbstractCounters<C extends Counter,G extends CounterGroupBase<C>> java.lang.Object org.apache.hadoop.mapreduce.counters.AbstractCounters<C,G> Type Parameters:C - type of counter inside the countersG - type of group inside the counters All Implemented Interfaces: Iterable<G>, Writable Direct Known Subclasses: Counters, Counters @InterfaceAudience.Public @InterfaceStability.Stable public abstract class AbstractCounters<C extends Counter,G extends CounterGroupBase<C>> extends Object implements Writable, Iterable<G> An abstract class to provide common implementation for the Counters  container in both mapred and mapreduce packages. Field Summary Fields  Modifier and Type Field and Description protected static org.apache.commons.logging.Log LOG  Constructor Summary Constructors  Constructor and Description AbstractCounters(AbstractCounters<C1,G1> counters,                                 org.apache.hadoop.mapreduce.counters.CounterGroupFactory<C,G> groupFactory) Construct from another counters object. AbstractCounters(org.apache.hadoop.mapreduce.counters.CounterGroupFactory<C,G> gf)  Method Summary Methods  Modifier and Type Method and Description int countCounters() Returns the total number of counters, by summing the number of counters  in each group. boolean equals(Object genericRight)  C findCounter(Enum<?> key) Find the counter for the given enum. C findCounter(String groupName,                       String counterName) Find a counter, create one if necessary G getGroup(String groupName) Returns the named counter group, or an empty group if there is none  with the specified name. Iterable<String> getGroupNames() Returns the names of all counter classes. int hashCode()  void incrAllCounters(AbstractCounters<C,G> other) Increments multiple counters by their amounts in another Counters  instance. Iterator<G> iterator()  void readFields(DataInput in) Deserialize the fields of this object from in. String toString() Return textual representation of the counter values. void write(DataOutput out) Write the set of groups. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail LOG protected static final org.apache.commons.logging.Log LOG Constructor Detail AbstractCounters @InterfaceAudience.Private public AbstractCounters(org.apache.hadoop.mapreduce.counters.CounterGroupFactory<C,G> gf) AbstractCounters @InterfaceAudience.Private public AbstractCounters(AbstractCounters<C1,G1> counters,                                           org.apache.hadoop.mapreduce.counters.CounterGroupFactory<C,G> groupFactory) Construct from another counters object. Type Parameters:C1 - type of the other counterG1 - type of the other counter groupParameters:counters - the counters object to copygroupFactory - the factory for new groups Method Detail findCounter public C findCounter(String groupName,             String counterName) Find a counter, create one if necessary Parameters:groupName - of the countercounterName - name of the counter Returns:the matching counter findCounter public C findCounter(Enum<?> key) Find the counter for the given enum. The same enum will always return the  same counter. Parameters:key - the counter key Returns:the matching counter object getGroupNames public Iterable<String> getGroupNames() Returns the names of all counter classes. Returns:Set of counter names. iterator public Iterator<G> iterator() Specified by: iterator in interface Iterable<G extends CounterGroupBase<C>> getGroup public G getGroup(String groupName) Returns the named counter group, or an empty group if there is none  with the specified name. Parameters:groupName - name of the group Returns:the group countCounters public int countCounters() Returns the total number of counters, by summing the number of counters  in each group. Returns:the total number of counters write public void write(DataOutput out)            throws IOException Write the set of groups.  Counters ::= version #fgroups (groupId, group)* #groups (group)* Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException toString public String toString() Return textual representation of the counter values. Overrides: toString in class Object Returns:the string incrAllCounters public void incrAllCounters(AbstractCounters<C,G> other) Increments multiple counters by their amounts in another Counters  instance. Parameters:other - the other Counters instance equals public boolean equals(Object genericRight) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AbstractDNSToSwitchMapping (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AbstractDNSToSwitchMapping (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.net Class AbstractDNSToSwitchMapping java.lang.Object org.apache.hadoop.net.AbstractDNSToSwitchMapping All Implemented Interfaces: Configurable, DNSToSwitchMapping Direct Known Subclasses: CachedDNSToSwitchMapping @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class AbstractDNSToSwitchMapping extends Object implements DNSToSwitchMapping, Configurable This is a base class for DNS to Switch mappings.  It is not mandatory to  derive DNSToSwitchMapping implementations from it, but it is strongly  recommended, as it makes it easy for the Hadoop developers to add new methods  to this base class that are automatically picked up by all implementations.    This class does not extend the Configured  base class, and should not be changed to do so, as it causes problems  for subclasses. The constructor of the Configured calls  the  setConf(Configuration) method, which will call into the  subclasses before they have been fully constructed. Constructor Summary Constructors  Modifier Constructor and Description protected  AbstractDNSToSwitchMapping() Create an unconfigured instance protected  AbstractDNSToSwitchMapping(Configuration conf) Create an instance, caching the configuration file. Method Summary Methods  Modifier and Type Method and Description String dumpTopology() Generate a string listing the switch mapping implementation,  the mapping for every known node and the number of nodes and  unique switches known about -each entry to a separate line. Configuration getConf() Return the configuration used by this object. Map<String,String> getSwitchMap() Get a copy of the map (for diagnostics) static boolean isMappingSingleSwitch(DNSToSwitchMapping mapping) Query for a DNSToSwitchMapping instance being on a single  switch. boolean isSingleSwitch() Predicate that indicates that the switch mapping is known to be  single-switch. protected boolean isSingleSwitchByScriptPolicy()  void setConf(Configuration conf) Set the configuration to be used by this object. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.net.DNSToSwitchMapping reloadCachedMappings, reloadCachedMappings, resolve Constructor Detail AbstractDNSToSwitchMapping protected AbstractDNSToSwitchMapping() Create an unconfigured instance AbstractDNSToSwitchMapping protected AbstractDNSToSwitchMapping(Configuration conf) Create an instance, caching the configuration file.  This constructor does not call setConf(Configuration); if  a subclass extracts information in that method, it must call it explicitly. Parameters:conf - the configuration Method Detail getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable isSingleSwitch public boolean isSingleSwitch() Predicate that indicates that the switch mapping is known to be  single-switch. The base class returns false: it assumes all mappings are  multi-rack. Subclasses may override this with methods that are more aware  of their topologies.    This method is used when parts of Hadoop need know whether to apply  single rack vs multi-rack policies, such as during block placement.  Such algorithms behave differently if they are on multi-switch systems.   Returns:true if the mapping thinks that it is on a single switch getSwitchMap public Map<String,String> getSwitchMap() Get a copy of the map (for diagnostics) Returns:a clone of the map or null for none known dumpTopology public String dumpTopology() Generate a string listing the switch mapping implementation,  the mapping for every known node and the number of nodes and  unique switches known about -each entry to a separate line. Returns:a string that can be presented to the ops team or used in  debug messages. isSingleSwitchByScriptPolicy protected boolean isSingleSwitchByScriptPolicy() isMappingSingleSwitch public static boolean isMappingSingleSwitch(DNSToSwitchMapping mapping) Query for a DNSToSwitchMapping instance being on a single  switch.    This predicate simply assumes that all mappings not derived from  this class are multi-switch. Parameters:mapping - the mapping to query Returns:true if the base class says it is single switch, or the mapping  is not derived from this class. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AbstractEvent (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AbstractEvent (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.event Class AbstractEvent<TYPE extends Enum<TYPE>> java.lang.Object org.apache.hadoop.yarn.event.AbstractEvent<TYPE> All Implemented Interfaces: Event<TYPE> @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class AbstractEvent<TYPE extends Enum<TYPE>> extends Object implements Event<TYPE> Parent class of all the events. All events extend this class. Constructor Summary Constructors  Constructor and Description AbstractEvent(TYPE type)  AbstractEvent(TYPE type,                           long timestamp)  Method Summary Methods  Modifier and Type Method and Description long getTimestamp()  TYPE getType()  String toString()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail AbstractEvent public AbstractEvent(TYPE type) AbstractEvent public AbstractEvent(TYPE type,              long timestamp) Method Detail getTimestamp public long getTimestamp() Specified by: getTimestamp in interface Event<TYPE extends Enum<TYPE>> getType public TYPE getType() Specified by: getType in interface Event<TYPE extends Enum<TYPE>> toString public String toString() Specified by: toString in interface Event<TYPE extends Enum<TYPE>> Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AbstractFileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AbstractFileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class AbstractFileSystem java.lang.Object org.apache.hadoop.fs.AbstractFileSystem Direct Known Subclasses: org.apache.hadoop.fs.DelegateToFileSystem, ViewFs @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class AbstractFileSystem extends Object This class provides an interface for implementors of a Hadoop file system  (analogous to the VFS of Unix). Applications do not access this class;  instead they access files across all file systems using FileContext.    Pathnames passed to AbstractFileSystem can be fully qualified URI that  matches the "this" file system (ie same scheme and authority)   or a Slash-relative name that is assumed to be relative  to the root of the "this" file system . Field Summary Fields  Modifier and Type Field and Description protected org.apache.hadoop.fs.FileSystem.Statistics statistics The statistics for this file system. Constructor Summary Constructors  Constructor and Description AbstractFileSystem(URI uri,                                     String supportedScheme,                                     boolean authorityNeeded,                                     int defaultPort) Constructor to be called by subclasses. Method Summary Methods  Modifier and Type Method and Description void checkPath(Path path) Check that a Path belongs to this FileSystem. void checkScheme(URI uri,                       String supportedScheme) Check that the Uri's scheme matches static void clearStatistics()  FSDataOutputStream create(Path f,             EnumSet<CreateFlag> createFlag,             org.apache.hadoop.fs.Options.CreateOpts... opts) The specification of this method matches that of  FileContext.create(Path, EnumSet, Options.CreateOpts...) except  that the Path f must be fully qualified and the permission is absolute  (i.e. static AbstractFileSystem createFileSystem(URI uri,                                 Configuration conf) Create a file system instance for the specified uri using the conf. abstract FSDataOutputStream createInternal(Path f,                             EnumSet<CreateFlag> flag,                             FsPermission absolutePermission,                             int bufferSize,                             short replication,                             long blockSize,                             Progressable progress,                             org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt,                             boolean createParent) The specification of this method matches that of  create(Path, EnumSet, Options.CreateOpts...) except that the opts  have been declared explicitly. void createSymlink(Path target,                           Path link,                           boolean createParent) The specification of this method matches that of    FileContext.createSymlink(Path, Path, boolean); abstract boolean delete(Path f,             boolean recursive) The specification of this method matches that of  FileContext.delete(Path, boolean) except that Path f must be for  this file system. boolean equals(Object other)  static AbstractFileSystem get(URI uri,       Configuration conf) The main factory method for creating a file system. AclStatus getAclStatus(Path path) Gets the ACLs of files and directories. protected static Map<URI,org.apache.hadoop.fs.FileSystem.Statistics> getAllStatistics()  String getCanonicalServiceName() Get a canonical name for this file system. abstract BlockLocation[] getFileBlockLocations(Path f,                                           long start,                                           long len) The specification of this method matches that of  FileContext.getFileBlockLocations(Path, long, long) except that  Path f must be for this file system. abstract FileChecksum getFileChecksum(Path f) The specification of this method matches that of  FileContext.getFileChecksum(Path) except that Path f must be for  this file system. FileStatus getFileLinkStatus(Path f) The specification of this method matches that of  FileContext.getFileLinkStatus(Path)  except that an UnresolvedLinkException may be thrown if a symlink is    encountered in the path leading up to the final path component. abstract FileStatus getFileStatus(Path f) The specification of this method matches that of  FileContext.getFileStatus(Path)   except that an UnresolvedLinkException may be thrown if a symlink is   encountered in the path. abstract FsStatus getFsStatus() The specification of this method matches that of  FileContext.getFsStatus(Path). FsStatus getFsStatus(Path f) The specification of this method matches that of  FileContext.getFsStatus(Path) except that Path f must be for this  file system. Path getHomeDirectory() Return the current user's home directory in this file system. Path getInitialWorkingDirectory() Some file systems like LocalFileSystem have an initial workingDir  that is used as the starting workingDir. Path getLinkTarget(Path f) Partially resolves the path. abstract FsServerDefaults getServerDefaults() Return a set of server default configuration values. org.apache.hadoop.fs.FileSystem.Statistics getStatistics()  protected static org.apache.hadoop.fs.FileSystem.Statistics getStatistics(URI uri) Get the statistics for a particular file system. URI getUri() Returns a URI whose scheme and authority identify this FileSystem. abstract int getUriDefaultPort() The default port of this file system. String getUriPath(Path p) Get the path-part of a pathname. byte[] getXAttr(Path path,                 String name) Get an xattr for a file or directory. Map<String,byte[]> getXAttrs(Path path) Get all of the xattrs for a file or directory. Map<String,byte[]> getXAttrs(Path path,                   List<String> names) Get all of the xattrs for a file or directory. int hashCode()  boolean isValidName(String src) Returns true if the specified string is considered valid in the path part  of a URI by this file system. org.apache.hadoop.fs.RemoteIterator<Path> listCorruptFileBlocks(Path path)  org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f) The specification of this method matches that of  FileContext.listLocatedStatus(Path) except that Path f   must be for this file system. abstract FileStatus[] listStatus(Path f) The specification of this method matches that of  FileContext.Util.listStatus(Path) except that Path f must be   for this file system. org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatusIterator(Path f) The specification of this method matches that of  FileContext.listStatus(Path) except that Path f must be for this  file system. List<String> listXAttrs(Path path) Get all of the xattr names for a file or directory. Path makeQualified(Path path) Make the path fully qualified to this file system abstract void mkdir(Path dir,           FsPermission permission,           boolean createParent) The specification of this method matches that of  FileContext.mkdir(Path, FsPermission, boolean) except that the Path  f must be fully qualified and the permission is absolute (i.e. void modifyAclEntries(Path path,                                 List<AclEntry> aclSpec) Modifies ACL entries of files and directories. FSDataInputStream open(Path f) The specification of this method matches that of  FileContext.open(Path) except that Path f must be for this  file system. abstract FSDataInputStream open(Path f,         int bufferSize) The specification of this method matches that of  FileContext.open(Path, int) except that Path f must be for this  file system. static void printStatistics() Prints statistics for all file systems. void removeAcl(Path path) Removes all but the base ACL entries of files and directories. void removeAclEntries(Path path,                                 List<AclEntry> aclSpec) Removes ACL entries from files and directories. void removeDefaultAcl(Path path) Removes all default ACL entries from files and directories. void removeXAttr(Path path,                       String name) Remove an xattr of a file or directory. void rename(Path src,             Path dst,             org.apache.hadoop.fs.Options.Rename... options) The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system. abstract void renameInternal(Path src,                             Path dst) The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system and NO OVERWRITE is performed. void renameInternal(Path src,                             Path dst,                             boolean overwrite) The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system. Path resolvePath(Path p) Return the fully-qualified path of path f resolving the path  through any internal symlinks or mount point void setAcl(Path path,             List<AclEntry> aclSpec) Fully replaces ACL of files and directories, discarding all existing  entries. abstract void setOwner(Path f,                 String username,                 String groupname) The specification of this method matches that of  FileContext.setOwner(Path, String, String) except that Path f must  be for this file system. abstract void setPermission(Path f,                           FsPermission permission) The specification of this method matches that of  FileContext.setPermission(Path, FsPermission) except that Path f  must be for this file system. abstract boolean setReplication(Path f,                             short replication) The specification of this method matches that of  FileContext.setReplication(Path, short) except that Path f must be  for this file system. abstract void setTimes(Path f,                 long mtime,                 long atime) The specification of this method matches that of  FileContext.setTimes(Path, long, long) except that Path f must be  for this file system. abstract void setVerifyChecksum(boolean verifyChecksum) The specification of this method matches that of  FileContext.setVerifyChecksum(boolean, Path) except that Path f  must be for this file system. void setXAttr(Path path,                 String name,                 byte[] value) Set an xattr of a file or directory. void setXAttr(Path path,                 String name,                 byte[] value,                 EnumSet<XAttrSetFlag> flag) Set an xattr of a file or directory. boolean supportsSymlinks() Returns true if the file system supports symlinks, false otherwise. boolean truncate(Path f,                 long newLength) The specification of this method matches that of  FileContext.truncate(Path, long) except that Path f must be for  this file system. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Field Detail statistics protected org.apache.hadoop.fs.FileSystem.Statistics statistics The statistics for this file system. Constructor Detail AbstractFileSystem public AbstractFileSystem(URI uri,                   String supportedScheme,                   boolean authorityNeeded,                   int defaultPort)                    throws URISyntaxException Constructor to be called by subclasses. Parameters:uri - for this file system.supportedScheme - the scheme supported by the implementorauthorityNeeded - if true then theURI must have authority, if false           then the URI must have null authority. Throws: URISyntaxException - uri has syntax error Method Detail getStatistics public org.apache.hadoop.fs.FileSystem.Statistics getStatistics() isValidName public boolean isValidName(String src) Returns true if the specified string is considered valid in the path part  of a URI by this file system.  The default implementation enforces the rules  of HDFS, but subclasses may override this method to implement specific  validation rules for specific file systems. Parameters:src - String source filename to check, path part of the URI Returns:boolean true if the specified string is considered valid createFileSystem public static AbstractFileSystem createFileSystem(URI uri,                                   Configuration conf)                                            throws UnsupportedFileSystemException Create a file system instance for the specified uri using the conf. The  conf is used to find the class name that implements the file system. The  conf is also passed to the file system for its configuration. Parameters:uri - URI of the file systemconf - Configuration for the file system Returns:Returns the file system for the given URI Throws: UnsupportedFileSystemException - file system for uri is            not found getStatistics protected static org.apache.hadoop.fs.FileSystem.Statistics getStatistics(URI uri) Get the statistics for a particular file system. Parameters:uri - used as key to lookup STATISTICS_TABLE. Only scheme and authority           part of the uri are used. Returns:a statistics object clearStatistics public static void clearStatistics() printStatistics public static void printStatistics() Prints statistics for all file systems. getAllStatistics protected static Map<URI,org.apache.hadoop.fs.FileSystem.Statistics> getAllStatistics() get public static AbstractFileSystem get(URI uri,                      Configuration conf)                               throws UnsupportedFileSystemException The main factory method for creating a file system. Get a file system for  the URI's scheme and authority. The scheme of the uri  determines a configuration property name,  fs.AbstractFileSystem.scheme.impl whose value names the  AbstractFileSystem class.    The entire URI and conf is passed to the AbstractFileSystem factory method. Parameters:uri - for the file system to be created.conf - which is passed to the file system impl. Returns:file system for the given URI. Throws: UnsupportedFileSystemException - if the file system for            uri is not supported. checkScheme public void checkScheme(URI uri,                String supportedScheme) Check that the Uri's scheme matches Parameters:uri - supportedScheme -  getUriDefaultPort public abstract int getUriDefaultPort() The default port of this file system. Returns:default port of this file system's Uri scheme          A uri with a port of -1 => default port; getUri public URI getUri() Returns a URI whose scheme and authority identify this FileSystem. Returns:the uri of this file system. checkPath public void checkPath(Path path) Check that a Path belongs to this FileSystem.    If the path is fully qualified URI, then its scheme and authority  matches that of this file system. Otherwise the path must be   slash-relative name. Throws: InvalidPathException - if the path is invalid getUriPath public String getUriPath(Path p) Get the path-part of a pathname. Checks that URI matches this file system  and that the path-part is a valid name. Parameters:p - path Returns:path-part of the Path p makeQualified public Path makeQualified(Path path) Make the path fully qualified to this file system Parameters:path -  Returns:the qualified path getInitialWorkingDirectory public Path getInitialWorkingDirectory() Some file systems like LocalFileSystem have an initial workingDir  that is used as the starting workingDir. For other file systems  like HDFS there is no built in notion of an initial workingDir. Returns:the initial workingDir if the file system has such a notion          otherwise return a null. getHomeDirectory public Path getHomeDirectory() Return the current user's home directory in this file system.  The default implementation returns "/user/$USER/". Returns:current user's home directory. getServerDefaults public abstract FsServerDefaults getServerDefaults()                                             throws IOException Return a set of server default configuration values. Returns:server default configuration values Throws: IOException - an I/O error occurred resolvePath public Path resolvePath(Path p)                  throws FileNotFoundException,                         org.apache.hadoop.fs.UnresolvedLinkException,                         org.apache.hadoop.security.AccessControlException,                         IOException Return the fully-qualified path of path f resolving the path  through any internal symlinks or mount point Parameters:p - path to be resolved Returns:fully qualified path Throws: FileNotFoundException, - AccessControlException, IOException          UnresolvedLinkException if symbolic link on path cannot be resolved           internally FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException org.apache.hadoop.security.AccessControlException IOException create public final FSDataOutputStream create(Path f,                         EnumSet<CreateFlag> createFlag,                         org.apache.hadoop.fs.Options.CreateOpts... opts)                                 throws org.apache.hadoop.security.AccessControlException,                                        FileAlreadyExistsException,                                        FileNotFoundException,                                        ParentNotDirectoryException,                                        UnsupportedFileSystemException,                                        org.apache.hadoop.fs.UnresolvedLinkException,                                        IOException The specification of this method matches that of  FileContext.create(Path, EnumSet, Options.CreateOpts...) except  that the Path f must be fully qualified and the permission is absolute  (i.e. umask has been applied). Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException ParentNotDirectoryException UnsupportedFileSystemException org.apache.hadoop.fs.UnresolvedLinkException IOException createInternal public abstract FSDataOutputStream createInternal(Path f,                                 EnumSet<CreateFlag> flag,                                 FsPermission absolutePermission,                                 int bufferSize,                                 short replication,                                 long blockSize,                                 Progressable progress,                                 org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt,                                 boolean createParent)                                            throws org.apache.hadoop.security.AccessControlException,                                                   FileAlreadyExistsException,                                                   FileNotFoundException,                                                   ParentNotDirectoryException,                                                   UnsupportedFileSystemException,                                                   org.apache.hadoop.fs.UnresolvedLinkException,                                                   IOException The specification of this method matches that of  create(Path, EnumSet, Options.CreateOpts...) except that the opts  have been declared explicitly. Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException ParentNotDirectoryException UnsupportedFileSystemException org.apache.hadoop.fs.UnresolvedLinkException IOException mkdir public abstract void mkdir(Path dir,          FsPermission permission,          boolean createParent)                     throws org.apache.hadoop.security.AccessControlException,                            FileAlreadyExistsException,                            FileNotFoundException,                            org.apache.hadoop.fs.UnresolvedLinkException,                            IOException The specification of this method matches that of  FileContext.mkdir(Path, FsPermission, boolean) except that the Path  f must be fully qualified and the permission is absolute (i.e.   umask has been applied). Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException delete public abstract boolean delete(Path f,              boolean recursive)                         throws org.apache.hadoop.security.AccessControlException,                                FileNotFoundException,                                org.apache.hadoop.fs.UnresolvedLinkException,                                IOException The specification of this method matches that of  FileContext.delete(Path, boolean) except that Path f must be for  this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException open public FSDataInputStream open(Path f)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               org.apache.hadoop.fs.UnresolvedLinkException,                               IOException The specification of this method matches that of  FileContext.open(Path) except that Path f must be for this  file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException open public abstract FSDataInputStream open(Path f,                      int bufferSize)                                 throws org.apache.hadoop.security.AccessControlException,                                        FileNotFoundException,                                        org.apache.hadoop.fs.UnresolvedLinkException,                                        IOException The specification of this method matches that of  FileContext.open(Path, int) except that Path f must be for this  file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException truncate public boolean truncate(Path f,                long newLength)                  throws org.apache.hadoop.security.AccessControlException,                         FileNotFoundException,                         org.apache.hadoop.fs.UnresolvedLinkException,                         IOException The specification of this method matches that of  FileContext.truncate(Path, long) except that Path f must be for  this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException setReplication public abstract boolean setReplication(Path f,                      short replication)                                 throws org.apache.hadoop.security.AccessControlException,                                        FileNotFoundException,                                        org.apache.hadoop.fs.UnresolvedLinkException,                                        IOException The specification of this method matches that of  FileContext.setReplication(Path, short) except that Path f must be  for this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException rename public final void rename(Path src,           Path dst,           org.apache.hadoop.fs.Options.Rename... options)                   throws org.apache.hadoop.security.AccessControlException,                          FileAlreadyExistsException,                          FileNotFoundException,                          ParentNotDirectoryException,                          org.apache.hadoop.fs.UnresolvedLinkException,                          IOException The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system. Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException ParentNotDirectoryException org.apache.hadoop.fs.UnresolvedLinkException IOException renameInternal public abstract void renameInternal(Path src,                   Path dst)                              throws org.apache.hadoop.security.AccessControlException,                                     FileAlreadyExistsException,                                     FileNotFoundException,                                     ParentNotDirectoryException,                                     org.apache.hadoop.fs.UnresolvedLinkException,                                     IOException The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system and NO OVERWRITE is performed.    File systems that do not have a built in overwrite need implement only this  method and can take advantage of the default impl of the other  renameInternal(Path, Path, boolean) Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException ParentNotDirectoryException org.apache.hadoop.fs.UnresolvedLinkException IOException renameInternal public void renameInternal(Path src,                   Path dst,                   boolean overwrite)                     throws org.apache.hadoop.security.AccessControlException,                            FileAlreadyExistsException,                            FileNotFoundException,                            ParentNotDirectoryException,                            org.apache.hadoop.fs.UnresolvedLinkException,                            IOException The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system. Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException ParentNotDirectoryException org.apache.hadoop.fs.UnresolvedLinkException IOException supportsSymlinks public boolean supportsSymlinks() Returns true if the file system supports symlinks, false otherwise. Returns:true if filesystem supports symlinks createSymlink public void createSymlink(Path target,                  Path link,                  boolean createParent)                    throws IOException,                           org.apache.hadoop.fs.UnresolvedLinkException The specification of this method matches that of    FileContext.createSymlink(Path, Path, boolean); Throws: IOException org.apache.hadoop.fs.UnresolvedLinkException getLinkTarget public Path getLinkTarget(Path f)                    throws IOException Partially resolves the path. This is used during symlink resolution in  FSLinkResolver, and differs from the similarly named method  FileContext.getLinkTarget(Path). Throws: IOException - subclass implementations may throw IOException setPermission public abstract void setPermission(Path f,                  FsPermission permission)                             throws org.apache.hadoop.security.AccessControlException,                                    FileNotFoundException,                                    org.apache.hadoop.fs.UnresolvedLinkException,                                    IOException The specification of this method matches that of  FileContext.setPermission(Path, FsPermission) except that Path f  must be for this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException setOwner public abstract void setOwner(Path f,             String username,             String groupname)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               org.apache.hadoop.fs.UnresolvedLinkException,                               IOException The specification of this method matches that of  FileContext.setOwner(Path, String, String) except that Path f must  be for this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException setTimes public abstract void setTimes(Path f,             long mtime,             long atime)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               org.apache.hadoop.fs.UnresolvedLinkException,                               IOException The specification of this method matches that of  FileContext.setTimes(Path, long, long) except that Path f must be  for this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException getFileChecksum public abstract FileChecksum getFileChecksum(Path f)                                       throws org.apache.hadoop.security.AccessControlException,                                              FileNotFoundException,                                              org.apache.hadoop.fs.UnresolvedLinkException,                                              IOException The specification of this method matches that of  FileContext.getFileChecksum(Path) except that Path f must be for  this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException getFileStatus public abstract FileStatus getFileStatus(Path f)                                   throws org.apache.hadoop.security.AccessControlException,                                          FileNotFoundException,                                          org.apache.hadoop.fs.UnresolvedLinkException,                                          IOException The specification of this method matches that of  FileContext.getFileStatus(Path)   except that an UnresolvedLinkException may be thrown if a symlink is   encountered in the path. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException getFileLinkStatus public FileStatus getFileLinkStatus(Path f)                              throws org.apache.hadoop.security.AccessControlException,                                     FileNotFoundException,                                     UnsupportedFileSystemException,                                     IOException The specification of this method matches that of  FileContext.getFileLinkStatus(Path)  except that an UnresolvedLinkException may be thrown if a symlink is    encountered in the path leading up to the final path component.  If the file system does not support symlinks then the behavior is  equivalent to getFileStatus(Path). Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException UnsupportedFileSystemException IOException getFileBlockLocations public abstract BlockLocation[] getFileBlockLocations(Path f,                                     long start,                                     long len)                                                throws org.apache.hadoop.security.AccessControlException,                                                       FileNotFoundException,                                                       org.apache.hadoop.fs.UnresolvedLinkException,                                                       IOException The specification of this method matches that of  FileContext.getFileBlockLocations(Path, long, long) except that  Path f must be for this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException getFsStatus public FsStatus getFsStatus(Path f)                      throws org.apache.hadoop.security.AccessControlException,                             FileNotFoundException,                             org.apache.hadoop.fs.UnresolvedLinkException,                             IOException The specification of this method matches that of  FileContext.getFsStatus(Path) except that Path f must be for this  file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException getFsStatus public abstract FsStatus getFsStatus()                               throws org.apache.hadoop.security.AccessControlException,                                      FileNotFoundException,                                      IOException The specification of this method matches that of  FileContext.getFsStatus(Path). Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException IOException listStatusIterator public org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatusIterator(Path f)                                                                    throws org.apache.hadoop.security.AccessControlException,                                                                           FileNotFoundException,                                                                           org.apache.hadoop.fs.UnresolvedLinkException,                                                                           IOException The specification of this method matches that of  FileContext.listStatus(Path) except that Path f must be for this  file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException listLocatedStatus public org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f)                                                                          throws org.apache.hadoop.security.AccessControlException,                                                                                 FileNotFoundException,                                                                                 org.apache.hadoop.fs.UnresolvedLinkException,                                                                                 IOException The specification of this method matches that of  FileContext.listLocatedStatus(Path) except that Path f   must be for this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException listStatus public abstract FileStatus[] listStatus(Path f)                                  throws org.apache.hadoop.security.AccessControlException,                                         FileNotFoundException,                                         org.apache.hadoop.fs.UnresolvedLinkException,                                         IOException The specification of this method matches that of  FileContext.Util.listStatus(Path) except that Path f must be   for this file system. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException listCorruptFileBlocks public org.apache.hadoop.fs.RemoteIterator<Path> listCorruptFileBlocks(Path path)                                                                 throws IOException Returns:an iterator over the corrupt files under the given path  (may contain duplicates if a file has more than one corrupt block) Throws: IOException setVerifyChecksum public abstract void setVerifyChecksum(boolean verifyChecksum)                                 throws org.apache.hadoop.security.AccessControlException,                                        IOException The specification of this method matches that of  FileContext.setVerifyChecksum(boolean, Path) except that Path f  must be for this file system. Throws: org.apache.hadoop.security.AccessControlException IOException getCanonicalServiceName public String getCanonicalServiceName() Get a canonical name for this file system. Returns:a URI string that uniquely identifies this file system modifyAclEntries public void modifyAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Modifies ACL entries of files and directories.  This method can add new ACL  entries or modify the permissions on existing ACL entries.  All existing  ACL entries that are not specified in this call are retained without  changes.  (Modifications are merged into the current ACL.) Parameters:path - Path to modifyaclSpec - List describing modifications Throws: IOException - if an ACL could not be modified removeAclEntries public void removeAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Removes ACL entries from files and directories.  Other ACL entries are  retained. Parameters:path - Path to modifyaclSpec - List describing entries to remove Throws: IOException - if an ACL could not be modified removeDefaultAcl public void removeDefaultAcl(Path path)                       throws IOException Removes all default ACL entries from files and directories. Parameters:path - Path to modify Throws: IOException - if an ACL could not be modified removeAcl public void removeAcl(Path path)                throws IOException Removes all but the base ACL entries of files and directories.  The entries  for user, group, and others are retained for compatibility with permission  bits. Parameters:path - Path to modify Throws: IOException - if an ACL could not be removed setAcl public void setAcl(Path path,           List<AclEntry> aclSpec)             throws IOException Fully replaces ACL of files and directories, discarding all existing  entries. Parameters:path - Path to modifyaclSpec - List describing modifications, must include entries    for user, group, and others for compatibility with permission bits. Throws: IOException - if an ACL could not be modified getAclStatus public AclStatus getAclStatus(Path path)                        throws IOException Gets the ACLs of files and directories. Parameters:path - Path to get Returns:RemoteIterator which returns each AclStatus Throws: IOException - if an ACL could not be read setXAttr public void setXAttr(Path path,             String name,             byte[] value)               throws IOException Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to modifyname - xattr name.value - xattr value. Throws: IOException setXAttr public void setXAttr(Path path,             String name,             byte[] value,             EnumSet<XAttrSetFlag> flag)               throws IOException Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to modifyname - xattr name.value - xattr value.flag - xattr set flag Throws: IOException getXAttr public byte[] getXAttr(Path path,               String name)                 throws IOException Get an xattr for a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributename - xattr name. Returns:byte[] xattr value. Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path)                              throws IOException Get all of the xattrs for a file or directory.  Only those xattrs for which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributes Returns:Map describing the XAttrs of the file or directory Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path,                            List<String> names)                              throws IOException Get all of the xattrs for a file or directory.  Only those xattrs for which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributesnames - XAttr names. Returns:Map describing the XAttrs of the file or directory Throws: IOException listXAttrs public List<String> listXAttrs(Path path)                         throws IOException Get all of the xattr names for a file or directory.  Only the xattr names for which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributes Returns:Map describing the XAttrs of the file or directory Throws: IOException removeXAttr public void removeXAttr(Path path,                String name)                  throws IOException Remove an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to remove extended attributename - xattr name Throws: IOException hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object other) Overrides: equals in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AbstractLivelinessMonitor (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AbstractLivelinessMonitor (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.util Class AbstractLivelinessMonitor<O> java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.util.AbstractLivelinessMonitor<O> All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class AbstractLivelinessMonitor<O> extends AbstractService A simple liveliness monitor with which clients can register, trust the  component to monitor liveliness, get a call-back on expiry and then finally  unregister. Field Summary Fields  Modifier and Type Field and Description static int DEFAULT_EXPIRE  Constructor Summary Constructors  Constructor and Description AbstractLivelinessMonitor(String name,                                                   Clock clock)  Method Summary Methods  Modifier and Type Method and Description protected abstract void expire(O ob)  void receivedPing(O ob)  void register(O ob)  void resetTimer()  protected void serviceStart() Actions called during the INITED to STARTED transition. protected void serviceStop() Actions called during the transition to the STOPPED state. protected void setExpireInterval(int expireInterval)  protected void setMonitorInterval(int monitorInterval)  void unregister(O ob)  Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceInit, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail DEFAULT_EXPIRE public static final int DEFAULT_EXPIRE See Also:Constant Field Values Constructor Detail AbstractLivelinessMonitor public AbstractLivelinessMonitor(String name,                          Clock clock) Method Detail serviceStart protected void serviceStart()                      throws Exception Description copied from class: AbstractService Actions called during the INITED to STARTED transition.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.start() prevents re-entrancy. Overrides: serviceStart in class AbstractService Throws: Exception - if needed -these will be caught,  wrapped, and trigger a service stop serviceStop protected void serviceStop()                     throws Exception Description copied from class: AbstractService Actions called during the transition to the STOPPED state.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.stop() prevents re-entrancy.  Implementations MUST write this to be robust against failures, including  checks for null references -and for the first failure to not stop other  attempts to shut down parts of the service. Overrides: serviceStop in class AbstractService Throws: Exception - if needed -these will be caught and logged. expire protected abstract void expire(O ob) setExpireInterval protected void setExpireInterval(int expireInterval) setMonitorInterval protected void setMonitorInterval(int monitorInterval) receivedPing public void receivedPing(O ob) register public void register(O ob) unregister public void unregister(O ob) resetTimer public void resetTimer() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AbstractMapWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AbstractMapWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class AbstractMapWritable java.lang.Object org.apache.hadoop.io.AbstractMapWritable All Implemented Interfaces: Configurable, Writable Direct Known Subclasses: MapWritable, SortedMapWritable @InterfaceAudience.Public @InterfaceStability.Stable public abstract class AbstractMapWritable extends Object implements Writable, Configurable Abstract base class for MapWritable and SortedMapWritable    Unlike org.apache.nutch.crawl.MapWritable, this class allows creation of  MapWritable<Writable, MapWritable> so the CLASS_TO_ID and ID_TO_CLASS  maps travel with the class instead of being static.    Class ids range from 1 to 127 so there can be at most 127 distinct classes  in any specific map instance. Constructor Summary Constructors  Modifier Constructor and Description protected  AbstractMapWritable() constructor. Method Summary Methods  Modifier and Type Method and Description protected void addToMap(Class<?> clazz) Add a Class to the maps if it is not already present. protected void copy(Writable other) Used by child copy constructors. protected Class<?> getClass(byte id)  Configuration getConf() Return the configuration used by this object. protected byte getId(Class<?> clazz)  void readFields(DataInput in) Deserialize the fields of this object from in. void setConf(Configuration conf) Set the configuration to be used by this object. void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AbstractMapWritable protected AbstractMapWritable() constructor. Method Detail addToMap protected void addToMap(Class<?> clazz) Add a Class to the maps if it is not already present. getClass protected Class<?> getClass(byte id) Returns:the Class class for the specified id getId protected byte getId(Class<?> clazz) Returns:the id for the specified Class copy protected void copy(Writable other) Used by child copy constructors. getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable Returns:the conf setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable Parameters:conf - the conf to set write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AbstractMetric (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AbstractMetric (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Class AbstractMetric java.lang.Object org.apache.hadoop.metrics2.AbstractMetric All Implemented Interfaces: MetricsInfo @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class AbstractMetric extends Object implements MetricsInfo The immutable metric Constructor Summary Constructors  Modifier Constructor and Description protected  AbstractMetric(MetricsInfo info) Construct the metric Method Summary Methods  Modifier and Type Method and Description String description()  boolean equals(Object obj)  int hashCode()  protected MetricsInfo info()  String name()  String toString()  abstract org.apache.hadoop.metrics2.MetricType type() Get the type of the metric abstract Number value() Get the value of the metric abstract void visit(MetricsVisitor visitor) Accept a visitor interface Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail AbstractMetric protected AbstractMetric(MetricsInfo info) Construct the metric Parameters:info - about the metric Method Detail name public String name() Specified by: name in interface MetricsInfo Returns:the name of the metric/tag description public String description() Specified by: description in interface MetricsInfo Returns:the description of the metric/tag info protected MetricsInfo info() value public abstract Number value() Get the value of the metric Returns:the value of the metric type public abstract org.apache.hadoop.metrics2.MetricType type() Get the type of the metric Returns:the type of the metric visit public abstract void visit(MetricsVisitor visitor) Accept a visitor interface Parameters:visitor - of the metric equals public boolean equals(Object obj) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AbstractMetricsContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AbstractMetricsContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.spi Class AbstractMetricsContext java.lang.Object org.apache.hadoop.metrics.spi.AbstractMetricsContext All Implemented Interfaces: org.apache.hadoop.metrics.MetricsContext Direct Known Subclasses: CompositeContext, GangliaContext, NoEmitMetricsContext, NullContext, NullContextWithUpdateThread @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class AbstractMetricsContext extends Object implements org.apache.hadoop.metrics.MetricsContext The main class of the Service Provider Interface.  This class should be  extended in order to integrate the Metrics API with a specific metrics  client library.   This class implements the internal table of metric data, and the timer  on which data is to be sent to the metrics system.  Subclasses must  override the abstract emitRecord method in order to transmit  the data.  Field Summary Fields inherited from interface org.apache.hadoop.metrics.MetricsContext DEFAULT_PERIOD Constructor Summary Constructors  Modifier Constructor and Description protected  AbstractMetricsContext() Creates a new instance of AbstractMetricsContext Method Summary Methods  Modifier and Type Method and Description void close() Stops monitoring and frees buffered data, returning this  object to its initial state. org.apache.hadoop.metrics.MetricsRecord createRecord(String recordName) Creates a new AbstractMetricsRecord instance with the given recordName. protected abstract void emitRecord(String contextName,                     String recordName,                     OutputRecord outRec) Sends a record to the metrics system. protected void flush() Called each period after all records have been emitted, this method does nothing. Map<String,Collection<OutputRecord>> getAllRecords() Retrieves all the records managed by this MetricsContext. protected String getAttribute(String attributeName) Convenience method for subclasses to access factory attributes. protected Map<String,String> getAttributeTable(String tableName) Returns an attribute-value map derived from the factory attributes  by finding all factory attributes that begin with   contextName.tableName. org.apache.hadoop.metrics.ContextFactory getContextFactory() Returns the factory by which this context was created. String getContextName() Returns the context name. int getPeriod() Returns the timer period. void init(String contextName,         org.apache.hadoop.metrics.ContextFactory factory) Initializes the context. boolean isMonitoring() Returns true if monitoring is currently in progress. protected org.apache.hadoop.metrics.MetricsRecord newRecord(String recordName) Subclasses should override this if they subclass MetricsRecordImpl. protected void parseAndSetPeriod(String attributeName) If a period is set in the attribute passed in, override  the default with it. void registerUpdater(org.apache.hadoop.metrics.Updater updater) Registers a callback to be called at time intervals determined by  the configuration. protected void remove(MetricsRecordImpl record) Called by MetricsRecordImpl.remove(). protected void setPeriod(int period) Sets the timer period void startMonitoring() Starts or restarts monitoring, the emitting of metrics records. void stopMonitoring() Stops monitoring. void unregisterUpdater(org.apache.hadoop.metrics.Updater updater) Removes a callback, if it exists. protected void update(MetricsRecordImpl record) Called by MetricsRecordImpl.update(). Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AbstractMetricsContext protected AbstractMetricsContext() Creates a new instance of AbstractMetricsContext Method Detail init public void init(String contextName,         org.apache.hadoop.metrics.ContextFactory factory) Initializes the context. Specified by: init in interface org.apache.hadoop.metrics.MetricsContext Parameters:contextName - The given name for this contextfactory - The creator of this context getAttribute protected String getAttribute(String attributeName) Convenience method for subclasses to access factory attributes. getAttributeTable protected Map<String,String> getAttributeTable(String tableName) Returns an attribute-value map derived from the factory attributes  by finding all factory attributes that begin with   contextName.tableName.  The returned map consists of  those attributes with the contextName and tableName stripped off. getContextName public String getContextName() Returns the context name. Specified by: getContextName in interface org.apache.hadoop.metrics.MetricsContext Returns:the context name getContextFactory public org.apache.hadoop.metrics.ContextFactory getContextFactory() Returns the factory by which this context was created. startMonitoring public void startMonitoring()                      throws IOException Starts or restarts monitoring, the emitting of metrics records. Specified by: startMonitoring in interface org.apache.hadoop.metrics.MetricsContext Throws: IOException stopMonitoring public void stopMonitoring() Stops monitoring.  This does not free buffered data. Specified by: stopMonitoring in interface org.apache.hadoop.metrics.MetricsContext See Also:close() isMonitoring public boolean isMonitoring() Returns true if monitoring is currently in progress. Specified by: isMonitoring in interface org.apache.hadoop.metrics.MetricsContext close public void close() Stops monitoring and frees buffered data, returning this  object to its initial state. Specified by: close in interface org.apache.hadoop.metrics.MetricsContext createRecord public final org.apache.hadoop.metrics.MetricsRecord createRecord(String recordName) Creates a new AbstractMetricsRecord instance with the given recordName.  Throws an exception if the metrics implementation is configured with a fixed  set of record names and recordName is not in that set. Specified by: createRecord in interface org.apache.hadoop.metrics.MetricsContext Parameters:recordName - the name of the record Throws: org.apache.hadoop.metrics.MetricsException - if recordName conflicts with configuration data newRecord protected org.apache.hadoop.metrics.MetricsRecord newRecord(String recordName) Subclasses should override this if they subclass MetricsRecordImpl. Parameters:recordName - the name of the record Returns:newly created instance of MetricsRecordImpl or subclass registerUpdater public void registerUpdater(org.apache.hadoop.metrics.Updater updater) Registers a callback to be called at time intervals determined by  the configuration. Specified by: registerUpdater in interface org.apache.hadoop.metrics.MetricsContext Parameters:updater - object to be run periodically; it should update  some metrics records unregisterUpdater public void unregisterUpdater(org.apache.hadoop.metrics.Updater updater) Removes a callback, if it exists. Specified by: unregisterUpdater in interface org.apache.hadoop.metrics.MetricsContext Parameters:updater - object to be removed from the callback list getAllRecords public Map<String,Collection<OutputRecord>> getAllRecords() Retrieves all the records managed by this MetricsContext.  Useful for monitoring systems that are polling-based. Specified by: getAllRecords in interface org.apache.hadoop.metrics.MetricsContext Returns:A non-null collection of all monitoring records. emitRecord protected abstract void emitRecord(String contextName,               String recordName,               OutputRecord outRec)                             throws IOException Sends a record to the metrics system. Throws: IOException flush protected void flush()               throws IOException Called each period after all records have been emitted, this method does nothing.  Subclasses may override it in order to perform some kind of flush. Throws: IOException update protected void update(MetricsRecordImpl record) Called by MetricsRecordImpl.update().  Creates or updates a row in  the internal table of metric data. remove protected void remove(MetricsRecordImpl record) Called by MetricsRecordImpl.remove().  Removes all matching rows in  the internal table of metric data.  A row matches if it has the same  tag names and values as record, but it may also have additional  tags. getPeriod public int getPeriod() Returns the timer period. Specified by: getPeriod in interface org.apache.hadoop.metrics.MetricsContext setPeriod protected void setPeriod(int period) Sets the timer period parseAndSetPeriod protected void parseAndSetPeriod(String attributeName) If a period is set in the attribute passed in, override  the default with it. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AbstractService (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AbstractService (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.service Class AbstractService java.lang.Object org.apache.hadoop.service.AbstractService All Implemented Interfaces: Closeable, AutoCloseable, Service Direct Known Subclasses: AbstractLivelinessMonitor, AHSClient, AMRMClient, AMRMClientAsync, AsyncDispatcher, CompositeService, HistoryFileManager, NMClient, NMClientAsync, SharedCacheClient, TimelineClient, YarnClient @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class AbstractService extends Object implements Service This is the base implementation class for services. Constructor Summary Constructors  Constructor and Description AbstractService(String name) Construct the service. Method Summary Methods  Modifier and Type Method and Description void close() Relay to stop() Map<String,String> getBlockers() Get the blockers on a service -remote dependencies  that are stopping the service from being live. Configuration getConfig() Get the configuration of this service. Throwable getFailureCause() Get the first exception raised during the service failure. org.apache.hadoop.service.Service.STATE getFailureState() Get the state in which the failure in Service.getFailureCause() occurred. List<LifecycleEvent> getLifecycleHistory() Get a snapshot of the lifecycle history; it is a static list String getName() Get the name of this service. org.apache.hadoop.service.Service.STATE getServiceState() Get the current service state long getStartTime() Get the service start time void init(Configuration conf) Initialize the service. boolean isInState(org.apache.hadoop.service.Service.STATE expected) Query to see if the service is in a specific state. protected void noteFailure(Exception exception) Failure handling: record the exception  that triggered it -if there was not one already. protected void putBlocker(String name,                     String details) Put a blocker to the blocker map -replacing any  with the same name. static void registerGlobalListener(ServiceStateChangeListener l) Register a global listener, which receives notifications  from the state change events of all services in the JVM void registerServiceListener(ServiceStateChangeListener l) Register a listener to the service state change events. void removeBlocker(String name) Remove a blocker from the blocker map -  this is a no-op if the blocker is not present protected void serviceInit(Configuration conf) All initialization code needed by a service. protected void serviceStart() Actions called during the INITED to STARTED transition. protected void serviceStop() Actions called during the transition to the STOPPED state. protected void setConfig(Configuration conf) Set the configuration for this service. void start() Start the service. void stop() Stop the service. String toString()  static boolean unregisterGlobalListener(ServiceStateChangeListener l) unregister a global listener. void unregisterServiceListener(ServiceStateChangeListener l) Unregister a previously registered listener of the service state  change events. boolean waitForServiceToStop(long timeout) Block waiting for the service to stop; uses the termination notification  object to do so. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail AbstractService public AbstractService(String name) Construct the service. Parameters:name - service name Method Detail getServiceState public final org.apache.hadoop.service.Service.STATE getServiceState() Description copied from interface: Service Get the current service state Specified by: getServiceState in interface Service Returns:the state of the service getFailureCause public final Throwable getFailureCause() Description copied from interface: Service Get the first exception raised during the service failure. If null,  no exception was logged Specified by: getFailureCause in interface Service Returns:the failure logged during a transition to the stopped state getFailureState public org.apache.hadoop.service.Service.STATE getFailureState() Description copied from interface: Service Get the state in which the failure in Service.getFailureCause() occurred. Specified by: getFailureState in interface Service Returns:the state or null if there was no failure setConfig protected void setConfig(Configuration conf) Set the configuration for this service.  This method is called during init(Configuration)  and should only be needed if for some reason a service implementation  needs to override that initial setting -for example replacing  it with a new subclass of Configuration Parameters:conf - new configuration. init public void init(Configuration conf) Initialize the service.  The transition MUST be from Service.STATE.NOTINITED to Service.STATE.INITED  unless the operation failed and an exception was raised, in which case  Service.stop() MUST be invoked and the service enter the state  Service.STATE.STOPPED.  This invokes serviceInit(org.apache.hadoop.conf.Configuration) Specified by: init in interface Service Parameters:conf - the configuration of the service. This must not be null Throws: ServiceStateException - if the configuration was null,  the state change not permitted, or something else went wrong start public void start() Start the service.  The transition MUST be from Service.STATE.INITED to Service.STATE.STARTED  unless the operation failed and an exception was raised, in which case  Service.stop() MUST be invoked and the service enter the state  Service.STATE.STOPPED. Specified by: start in interface Service Throws: ServiceStateException - if the current service state does not permit  this action stop public void stop() Stop the service. This MUST be a no-op if the service is already  in the Service.STATE.STOPPED state. It SHOULD be a best-effort attempt  to stop all parts of the service.  The implementation must be designed to complete regardless of the service  state, including the initialized/uninitialized state of all its internal  fields. Specified by: stop in interface Service close public final void close()                  throws IOException Relay to stop() Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in interface Service Throws: IOException noteFailure protected final void noteFailure(Exception exception) Failure handling: record the exception  that triggered it -if there was not one already.  Services are free to call this themselves. Parameters:exception - the exception waitForServiceToStop public final boolean waitForServiceToStop(long timeout) Description copied from interface: Service Block waiting for the service to stop; uses the termination notification  object to do so.  This method will only return after all the service stop actions  have been executed (to success or failure), or the timeout elapsed  This method can be called before the service is inited or started; this is  to eliminate any race condition with the service stopping before  this event occurs. Specified by: waitForServiceToStop in interface Service Parameters:timeout - timeout in milliseconds. A value of zero means "forever" Returns:true iff the service stopped in the time period serviceInit protected void serviceInit(Configuration conf)                     throws Exception All initialization code needed by a service.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in init(Configuration) prevents re-entrancy.  The base implementation checks to see if the subclass has created  a new configuration instance, and if so, updates the base class value Parameters:conf - configuration Throws: Exception - on a failure -these will be caught,  possibly wrapped, and wil; trigger a service stop serviceStart protected void serviceStart()                      throws Exception Actions called during the INITED to STARTED transition.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in start() prevents re-entrancy. Throws: Exception - if needed -these will be caught,  wrapped, and trigger a service stop serviceStop protected void serviceStop()                     throws Exception Actions called during the transition to the STOPPED state.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in stop() prevents re-entrancy.  Implementations MUST write this to be robust against failures, including  checks for null references -and for the first failure to not stop other  attempts to shut down parts of the service. Throws: Exception - if needed -these will be caught and logged. registerServiceListener public void registerServiceListener(ServiceStateChangeListener l) Description copied from interface: Service Register a listener to the service state change events.  If the supplied listener is already listening to this service,  this method is a no-op. Specified by: registerServiceListener in interface Service Parameters:l - a new listener unregisterServiceListener public void unregisterServiceListener(ServiceStateChangeListener l) Description copied from interface: Service Unregister a previously registered listener of the service state  change events. No-op if the listener is already unregistered. Specified by: unregisterServiceListener in interface Service Parameters:l - the listener to unregister. registerGlobalListener public static void registerGlobalListener(ServiceStateChangeListener l) Register a global listener, which receives notifications  from the state change events of all services in the JVM Parameters:l - listener unregisterGlobalListener public static boolean unregisterGlobalListener(ServiceStateChangeListener l) unregister a global listener. Parameters:l - listener to unregister Returns:true if the listener was found (and then deleted) getName public String getName() Description copied from interface: Service Get the name of this service. Specified by: getName in interface Service Returns:the service name getConfig public Configuration getConfig() Description copied from interface: Service Get the configuration of this service.  This is normally not a clone and may be manipulated, though there are no  guarantees as to what the consequences of such actions may be Specified by: getConfig in interface Service Returns:the current configuration, unless a specific implentation chooses  otherwise. getStartTime public long getStartTime() Description copied from interface: Service Get the service start time Specified by: getStartTime in interface Service Returns:the start time of the service. This will be zero if the service  has not yet been started. getLifecycleHistory public List<LifecycleEvent> getLifecycleHistory() Description copied from interface: Service Get a snapshot of the lifecycle history; it is a static list Specified by: getLifecycleHistory in interface Service Returns:a possibly empty but never null list of lifecycle events. isInState public final boolean isInState(org.apache.hadoop.service.Service.STATE expected) Description copied from interface: Service Query to see if the service is in a specific state.  In a multi-threaded system, the state may not hold for very long. Specified by: isInState in interface Service Parameters:expected - the expected state Returns:true if, at the time of invocation, the service was in that state. toString public String toString() Overrides: toString in class Object putBlocker protected void putBlocker(String name,               String details) Put a blocker to the blocker map -replacing any  with the same name. Parameters:name - blocker namedetails - any specifics on the block. This must be non-null. removeBlocker public void removeBlocker(String name) Remove a blocker from the blocker map -  this is a no-op if the blocker is not present Parameters:name - the name of the blocker getBlockers public Map<String,String> getBlockers() Description copied from interface: Service Get the blockers on a service -remote dependencies  that are stopping the service from being live. Specified by: getBlockers in interface Service Returns:a (snapshotted) map of blocker name->description values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AccessControlException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AccessControlException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.permission Class AccessControlException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.permission.AccessControlException All Implemented Interfaces: Serializable Deprecated.  Use AccessControlException               instead. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class AccessControlException extends IOException An exception class for access control related issues. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description AccessControlException() Deprecated.  Default constructor is needed for unwrapping from   RemoteException. AccessControlException(String s) Deprecated.  Constructs an AccessControlException  with the specified detail message. AccessControlException(Throwable cause) Deprecated.  Constructs a new exception with the specified cause and a detail  message of (cause==null ? null : cause.toString()) (which  typically contains the class and detail message of cause). Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail AccessControlException public AccessControlException() Deprecated.  Default constructor is needed for unwrapping from   RemoteException. AccessControlException public AccessControlException(String s) Deprecated.  Constructs an AccessControlException  with the specified detail message. Parameters:s - the detail message. AccessControlException public AccessControlException(Throwable cause) Deprecated.  Constructs a new exception with the specified cause and a detail  message of (cause==null ? null : cause.toString()) (which  typically contains the class and detail message of cause). Parameters:cause - the cause (which is saved for later retrieval by the          Throwable.getCause() method).  (A null value is          permitted, and indicates that the cause is nonexistent or          unknown.) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AclEntry (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AclEntry (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.permission Class AclEntry java.lang.Object org.apache.hadoop.fs.permission.AclEntry @InterfaceAudience.Public @InterfaceStability.Evolving public class AclEntry extends Object Defines a single entry in an ACL.  An ACL entry has a type (user, group,  mask, or other), an optional name (referring to a specific user or group), a  set of permissions (any combination of read, write and execute), and a scope  (access or default).  AclEntry instances are immutable.  Use a AclEntry.Builder  to create a new instance. Method Summary Methods  Modifier and Type Method and Description static String aclSpecToString(List<AclEntry> aclSpec) Convert a List of AclEntries into a string - the reverse of parseAclSpec. boolean equals(Object o)  String getName() Returns the optional ACL entry name. FsAction getPermission() Returns the set of permissions in the ACL entry. AclEntryScope getScope() Returns the scope of the ACL entry. AclEntryType getType() Returns the ACL entry type. int hashCode()  static AclEntry parseAclEntry(String aclStr,                           boolean includePermission) Parses a string representation of an ACL into a AclEntry object. static List<AclEntry> parseAclSpec(String aclSpec,                         boolean includePermission) Parses a string representation of an ACL spec into a list of AclEntry  objects. String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Method Detail getType public AclEntryType getType() Returns the ACL entry type. Returns:AclEntryType ACL entry type getName public String getName() Returns the optional ACL entry name. Returns:String ACL entry name, or null if undefined getPermission public FsAction getPermission() Returns the set of permissions in the ACL entry. Returns:FsAction set of permissions in the ACL entry getScope public AclEntryScope getScope() Returns the scope of the ACL entry. Returns:AclEntryScope scope of the ACL entry equals public boolean equals(Object o) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object toString public String toString() Overrides: toString in class Object parseAclSpec public static List<AclEntry> parseAclSpec(String aclSpec,                           boolean includePermission) Parses a string representation of an ACL spec into a list of AclEntry  objects. Example: "user::rwx,user:foo:rw-,group::r--,other::---" Parameters:aclSpec - String representation of an ACL spec.includePermission - for setAcl operations this will be true. i.e. AclSpec should           include permissions.           But for removeAcl operation it will be false. i.e. AclSpec should           not contain permissions.           Example: "user:foo,group:bar" Returns:Returns list of AclEntry parsed parseAclEntry public static AclEntry parseAclEntry(String aclStr,                      boolean includePermission) Parses a string representation of an ACL into a AclEntry object. Parameters:aclStr - String representation of an ACL.           Example: "user:foo:rw-"includePermission - for setAcl operations this will be true. i.e. Acl should include           permissions.           But for removeAcl operation it will be false. i.e. Acl should not           contain permissions.           Example: "user:foo,group:bar,mask::" Returns:Returns an AclEntry object aclSpecToString public static String aclSpecToString(List<AclEntry> aclSpec) Convert a List of AclEntries into a string - the reverse of parseAclSpec. Parameters:aclSpec - List of AclEntries to convert Returns:String representation of aclSpec Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AclEntryScope (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AclEntryScope (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.fs.permission Enum AclEntryScope java.lang.Object java.lang.Enum<AclEntryScope> org.apache.hadoop.fs.permission.AclEntryScope All Implemented Interfaces: Serializable, Comparable<AclEntryScope> @InterfaceAudience.Public @InterfaceStability.Evolving public enum AclEntryScope extends Enum<AclEntryScope> Specifies the scope or intended usage of an ACL entry. Enum Constant Summary Enum Constants  Enum Constant and Description ACCESS An ACL entry that is inspected during permission checks to enforce  permissions. DEFAULT An ACL entry to be applied to a directory's children that do not otherwise  have their own ACL defined. Method Summary Methods  Modifier and Type Method and Description static AclEntryScope valueOf(String name) Returns the enum constant of this type with the specified name. static AclEntryScope[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail ACCESS public static final AclEntryScope ACCESS An ACL entry that is inspected during permission checks to enforce  permissions. DEFAULT public static final AclEntryScope DEFAULT An ACL entry to be applied to a directory's children that do not otherwise  have their own ACL defined.  Unlike an access ACL entry, a default ACL  entry is not inspected as part of permission enforcement on the directory  that owns it. Method Detail values public static AclEntryScope[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (AclEntryScope c : AclEntryScope.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static AclEntryScope valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AclEntryType (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AclEntryType (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.fs.permission Enum AclEntryType java.lang.Object java.lang.Enum<AclEntryType> org.apache.hadoop.fs.permission.AclEntryType All Implemented Interfaces: Serializable, Comparable<AclEntryType> @InterfaceAudience.Public @InterfaceStability.Evolving public enum AclEntryType extends Enum<AclEntryType> Specifies the type of an ACL entry. Enum Constant Summary Enum Constants  Enum Constant and Description GROUP An ACL entry applied to a specific group. MASK An ACL mask entry. OTHER An ACL entry that applies to all other users that were not covered by one  of the more specific ACL entry types. USER An ACL entry applied to a specific user. Method Summary Methods  Modifier and Type Method and Description static AclEntryType valueOf(String name) Returns the enum constant of this type with the specified name. static AclEntryType[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail USER public static final AclEntryType USER An ACL entry applied to a specific user.  These ACL entries can be unnamed,  which applies to the file owner, or named, which applies to the specific  named user. GROUP public static final AclEntryType GROUP An ACL entry applied to a specific group.  These ACL entries can be  unnamed, which applies to the file's group, or named, which applies to the  specific named group. MASK public static final AclEntryType MASK An ACL mask entry.  Mask entries are unnamed.  During permission checks,  the mask entry interacts with all ACL entries that are members of the group  class.  This consists of all named user entries, the unnamed group entry,  and all named group entries.  For each such entry, any permissions that are  absent from the mask entry are removed from the effective permissions used  during the permission check. OTHER public static final AclEntryType OTHER An ACL entry that applies to all other users that were not covered by one  of the more specific ACL entry types. Method Detail values public static AclEntryType[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (AclEntryType c : AclEntryType.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static AclEntryType valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AclStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AclStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.permission Class AclStatus java.lang.Object org.apache.hadoop.fs.permission.AclStatus @InterfaceAudience.Public @InterfaceStability.Evolving public class AclStatus extends Object An AclStatus contains the ACL information of a specific file. AclStatus  instances are immutable. Use a AclStatus.Builder to create a new instance. Method Summary Methods  Modifier and Type Method and Description boolean equals(Object o)  FsAction getEffectivePermission(AclEntry entry) Get the effective permission for the AclEntry FsAction getEffectivePermission(AclEntry entry,                                             FsPermission permArg) Get the effective permission for the AclEntry. List<AclEntry> getEntries() Returns the list of all ACL entries, ordered by their natural ordering. String getGroup() Returns the file group. String getOwner() Returns the file owner. FsPermission getPermission() Returns the permission set for the path int hashCode()  boolean isStickyBit() Returns the sticky bit. String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Method Detail getOwner public String getOwner() Returns the file owner. Returns:String file owner getGroup public String getGroup() Returns the file group. Returns:String file group isStickyBit public boolean isStickyBit() Returns the sticky bit. Returns:boolean sticky bit getEntries public List<AclEntry> getEntries() Returns the list of all ACL entries, ordered by their natural ordering. Returns:List unmodifiable ordered list of all ACL entries getPermission public FsPermission getPermission() Returns the permission set for the path Returns:FsPermission for the path equals public boolean equals(Object o) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object toString public String toString() Overrides: toString in class Object getEffectivePermission public FsAction getEffectivePermission(AclEntry entry) Get the effective permission for the AclEntry Parameters:entry - AclEntry to get the effective action getEffectivePermission public FsAction getEffectivePermission(AclEntry entry,                               FsPermission permArg)                                 throws IllegalArgumentException Get the effective permission for the AclEntry.   Recommended to use this API ONLY if client communicates with the old  NameNode, needs to pass the Permission for the path to get effective  permission, else use getEffectivePermission(AclEntry). Parameters:entry - AclEntry to get the effective actionpermArg - Permission for the path. However if the client is NOT           communicating with old namenode, then this argument will not have           any preference. Returns:Returns the effective permission for the entry. Throws: IllegalArgumentException - If the client communicating with old            namenode and permission is not passed as an argument. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AddingCompositeService (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AddingCompositeService (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.server.services Class AddingCompositeService java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.service.CompositeService org.apache.hadoop.registry.server.services.AddingCompositeService All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Evolving public class AddingCompositeService extends CompositeService Composite service that exports the add/remove methods.    This allows external classes to add services to these methods, after which  they follow the same lifecyce.    It is essential that any service added is in a state where it can be moved  on with that of the parent services. Specifically, do not add an uninited  service to a parent that is already inited —as the start  operation will then fail Field Summary Fields inherited from class org.apache.hadoop.service.CompositeService STOP_ONLY_STARTED_SERVICES Constructor Summary Constructors  Constructor and Description AddingCompositeService(String name)  Method Summary Methods  Modifier and Type Method and Description void addService(Service service) Add the passed Service to the list of services managed by this  CompositeService boolean removeService(Service service)  Methods inherited from class org.apache.hadoop.service.CompositeService addIfService, getServices, serviceInit, serviceStart, serviceStop Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail AddingCompositeService public AddingCompositeService(String name) Method Detail addService public void addService(Service service) Description copied from class: CompositeService Add the passed Service to the list of services managed by this  CompositeService Overrides: addService in class CompositeService Parameters:service - the Service to be added removeService public boolean removeService(Service service) Overrides: removeService in class CompositeService Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AddressTypes (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AddressTypes (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.types Interface AddressTypes @InterfaceAudience.Public @InterfaceStability.Evolving public interface AddressTypes Enum of address types -as integers.  Why integers and not enums? Cross platform serialization as JSON Field Summary Fields  Modifier and Type Field and Description static String ADDRESS_HOSTNAME_AND_PORT hostname/FQDN and port pair: "host/port". static String ADDRESS_HOSTNAME_FIELD  static String ADDRESS_OTHER Any other address: "". static String ADDRESS_PATH Path /a/b/c style: "path". static String ADDRESS_PORT_FIELD  static String ADDRESS_URI URI entries: "uri". static String ADDRESS_ZOOKEEPER Zookeeper addresses as a triple : "zktriple". Field Detail ADDRESS_HOSTNAME_AND_PORT static final String ADDRESS_HOSTNAME_AND_PORT hostname/FQDN and port pair: "host/port".  The host/domain name and port are set as separate strings in the address  list, e.g.      ["namenode.example.org", "50070"]   See Also:Constant Field Values ADDRESS_HOSTNAME_FIELD static final String ADDRESS_HOSTNAME_FIELD See Also:Constant Field Values ADDRESS_PORT_FIELD static final String ADDRESS_PORT_FIELD See Also:Constant Field Values ADDRESS_PATH static final String ADDRESS_PATH Path /a/b/c style: "path".  The entire path is encoded in a single entry      ["/users/example/dataset"]   See Also:Constant Field Values ADDRESS_URI static final String ADDRESS_URI URI entries: "uri".      ["http://example.org"]   See Also:Constant Field Values ADDRESS_ZOOKEEPER static final String ADDRESS_ZOOKEEPER Zookeeper addresses as a triple : "zktriple".    These are provide as a 3 element tuple of: hostname, port  and optionally path (depending on the application)      A single element would be      ["zk1","2181","/registry"]     An endpoint with multiple elements would list them as      [     ["zk1","2181","/registry"]     ["zk2","1600","/registry"]    ]    the third element in each entry , the path, MUST be the same in each entry.  A client reading the addresses of an endpoint is free to pick any  of the set, so they must be the same. See Also:Constant Field Values ADDRESS_OTHER static final String ADDRESS_OTHER Any other address: "". See Also:Constant Field Values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AdminSecurityInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AdminSecurityInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.admin Class AdminSecurityInfo java.lang.Object org.apache.hadoop.security.SecurityInfo org.apache.hadoop.yarn.security.admin.AdminSecurityInfo @InterfaceAudience.Public @InterfaceStability.Stable public class AdminSecurityInfo extends org.apache.hadoop.security.SecurityInfo Constructor Summary Constructors  Constructor and Description AdminSecurityInfo()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                               Configuration conf) Get the KerberosInfo for a given protocol. org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                         Configuration conf) Get the TokenInfo for a given protocol. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AdminSecurityInfo public AdminSecurityInfo() Method Detail getKerberosInfo public org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the KerberosInfo for a given protocol. Specified by: getKerberosInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration Returns:KerberosInfo getTokenInfo public org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the TokenInfo for a given protocol. Specified by: getTokenInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration object. Returns:TokenInfo instance Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AggregatedLogFormat.LogKey (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AggregatedLogFormat.LogKey (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.logaggregation Class AggregatedLogFormat.LogKey java.lang.Object org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat.LogKey All Implemented Interfaces: Writable Enclosing class: AggregatedLogFormat @InterfaceAudience.Public public static class AggregatedLogFormat.LogKey extends Object implements Writable Constructor Summary Constructors  Constructor and Description AggregatedLogFormat.LogKey()  AggregatedLogFormat.LogKey(ContainerId containerId)  AggregatedLogFormat.LogKey(String keyString)  Method Summary Methods  Modifier and Type Method and Description boolean equals(Object obj)  int hashCode()  String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail AggregatedLogFormat.LogKey public AggregatedLogFormat.LogKey() AggregatedLogFormat.LogKey public AggregatedLogFormat.LogKey(ContainerId containerId) AggregatedLogFormat.LogKey public AggregatedLogFormat.LogKey(String keyString) Method Detail hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AggregatedLogFormat.LogReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AggregatedLogFormat.LogReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.logaggregation Class AggregatedLogFormat.LogReader java.lang.Object org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat.LogReader Enclosing class: AggregatedLogFormat @InterfaceAudience.Public @InterfaceStability.Evolving public static class AggregatedLogFormat.LogReader extends Object Constructor Summary Constructors  Constructor and Description AggregatedLogFormat.LogReader(Configuration conf,                                                           Path remoteAppLogFile)  Method Summary Methods  Modifier and Type Method and Description void close()  Map<ApplicationAccessType,String> getApplicationAcls() Returns ACLs for the application. String getApplicationOwner() Returns the owner of the application. DataInputStream next(AggregatedLogFormat.LogKey key) Read the next key and return the value-stream. static void readAcontainerLogs(DataInputStream valueStream,                                     Writer writer) Writes all logs for a single container to the provided writer. static void readAcontainerLogs(DataInputStream valueStream,                                     Writer writer,                                     long logUploadedTime) Writes all logs for a single container to the provided writer. static void readAContainerLogsForALogType(DataInputStream valueStream,                                                           PrintStream out) Keep calling this till you get a EOFException for getting logs of  all types for a single container. static void readAContainerLogsForALogType(DataInputStream valueStream,                                                           PrintStream out,                                                           long logUploadedTime) Keep calling this till you get a EOFException for getting logs of  all types for a single container. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AggregatedLogFormat.LogReader public AggregatedLogFormat.LogReader(Configuration conf,                              Path remoteAppLogFile)                               throws IOException Throws: IOException Method Detail getApplicationOwner public String getApplicationOwner()                            throws IOException Returns the owner of the application. Returns:the application owner. Throws: IOException getApplicationAcls public Map<ApplicationAccessType,String> getApplicationAcls()                                                      throws IOException Returns ACLs for the application. An empty map is returned if no ACLs are  found. Returns:a map of the Application ACLs. Throws: IOException next public DataInputStream next(AggregatedLogFormat.LogKey key)                      throws IOException Read the next key and return the value-stream. Parameters:key -  Returns:the valueStream if there are more keys or null otherwise. Throws: IOException readAcontainerLogs public static void readAcontainerLogs(DataInputStream valueStream,                       Writer writer,                       long logUploadedTime)                                throws IOException Writes all logs for a single container to the provided writer. Parameters:valueStream - writer - logUploadedTime -  Throws: IOException readAcontainerLogs public static void readAcontainerLogs(DataInputStream valueStream,                       Writer writer)                                throws IOException Writes all logs for a single container to the provided writer. Parameters:valueStream - writer -  Throws: IOException readAContainerLogsForALogType public static void readAContainerLogsForALogType(DataInputStream valueStream,                                  PrintStream out,                                  long logUploadedTime)                                           throws IOException Keep calling this till you get a EOFException for getting logs of  all types for a single container. Parameters:valueStream - out - logUploadedTime -  Throws: IOException readAContainerLogsForALogType public static void readAContainerLogsForALogType(DataInputStream valueStream,                                  PrintStream out)                                           throws IOException Keep calling this till you get a EOFException for getting logs of  all types for a single container. Parameters:valueStream - out -  Throws: IOException close public void close() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AggregatedLogFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AggregatedLogFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.logaggregation Class AggregatedLogFormat java.lang.Object org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat @InterfaceAudience.Public @InterfaceStability.Evolving public class AggregatedLogFormat extends Object Nested Class Summary Nested Classes  Modifier and Type Class and Description static class  AggregatedLogFormat.LogKey  static class  AggregatedLogFormat.LogReader  Constructor Summary Constructors  Constructor and Description AggregatedLogFormat()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AggregatedLogFormat public AggregatedLogFormat() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AllocateRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AllocateRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class AllocateRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class AllocateRequest extends Object The core request sent by the ApplicationMaster to the   ResourceManager to obtain resources in the cluster.   The request includes:      A response id to track duplicate responses.    Progress information.          A list of ResourceRequest to inform the      ResourceManager about the application's      resource requirements.              A list of unused Container which are being returned.       See Also:ApplicationMasterProtocol.allocate(AllocateRequest) Constructor Summary Constructors  Constructor and Description AllocateRequest()  Method Summary Methods  Modifier and Type Method and Description abstract List<ResourceRequest> getAskList() Get the list of ResourceRequest to update the   ResourceManager about the application's resource requirements. abstract List<ContainerResourceIncreaseRequest> getIncreaseRequests() Get the ContainerResourceIncreaseRequest being sent by the  ApplicationMaster abstract float getProgress() Get the current progress of application. abstract List<ContainerId> getReleaseList() Get the list of ContainerId of containers being   released by the ApplicationMaster. abstract ResourceBlacklistRequest getResourceBlacklistRequest() Get the ResourceBlacklistRequest being sent by the   ApplicationMaster. abstract int getResponseId() Get the response id used to track duplicate responses. static AllocateRequest newInstance(int responseID,                       float appProgress,                       List<ResourceRequest> resourceAsk,                       List<ContainerId> containersToBeReleased,                       ResourceBlacklistRequest resourceBlacklistRequest)  static AllocateRequest newInstance(int responseID,                       float appProgress,                       List<ResourceRequest> resourceAsk,                       List<ContainerId> containersToBeReleased,                       ResourceBlacklistRequest resourceBlacklistRequest,                       List<ContainerResourceIncreaseRequest> increaseRequests)  abstract void setAskList(List<ResourceRequest> resourceRequests) Set list of ResourceRequest to update the  ResourceManager about the application's resource requirements. abstract void setIncreaseRequests(List<ContainerResourceIncreaseRequest> increaseRequests) Set the ContainerResourceIncreaseRequest to inform the  ResourceManager about some container's resources need to be  increased abstract void setProgress(float progress) Set the current progress of application abstract void setReleaseList(List<ContainerId> releaseContainers) Set the list of ContainerId of containers being  released by the ApplicationMaster abstract void setResourceBlacklistRequest(ResourceBlacklistRequest resourceBlacklistRequest) Set the ResourceBlacklistRequest to inform the   ResourceManager about the blacklist additions and removals  per the ApplicationMaster. abstract void setResponseId(int id) Set the response id used to track duplicate responses. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AllocateRequest public AllocateRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static AllocateRequest newInstance(int responseID,                                                                              float appProgress,                                                                              List<ResourceRequest> resourceAsk,                                                                              List<ContainerId> containersToBeReleased,                                                                              ResourceBlacklistRequest resourceBlacklistRequest) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static AllocateRequest newInstance(int responseID,                                                                              float appProgress,                                                                              List<ResourceRequest> resourceAsk,                                                                              List<ContainerId> containersToBeReleased,                                                                              ResourceBlacklistRequest resourceBlacklistRequest,                                                                              List<ContainerResourceIncreaseRequest> increaseRequests) getResponseId @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getResponseId() Get the response id used to track duplicate responses. Returns:response id setResponseId @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setResponseId(int id) Set the response id used to track duplicate responses. Parameters:id - response id getProgress @InterfaceAudience.Public @InterfaceStability.Stable public abstract float getProgress() Get the current progress of application. Returns:current progress of application setProgress @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setProgress(float progress) Set the current progress of application Parameters:progress - current progress of application getAskList @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ResourceRequest> getAskList() Get the list of ResourceRequest to update the   ResourceManager about the application's resource requirements. Returns:the list of ResourceRequestSee Also:ResourceRequest setAskList @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setAskList(List<ResourceRequest> resourceRequests) Set list of ResourceRequest to update the  ResourceManager about the application's resource requirements. Parameters:resourceRequests - list of ResourceRequest to update the                          ResourceManager about the application's                          resource requirementsSee Also:ResourceRequest getReleaseList @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ContainerId> getReleaseList() Get the list of ContainerId of containers being   released by the ApplicationMaster. Returns:list of ContainerId of containers being           released by the ApplicationMaster setReleaseList @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setReleaseList(List<ContainerId> releaseContainers) Set the list of ContainerId of containers being  released by the ApplicationMaster Parameters:releaseContainers - list of ContainerId of                            containers being released by the                            ApplicationMaster getResourceBlacklistRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract ResourceBlacklistRequest getResourceBlacklistRequest() Get the ResourceBlacklistRequest being sent by the   ApplicationMaster. Returns:the ResourceBlacklistRequest being sent by the           ApplicationMasterSee Also:ResourceBlacklistRequest setResourceBlacklistRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setResourceBlacklistRequest(ResourceBlacklistRequest resourceBlacklistRequest) Set the ResourceBlacklistRequest to inform the   ResourceManager about the blacklist additions and removals  per the ApplicationMaster. Parameters:resourceBlacklistRequest - the ResourceBlacklistRequest                            to inform the ResourceManager about                            the blacklist additions and removals                          per the ApplicationMasterSee Also:ResourceBlacklistRequest getIncreaseRequests @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ContainerResourceIncreaseRequest> getIncreaseRequests() Get the ContainerResourceIncreaseRequest being sent by the  ApplicationMaster setIncreaseRequests @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setIncreaseRequests(List<ContainerResourceIncreaseRequest> increaseRequests) Set the ContainerResourceIncreaseRequest to inform the  ResourceManager about some container's resources need to be  increased Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AllocateResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AllocateResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class AllocateResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class AllocateResponse extends Object The response sent by the ResourceManager the  ApplicationMaster during resource negotiation.    The response, includes:      Response ID to track duplicate responses.          An AMCommand sent by ResourceManager to let the      ApplicationMaster take some actions (resync, shutdown etc.).        A list of newly allocated Container.    A list of completed Containers' statuses.          The available headroom for resources in the cluster for the      application.        A list of nodes whose status has been updated.    The number of available nodes in a cluster.    A description of resources requested back by the cluster    AMRMToken, if AMRMToken has been rolled over   See Also:ApplicationMasterProtocol.allocate(AllocateRequest) Constructor Summary Constructors  Constructor and Description AllocateResponse()  Method Summary Methods  Modifier and Type Method and Description abstract List<Container> getAllocatedContainers() Get the list of newly allocated Container by the  ResourceManager. abstract AMCommand getAMCommand() If the ResourceManager needs the  ApplicationMaster to take some action then it will send an  AMCommand to the ApplicationMaster. abstract Token getAMRMToken() The AMRMToken that belong to this attempt abstract Resource getAvailableResources() Get the available headroom for resources in the cluster for the  application. abstract List<ContainerStatus> getCompletedContainersStatuses() Get the list of completed containers' statuses. abstract List<org.apache.hadoop.yarn.api.records.ContainerResourceDecrease> getDecreasedContainers() Get the list of newly decreased containers by NodeManager abstract List<org.apache.hadoop.yarn.api.records.ContainerResourceIncrease> getIncreasedContainers() Get the list of newly increased containers by ResourceManager abstract List<NMToken> getNMTokens() Get the list of NMTokens required for communicating with NM. abstract int getNumClusterNodes() Get the number of hosts available on the cluster. abstract PreemptionMessage getPreemptionMessage() Get the description of containers owned by the AM, but requested back by  the cluster. abstract int getResponseId() Get the last response id. abstract List<NodeReport> getUpdatedNodes() Get the list of updated NodeReports. static AllocateResponse newInstance(int responseId,                       List<ContainerStatus> completedContainers,                       List<Container> allocatedContainers,                       List<NodeReport> updatedNodes,                       Resource availResources,                       AMCommand command,                       int numClusterNodes,                       PreemptionMessage preempt,                       List<NMToken> nmTokens)  static AllocateResponse newInstance(int responseId,                       List<ContainerStatus> completedContainers,                       List<Container> allocatedContainers,                       List<NodeReport> updatedNodes,                       Resource availResources,                       AMCommand command,                       int numClusterNodes,                       PreemptionMessage preempt,                       List<NMToken> nmTokens,                       List<org.apache.hadoop.yarn.api.records.ContainerResourceIncrease> increasedContainers,                       List<org.apache.hadoop.yarn.api.records.ContainerResourceDecrease> decreasedContainers)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AllocateResponse public AllocateResponse() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static AllocateResponse newInstance(int responseId,                                                                               List<ContainerStatus> completedContainers,                                                                               List<Container> allocatedContainers,                                                                               List<NodeReport> updatedNodes,                                                                               Resource availResources,                                                                               AMCommand command,                                                                               int numClusterNodes,                                                                               PreemptionMessage preempt,                                                                               List<NMToken> nmTokens) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static AllocateResponse newInstance(int responseId,                                                                               List<ContainerStatus> completedContainers,                                                                               List<Container> allocatedContainers,                                                                               List<NodeReport> updatedNodes,                                                                               Resource availResources,                                                                               AMCommand command,                                                                               int numClusterNodes,                                                                               PreemptionMessage preempt,                                                                               List<NMToken> nmTokens,                                                                               List<org.apache.hadoop.yarn.api.records.ContainerResourceIncrease> increasedContainers,                                                                               List<org.apache.hadoop.yarn.api.records.ContainerResourceDecrease> decreasedContainers) getAMCommand @InterfaceAudience.Public @InterfaceStability.Stable public abstract AMCommand getAMCommand() If the ResourceManager needs the  ApplicationMaster to take some action then it will send an  AMCommand to the ApplicationMaster. See AMCommand   for details on commands and actions for them. Returns:AMCommand if the ApplicationMaster should          take action, null otherwiseSee Also:AMCommand getResponseId @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getResponseId() Get the last response id. Returns:last response id getAllocatedContainers @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<Container> getAllocatedContainers() Get the list of newly allocated Container by the  ResourceManager. Returns:list of newly allocated Container getAvailableResources @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getAvailableResources() Get the available headroom for resources in the cluster for the  application. Returns:limit of available headroom for resources in the cluster for the  application getCompletedContainersStatuses @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ContainerStatus> getCompletedContainersStatuses() Get the list of completed containers' statuses. Returns:the list of completed containers' statuses getUpdatedNodes @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<NodeReport> getUpdatedNodes() Get the list of updated NodeReports. Updates could  be changes in health, availability etc of the nodes. Returns:The delta of updated nodes since the last response getNumClusterNodes @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getNumClusterNodes() Get the number of hosts available on the cluster. Returns:the available host count. getPreemptionMessage @InterfaceAudience.Public @InterfaceStability.Evolving public abstract PreemptionMessage getPreemptionMessage() Get the description of containers owned by the AM, but requested back by  the cluster. Note that the RM may have an inconsistent view of the  resources owned by the AM. These messages are advisory, and the AM may  elect to ignore them.    The message is a snapshot of the resources the RM wants back from the AM.  While demand persists, the RM will repeat its request; applications should  not interpret each message as a request for additional  resources on top of previous messages. Resources requested consistently  over some duration may be forcibly killed by the RM. Returns:A specification of the resources to reclaim from this AM. getNMTokens @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<NMToken> getNMTokens() Get the list of NMTokens required for communicating with NM. New NMTokens  issued only if    1) AM is receiving first container on underlying NodeManager.  OR  2) NMToken master key rolled over in ResourceManager and AM is getting new  container on the same underlying NodeManager.    AM will receive one NMToken per NM irrespective of the number of containers  issued on same NM. AM is expected to store these tokens until issued a  new token for the same NM. getIncreasedContainers @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<org.apache.hadoop.yarn.api.records.ContainerResourceIncrease> getIncreasedContainers() Get the list of newly increased containers by ResourceManager getDecreasedContainers @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<org.apache.hadoop.yarn.api.records.ContainerResourceDecrease> getDecreasedContainers() Get the list of newly decreased containers by NodeManager getAMRMToken @InterfaceAudience.Public @InterfaceStability.Unstable public abstract Token getAMRMToken() The AMRMToken that belong to this attempt Returns:The AMRMToken that belong to this attempt Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationAccessType (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationAccessType (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum ApplicationAccessType java.lang.Object java.lang.Enum<ApplicationAccessType> org.apache.hadoop.yarn.api.records.ApplicationAccessType All Implemented Interfaces: Serializable, Comparable<ApplicationAccessType> @InterfaceAudience.Public @InterfaceStability.Stable public enum ApplicationAccessType extends Enum<ApplicationAccessType> Application access types. Enum Constant Summary Enum Constants  Enum Constant and Description MODIFY_APP Access-type representing 'modifying' application. VIEW_APP Access-type representing 'viewing' application. Method Summary Methods  Modifier and Type Method and Description static ApplicationAccessType valueOf(String name) Returns the enum constant of this type with the specified name. static ApplicationAccessType[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail VIEW_APP public static final ApplicationAccessType VIEW_APP Access-type representing 'viewing' application. ACLs against this type  dictate who can 'view' some or all of the application related details. MODIFY_APP public static final ApplicationAccessType MODIFY_APP Access-type representing 'modifying' application. ACLs against this type  dictate who can 'modify' the application for e.g., by killing the  application Method Detail values public static ApplicationAccessType[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (ApplicationAccessType c : ApplicationAccessType.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static ApplicationAccessType valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationAttemptId (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationAttemptId (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ApplicationAttemptId java.lang.Object org.apache.hadoop.yarn.api.records.ApplicationAttemptId All Implemented Interfaces: Comparable<ApplicationAttemptId> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ApplicationAttemptId extends Object implements Comparable<ApplicationAttemptId> ApplicationAttemptId denotes the particular attempt  of an ApplicationMaster for a given ApplicationId.    Multiple attempts might be needed to run an application to completion due  to temporal failures of the ApplicationMaster such as hardware  failures, connectivity issues etc. on the node on which it was scheduled. Constructor Summary Constructors  Constructor and Description ApplicationAttemptId()  Method Summary Methods  Modifier and Type Method and Description protected abstract void build()  int compareTo(ApplicationAttemptId other)  boolean equals(Object obj)  abstract ApplicationId getApplicationId() Get the ApplicationId of the ApplicationAttempId. abstract int getAttemptId() Get the attempt id of the Application. int hashCode()  String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail ApplicationAttemptId public ApplicationAttemptId() Method Detail getApplicationId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationId getApplicationId() Get the ApplicationId of the ApplicationAttempId. Returns:ApplicationId of the ApplicationAttempId getAttemptId @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getAttemptId() Get the attempt id of the Application. Returns:attempt id of the Application hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object compareTo public int compareTo(ApplicationAttemptId other) Specified by: compareTo in interface Comparable<ApplicationAttemptId> toString public String toString() Overrides: toString in class Object build protected abstract void build() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationAttemptNotFoundException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationAttemptNotFoundException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.exceptions Class ApplicationAttemptNotFoundException java.lang.Object java.lang.Throwable java.lang.Exception org.apache.hadoop.yarn.exceptions.YarnException org.apache.hadoop.yarn.exceptions.ApplicationAttemptNotFoundException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Unstable public class ApplicationAttemptNotFoundException extends YarnException This exception is thrown on  (GetApplicationAttemptReportRequest)  API when the Application Attempt doesn't exist in Application History Server or  ApplicationMasterProtocol.allocate(AllocateRequest) if application  doesn't exist in RM. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ApplicationAttemptNotFoundException(String message)  ApplicationAttemptNotFoundException(String message,                                                                       Throwable cause)  ApplicationAttemptNotFoundException(Throwable cause)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ApplicationAttemptNotFoundException public ApplicationAttemptNotFoundException(Throwable cause) ApplicationAttemptNotFoundException public ApplicationAttemptNotFoundException(String message) ApplicationAttemptNotFoundException public ApplicationAttemptNotFoundException(String message,                                    Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationAttemptReport (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationAttemptReport (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ApplicationAttemptReport java.lang.Object org.apache.hadoop.yarn.api.records.ApplicationAttemptReport @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ApplicationAttemptReport extends Object ApplicationAttemptReport is a report of an application attempt.    It includes details such as:      ApplicationAttemptId of the application.    Host on which the ApplicationMaster of this attempt is    running.    RPC port of the ApplicationMaster of this attempt.    Tracking URL.    Diagnostic information in case of errors.    YarnApplicationAttemptState of the application attempt.    ContainerId of the master Container.   Constructor Summary Constructors  Constructor and Description ApplicationAttemptReport()  Method Summary Methods  Modifier and Type Method and Description abstract ContainerId getAMContainerId() Get the ContainerId of AMContainer for this attempt abstract ApplicationAttemptId getApplicationAttemptId() Get the ApplicationAttemptId of this attempt of the  application abstract String getDiagnostics() Get the diagnositic information of the application attempt in case  of errors. abstract String getHost() Get the host on which this attempt of  ApplicationMaster is running. abstract String getOriginalTrackingUrl() Get the original tracking url for the application attempt. abstract int getRpcPort() Get the RPC port of this attempt ApplicationMaster. abstract String getTrackingUrl() Get the tracking url for the application attempt. abstract YarnApplicationAttemptState getYarnApplicationAttemptState() Get the YarnApplicationAttemptState of the application attempt. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ApplicationAttemptReport public ApplicationAttemptReport() Method Detail getYarnApplicationAttemptState @InterfaceAudience.Public @InterfaceStability.Unstable public abstract YarnApplicationAttemptState getYarnApplicationAttemptState() Get the YarnApplicationAttemptState of the application attempt. Returns:YarnApplicationAttemptState of the application attempt getRpcPort @InterfaceAudience.Public @InterfaceStability.Unstable public abstract int getRpcPort() Get the RPC port of this attempt ApplicationMaster. Returns:RPC port of this attempt ApplicationMaster getHost @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getHost() Get the host on which this attempt of  ApplicationMaster is running. Returns:host on which this attempt of          ApplicationMaster is running getDiagnostics @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getDiagnostics() Get the diagnositic information of the application attempt in case  of errors. Returns:diagnositic information of the application attempt in case          of errors getTrackingUrl @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getTrackingUrl() Get the tracking url for the application attempt. Returns:tracking url for the application attempt getOriginalTrackingUrl @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getOriginalTrackingUrl() Get the original tracking url for the application attempt. Returns:original tracking url for the application attempt getApplicationAttemptId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ApplicationAttemptId getApplicationAttemptId() Get the ApplicationAttemptId of this attempt of the  application Returns:ApplicationAttemptId of the attempt getAMContainerId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ContainerId getAMContainerId() Get the ContainerId of AMContainer for this attempt Returns:ContainerId of the attempt Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationClassLoader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationClassLoader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.util Class ApplicationClassLoader java.lang.Object java.lang.ClassLoader java.security.SecureClassLoader java.net.URLClassLoader org.apache.hadoop.util.ApplicationClassLoader org.apache.hadoop.yarn.util.ApplicationClassLoader All Implemented Interfaces: Closeable, AutoCloseable Deprecated. @InterfaceAudience.Public @InterfaceStability.Unstable @Deprecated public class ApplicationClassLoader extends ApplicationClassLoader This type has been deprecated in favor of  ApplicationClassLoader. All new uses of  ApplicationClassLoader should use that type instead. Field Summary Fields inherited from class org.apache.hadoop.util.ApplicationClassLoader SYSTEM_CLASSES_DEFAULT Constructor Summary Constructors  Constructor and Description ApplicationClassLoader(String classpath,                                             ClassLoader parent,                                             List<String> systemClasses) Deprecated.    ApplicationClassLoader(URL[] urls,                                             ClassLoader parent,                                             List<String> systemClasses) Deprecated.    Method Summary Methods inherited from class org.apache.hadoop.util.ApplicationClassLoader getResource, isSystemClass, loadClass, loadClass Methods inherited from class java.net.URLClassLoader addURL, close, definePackage, findClass, findResource, findResources, getPermissions, getResourceAsStream, getURLs, newInstance, newInstance Methods inherited from class java.security.SecureClassLoader defineClass, defineClass Methods inherited from class java.lang.ClassLoader clearAssertionStatus, defineClass, defineClass, defineClass, defineClass, definePackage, findLibrary, findLoadedClass, findSystemClass, getClassLoadingLock, getPackage, getPackages, getParent, getResources, getSystemClassLoader, getSystemResource, getSystemResourceAsStream, getSystemResources, registerAsParallelCapable, resolveClass, setClassAssertionStatus, setDefaultAssertionStatus, setPackageAssertionStatus, setSigners Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ApplicationClassLoader public ApplicationClassLoader(URL[] urls,                       ClassLoader parent,                       List<String> systemClasses) Deprecated.  ApplicationClassLoader public ApplicationClassLoader(String classpath,                       ClassLoader parent,                       List<String> systemClasses)                        throws MalformedURLException Deprecated.  Throws: MalformedURLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationClientProtocol (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationClientProtocol (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api Interface ApplicationClientProtocol All Superinterfaces: org.apache.hadoop.yarn.api.ApplicationBaseProtocol @InterfaceAudience.Public @InterfaceStability.Stable public interface ApplicationClientProtocol extends org.apache.hadoop.yarn.api.ApplicationBaseProtocol The protocol between clients and the ResourceManager  to submit/abort jobs and to get information on applications, cluster metrics,  nodes, queues and ACLs. Method Summary Methods  Modifier and Type Method and Description ReservationDeleteResponse deleteReservation(ReservationDeleteRequest request)  The interface used by clients to remove an existing Reservation. KillApplicationResponse forceKillApplication(KillApplicationRequest request) The interface used by clients to request the   ResourceManager to abort submitted application. GetClusterMetricsResponse getClusterMetrics(GetClusterMetricsRequest request) The interface used by clients to get metrics about the cluster from  the ResourceManager. GetClusterNodeLabelsResponse getClusterNodeLabels(GetClusterNodeLabelsRequest request)  The interface used by client to get node labels in the cluster GetClusterNodesResponse getClusterNodes(GetClusterNodesRequest request) The interface used by clients to get a report of all nodes  in the cluster from the ResourceManager. org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse getLabelsToNodes(org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest request)  The interface used by client to get labels to nodes mappings  in existing cluster GetNewApplicationResponse getNewApplication(GetNewApplicationRequest request) The interface used by clients to obtain a new ApplicationId for   submitting new applications. org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse getNodeToLabels(org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest request)  The interface used by client to get node to labels mappings in existing cluster GetQueueInfoResponse getQueueInfo(GetQueueInfoRequest request) The interface used by clients to get information about queues  from the ResourceManager. GetQueueUserAclsInfoResponse getQueueUserAcls(GetQueueUserAclsInfoRequest request) The interface used by clients to get information about queue   acls for current user from the ResourceManager. MoveApplicationAcrossQueuesResponse moveApplicationAcrossQueues(MoveApplicationAcrossQueuesRequest request) Move an application to a new queue. SubmitApplicationResponse submitApplication(SubmitApplicationRequest request) The interface used by clients to submit a new application to the  ResourceManager. ReservationSubmissionResponse submitReservation(ReservationSubmissionRequest request)  The interface used by clients to submit a new reservation to the  ResourceManager. ReservationUpdateResponse updateReservation(ReservationUpdateRequest request)  The interface used by clients to update an existing Reservation. Methods inherited from interface org.apache.hadoop.yarn.api.ApplicationBaseProtocol getApplicationAttemptReport, getApplicationAttempts, getApplicationReport, getApplications, getContainerReport, getContainers, getDelegationToken Method Detail getNewApplication @InterfaceAudience.Public @InterfaceStability.Stable GetNewApplicationResponse getNewApplication(GetNewApplicationRequest request)                                             throws YarnException,                                                    IOException The interface used by clients to obtain a new ApplicationId for   submitting new applications.    The ResourceManager responds with a new, monotonically  increasing, ApplicationId which is used by the client to submit  a new application.  The ResourceManager also responds with details such   as maximum resource capabilities in the cluster as specified in  GetNewApplicationResponse. Parameters:request - request to get a new ApplicationId Returns:response containing the new ApplicationId to be used  to submit an application Throws: YarnException IOExceptionSee Also:submitApplication(SubmitApplicationRequest) submitApplication @InterfaceAudience.Public @InterfaceStability.Stable SubmitApplicationResponse submitApplication(SubmitApplicationRequest request)                                             throws YarnException,                                                    IOException The interface used by clients to submit a new application to the  ResourceManager.    The client is required to provide details such as queue,   Resource required to run the ApplicationMaster,   the equivalent of ContainerLaunchContext for launching  the ApplicationMaster etc. via the   SubmitApplicationRequest.    Currently the ResourceManager sends an immediate (empty)   SubmitApplicationResponse on accepting the submission and throws   an exception if it rejects the submission. However, this call needs to be  followed by ApplicationBaseProtocol.getApplicationReport(GetApplicationReportRequest)  to make sure that the application gets properly submitted - obtaining a  SubmitApplicationResponse from ResourceManager doesn't guarantee  that RM 'remembers' this application beyond failover or restart. If RM  failover or RM restart happens before ResourceManager saves the  application's state successfully, the subsequent  ApplicationBaseProtocol.getApplicationReport(GetApplicationReportRequest) will throw  a ApplicationNotFoundException. The Clients need to re-submit  the application with the same ApplicationSubmissionContext when  it encounters the ApplicationNotFoundException on the  ApplicationBaseProtocol.getApplicationReport(GetApplicationReportRequest) call.    During the submission process, it checks whether the application  already exists. If the application exists, it will simply return  SubmitApplicationResponse   In secure mode,the ResourceManager verifies access to  queues etc. before accepting the application submission. Parameters:request - request to submit a new application Returns:(empty) response on accepting the submission Throws: YarnException IOExceptionSee Also:getNewApplication(GetNewApplicationRequest) forceKillApplication @InterfaceAudience.Public @InterfaceStability.Stable KillApplicationResponse forceKillApplication(KillApplicationRequest request)                                              throws YarnException,                                                     IOException The interface used by clients to request the   ResourceManager to abort submitted application.    The client, via KillApplicationRequest provides the  ApplicationId of the application to be aborted.     In secure mode,the ResourceManager verifies access to the  application, queue etc. before terminating the application.     Currently, the ResourceManager returns an empty response  on success and throws an exception on rejecting the request. Parameters:request - request to abort a submitted application Returns:ResourceManager returns an empty response          on success and throws an exception on rejecting the request Throws: YarnException IOExceptionSee Also:getQueueUserAcls(GetQueueUserAclsInfoRequest) getClusterMetrics @InterfaceAudience.Public @InterfaceStability.Stable GetClusterMetricsResponse getClusterMetrics(GetClusterMetricsRequest request)                                             throws YarnException,                                                    IOException The interface used by clients to get metrics about the cluster from  the ResourceManager.    The ResourceManager responds with a  GetClusterMetricsResponse which includes the   YarnClusterMetrics with details such as number of current  nodes in the cluster. Parameters:request - request for cluster metrics Returns:cluster metrics Throws: YarnException IOException getClusterNodes @InterfaceAudience.Public @InterfaceStability.Stable GetClusterNodesResponse getClusterNodes(GetClusterNodesRequest request)                                         throws YarnException,                                                IOException The interface used by clients to get a report of all nodes  in the cluster from the ResourceManager.    The ResourceManager responds with a   GetClusterNodesResponse which includes the   NodeReport for all the nodes in the cluster. Parameters:request - request for report on all nodes Returns:report on all nodes Throws: YarnException IOException getQueueInfo @InterfaceAudience.Public @InterfaceStability.Stable GetQueueInfoResponse getQueueInfo(GetQueueInfoRequest request)                                   throws YarnException,                                          IOException The interface used by clients to get information about queues  from the ResourceManager.    The client, via GetQueueInfoRequest, can ask for details such  as used/total resources, child queues, running applications etc.   In secure mode,the ResourceManager verifies access before  providing the information. Parameters:request - request to get queue information Returns:queue information Throws: YarnException IOException getQueueUserAcls @InterfaceAudience.Public @InterfaceStability.Stable GetQueueUserAclsInfoResponse getQueueUserAcls(GetQueueUserAclsInfoRequest request)                                               throws YarnException,                                                      IOException The interface used by clients to get information about queue   acls for current user from the ResourceManager.      The ResourceManager responds with queue acls for all  existing queues. Parameters:request - request to get queue acls for current user Returns:queue acls for current user Throws: YarnException IOException moveApplicationAcrossQueues @InterfaceAudience.Public @InterfaceStability.Unstable MoveApplicationAcrossQueuesResponse moveApplicationAcrossQueues(MoveApplicationAcrossQueuesRequest request)                                                                 throws YarnException,                                                                        IOException Move an application to a new queue. Parameters:request - the application ID and the target queue Returns:an empty response Throws: YarnException IOException submitReservation @InterfaceAudience.Public @InterfaceStability.Unstable ReservationSubmissionResponse submitReservation(ReservationSubmissionRequest request)                                                 throws YarnException,                                                        IOException  The interface used by clients to submit a new reservation to the  ResourceManager.        The client packages all details of its request in a  ReservationSubmissionRequest object. This contains information  about the amount of capacity, temporal constraints, and concurrency needs.  Furthermore, the reservation might be composed of multiple stages, with  ordering dependencies among them.        In order to respond, a new admission control component in the  ResourceManager performs an analysis of the resources that have  been committed over the period of time the user is requesting, verify that  the user requests can be fulfilled, and that it respect a sharing policy  (e.g., CapacityOverTimePolicy). Once it has positively determined  that the ReservationSubmissionRequest is satisfiable the  ResourceManager answers with a  ReservationSubmissionResponse that include a non-null  ReservationId. Upon failure to find a valid allocation the response  is an exception with the reason.    On application submission the client can use this ReservationId to  obtain access to the reserved resources.        The system guarantees that during the time-range specified by the user, the  reservationID will be corresponding to a valid reservation. The amount of  capacity dedicated to such queue can vary overtime, depending of the  allocation that has been determined. But it is guaranteed to satisfy all  the constraint expressed by the user in the  ReservationSubmissionRequest.   Parameters:request - the request to submit a new Reservation Returns:response the ReservationId on accepting the submission Throws: YarnException - if the request is invalid or reservation cannot be            created successfully IOException updateReservation @InterfaceAudience.Public @InterfaceStability.Unstable ReservationUpdateResponse updateReservation(ReservationUpdateRequest request)                                             throws YarnException,                                                    IOException  The interface used by clients to update an existing Reservation. This is  referred to as a re-negotiation process, in which a user that has  previously submitted a Reservation.        The allocation is attempted by virtually substituting all previous  allocations related to this Reservation with new ones, that satisfy the new  ReservationUpdateRequest. Upon success the previous allocation is  substituted by the new one, and on failure (i.e., if the system cannot find  a valid allocation for the updated request), the previous allocation  remains valid.    The ReservationId is not changed, and applications currently  running within this reservation will automatically receive the resources  based on the new allocation.   Parameters:request - to update an existing Reservation (the ReservationRequest           should refer to an existing valid ReservationId) Returns:response empty on successfully updating the existing reservation Throws: YarnException - if the request is invalid or reservation cannot be            updated successfully IOException deleteReservation @InterfaceAudience.Public @InterfaceStability.Unstable ReservationDeleteResponse deleteReservation(ReservationDeleteRequest request)                                             throws YarnException,                                                    IOException  The interface used by clients to remove an existing Reservation.    Upon deletion of a reservation applications running with this reservation,  are automatically downgraded to normal jobs running without any dedicated  reservation.   Parameters:request - to remove an existing Reservation (the ReservationRequest           should refer to an existing valid ReservationId) Returns:response empty on successfully deleting the existing reservation Throws: YarnException - if the request is invalid or reservation cannot be            deleted successfully IOException getNodeToLabels @InterfaceAudience.Public @InterfaceStability.Unstable org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse getNodeToLabels(org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest request)                                                                                     throws YarnException,                                                                                            IOException  The interface used by client to get node to labels mappings in existing cluster   Parameters:request -  Returns:node to labels mappings Throws: YarnException IOException getLabelsToNodes @InterfaceAudience.Public @InterfaceStability.Unstable org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse getLabelsToNodes(org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest request)                                                                                      throws YarnException,                                                                                             IOException  The interface used by client to get labels to nodes mappings  in existing cluster   Parameters:request -  Returns:labels to nodes mappings Throws: YarnException IOException getClusterNodeLabels @InterfaceAudience.Public @InterfaceStability.Unstable GetClusterNodeLabelsResponse getClusterNodeLabels(GetClusterNodeLabelsRequest request)                                                   throws YarnException,                                                          IOException  The interface used by client to get node labels in the cluster   Parameters:request - to get node labels collection of this cluster Returns:node labels collection of this cluster Throws: YarnException IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationConstants (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationConstants (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api Interface ApplicationConstants @InterfaceAudience.Public @InterfaceStability.Evolving public interface ApplicationConstants This is the API for the applications comprising of constants that YARN sets  up for the applications and the containers.    TODO: Investigate the semantics and security of each cross-boundary refs. Field Summary Fields  Modifier and Type Field and Description static String APP_SUBMIT_TIME_ENV The environment variable for APP_SUBMIT_TIME. static String APPLICATION_WEB_PROXY_BASE_ENV The environmental variable for APPLICATION_WEB_PROXY_BASE. static String CLASS_PATH_SEPARATOR This constant is used to construct class path and it will be replaced with  real class path separator(':' for Linux and ';' for Windows) by  NodeManager on container launch. static String CONTAINER_TOKEN_FILE_ENV_NAME The cache file into which container token is written static String LOG_DIR_EXPANSION_VAR The temporary environmental variable for container log directory. static String MAX_APP_ATTEMPTS_ENV The environment variable for MAX_APP_ATTEMPTS. static String PARAMETER_EXPANSION_LEFT The following two constants are used to expand parameter and it will be  replaced with real parameter expansion marker ('%' for Windows and '$' for  Linux) by NodeManager on container launch. static String PARAMETER_EXPANSION_RIGHT User has to use this constant to construct class path if user wants  cross-platform practice i.e. static String STDERR  static String STDOUT  Field Detail APP_SUBMIT_TIME_ENV static final String APP_SUBMIT_TIME_ENV The environment variable for APP_SUBMIT_TIME. Set in AppMaster environment  only See Also:Constant Field Values CONTAINER_TOKEN_FILE_ENV_NAME static final String CONTAINER_TOKEN_FILE_ENV_NAME The cache file into which container token is written See Also:Constant Field Values APPLICATION_WEB_PROXY_BASE_ENV static final String APPLICATION_WEB_PROXY_BASE_ENV The environmental variable for APPLICATION_WEB_PROXY_BASE. Set in   ApplicationMaster's environment only. This states that for all non-relative  web URLs in the app masters web UI what base should they have. See Also:Constant Field Values LOG_DIR_EXPANSION_VAR static final String LOG_DIR_EXPANSION_VAR The temporary environmental variable for container log directory. This  should be replaced by real container log directory on container launch. See Also:Constant Field Values CLASS_PATH_SEPARATOR @InterfaceAudience.Public @InterfaceStability.Unstable static final String CLASS_PATH_SEPARATOR This constant is used to construct class path and it will be replaced with  real class path separator(':' for Linux and ';' for Windows) by  NodeManager on container launch. User has to use this constant to construct  class path if user wants cross-platform practice i.e. submit an application  from a Windows client to a Linux/Unix server or vice versa. See Also:Constant Field Values PARAMETER_EXPANSION_LEFT @InterfaceAudience.Public @InterfaceStability.Unstable static final String PARAMETER_EXPANSION_LEFT The following two constants are used to expand parameter and it will be  replaced with real parameter expansion marker ('%' for Windows and '$' for  Linux) by NodeManager on container launch. For example: {{VAR}} will be  replaced as $VAR on Linux, and %VAR% on Windows. User has to use this  constant to construct class path if user wants cross-platform practice i.e.  submit an application from a Windows client to a Linux/Unix server or vice  versa. See Also:Constant Field Values PARAMETER_EXPANSION_RIGHT @InterfaceAudience.Public @InterfaceStability.Unstable static final String PARAMETER_EXPANSION_RIGHT User has to use this constant to construct class path if user wants  cross-platform practice i.e. submit an application from a Windows client to  a Linux/Unix server or vice versa. See Also:Constant Field Values STDERR static final String STDERR See Also:Constant Field Values STDOUT static final String STDOUT See Also:Constant Field Values MAX_APP_ATTEMPTS_ENV static final String MAX_APP_ATTEMPTS_ENV The environment variable for MAX_APP_ATTEMPTS. Set in AppMaster environment  only See Also:Constant Field Values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationHistoryProtocol (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationHistoryProtocol (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api Interface ApplicationHistoryProtocol All Superinterfaces: org.apache.hadoop.yarn.api.ApplicationBaseProtocol @InterfaceAudience.Public @InterfaceStability.Unstable public interface ApplicationHistoryProtocol extends org.apache.hadoop.yarn.api.ApplicationBaseProtocol  The protocol between clients and the ApplicationHistoryServer to  get the information of completed applications etc.   Method Summary Methods inherited from interface org.apache.hadoop.yarn.api.ApplicationBaseProtocol getApplicationAttemptReport, getApplicationAttempts, getApplicationReport, getApplications, getContainerReport, getContainers, getDelegationToken Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationId (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationId (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ApplicationId java.lang.Object org.apache.hadoop.yarn.api.records.ApplicationId All Implemented Interfaces: Comparable<ApplicationId> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ApplicationId extends Object implements Comparable<ApplicationId> ApplicationId represents the globally unique   identifier for an application.    The globally unique nature of the identifier is achieved by using the   cluster timestamp i.e. start-time of the   ResourceManager along with a monotonically increasing counter  for the application. Constructor Summary Constructors  Constructor and Description ApplicationId()  Method Summary Methods  Modifier and Type Method and Description protected abstract void build()  int compareTo(ApplicationId other)  boolean equals(Object obj)  abstract long getClusterTimestamp() Get the start time of the ResourceManager which is   used to generate globally unique ApplicationId. abstract int getId() Get the short integer identifier of the ApplicationId  which is unique for all applications started by a particular instance  of the ResourceManager. int hashCode()  String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail ApplicationId public ApplicationId() Method Detail getId @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getId() Get the short integer identifier of the ApplicationId  which is unique for all applications started by a particular instance  of the ResourceManager. Returns:short integer identifier of the ApplicationId getClusterTimestamp @InterfaceAudience.Public @InterfaceStability.Stable public abstract long getClusterTimestamp() Get the start time of the ResourceManager which is   used to generate globally unique ApplicationId. Returns:start time of the ResourceManager build protected abstract void build() compareTo public int compareTo(ApplicationId other) Specified by: compareTo in interface Comparable<ApplicationId> toString public String toString() Overrides: toString in class Object hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationIdNotProvidedException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationIdNotProvidedException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.exceptions Class ApplicationIdNotProvidedException java.lang.Object java.lang.Throwable java.lang.Exception org.apache.hadoop.yarn.exceptions.YarnException org.apache.hadoop.yarn.exceptions.ApplicationIdNotProvidedException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Unstable public class ApplicationIdNotProvidedException extends YarnException Exception to be thrown when Client submit an application without  providing ApplicationId in ApplicationSubmissionContext. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ApplicationIdNotProvidedException(String message)  ApplicationIdNotProvidedException(String message,                                                                   Throwable cause)  ApplicationIdNotProvidedException(Throwable cause)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ApplicationIdNotProvidedException public ApplicationIdNotProvidedException(Throwable cause) ApplicationIdNotProvidedException public ApplicationIdNotProvidedException(String message) ApplicationIdNotProvidedException public ApplicationIdNotProvidedException(String message,                                  Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationMaster (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationMaster (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.applications.distributedshell Class ApplicationMaster java.lang.Object org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster @InterfaceAudience.Public @InterfaceStability.Unstable public class ApplicationMaster extends Object An ApplicationMaster for executing shell commands on a set of launched  containers using the YARN framework.      This class is meant to act as an example on how to write yarn-based  application masters.        The ApplicationMaster is started on a container by the  ResourceManager's launcher. The first thing that the  ApplicationMaster needs to do is to connect and register itself  with the ResourceManager. The registration sets up information  within the ResourceManager regarding what host:port the  ApplicationMaster is listening on to provide any form of functionality to a  client as well as a tracking url that a client can use to keep track of  status/job history if needed. However, in the distributedshell, trackingurl  and appMasterHost:appMasterRpcPort are not supported.        The ApplicationMaster needs to send a heartbeat to the  ResourceManager at regular intervals to inform the  ResourceManager that it is up and alive. The  ApplicationMasterProtocol.allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest) to the ResourceManager from the  ApplicationMaster acts as a heartbeat.      For the actual handling of the job, the ApplicationMaster has to  request the ResourceManager via AllocateRequest for the  required no. of containers using ResourceRequest with the necessary  resource specifications such as node location, computational  (memory/disk/cpu) resource requirements. The ResourceManager  responds with an AllocateResponse that informs the  ApplicationMaster of the set of newly allocated containers,  completed containers as well as current state of available resources.        For each allocated container, the ApplicationMaster can then set  up the necessary launch context via ContainerLaunchContext to specify  the allocated container id, local resources required by the executable, the  environment to be setup for the executable, commands to execute, etc. and  submit a StartContainerRequest to the ContainerManagementProtocol to  launch and execute the defined commands on the given allocated container.        The ApplicationMaster can monitor the launched container by  either querying the ResourceManager using  ApplicationMasterProtocol.allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest) to get updates on completed containers or via  the ContainerManagementProtocol by querying for the status of the allocated  container's ContainerId.    After the job has been completed, the ApplicationMaster has to  send a FinishApplicationMasterRequest to the  ResourceManager to inform it that the  ApplicationMaster has been completed. Field Summary Fields  Modifier and Type Field and Description protected ApplicationAttemptId appAttemptID  protected AtomicInteger numAllocatedContainers  protected AtomicInteger numRequestedContainers  protected int numTotalContainers  Constructor Summary Constructors  Constructor and Description ApplicationMaster()  Method Summary Methods  Modifier and Type Method and Description protected boolean finish()  boolean init(String[] args) Parse command line options static void main(String[] args)  void run() Main run function for the application master Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail appAttemptID protected ApplicationAttemptId appAttemptID numTotalContainers protected int numTotalContainers numAllocatedContainers protected AtomicInteger numAllocatedContainers numRequestedContainers protected AtomicInteger numRequestedContainers Constructor Detail ApplicationMaster public ApplicationMaster() Method Detail main public static void main(String[] args) Parameters:args - Command line args init public boolean init(String[] args)              throws org.apache.commons.cli.ParseException,                     IOException Parse command line options Parameters:args - Command line args Returns:Whether init successful and run should be invoked Throws: org.apache.commons.cli.ParseException IOException run public void run()          throws YarnException,                 IOException,                 InterruptedException Main run function for the application master Throws: YarnException IOException InterruptedException finish protected boolean finish() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationMasterProtocol (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationMasterProtocol (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api Interface ApplicationMasterProtocol @InterfaceAudience.Public @InterfaceStability.Stable public interface ApplicationMasterProtocol The protocol between a live instance of ApplicationMaster   and the ResourceManager.    This is used by the ApplicationMaster to register/unregister  and to request and obtain resources in the cluster from the  ResourceManager. Method Summary Methods  Modifier and Type Method and Description AllocateResponse allocate(AllocateRequest request)  The main interface between an ApplicationMaster and the  ResourceManager. FinishApplicationMasterResponse finishApplicationMaster(FinishApplicationMasterRequest request) The interface used by an ApplicationMaster to notify the   ResourceManager about its completion (success or failed). RegisterApplicationMasterResponse registerApplicationMaster(RegisterApplicationMasterRequest request)  The interface used by a new ApplicationMaster to register with  the ResourceManager. Method Detail registerApplicationMaster @InterfaceAudience.Public @InterfaceStability.Stable RegisterApplicationMasterResponse registerApplicationMaster(RegisterApplicationMasterRequest request)                                                             throws YarnException,                                                                    IOException  The interface used by a new ApplicationMaster to register with  the ResourceManager.        The ApplicationMaster needs to provide details such as RPC  Port, HTTP tracking url etc. as specified in  RegisterApplicationMasterRequest.        The ResourceManager responds with critical details such as  maximum resource capabilities in the cluster as specified in  RegisterApplicationMasterResponse.   Parameters:request - registration request Returns:registration respose Throws: YarnException IOException org.apache.hadoop.yarn.exceptions.InvalidApplicationMasterRequestException - The exception is thrown when an ApplicationMaster tries to            register more then once.See Also:RegisterApplicationMasterRequest,  RegisterApplicationMasterResponse finishApplicationMaster @InterfaceAudience.Public @InterfaceStability.Stable FinishApplicationMasterResponse finishApplicationMaster(FinishApplicationMasterRequest request)                                                         throws YarnException,                                                                IOException The interface used by an ApplicationMaster to notify the   ResourceManager about its completion (success or failed).    The ApplicationMaster has to provide details such as   final state, diagnostics (in case of failures) etc. as specified in   FinishApplicationMasterRequest.    The ResourceManager responds with   FinishApplicationMasterResponse. Parameters:request - completion request Returns:completion response Throws: YarnException IOExceptionSee Also:FinishApplicationMasterRequest,  FinishApplicationMasterResponse allocate @InterfaceAudience.Public @InterfaceStability.Stable AllocateResponse allocate(AllocateRequest request)                           throws YarnException,                                  IOException  The main interface between an ApplicationMaster and the  ResourceManager.        The ApplicationMaster uses this interface to provide a list of  ResourceRequest and returns unused Container allocated to  it via AllocateRequest. Optionally, the  ApplicationMaster can also blacklist resources which  it doesn't want to use.        This also doubles up as a heartbeat to let the  ResourceManager know that the ApplicationMaster  is alive. Thus, applications should periodically make this call to be kept  alive. The frequency depends on  YarnConfiguration.RM_AM_EXPIRY_INTERVAL_MS which defaults to  YarnConfiguration.DEFAULT_RM_AM_EXPIRY_INTERVAL_MS.        The ResourceManager responds with list of allocated  Container, status of completed containers and headroom information  for the application.        The ApplicationMaster can use the available headroom  (resources) to decide how to utilized allocated resources and make informed  decisions about future resource requests.   Parameters:request - allocation request Returns:allocation response Throws: YarnException IOException org.apache.hadoop.yarn.exceptions.InvalidApplicationMasterRequestException - This exception is thrown when an ApplicationMaster calls allocate            without registering first. org.apache.hadoop.yarn.exceptions.InvalidResourceBlacklistRequestException - This exception is thrown when an application provides an invalid            specification for blacklist of resources. org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException - This exception is thrown when a ResourceRequest is out of            the range of the configured lower and upper limits on the            resources.See Also:AllocateRequest,  AllocateResponse Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationNotFoundException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationNotFoundException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.exceptions Class ApplicationNotFoundException java.lang.Object java.lang.Throwable java.lang.Exception org.apache.hadoop.yarn.exceptions.YarnException org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Unstable public class ApplicationNotFoundException extends YarnException This exception is thrown on  (GetApplicationReportRequest) API  when the Application doesn't exist in RM and AHS See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ApplicationNotFoundException(String message)  ApplicationNotFoundException(String message,                                                         Throwable cause)  ApplicationNotFoundException(Throwable cause)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ApplicationNotFoundException public ApplicationNotFoundException(Throwable cause) ApplicationNotFoundException public ApplicationNotFoundException(String message) ApplicationNotFoundException public ApplicationNotFoundException(String message,                             Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationReport (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationReport (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ApplicationReport java.lang.Object org.apache.hadoop.yarn.api.records.ApplicationReport @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ApplicationReport extends Object ApplicationReport is a report of an application.    It includes details such as:      ApplicationId of the application.    Applications user.    Application queue.    Application name.    Host on which the ApplicationMaster is running.    RPC port of the ApplicationMaster.    Tracking URL.    YarnApplicationState of the application.    Diagnostic information in case of errors.    Start time of the application.    Client Token of the application (if security is enabled).   See Also:ApplicationBaseProtocol.getApplicationReport(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest) Constructor Summary Constructors  Constructor and Description ApplicationReport()  Method Summary Methods  Modifier and Type Method and Description abstract Token getAMRMToken() Get the AMRM token of the application. abstract ApplicationId getApplicationId() Get the ApplicationId of the application. abstract ApplicationResourceUsageReport getApplicationResourceUsageReport() Retrieve the structure containing the job resources for this application abstract Set<String> getApplicationTags() Get all tags corresponding to the application abstract String getApplicationType() Get the application's Type abstract Token getClientToAMToken() Get the client token for communicating with the  ApplicationMaster. abstract ApplicationAttemptId getCurrentApplicationAttemptId() Get the ApplicationAttemptId of the current  attempt of the application abstract String getDiagnostics() Get  the diagnositic information of the application in case of  errors. abstract FinalApplicationStatus getFinalApplicationStatus() Get the final finish status of the application. abstract long getFinishTime() Get the finish time of the application. abstract String getHost() Get the host on which the ApplicationMaster  is running. abstract String getName() Get the user-defined name of the application. abstract float getProgress() Get the application's progress ( range 0.0 to 1.0 ) abstract String getQueue() Get the queue to which the application was submitted. abstract int getRpcPort() Get the RPC port of the ApplicationMaster. abstract long getStartTime() Get the start time of the application. abstract String getTrackingUrl() Get the tracking url for the application. abstract String getUser() Get the user who submitted the application. abstract YarnApplicationState getYarnApplicationState() Get the YarnApplicationState of the application. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ApplicationReport public ApplicationReport() Method Detail getApplicationId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationId getApplicationId() Get the ApplicationId of the application. Returns:ApplicationId of the application getCurrentApplicationAttemptId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationAttemptId getCurrentApplicationAttemptId() Get the ApplicationAttemptId of the current  attempt of the application Returns:ApplicationAttemptId of the attempt getUser @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getUser() Get the user who submitted the application. Returns:user who submitted the application getQueue @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getQueue() Get the queue to which the application was submitted. Returns:queue to which the application was submitted getName @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getName() Get the user-defined name of the application. Returns:name of the application getHost @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getHost() Get the host on which the ApplicationMaster  is running. Returns:host on which the ApplicationMaster          is running getRpcPort @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getRpcPort() Get the RPC port of the ApplicationMaster. Returns:RPC port of the ApplicationMaster getClientToAMToken @InterfaceAudience.Public @InterfaceStability.Stable public abstract Token getClientToAMToken() Get the client token for communicating with the  ApplicationMaster.    ClientToAMToken is the security token used by the AMs to verify  authenticity of any client.      The ResourceManager, provides a secure token (via  getClientToAMToken()) which is verified by the  ApplicationMaster when the client directly talks to an AM.   Returns:client token for communicating with the  ApplicationMaster getYarnApplicationState @InterfaceAudience.Public @InterfaceStability.Stable public abstract YarnApplicationState getYarnApplicationState() Get the YarnApplicationState of the application. Returns:YarnApplicationState of the application getDiagnostics @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getDiagnostics() Get  the diagnositic information of the application in case of  errors. Returns:diagnositic information of the application in case          of errors getTrackingUrl @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getTrackingUrl() Get the tracking url for the application. Returns:tracking url for the application getStartTime @InterfaceAudience.Public @InterfaceStability.Stable public abstract long getStartTime() Get the start time of the application. Returns:start time of the application getFinishTime @InterfaceAudience.Public @InterfaceStability.Stable public abstract long getFinishTime() Get the finish time of the application. Returns:finish time of the application getFinalApplicationStatus @InterfaceAudience.Public @InterfaceStability.Stable public abstract FinalApplicationStatus getFinalApplicationStatus() Get the final finish status of the application. Returns:final finish status of the application getApplicationResourceUsageReport @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationResourceUsageReport getApplicationResourceUsageReport() Retrieve the structure containing the job resources for this application Returns:the job resources structure for this application getProgress @InterfaceAudience.Public @InterfaceStability.Stable public abstract float getProgress() Get the application's progress ( range 0.0 to 1.0 ) Returns:application's progress getApplicationType @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getApplicationType() Get the application's Type Returns:application's Type getApplicationTags @InterfaceAudience.Public @InterfaceStability.Stable public abstract Set<String> getApplicationTags() Get all tags corresponding to the application Returns:Application's tags getAMRMToken @InterfaceAudience.Public @InterfaceStability.Stable public abstract Token getAMRMToken() Get the AMRM token of the application.    The AMRM token is required for AM to RM scheduling operations. For   managed Application Masters Yarn takes care of injecting it. For unmanaged  Applications Masters, the token must be obtained via this method and set  in the UserGroupInformation of the  current user.    The AMRM token will be returned only if all the following conditions are  met:      the requester is the owner of the ApplicationMaster    the application master is an unmanaged ApplicationMaster    the application master is in ACCEPTED state    Else this method returns NULL. Returns:the AM to RM token if available. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationResourceUsageReport (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationResourceUsageReport (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ApplicationResourceUsageReport java.lang.Object org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ApplicationResourceUsageReport extends Object Contains various scheduling metrics to be reported by UI and CLI. Constructor Summary Constructors  Constructor and Description ApplicationResourceUsageReport()  Method Summary Methods  Modifier and Type Method and Description abstract long getMemorySeconds() Get the aggregated amount of memory (in megabytes) the application has  allocated times the number of seconds the application has been running. abstract Resource getNeededResources() Get the needed Resource. abstract int getNumUsedContainers() Get the number of used containers. abstract Resource getReservedResources() Get the reserved Resource. abstract Resource getUsedResources() Get the used Resource. abstract long getVcoreSeconds() Get the aggregated number of vcores that the application has allocated  times the number of seconds the application has been running. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ApplicationResourceUsageReport public ApplicationResourceUsageReport() Method Detail getNumUsedContainers @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getNumUsedContainers() Get the number of used containers.  -1 for invalid/inaccessible reports. Returns:the number of used containers getUsedResources @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getUsedResources() Get the used Resource.  -1 for invalid/inaccessible reports. Returns:the used Resource getReservedResources @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getReservedResources() Get the reserved Resource.  -1 for invalid/inaccessible reports. Returns:the reserved Resource getNeededResources @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getNeededResources() Get the needed Resource.  -1 for invalid/inaccessible reports. Returns:the needed Resource getMemorySeconds @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getMemorySeconds() Get the aggregated amount of memory (in megabytes) the application has  allocated times the number of seconds the application has been running. Returns:the aggregated amount of memory seconds getVcoreSeconds @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getVcoreSeconds() Get the aggregated number of vcores that the application has allocated  times the number of seconds the application has been running. Returns:the aggregated number of vcore seconds Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationSubmissionContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationSubmissionContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ApplicationSubmissionContext java.lang.Object org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ApplicationSubmissionContext extends Object ApplicationSubmissionContext represents all of the  information needed by the ResourceManager to launch  the ApplicationMaster for an application.    It includes details such as:      ApplicationId of the application.    Application user.    Application name.    Priority of the application.          ContainerLaunchContext of the container in which the      ApplicationMaster is executed.              maxAppAttempts. The maximum number of application attempts.      It should be no larger than the global number of max attempts in the      Yarn configuration.              attemptFailuresValidityInterval. The default value is -1.      when attemptFailuresValidityInterval in milliseconds is set to      > 0, the failure number will no take failures which happen      out of the validityInterval into failure count. If failure count      reaches to maxAppAttempts, the application will be failed.        Optional, application-specific LogAggregationContext   See Also:ContainerLaunchContext,  ApplicationClientProtocol.submitApplication(org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest) Constructor Summary Constructors  Constructor and Description ApplicationSubmissionContext()  Method Summary Methods  Modifier and Type Method and Description abstract ResourceRequest getAMContainerResourceRequest() Get ResourceRequest of AM container, if this is not null, scheduler will  use this to acquire resource for AM container. abstract ContainerLaunchContext getAMContainerSpec() Get the ContainerLaunchContext to describe the   Container with which the ApplicationMaster is  launched. abstract ApplicationId getApplicationId() Get the ApplicationId of the submitted application. abstract String getApplicationName() Get the application name. abstract Set<String> getApplicationTags() Get tags for the application abstract String getApplicationType() Get the application type abstract long getAttemptFailuresValidityInterval() Get the attemptFailuresValidityInterval in milliseconds for the application abstract boolean getKeepContainersAcrossApplicationAttempts() Get the flag which indicates whether to keep containers across application  attempts or not. abstract LogAggregationContext getLogAggregationContext() Get LogAggregationContext of the application abstract int getMaxAppAttempts()  abstract String getNodeLabelExpression() Get node-label-expression for this app. abstract Priority getPriority() Get the Priority of the application. abstract String getQueue() Get the queue to which the application is being submitted. abstract ReservationId getReservationID() Get the reservation id, that corresponds to a valid resource allocation in  the scheduler (between start and end time of the corresponding reservation) abstract Resource getResource() Get the resource required by the ApplicationMaster for this  application. abstract boolean getUnmanagedAM() Get if the RM should manage the execution of the AM. static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                       String applicationName,                       String queue,                       ContainerLaunchContext amContainer,                       boolean isUnmanagedAM,                       boolean cancelTokensWhenComplete,                       int maxAppAttempts,                       String applicationType,                       boolean keepContainers,                       String appLabelExpression,                       ResourceRequest resourceRequest)  static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                       String applicationName,                       String queue,                       Priority priority,                       ContainerLaunchContext amContainer,                       boolean isUnmanagedAM,                       boolean cancelTokensWhenComplete,                       int maxAppAttempts,                       Resource resource)  static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                       String applicationName,                       String queue,                       Priority priority,                       ContainerLaunchContext amContainer,                       boolean isUnmanagedAM,                       boolean cancelTokensWhenComplete,                       int maxAppAttempts,                       Resource resource,                       String applicationType)  static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                       String applicationName,                       String queue,                       Priority priority,                       ContainerLaunchContext amContainer,                       boolean isUnmanagedAM,                       boolean cancelTokensWhenComplete,                       int maxAppAttempts,                       Resource resource,                       String applicationType,                       boolean keepContainers)  static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                       String applicationName,                       String queue,                       Priority priority,                       ContainerLaunchContext amContainer,                       boolean isUnmanagedAM,                       boolean cancelTokensWhenComplete,                       int maxAppAttempts,                       Resource resource,                       String applicationType,                       boolean keepContainers,                       LogAggregationContext logAggregationContext)  static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                       String applicationName,                       String queue,                       Priority priority,                       ContainerLaunchContext amContainer,                       boolean isUnmanagedAM,                       boolean cancelTokensWhenComplete,                       int maxAppAttempts,                       Resource resource,                       String applicationType,                       boolean keepContainers,                       long attemptFailuresValidityInterval)  static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                       String applicationName,                       String queue,                       Priority priority,                       ContainerLaunchContext amContainer,                       boolean isUnmanagedAM,                       boolean cancelTokensWhenComplete,                       int maxAppAttempts,                       Resource resource,                       String applicationType,                       boolean keepContainers,                       String appLabelExpression,                       String amContainerLabelExpression)  abstract void setAMContainerResourceRequest(ResourceRequest request) Set ResourceRequest of AM container abstract void setAMContainerSpec(ContainerLaunchContext amContainer) Set the ContainerLaunchContext to describe the   Container with which the ApplicationMaster is  launched. abstract void setApplicationId(ApplicationId applicationId) Set the ApplicationId of the submitted application. abstract void setApplicationName(String applicationName) Set the application name. abstract void setApplicationTags(Set<String> tags) Set tags for the application. abstract void setApplicationType(String applicationType) Set the application type abstract void setAttemptFailuresValidityInterval(long attemptFailuresValidityInterval) Set the attemptFailuresValidityInterval in milliseconds for the application abstract void setKeepContainersAcrossApplicationAttempts(boolean keepContainers) Set the flag which indicates whether to keep containers across application  attempts. abstract void setLogAggregationContext(LogAggregationContext logAggregationContext) Set LogAggregationContext for the application abstract void setMaxAppAttempts(int maxAppAttempts) Set the number of max attempts of the application to be submitted. abstract void setNodeLabelExpression(String nodeLabelExpression) Set node-label-expression for this app abstract void setQueue(String queue) Set the queue to which the application is being submitted abstract void setReservationID(ReservationId reservationID) Set the reservation id, that correspond to a valid resource allocation in  the scheduler (between start and end time of the corresponding reservation) abstract void setResource(Resource resource) Set the resource required by the ApplicationMaster for this  application. abstract void setUnmanagedAM(boolean value)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ApplicationSubmissionContext public ApplicationSubmissionContext() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                                                                                           String applicationName,                                                                                           String queue,                                                                                           Priority priority,                                                                                           ContainerLaunchContext amContainer,                                                                                           boolean isUnmanagedAM,                                                                                           boolean cancelTokensWhenComplete,                                                                                           int maxAppAttempts,                                                                                           Resource resource,                                                                                           String applicationType,                                                                                           boolean keepContainers,                                                                                           String appLabelExpression,                                                                                           String amContainerLabelExpression) newInstance public static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                                        String applicationName,                                        String queue,                                        Priority priority,                                        ContainerLaunchContext amContainer,                                        boolean isUnmanagedAM,                                        boolean cancelTokensWhenComplete,                                        int maxAppAttempts,                                        Resource resource,                                        String applicationType,                                        boolean keepContainers) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                                                                                           String applicationName,                                                                                           String queue,                                                                                           Priority priority,                                                                                           ContainerLaunchContext amContainer,                                                                                           boolean isUnmanagedAM,                                                                                           boolean cancelTokensWhenComplete,                                                                                           int maxAppAttempts,                                                                                           Resource resource,                                                                                           String applicationType) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                                                                                           String applicationName,                                                                                           String queue,                                                                                           Priority priority,                                                                                           ContainerLaunchContext amContainer,                                                                                           boolean isUnmanagedAM,                                                                                           boolean cancelTokensWhenComplete,                                                                                           int maxAppAttempts,                                                                                           Resource resource) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                                                                                           String applicationName,                                                                                           String queue,                                                                                           ContainerLaunchContext amContainer,                                                                                           boolean isUnmanagedAM,                                                                                           boolean cancelTokensWhenComplete,                                                                                           int maxAppAttempts,                                                                                           String applicationType,                                                                                           boolean keepContainers,                                                                                           String appLabelExpression,                                                                                           ResourceRequest resourceRequest) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                                                                                           String applicationName,                                                                                           String queue,                                                                                           Priority priority,                                                                                           ContainerLaunchContext amContainer,                                                                                           boolean isUnmanagedAM,                                                                                           boolean cancelTokensWhenComplete,                                                                                           int maxAppAttempts,                                                                                           Resource resource,                                                                                           String applicationType,                                                                                           boolean keepContainers,                                                                                           long attemptFailuresValidityInterval) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ApplicationSubmissionContext newInstance(ApplicationId applicationId,                                                                                           String applicationName,                                                                                           String queue,                                                                                           Priority priority,                                                                                           ContainerLaunchContext amContainer,                                                                                           boolean isUnmanagedAM,                                                                                           boolean cancelTokensWhenComplete,                                                                                           int maxAppAttempts,                                                                                           Resource resource,                                                                                           String applicationType,                                                                                           boolean keepContainers,                                                                                           LogAggregationContext logAggregationContext) getApplicationId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationId getApplicationId() Get the ApplicationId of the submitted application. Returns:ApplicationId of the submitted application setApplicationId @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setApplicationId(ApplicationId applicationId) Set the ApplicationId of the submitted application. Parameters:applicationId - ApplicationId of the submitted                       application getApplicationName @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getApplicationName() Get the application name. Returns:application name setApplicationName @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setApplicationName(String applicationName) Set the application name. Parameters:applicationName - application name getQueue @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getQueue() Get the queue to which the application is being submitted. Returns:queue to which the application is being submitted setQueue @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setQueue(String queue) Set the queue to which the application is being submitted Parameters:queue - queue to which the application is being submitted getPriority @InterfaceAudience.Public @InterfaceStability.Stable public abstract Priority getPriority() Get the Priority of the application. Returns:Priority of the application getAMContainerSpec @InterfaceAudience.Public @InterfaceStability.Stable public abstract ContainerLaunchContext getAMContainerSpec() Get the ContainerLaunchContext to describe the   Container with which the ApplicationMaster is  launched. Returns:ContainerLaunchContext for the           ApplicationMaster container setAMContainerSpec @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setAMContainerSpec(ContainerLaunchContext amContainer) Set the ContainerLaunchContext to describe the   Container with which the ApplicationMaster is  launched. Parameters:amContainer - ContainerLaunchContext for the                      ApplicationMaster container getUnmanagedAM @InterfaceAudience.Public @InterfaceStability.Stable public abstract boolean getUnmanagedAM() Get if the RM should manage the execution of the AM.   If true, then the RM   will not allocate a container for the AM and start it. It will expect the   AM to be launched and connect to the RM within the AM liveliness period and   fail the app otherwise. The client should launch the AM only after the RM   has ACCEPTED the application and changed the YarnApplicationState.  Such apps will not be retried by the RM on app attempt failure.  The default value is false. Returns:true if the AM is not managed by the RM setUnmanagedAM @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setUnmanagedAM(boolean value) Parameters:value - true if RM should not manage the AM getMaxAppAttempts @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getMaxAppAttempts() Returns:the number of max attempts of the application to be submitted setMaxAppAttempts @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setMaxAppAttempts(int maxAppAttempts) Set the number of max attempts of the application to be submitted. WARNING:  it should be no larger than the global number of max attempts in the Yarn  configuration. Parameters:maxAppAttempts - the number of max attempts of the application  to be submitted. getResource @InterfaceAudience.Public public abstract Resource getResource() Get the resource required by the ApplicationMaster for this  application. Please note this will be DEPRECATED, use getResource  in getAMContainerResourceRequest instead. Returns:the resource required by the ApplicationMaster for          this application. setResource @InterfaceAudience.Public public abstract void setResource(Resource resource) Set the resource required by the ApplicationMaster for this  application. Parameters:resource - the resource required by the ApplicationMaster  for this application. getApplicationType @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getApplicationType() Get the application type Returns:the application type setApplicationType @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setApplicationType(String applicationType) Set the application type Parameters:applicationType - the application type getKeepContainersAcrossApplicationAttempts @InterfaceAudience.Public @InterfaceStability.Stable public abstract boolean getKeepContainersAcrossApplicationAttempts() Get the flag which indicates whether to keep containers across application  attempts or not. Returns:the flag which indicates whether to keep containers across          application attempts or not. setKeepContainersAcrossApplicationAttempts @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setKeepContainersAcrossApplicationAttempts(boolean keepContainers) Set the flag which indicates whether to keep containers across application  attempts.    If the flag is true, running containers will not be killed when application  attempt fails and these containers will be retrieved by the new application  attempt on registration via  ApplicationMasterProtocol.registerApplicationMaster(RegisterApplicationMasterRequest).   Parameters:keepContainers - the flag which indicates whether to keep containers across           application attempts. getApplicationTags @InterfaceAudience.Public @InterfaceStability.Stable public abstract Set<String> getApplicationTags() Get tags for the application Returns:the application tags setApplicationTags @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setApplicationTags(Set<String> tags) Set tags for the application. A maximum of  YarnConfiguration.APPLICATION_MAX_TAGS are allowed  per application. Each tag can be at most  YarnConfiguration.APPLICATION_MAX_TAG_LENGTH  characters, and can contain only ASCII characters. Parameters:tags - tags to set getNodeLabelExpression @InterfaceAudience.Public @InterfaceStability.Evolving public abstract String getNodeLabelExpression() Get node-label-expression for this app. If this is set, all containers of  this application without setting node-label-expression in ResurceRequest  will get allocated resources on only those nodes that satisfy this  node-label-expression.    If different node-label-expression of this app and ResourceRequest are set  at the same time, the one set in ResourceRequest will be used when  allocating container Returns:node-label-expression for this app setNodeLabelExpression @InterfaceAudience.Public @InterfaceStability.Evolving public abstract void setNodeLabelExpression(String nodeLabelExpression) Set node-label-expression for this app Parameters:nodeLabelExpression - node-label-expression of this app getAMContainerResourceRequest @InterfaceAudience.Public @InterfaceStability.Evolving public abstract ResourceRequest getAMContainerResourceRequest() Get ResourceRequest of AM container, if this is not null, scheduler will  use this to acquire resource for AM container.    If this is null, scheduler will assemble a ResourceRequest by using  getResource and getPriority of  ApplicationSubmissionContext.    Number of containers and Priority will be ignore. Returns:ResourceRequest of AM container setAMContainerResourceRequest @InterfaceAudience.Public @InterfaceStability.Evolving public abstract void setAMContainerResourceRequest(ResourceRequest request) Set ResourceRequest of AM container Parameters:request - of AM container getAttemptFailuresValidityInterval @InterfaceAudience.Public @InterfaceStability.Stable public abstract long getAttemptFailuresValidityInterval() Get the attemptFailuresValidityInterval in milliseconds for the application Returns:the attemptFailuresValidityInterval setAttemptFailuresValidityInterval @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setAttemptFailuresValidityInterval(long attemptFailuresValidityInterval) Set the attemptFailuresValidityInterval in milliseconds for the application Parameters:attemptFailuresValidityInterval -  getLogAggregationContext @InterfaceAudience.Public @InterfaceStability.Stable public abstract LogAggregationContext getLogAggregationContext() Get LogAggregationContext of the application Returns:LogAggregationContext of the application setLogAggregationContext @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setLogAggregationContext(LogAggregationContext logAggregationContext) Set LogAggregationContext for the application Parameters:logAggregationContext - for the application getReservationID @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationId getReservationID() Get the reservation id, that corresponds to a valid resource allocation in  the scheduler (between start and end time of the corresponding reservation) Returns:the reservation id representing the unique id of the corresponding          reserved resource allocation in the scheduler setReservationID @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setReservationID(ReservationId reservationID) Set the reservation id, that correspond to a valid resource allocation in  the scheduler (between start and end time of the corresponding reservation) Parameters:reservationID - representing the unique id of the           corresponding reserved resource allocation in the scheduler Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ApplicationsRequestScope (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ApplicationsRequestScope (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.protocolrecords Enum ApplicationsRequestScope java.lang.Object java.lang.Enum<ApplicationsRequestScope> org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope All Implemented Interfaces: Serializable, Comparable<ApplicationsRequestScope> @InterfaceAudience.Public @InterfaceStability.Unstable public enum ApplicationsRequestScope extends Enum<ApplicationsRequestScope> Enumeration that controls the scope of applications fetched Enum Constant Summary Enum Constants  Enum Constant and Description ALL All jobs OWN Jobs owned by current user VIEWABLE Jobs viewable by current user Method Summary Methods  Modifier and Type Method and Description static ApplicationsRequestScope valueOf(String name) Returns the enum constant of this type with the specified name. static ApplicationsRequestScope[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail ALL public static final ApplicationsRequestScope ALL All jobs VIEWABLE public static final ApplicationsRequestScope VIEWABLE Jobs viewable by current user OWN public static final ApplicationsRequestScope OWN Jobs owned by current user Method Detail values public static ApplicationsRequestScope[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (ApplicationsRequestScope c : ApplicationsRequestScope.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static ApplicationsRequestScope valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ArrayFile (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ArrayFile (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class ArrayFile java.lang.Object org.apache.hadoop.io.MapFile org.apache.hadoop.io.ArrayFile @InterfaceAudience.Public @InterfaceStability.Stable public class ArrayFile extends MapFile A dense file-based mapping from integers to values. Field Summary Fields inherited from class org.apache.hadoop.io.MapFile DATA_FILE_NAME, INDEX_FILE_NAME Constructor Summary Constructors  Modifier Constructor and Description protected  ArrayFile()  Method Summary Methods inherited from class org.apache.hadoop.io.MapFile delete, fix, main, rename Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ArrayFile protected ArrayFile() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ArrayListBackedIterator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ArrayListBackedIterator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class ArrayListBackedIterator<X extends Writable> java.lang.Object org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator<X> All Implemented Interfaces: ResetableIterator<X> Direct Known Subclasses: ArrayListBackedIterator @InterfaceAudience.Public @InterfaceStability.Stable public class ArrayListBackedIterator<X extends Writable> extends Object implements ResetableIterator<X> This class provides an implementation of ResetableIterator. The  implementation uses an ArrayList to store elements  added to it, replaying them as requested.  Prefer StreamBackedIterator. Constructor Summary Constructors  Constructor and Description ArrayListBackedIterator()  ArrayListBackedIterator(ArrayList<X> data)  Method Summary Methods  Modifier and Type Method and Description void add(X item) Add an element to the collection of elements to iterate over. void clear() Close datasources, but do not release internal resources. void close() Close datasources and release resources. boolean hasNext() True if a call to next may return a value. boolean next(X val) Assign next value to actual. boolean replay(X val) Assign last value returned to actual. void reset() Set iterator to return to the start of its range. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ArrayListBackedIterator public ArrayListBackedIterator() ArrayListBackedIterator public ArrayListBackedIterator(ArrayList<X> data) Method Detail hasNext public boolean hasNext() Description copied from interface: ResetableIterator True if a call to next may return a value. This is permitted false  positives, but not false negatives. Specified by: hasNext in interface ResetableIterator<X extends Writable> next public boolean next(X val)              throws IOException Description copied from interface: ResetableIterator Assign next value to actual.  It is required that elements added to a ResetableIterator be returned in  the same order after a call to ResetableIterator.reset() (FIFO).  Note that a call to this may fail for nested joins (i.e. more elements  available, but none satisfying the constraints of the join) Specified by: next in interface ResetableIterator<X extends Writable> Throws: IOException replay public boolean replay(X val)                throws IOException Description copied from interface: ResetableIterator Assign last value returned to actual. Specified by: replay in interface ResetableIterator<X extends Writable> Throws: IOException reset public void reset() Description copied from interface: ResetableIterator Set iterator to return to the start of its range. Must be called after  calling ResetableIterator.add(T) to avoid a ConcurrentModificationException. Specified by: reset in interface ResetableIterator<X extends Writable> add public void add(X item)          throws IOException Description copied from interface: ResetableIterator Add an element to the collection of elements to iterate over. Specified by: add in interface ResetableIterator<X extends Writable> Throws: IOException close public void close()            throws IOException Description copied from interface: ResetableIterator Close datasources and release resources. Calling methods on the iterator  after calling close has undefined behavior. Specified by: close in interface ResetableIterator<X extends Writable> Throws: IOException clear public void clear() Description copied from interface: ResetableIterator Close datasources, but do not release internal resources. Calling this  method should permit the object to be reused with a different datasource. Specified by: clear in interface ResetableIterator<X extends Writable> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ArrayPrimitiveWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ArrayPrimitiveWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class ArrayPrimitiveWritable java.lang.Object org.apache.hadoop.io.ArrayPrimitiveWritable All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class ArrayPrimitiveWritable extends Object implements Writable This is a wrapper class.  It wraps a Writable implementation around  an array of primitives (e.g., int[], long[], etc.), with optimized   wire format, and without creating new objects per element.    This is a wrapper class only; it does not make a copy of the   underlying array. Constructor Summary Constructors  Constructor and Description ArrayPrimitiveWritable() Construct an empty instance, for use during Writable read ArrayPrimitiveWritable(Class<?> componentType) Construct an instance of known type but no value yet  for use with type-specific wrapper classes ArrayPrimitiveWritable(Object value) Wrap an existing array of primitives Method Summary Methods  Modifier and Type Method and Description Object get() Get the original array. Class<?> getComponentType()  Class<?> getDeclaredComponentType()  boolean isDeclaredComponentType(Class<?> componentType)  void readFields(DataInput in) Deserialize the fields of this object from in. void set(Object value)  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ArrayPrimitiveWritable public ArrayPrimitiveWritable() Construct an empty instance, for use during Writable read ArrayPrimitiveWritable public ArrayPrimitiveWritable(Class<?> componentType) Construct an instance of known type but no value yet  for use with type-specific wrapper classes ArrayPrimitiveWritable public ArrayPrimitiveWritable(Object value) Wrap an existing array of primitives Parameters:value - - array of primitives Method Detail get public Object get() Get the original array.    Client must cast it back to type componentType[]  (or may use type-specific wrapper classes). Returns:- original array as Object getComponentType public Class<?> getComponentType() getDeclaredComponentType public Class<?> getDeclaredComponentType() isDeclaredComponentType public boolean isDeclaredComponentType(Class<?> componentType) set public void set(Object value) write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ArrayWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ArrayWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class ArrayWritable java.lang.Object org.apache.hadoop.io.ArrayWritable All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class ArrayWritable extends Object implements Writable A Writable for arrays containing instances of a class. The elements of this  writable must all be instances of the same class. If this writable will be  the input for a Reducer, you will need to create a subclass that sets the  value to be of the proper type.  For example:    public class IntArrayWritable extends ArrayWritable {    public IntArrayWritable() {       super(IntWritable.class);     }      }   Constructor Summary Constructors  Constructor and Description ArrayWritable(Class<? extends Writable> valueClass)  ArrayWritable(Class<? extends Writable> valueClass,                           Writable[] values)  ArrayWritable(String[] strings)  Method Summary Methods  Modifier and Type Method and Description Writable[] get()  Class getValueClass()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(Writable[] values)  Object toArray()  String[] toStrings()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ArrayWritable public ArrayWritable(Class<? extends Writable> valueClass) ArrayWritable public ArrayWritable(Class<? extends Writable> valueClass,              Writable[] values) ArrayWritable public ArrayWritable(String[] strings) Method Detail getValueClass public Class getValueClass() toStrings public String[] toStrings() toArray public Object toArray() set public void set(Writable[] values) get public Writable[] get() readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AsyncDispatcher (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AsyncDispatcher (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.event Class AsyncDispatcher java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.event.AsyncDispatcher All Implemented Interfaces: Closeable, AutoCloseable, Service, Dispatcher @InterfaceAudience.Public @InterfaceStability.Evolving public class AsyncDispatcher extends AbstractService implements Dispatcher Dispatches Events in a separate thread. Currently only single thread  does that. Potentially there could be multiple channels for each event type  class and a thread pool can be used to dispatch the events. Field Summary Fields  Modifier and Type Field and Description protected Map<Class<? extends Enum>,EventHandler> eventDispatchers  Fields inherited from interface org.apache.hadoop.yarn.event.Dispatcher DEFAULT_DISPATCHER_EXIT_ON_ERROR, DISPATCHER_EXIT_ON_ERROR_KEY Constructor Summary Constructors  Constructor and Description AsyncDispatcher()  AsyncDispatcher(BlockingQueue<Event> eventQueue)  Method Summary Methods  Modifier and Type Method and Description protected void dispatch(Event event)  EventHandler getEventHandler()  protected boolean isDrained()  protected boolean isEventThreadWaiting()  void register(Class<? extends Enum> eventType,                 EventHandler handler)  protected void serviceInit(Configuration conf) All initialization code needed by a service. protected void serviceStart() Actions called during the INITED to STARTED transition. protected void serviceStop() Actions called during the transition to the STOPPED state. void setDrainEventsOnStop()  Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail eventDispatchers protected final Map<Class<? extends Enum>,EventHandler> eventDispatchers Constructor Detail AsyncDispatcher public AsyncDispatcher() AsyncDispatcher public AsyncDispatcher(BlockingQueue<Event> eventQueue) Method Detail serviceInit protected void serviceInit(Configuration conf)                     throws Exception Description copied from class: AbstractService All initialization code needed by a service.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.init(Configuration) prevents re-entrancy.  The base implementation checks to see if the subclass has created  a new configuration instance, and if so, updates the base class value Overrides: serviceInit in class AbstractService Parameters:conf - configuration Throws: Exception - on a failure -these will be caught,  possibly wrapped, and wil; trigger a service stop serviceStart protected void serviceStart()                      throws Exception Description copied from class: AbstractService Actions called during the INITED to STARTED transition.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.start() prevents re-entrancy. Overrides: serviceStart in class AbstractService Throws: Exception - if needed -these will be caught,  wrapped, and trigger a service stop setDrainEventsOnStop public void setDrainEventsOnStop() serviceStop protected void serviceStop()                     throws Exception Description copied from class: AbstractService Actions called during the transition to the STOPPED state.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.stop() prevents re-entrancy.  Implementations MUST write this to be robust against failures, including  checks for null references -and for the first failure to not stop other  attempts to shut down parts of the service. Overrides: serviceStop in class AbstractService Throws: Exception - if needed -these will be caught and logged. dispatch protected void dispatch(Event event) register public void register(Class<? extends Enum> eventType,             EventHandler handler) Specified by: register in interface Dispatcher getEventHandler public EventHandler getEventHandler() Specified by: getEventHandler in interface Dispatcher isEventThreadWaiting protected boolean isEventThreadWaiting() isDrained protected boolean isDrained() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AvroFSInput (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AvroFSInput (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class AvroFSInput java.lang.Object org.apache.hadoop.fs.AvroFSInput All Implemented Interfaces: Closeable, AutoCloseable, org.apache.avro.file.SeekableInput @InterfaceAudience.Public @InterfaceStability.Stable public class AvroFSInput extends Object implements Closeable, org.apache.avro.file.SeekableInput Adapts an FSDataInputStream to Avro's SeekableInput interface. Constructor Summary Constructors  Constructor and Description AvroFSInput(FileContext fc,                       Path p) Construct given a FileContext and a Path. AvroFSInput(FSDataInputStream in,                       long len) Construct given an FSDataInputStream and its length. Method Summary Methods  Modifier and Type Method and Description void close()  long length()  int read(byte[] b,         int off,         int len)  void seek(long p)  long tell()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AvroFSInput public AvroFSInput(FSDataInputStream in,            long len) Construct given an FSDataInputStream and its length. AvroFSInput public AvroFSInput(FileContext fc,            Path p)             throws IOException Construct given a FileContext and a Path. Throws: IOException Method Detail length public long length() Specified by: length in interface org.apache.avro.file.SeekableInput read public int read(byte[] b,        int off,        int len)          throws IOException Specified by: read in interface org.apache.avro.file.SeekableInput Throws: IOException seek public void seek(long p)           throws IOException Specified by: seek in interface org.apache.avro.file.SeekableInput Throws: IOException tell public long tell()           throws IOException Specified by: tell in interface org.apache.avro.file.SeekableInput Throws: IOException close public void close()            throws IOException Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AvroReflectSerializable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AvroReflectSerializable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.serializer.avro Interface AvroReflectSerializable @InterfaceAudience.Public @InterfaceStability.Evolving public interface AvroReflectSerializable Tag interface for Avro 'reflect' serializable classes. Classes implementing   this interface can be serialized/deserialized using   AvroReflectSerialization. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AvroReflectSerialization (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AvroReflectSerialization (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.serializer.avro Class AvroReflectSerialization java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.io.serializer.avro.AvroSerialization<Object> org.apache.hadoop.io.serializer.avro.AvroReflectSerialization All Implemented Interfaces: Configurable, org.apache.hadoop.io.serializer.Serialization<Object> @InterfaceAudience.Public @InterfaceStability.Evolving public class AvroReflectSerialization extends AvroSerialization<Object> Serialization for Avro Reflect classes. For a class to be accepted by this   serialization, it must either be in the package list configured via   avro.reflect.pkgs or implement   AvroReflectSerializable interface. Constructor Summary Constructors  Constructor and Description AvroReflectSerialization()  Method Summary Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AvroReflectSerialization public AvroReflectSerialization() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AvroSerialization (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AvroSerialization (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.serializer.avro Class AvroSerialization<T> java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.io.serializer.avro.AvroSerialization<T> All Implemented Interfaces: Configurable, org.apache.hadoop.io.serializer.Serialization<T> Direct Known Subclasses: AvroReflectSerialization, AvroSpecificSerialization @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class AvroSerialization<T> extends Configured implements org.apache.hadoop.io.serializer.Serialization<T> Base class for providing serialization to Avro types. Constructor Summary Constructors  Constructor and Description AvroSerialization()  Method Summary Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.io.serializer.Serialization accept Constructor Detail AvroSerialization public AvroSerialization() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AvroSpecificSerialization (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AvroSpecificSerialization (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.serializer.avro Class AvroSpecificSerialization java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.io.serializer.avro.AvroSerialization<org.apache.avro.specific.SpecificRecord> org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization All Implemented Interfaces: Configurable, org.apache.hadoop.io.serializer.Serialization<org.apache.avro.specific.SpecificRecord> @InterfaceAudience.Public @InterfaceStability.Evolving public class AvroSpecificSerialization extends AvroSerialization<org.apache.avro.specific.SpecificRecord> Serialization for Avro Specific classes. This serialization is to be used   for classes generated by Avro's 'specific' compiler. Constructor Summary Constructors  Constructor and Description AvroSpecificSerialization()  Method Summary Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail AvroSpecificSerialization public AvroSpecificSerialization() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AzureException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AzureException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.azure Class AzureException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.azure.AzureException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class AzureException extends IOException Thrown if there is a problem communicating with Azure Storage service. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description AzureException(String message)  AzureException(String message,                             Throwable cause)  AzureException(Throwable t)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail AzureException public AzureException(String message) AzureException public AzureException(String message,               Throwable cause) AzureException public AzureException(Throwable t) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  AzureFileSystemInstrumentation (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="AzureFileSystemInstrumentation (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.azure.metrics Class AzureFileSystemInstrumentation java.lang.Object org.apache.hadoop.fs.azure.metrics.AzureFileSystemInstrumentation All Implemented Interfaces: MetricsSource @Metrics(about="Metrics for WASB",          context="azureFileSystem") @InterfaceAudience.Public @InterfaceStability.Evolving public final class AzureFileSystemInstrumentation extends Object implements MetricsSource A metrics source for the WASB file system to track all the metrics we care  about for getting a clear picture of the performance/reliability/interaction  of the Hadoop cluster with Azure Storage. Field Summary Fields  Modifier and Type Field and Description static String METRIC_TAG_ACCOUNT_NAME  static String METRIC_TAG_CONTAINTER_NAME  static String METRIC_TAG_FILESYSTEM_ID  static String WASB_BYTES_READ  static String WASB_BYTES_WRITTEN  static String WASB_CLIENT_ERRORS  static String WASB_DIRECTORIES_CREATED  static String WASB_DIRECTORIES_DELETED  static String WASB_DOWNLOAD_LATENCY  static String WASB_DOWNLOAD_RATE  static String WASB_FILES_CREATED  static String WASB_FILES_DELETED  static String WASB_RAW_BYTES_DOWNLOADED  static String WASB_RAW_BYTES_UPLOADED  static String WASB_SERVER_ERRORS  static String WASB_UPLOAD_LATENCY  static String WASB_UPLOAD_RATE  static String WASB_WEB_RESPONSES  Constructor Summary Constructors  Constructor and Description AzureFileSystemInstrumentation(Configuration conf)  Method Summary Methods  Modifier and Type Method and Description void blockDownloaded(long latency) Indicate that we just downloaded a block and record its latency. void blockUploaded(long latency) Indicate that we just uploaded a block and record its latency. void clientErrorEncountered() Indicate that we just encountered a client-side error. void currentDownloadBytesPerSecond(long bytesPerSecond) Record the current bytes-per-second download rate seen. void currentUploadBytesPerSecond(long bytesPerSecond) Record the current bytes-per-second upload rate seen. void directoryCreated() Indicate that we just created a directory through WASB. void directoryDeleted() Indicate that we just deleted a directory through WASB. void fileCreated() Indicate that we just created a file through WASB. void fileDeleted() Indicate that we just deleted a file through WASB. long getBlockDownloadLatency() Get the current rolling average of the download latency. long getBlockUploadLatency() Get the current rolling average of the upload latency. long getCurrentMaximumDownloadBandwidth() Get the current maximum download bandwidth. long getCurrentMaximumUploadBandwidth() Get the current maximum upload bandwidth. long getCurrentWebResponses() Gets the current number of web responses obtained from Azure Storage. UUID getFileSystemInstanceId() The unique identifier for this file system in the metrics. void getMetrics(MetricsCollector builder,                     boolean all) Get metrics from the source MetricsInfo getMetricsRegistryInfo() Get the metrics registry information. void rawBytesDownloaded(long numberOfBytes) Indicate that we just downloaded some data to Azure storage. void rawBytesUploaded(long numberOfBytes) Indicate that we just uploaded some data to Azure storage. void serverErrorEncountered() Indicate that we just encountered a server-caused error. void setAccountName(String accountName) Sets the account name to tag all the metrics with. void setContainerName(String containerName) Sets the container name to tag all the metrics with. void updateBytesReadInLastSecond(long currentBytesRead) Sets the current gauge value for how many bytes were read in the last   second. void updateBytesWrittenInLastSecond(long currentBytesWritten) Sets the current gauge value for how many bytes were written in the last   second. void webResponse() Indicate that we just got a web response from Azure Storage. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail METRIC_TAG_FILESYSTEM_ID public static final String METRIC_TAG_FILESYSTEM_ID See Also:Constant Field Values METRIC_TAG_ACCOUNT_NAME public static final String METRIC_TAG_ACCOUNT_NAME See Also:Constant Field Values METRIC_TAG_CONTAINTER_NAME public static final String METRIC_TAG_CONTAINTER_NAME See Also:Constant Field Values WASB_WEB_RESPONSES public static final String WASB_WEB_RESPONSES See Also:Constant Field Values WASB_BYTES_WRITTEN public static final String WASB_BYTES_WRITTEN See Also:Constant Field Values WASB_BYTES_READ public static final String WASB_BYTES_READ See Also:Constant Field Values WASB_RAW_BYTES_UPLOADED public static final String WASB_RAW_BYTES_UPLOADED See Also:Constant Field Values WASB_RAW_BYTES_DOWNLOADED public static final String WASB_RAW_BYTES_DOWNLOADED See Also:Constant Field Values WASB_FILES_CREATED public static final String WASB_FILES_CREATED See Also:Constant Field Values WASB_FILES_DELETED public static final String WASB_FILES_DELETED See Also:Constant Field Values WASB_DIRECTORIES_CREATED public static final String WASB_DIRECTORIES_CREATED See Also:Constant Field Values WASB_DIRECTORIES_DELETED public static final String WASB_DIRECTORIES_DELETED See Also:Constant Field Values WASB_UPLOAD_RATE public static final String WASB_UPLOAD_RATE See Also:Constant Field Values WASB_DOWNLOAD_RATE public static final String WASB_DOWNLOAD_RATE See Also:Constant Field Values WASB_UPLOAD_LATENCY public static final String WASB_UPLOAD_LATENCY See Also:Constant Field Values WASB_DOWNLOAD_LATENCY public static final String WASB_DOWNLOAD_LATENCY See Also:Constant Field Values WASB_CLIENT_ERRORS public static final String WASB_CLIENT_ERRORS See Also:Constant Field Values WASB_SERVER_ERRORS public static final String WASB_SERVER_ERRORS See Also:Constant Field Values Constructor Detail AzureFileSystemInstrumentation public AzureFileSystemInstrumentation(Configuration conf) Method Detail getFileSystemInstanceId public UUID getFileSystemInstanceId() The unique identifier for this file system in the metrics. getMetricsRegistryInfo public MetricsInfo getMetricsRegistryInfo() Get the metrics registry information. setAccountName public void setAccountName(String accountName) Sets the account name to tag all the metrics with. Parameters:accountName - The account name. setContainerName public void setContainerName(String containerName) Sets the container name to tag all the metrics with. Parameters:containerName - The container name. webResponse public void webResponse() Indicate that we just got a web response from Azure Storage. This should  be called for every web request/response we do (to get accurate metrics  of how we're hitting the storage service). getCurrentWebResponses public long getCurrentWebResponses() Gets the current number of web responses obtained from Azure Storage. Returns:The number of web responses. fileCreated public void fileCreated() Indicate that we just created a file through WASB. fileDeleted public void fileDeleted() Indicate that we just deleted a file through WASB. directoryCreated public void directoryCreated() Indicate that we just created a directory through WASB. directoryDeleted public void directoryDeleted() Indicate that we just deleted a directory through WASB. updateBytesWrittenInLastSecond public void updateBytesWrittenInLastSecond(long currentBytesWritten) Sets the current gauge value for how many bytes were written in the last   second. Parameters:currentBytesWritten - The number of bytes. updateBytesReadInLastSecond public void updateBytesReadInLastSecond(long currentBytesRead) Sets the current gauge value for how many bytes were read in the last   second. Parameters:currentBytesRead - The number of bytes. currentUploadBytesPerSecond public void currentUploadBytesPerSecond(long bytesPerSecond) Record the current bytes-per-second upload rate seen. Parameters:bytesPerSecond - The bytes per second. currentDownloadBytesPerSecond public void currentDownloadBytesPerSecond(long bytesPerSecond) Record the current bytes-per-second download rate seen. Parameters:bytesPerSecond - The bytes per second. rawBytesUploaded public void rawBytesUploaded(long numberOfBytes) Indicate that we just uploaded some data to Azure storage. Parameters:numberOfBytes - The raw number of bytes uploaded (including overhead). rawBytesDownloaded public void rawBytesDownloaded(long numberOfBytes) Indicate that we just downloaded some data to Azure storage. Parameters:numberOfBytes - The raw number of bytes downloaded (including overhead). blockUploaded public void blockUploaded(long latency) Indicate that we just uploaded a block and record its latency. Parameters:latency - The latency in milliseconds. blockDownloaded public void blockDownloaded(long latency) Indicate that we just downloaded a block and record its latency. Parameters:latency - The latency in milliseconds. clientErrorEncountered public void clientErrorEncountered() Indicate that we just encountered a client-side error. serverErrorEncountered public void serverErrorEncountered() Indicate that we just encountered a server-caused error. getBlockUploadLatency public long getBlockUploadLatency() Get the current rolling average of the upload latency. Returns:rolling average of upload latency in milliseconds. getBlockDownloadLatency public long getBlockDownloadLatency() Get the current rolling average of the download latency. Returns:rolling average of download latency in milliseconds. getCurrentMaximumUploadBandwidth public long getCurrentMaximumUploadBandwidth() Get the current maximum upload bandwidth. Returns:maximum upload bandwidth in bytes per second. getCurrentMaximumDownloadBandwidth public long getCurrentMaximumDownloadBandwidth() Get the current maximum download bandwidth. Returns:maximum download bandwidth in bytes per second. getMetrics public void getMetrics(MetricsCollector builder,               boolean all) Description copied from interface: MetricsSource Get metrics from the source Specified by: getMetrics in interface MetricsSource Parameters:builder - to contain the resulting metrics snapshotall - if true, return all metrics even if unchanged. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BZip2Codec (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BZip2Codec (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class BZip2Codec java.lang.Object org.apache.hadoop.io.compress.BZip2Codec All Implemented Interfaces: Configurable, CompressionCodec, SplittableCompressionCodec @InterfaceAudience.Public @InterfaceStability.Evolving public class BZip2Codec extends Object implements Configurable, SplittableCompressionCodec This class provides output and input streams for bzip2 compression  and decompression.  It uses the native bzip2 library on the system  if possible, else it uses a pure-Java implementation of the bzip2  algorithm.  The configuration parameter  io.compression.codec.bzip2.library can be used to control this  behavior.  In the pure-Java mode, the Compressor and Decompressor interfaces  are not implemented.  Therefore, in that mode, those methods of  CompressionCodec which have a Compressor or Decompressor type  argument, throw UnsupportedOperationException.  Currently, support for splittability is available only in the  pure-Java mode; therefore, if a SplitCompressionInputStream is  requested, the pure-Java implementation is used, regardless of the  setting of the configuration parameter mentioned above. Constructor Summary Constructors  Constructor and Description BZip2Codec() Creates a new instance of BZip2Codec. Method Summary Methods  Modifier and Type Method and Description Compressor createCompressor() Create a new Compressor for use by this CompressionCodec. Decompressor createDecompressor() Create a new Decompressor for use by this CompressionCodec. CompressionInputStream createInputStream(InputStream in) Create a CompressionInputStream that will read from the given  input stream and return a stream for uncompressed data. CompressionInputStream createInputStream(InputStream in,                                   Decompressor decompressor) Create a CompressionInputStream that will read from the given  InputStream with the given Decompressor, and return a   stream for uncompressed data. SplitCompressionInputStream createInputStream(InputStream seekableIn,                                   Decompressor decompressor,                                   long start,                                   long end,                                   org.apache.hadoop.io.compress.SplittableCompressionCodec.READ_MODE readMode) Creates CompressionInputStream to be used to read off uncompressed data  in one of the two reading modes. CompressionOutputStream createOutputStream(OutputStream out) Create a CompressionOutputStream that will write to the given  OutputStream. CompressionOutputStream createOutputStream(OutputStream out,                                     Compressor compressor) Create a CompressionOutputStream that will write to the given  OutputStream with the given Compressor. Class<? extends Compressor> getCompressorType() Get the type of Compressor needed by this CompressionCodec. Configuration getConf() Return the configuration used by this object. Class<? extends Decompressor> getDecompressorType() Get the type of Decompressor needed by this CompressionCodec. String getDefaultExtension() .bz2 is recognized as the default extension for compressed BZip2 files void setConf(Configuration conf) Set the configuration to be used by this object. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail BZip2Codec public BZip2Codec() Creates a new instance of BZip2Codec. Method Detail setConf public void setConf(Configuration conf) Set the configuration to be used by this object. Specified by: setConf in interface Configurable Parameters:conf - the configuration object. getConf public Configuration getConf() Return the configuration used by this object. Specified by: getConf in interface Configurable Returns:the configuration object used by this objec. createOutputStream public CompressionOutputStream createOutputStream(OutputStream out)                                            throws IOException Create a CompressionOutputStream that will write to the given  OutputStream. Specified by: createOutputStream in interface CompressionCodec Parameters:out - the location for the final output stream Returns:a stream the user can write uncompressed data to, to have it           compressed Throws: IOException createOutputStream public CompressionOutputStream createOutputStream(OutputStream out,                                          Compressor compressor)                                            throws IOException Create a CompressionOutputStream that will write to the given  OutputStream with the given Compressor. Specified by: createOutputStream in interface CompressionCodec Parameters:out - the location for the final output streamcompressor - compressor to use Returns:a stream the user can write uncompressed data to, to have it           compressed Throws: IOException getCompressorType public Class<? extends Compressor> getCompressorType() Get the type of Compressor needed by this CompressionCodec. Specified by: getCompressorType in interface CompressionCodec Returns:the type of compressor needed by this codec. createCompressor public Compressor createCompressor() Create a new Compressor for use by this CompressionCodec. Specified by: createCompressor in interface CompressionCodec Returns:a new compressor for use by this codec createInputStream public CompressionInputStream createInputStream(InputStream in)                                          throws IOException Create a CompressionInputStream that will read from the given  input stream and return a stream for uncompressed data. Specified by: createInputStream in interface CompressionCodec Parameters:in - the stream to read compressed bytes from Returns:a stream to read uncompressed bytes from Throws: IOException createInputStream public CompressionInputStream createInputStream(InputStream in,                                        Decompressor decompressor)                                          throws IOException Create a CompressionInputStream that will read from the given  InputStream with the given Decompressor, and return a   stream for uncompressed data. Specified by: createInputStream in interface CompressionCodec Parameters:in - the stream to read compressed bytes fromdecompressor - decompressor to use Returns:a stream to read uncompressed bytes from Throws: IOException createInputStream public SplitCompressionInputStream createInputStream(InputStream seekableIn,                                             Decompressor decompressor,                                             long start,                                             long end,                                             org.apache.hadoop.io.compress.SplittableCompressionCodec.READ_MODE readMode)                                               throws IOException Creates CompressionInputStream to be used to read off uncompressed data  in one of the two reading modes. i.e. Continuous or Blocked reading modes Specified by: createInputStream in interface SplittableCompressionCodec Parameters:seekableIn - The InputStreamstart - The start offset into the compressed streamend - The end offset into the compressed streamreadMode - Controls whether progress is reported continuously or                  only at block boundaries. Returns:CompressionInputStream for BZip2 aligned at block boundaries Throws: IOException getDecompressorType public Class<? extends Decompressor> getDecompressorType() Get the type of Decompressor needed by this CompressionCodec. Specified by: getDecompressorType in interface CompressionCodec Returns:the type of decompressor needed by this codec. createDecompressor public Decompressor createDecompressor() Create a new Decompressor for use by this CompressionCodec. Specified by: createDecompressor in interface CompressionCodec Returns:a new decompressor for use by this codec getDefaultExtension public String getDefaultExtension() .bz2 is recognized as the default extension for compressed BZip2 files Specified by: getDefaultExtension in interface CompressionCodec Returns:A String telling the default bzip2 file extension Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BadFencingConfigurationException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BadFencingConfigurationException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha Class BadFencingConfigurationException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.ha.BadFencingConfigurationException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class BadFencingConfigurationException extends IOException Indicates that the operator has specified an invalid configuration  for fencing methods. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description BadFencingConfigurationException(String msg)  BadFencingConfigurationException(String msg,                                                                 Throwable cause)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail BadFencingConfigurationException public BadFencingConfigurationException(String msg) BadFencingConfigurationException public BadFencingConfigurationException(String msg,                                 Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BaseClientToAMTokenSecretManager (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BaseClientToAMTokenSecretManager (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.client Class BaseClientToAMTokenSecretManager java.lang.Object org.apache.hadoop.security.token.SecretManager<ClientToAMTokenIdentifier> org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager Direct Known Subclasses: ClientToAMTokenSecretManager @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class BaseClientToAMTokenSecretManager extends org.apache.hadoop.security.token.SecretManager<ClientToAMTokenIdentifier> A base SecretManager for AMs to extend and validate Client-RM tokens  issued to clients by the RM using the underlying master-key shared by RM to  the AMs on their launch. All the methods are called by either Hadoop RPC or  YARN, so this class is strictly for the purpose of inherit/extend and  register with Hadoop RPC. Constructor Summary Constructors  Constructor and Description BaseClientToAMTokenSecretManager()  Method Summary Methods inherited from class org.apache.hadoop.security.token.SecretManager checkAvailableForRead, createPassword, createSecretKey, generateSecret, retriableRetrievePassword Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail BaseClientToAMTokenSecretManager public BaseClientToAMTokenSecretManager() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BigDecimalSplitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BigDecimalSplitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class BigDecimalSplitter java.lang.Object org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter All Implemented Interfaces: DBSplitter Direct Known Subclasses: TextSplitter @InterfaceAudience.Public @InterfaceStability.Evolving public class BigDecimalSplitter extends Object implements DBSplitter Implement DBSplitter over BigDecimal values. Constructor Summary Constructors  Constructor and Description BigDecimalSplitter()  Method Summary Methods  Modifier and Type Method and Description List<InputSplit> split(Configuration conf,           ResultSet results,           String colName) Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. protected BigDecimal tryDivide(BigDecimal numerator,                   BigDecimal denominator) Divide numerator by denominator. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail BigDecimalSplitter public BigDecimalSplitter() Method Detail split public List<InputSplit> split(Configuration conf,                      ResultSet results,                      String colName)                        throws SQLException Description copied from interface: DBSplitter Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Specified by: split in interface DBSplitter Throws: SQLException tryDivide protected BigDecimal tryDivide(BigDecimal numerator,                    BigDecimal denominator) Divide numerator by denominator. If impossible in exact mode, use rounding. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BinaryComparable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BinaryComparable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class BinaryComparable java.lang.Object org.apache.hadoop.io.BinaryComparable All Implemented Interfaces: Comparable<BinaryComparable> Direct Known Subclasses: BytesWritable, Text @InterfaceAudience.Public @InterfaceStability.Stable public abstract class BinaryComparable extends Object implements Comparable<BinaryComparable> Interface supported by WritableComparable  types supporting ordering/permutation by a representative set of bytes. Constructor Summary Constructors  Constructor and Description BinaryComparable()  Method Summary Methods  Modifier and Type Method and Description int compareTo(BinaryComparable other) Compare bytes from {#getBytes()}. int compareTo(byte[] other,                   int off,                   int len) Compare bytes from {#getBytes()} to those provided. boolean equals(Object other) Return true if bytes from {#getBytes()} match. abstract byte[] getBytes() Return representative byte array for this instance. abstract int getLength() Return n st bytes 0..n-1 from {#getBytes()} are valid. int hashCode() Return a hash of the bytes returned from {#getBytes()}. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail BinaryComparable public BinaryComparable() Method Detail getLength public abstract int getLength() Return n st bytes 0..n-1 from {#getBytes()} are valid. getBytes public abstract byte[] getBytes() Return representative byte array for this instance. compareTo public int compareTo(BinaryComparable other) Compare bytes from {#getBytes()}. Specified by: compareTo in interface Comparable<BinaryComparable> See Also:WritableComparator.compareBytes(byte[],int,int,byte[],int,int) compareTo public int compareTo(byte[] other,             int off,             int len) Compare bytes from {#getBytes()} to those provided. equals public boolean equals(Object other) Return true if bytes from {#getBytes()} match. Overrides: equals in class Object hashCode public int hashCode() Return a hash of the bytes returned from {#getBytes()}. Overrides: hashCode in class Object See Also:WritableComparator.hashBytes(byte[],int) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BinaryPartitioner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BinaryPartitioner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.partition Class BinaryPartitioner<V> java.lang.Object org.apache.hadoop.mapreduce.Partitioner<BinaryComparable,V> org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner<V> All Implemented Interfaces: Configurable Direct Known Subclasses: BinaryPartitioner @InterfaceAudience.Public @InterfaceStability.Evolving public class BinaryPartitioner<V> extends Partitioner<BinaryComparable,V> implements Configurable Partition BinaryComparable keys using a configurable part of   the bytes array returned by BinaryComparable.getBytes().    The subarray to be used for the partitioning can be defined by means  of the following properties:            mapreduce.partition.binarypartitioner.left.offset:      left offset in array (0 by default)              mapreduce.partition.binarypartitioner.right.offset:       right offset in array (-1 by default)        Like in Python, both negative and positive offsets are allowed, but  the meaning is slightly different. In case of an array of length 5,  for instance, the possible offsets are:     +---+---+---+---+---+   | B | B | B | B | B |   +---+---+---+---+---+     0   1   2   3   4    -5  -4  -3  -2  -1    The first row of numbers gives the position of the offsets 0...5 in   the array; the second row gives the corresponding negative offsets.   Contrary to Python, the specified subarray has byte i   and j as first and last element, repectively, when   i and j are the left and right offset.    For Hadoop programs written in Java, it is advisable to use one of   the following static convenience methods for setting the offsets:      setOffsets(org.apache.hadoop.conf.Configuration, int, int)    setLeftOffset(org.apache.hadoop.conf.Configuration, int)    setRightOffset(org.apache.hadoop.conf.Configuration, int)   Field Summary Fields  Modifier and Type Field and Description static String LEFT_OFFSET_PROPERTY_NAME  static String RIGHT_OFFSET_PROPERTY_NAME  Constructor Summary Constructors  Constructor and Description BinaryPartitioner()  Method Summary Methods  Modifier and Type Method and Description Configuration getConf() Return the configuration used by this object. int getPartition(BinaryComparable key,                         V value,                         int numPartitions) Use (the specified slice of the array returned by)   BinaryComparable.getBytes() to partition. void setConf(Configuration conf) Set the configuration to be used by this object. static void setLeftOffset(Configuration conf,                           int offset) Set the subarray to be used for partitioning to   bytes[offset:] in Python syntax. static void setOffsets(Configuration conf,                     int left,                     int right) Set the subarray to be used for partitioning to   bytes[left:(right+1)] in Python syntax. static void setRightOffset(Configuration conf,                             int offset) Set the subarray to be used for partitioning to   bytes[:(offset+1)] in Python syntax. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LEFT_OFFSET_PROPERTY_NAME public static final String LEFT_OFFSET_PROPERTY_NAME See Also:Constant Field Values RIGHT_OFFSET_PROPERTY_NAME public static final String RIGHT_OFFSET_PROPERTY_NAME See Also:Constant Field Values Constructor Detail BinaryPartitioner public BinaryPartitioner() Method Detail setOffsets public static void setOffsets(Configuration conf,               int left,               int right) Set the subarray to be used for partitioning to   bytes[left:(right+1)] in Python syntax. Parameters:conf - configuration objectleft - left Python-style offsetright - right Python-style offset setLeftOffset public static void setLeftOffset(Configuration conf,                  int offset) Set the subarray to be used for partitioning to   bytes[offset:] in Python syntax. Parameters:conf - configuration objectoffset - left Python-style offset setRightOffset public static void setRightOffset(Configuration conf,                   int offset) Set the subarray to be used for partitioning to   bytes[:(offset+1)] in Python syntax. Parameters:conf - configuration objectoffset - right Python-style offset setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable getPartition public int getPartition(BinaryComparable key,                V value,                int numPartitions) Use (the specified slice of the array returned by)   BinaryComparable.getBytes() to partition. Specified by: getPartition in class Partitioner<BinaryComparable,V> Parameters:key - the key to be partioned.value - the entry value.numPartitions - the total number of partitions. Returns:the partition number for the key. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BinaryRecordInput (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BinaryRecordInput (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class BinaryRecordInput java.lang.Object org.apache.hadoop.record.BinaryRecordInput All Implemented Interfaces: RecordInput Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class BinaryRecordInput extends Object implements RecordInput Constructor Summary Constructors  Constructor and Description BinaryRecordInput(DataInput din) Deprecated.  Creates a new instance of BinaryRecordInput BinaryRecordInput(InputStream strm) Deprecated.  Creates a new instance of BinaryRecordInput Method Summary Methods  Modifier and Type Method and Description void endMap(String tag) Deprecated.  Check the mark for end of the serialized map. void endRecord(String tag) Deprecated.  Check the mark for end of the serialized record. void endVector(String tag) Deprecated.  Check the mark for end of the serialized vector. static BinaryRecordInput get(DataInput inp) Deprecated.  Get a thread-local record input for the supplied DataInput. boolean readBool(String tag) Deprecated.  Read a boolean from serialized record. Buffer readBuffer(String tag) Deprecated.  Read byte array from serialized record. byte readByte(String tag) Deprecated.  Read a byte from serialized record. double readDouble(String tag) Deprecated.  Read a double-precision number from serialized record. float readFloat(String tag) Deprecated.  Read a single-precision float from serialized record. int readInt(String tag) Deprecated.  Read an integer from serialized record. long readLong(String tag) Deprecated.  Read a long integer from serialized record. String readString(String tag) Deprecated.  Read a UTF-8 encoded string from serialized record. Index startMap(String tag) Deprecated.  Check the mark for start of the serialized map. void startRecord(String tag) Deprecated.  Check the mark for start of the serialized record. Index startVector(String tag) Deprecated.  Check the mark for start of the serialized vector. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail BinaryRecordInput public BinaryRecordInput(InputStream strm) Deprecated.  Creates a new instance of BinaryRecordInput BinaryRecordInput public BinaryRecordInput(DataInput din) Deprecated.  Creates a new instance of BinaryRecordInput Method Detail get public static BinaryRecordInput get(DataInput inp) Deprecated.  Get a thread-local record input for the supplied DataInput. Parameters:inp - data input stream Returns:binary record input corresponding to the supplied DataInput. readByte public byte readByte(String tag)               throws IOException Deprecated.  Description copied from interface: RecordInput Read a byte from serialized record. Specified by: readByte in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readBool public boolean readBool(String tag)                  throws IOException Deprecated.  Description copied from interface: RecordInput Read a boolean from serialized record. Specified by: readBool in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readInt public int readInt(String tag)             throws IOException Deprecated.  Description copied from interface: RecordInput Read an integer from serialized record. Specified by: readInt in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readLong public long readLong(String tag)               throws IOException Deprecated.  Description copied from interface: RecordInput Read a long integer from serialized record. Specified by: readLong in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readFloat public float readFloat(String tag)                 throws IOException Deprecated.  Description copied from interface: RecordInput Read a single-precision float from serialized record. Specified by: readFloat in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readDouble public double readDouble(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Read a double-precision number from serialized record. Specified by: readDouble in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readString public String readString(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Read a UTF-8 encoded string from serialized record. Specified by: readString in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readBuffer public Buffer readBuffer(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Read byte array from serialized record. Specified by: readBuffer in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException startRecord public void startRecord(String tag)                  throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for start of the serialized record. Specified by: startRecord in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException endRecord public void endRecord(String tag)                throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for end of the serialized record. Specified by: endRecord in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException startVector public Index startVector(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for start of the serialized vector. Specified by: startVector in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:Index that is used to count the number of elements. Throws: IOException endVector public void endVector(String tag)                throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for end of the serialized vector. Specified by: endVector in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException startMap public Index startMap(String tag)                throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for start of the serialized map. Specified by: startMap in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:Index that is used to count the number of map entries. Throws: IOException endMap public void endMap(String tag)             throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for end of the serialized map. Specified by: endMap in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BinaryRecordOutput (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BinaryRecordOutput (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class BinaryRecordOutput java.lang.Object org.apache.hadoop.record.BinaryRecordOutput All Implemented Interfaces: RecordOutput Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class BinaryRecordOutput extends Object implements RecordOutput Constructor Summary Constructors  Constructor and Description BinaryRecordOutput(DataOutput out) Deprecated.  Creates a new instance of BinaryRecordOutput BinaryRecordOutput(OutputStream out) Deprecated.  Creates a new instance of BinaryRecordOutput Method Summary Methods  Modifier and Type Method and Description void endMap(TreeMap v,             String tag) Deprecated.  Mark the end of a serialized map. void endRecord(Record r,                   String tag) Deprecated.  Mark the end of a serialized record. void endVector(ArrayList v,                   String tag) Deprecated.  Mark the end of a serialized vector. static BinaryRecordOutput get(DataOutput out) Deprecated.  Get a thread-local record output for the supplied DataOutput. void startMap(TreeMap v,                 String tag) Deprecated.  Mark the start of a map to be serialized. void startRecord(Record r,                       String tag) Deprecated.  Mark the start of a record to be serialized. void startVector(ArrayList v,                       String tag) Deprecated.  Mark the start of a vector to be serialized. void writeBool(boolean b,                   String tag) Deprecated.  Write a boolean to serialized record. void writeBuffer(Buffer buf,                       String tag) Deprecated.  Write a buffer to serialized record. void writeByte(byte b,                   String tag) Deprecated.  Write a byte to serialized record. void writeDouble(double d,                       String tag) Deprecated.  Write a double precision floating point number to serialized record. void writeFloat(float f,                     String tag) Deprecated.  Write a single-precision float to serialized record. void writeInt(int i,                 String tag) Deprecated.  Write an integer to serialized record. void writeLong(long l,                   String tag) Deprecated.  Write a long integer to serialized record. void writeString(String s,                       String tag) Deprecated.  Write a unicode string to serialized record. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail BinaryRecordOutput public BinaryRecordOutput(OutputStream out) Deprecated.  Creates a new instance of BinaryRecordOutput BinaryRecordOutput public BinaryRecordOutput(DataOutput out) Deprecated.  Creates a new instance of BinaryRecordOutput Method Detail get public static BinaryRecordOutput get(DataOutput out) Deprecated.  Get a thread-local record output for the supplied DataOutput. Parameters:out - data output stream Returns:binary record output corresponding to the supplied DataOutput. writeByte public void writeByte(byte b,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Write a byte to serialized record. Specified by: writeByte in interface RecordOutput Parameters:b - Byte to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeBool public void writeBool(boolean b,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Write a boolean to serialized record. Specified by: writeBool in interface RecordOutput Parameters:b - Boolean to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeInt public void writeInt(int i,             String tag)               throws IOException Deprecated.  Description copied from interface: RecordOutput Write an integer to serialized record. Specified by: writeInt in interface RecordOutput Parameters:i - Integer to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeLong public void writeLong(long l,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Write a long integer to serialized record. Specified by: writeLong in interface RecordOutput Parameters:l - Long to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeFloat public void writeFloat(float f,               String tag)                 throws IOException Deprecated.  Description copied from interface: RecordOutput Write a single-precision float to serialized record. Specified by: writeFloat in interface RecordOutput Parameters:f - Float to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeDouble public void writeDouble(double d,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Write a double precision floating point number to serialized record. Specified by: writeDouble in interface RecordOutput Parameters:d - Double to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeString public void writeString(String s,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Write a unicode string to serialized record. Specified by: writeString in interface RecordOutput Parameters:s - String to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeBuffer public void writeBuffer(Buffer buf,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Write a buffer to serialized record. Specified by: writeBuffer in interface RecordOutput Parameters:buf - Buffer to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startRecord public void startRecord(Record r,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the start of a record to be serialized. Specified by: startRecord in interface RecordOutput Parameters:r - Record to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endRecord public void endRecord(Record r,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the end of a serialized record. Specified by: endRecord in interface RecordOutput Parameters:r - Record to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startVector public void startVector(ArrayList v,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the start of a vector to be serialized. Specified by: startVector in interface RecordOutput Parameters:v - Vector to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endVector public void endVector(ArrayList v,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the end of a serialized vector. Specified by: endVector in interface RecordOutput Parameters:v - Vector to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startMap public void startMap(TreeMap v,             String tag)               throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the start of a map to be serialized. Specified by: startMap in interface RecordOutput Parameters:v - Map to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endMap public void endMap(TreeMap v,           String tag)             throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the end of a serialized map. Specified by: endMap in interface RecordOutput Parameters:v - Map to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BindFlags (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BindFlags (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.api Interface BindFlags @InterfaceAudience.Public @InterfaceStability.Evolving public interface BindFlags Combinable Flags to use when creating a service entry. Field Summary Fields  Modifier and Type Field and Description static int CREATE Create the entry.. static int OVERWRITE The entry should be created even if an existing entry is there. Field Detail CREATE static final int CREATE Create the entry.. This is just "0" and can be "or"ed with anything See Also:Constant Field Values OVERWRITE static final int OVERWRITE The entry should be created even if an existing entry is there. See Also:Constant Field Values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BindingInformation (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BindingInformation (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.impl.zk Class BindingInformation java.lang.Object org.apache.hadoop.registry.client.impl.zk.BindingInformation @InterfaceAudience.Public @InterfaceStability.Evolving public class BindingInformation extends Object Binding information provided by a RegistryBindingSource Field Summary Fields  Modifier and Type Field and Description String description Any information that may be useful for diagnostics org.apache.curator.ensemble.EnsembleProvider ensembleProvider The Curator Ensemble Provider Constructor Summary Constructors  Constructor and Description BindingInformation()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail ensembleProvider public org.apache.curator.ensemble.EnsembleProvider ensembleProvider The Curator Ensemble Provider description public String description Any information that may be useful for diagnostics Constructor Detail BindingInformation public BindingInformation() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BlockCompressorStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BlockCompressorStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class BlockCompressorStream java.lang.Object java.io.OutputStream org.apache.hadoop.io.compress.CompressionOutputStream org.apache.hadoop.io.compress.CompressorStream org.apache.hadoop.io.compress.BlockCompressorStream All Implemented Interfaces: Closeable, Flushable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Evolving public class BlockCompressorStream extends CompressorStream A CompressorStream which works  with 'block-based' based compression algorithms, as opposed to   'stream-based' compression algorithms.  It should be noted that this wrapper does not guarantee that blocks will  be sized for the compressor. If the  Compressor requires buffering to  effect meaningful compression, it is responsible for it. Field Summary Fields inherited from class org.apache.hadoop.io.compress.CompressorStream buffer, closed, compressor Fields inherited from class org.apache.hadoop.io.compress.CompressionOutputStream out Constructor Summary Constructors  Constructor and Description BlockCompressorStream(OutputStream out,                                           Compressor compressor) Create a BlockCompressorStream with given output-stream and   compressor. BlockCompressorStream(OutputStream out,                                           Compressor compressor,                                           int bufferSize,                                           int compressionOverhead) Create a BlockCompressorStream. Method Summary Methods  Modifier and Type Method and Description protected void compress()  void finish() Finishes writing compressed data to the output stream   without closing the underlying stream. void write(byte[] b,           int off,           int len) Write the data provided to the compression codec, compressing no more  than the buffer size less the compression overhead as specified during  construction for each block. Methods inherited from class org.apache.hadoop.io.compress.CompressorStream close, resetState, write Methods inherited from class org.apache.hadoop.io.compress.CompressionOutputStream flush Methods inherited from class java.io.OutputStream write Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail BlockCompressorStream public BlockCompressorStream(OutputStream out,                      Compressor compressor,                      int bufferSize,                      int compressionOverhead) Create a BlockCompressorStream. Parameters:out - streamcompressor - compressor to be usedbufferSize - size of buffercompressionOverhead - maximum 'overhead' of the compression                              algorithm with given bufferSize BlockCompressorStream public BlockCompressorStream(OutputStream out,                      Compressor compressor) Create a BlockCompressorStream with given output-stream and   compressor.  Use default of 512 as bufferSize and compressionOverhead of   (1% of bufferSize + 12 bytes) =  18 bytes (zlib algorithm). Parameters:out - streamcompressor - compressor to be used Method Detail write public void write(byte[] b,          int off,          int len)            throws IOException Write the data provided to the compression codec, compressing no more  than the buffer size less the compression overhead as specified during  construction for each block.  Each block contains the uncompressed length for the block, followed by  one or more length-prefixed blocks of compressed data. Overrides: write in class CompressorStream Throws: IOException finish public void finish()             throws IOException Description copied from class: CompressionOutputStream Finishes writing compressed data to the output stream   without closing the underlying stream. Overrides: finish in class CompressorStream Throws: IOException compress protected void compress()                  throws IOException Overrides: compress in class CompressorStream Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BlockDecompressorStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BlockDecompressorStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class BlockDecompressorStream java.lang.Object java.io.InputStream org.apache.hadoop.io.compress.CompressionInputStream org.apache.hadoop.io.compress.DecompressorStream org.apache.hadoop.io.compress.BlockDecompressorStream All Implemented Interfaces: Closeable, AutoCloseable, Seekable @InterfaceAudience.Public @InterfaceStability.Evolving public class BlockDecompressorStream extends DecompressorStream A DecompressorStream which works  with 'block-based' based compression algorithms, as opposed to   'stream-based' compression algorithms. Field Summary Fields inherited from class org.apache.hadoop.io.compress.DecompressorStream buffer, closed, decompressor, eof Fields inherited from class org.apache.hadoop.io.compress.CompressionInputStream in, maxAvailableData Constructor Summary Constructors  Modifier Constructor and Description protected  BlockDecompressorStream(InputStream in)    BlockDecompressorStream(InputStream in,                                               Decompressor decompressor) Create a BlockDecompressorStream.   BlockDecompressorStream(InputStream in,                                               Decompressor decompressor,                                               int bufferSize) Create a BlockDecompressorStream. Method Summary Methods  Modifier and Type Method and Description protected int decompress(byte[] b,                     int off,                     int len)  protected int getCompressedData()  void resetState() Reset the decompressor to its initial state and discard any buffered data,  as the underlying stream may have been repositioned. Methods inherited from class org.apache.hadoop.io.compress.DecompressorStream available, checkStream, close, mark, markSupported, read, read, reset, skip Methods inherited from class org.apache.hadoop.io.compress.CompressionInputStream getPos, seek, seekToNewSource Methods inherited from class java.io.InputStream read Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail BlockDecompressorStream public BlockDecompressorStream(InputStream in,                        Decompressor decompressor,                        int bufferSize)                         throws IOException Create a BlockDecompressorStream. Parameters:in - input streamdecompressor - decompressor to usebufferSize - size of buffer Throws: IOException BlockDecompressorStream public BlockDecompressorStream(InputStream in,                        Decompressor decompressor)                         throws IOException Create a BlockDecompressorStream. Parameters:in - input streamdecompressor - decompressor to use Throws: IOException BlockDecompressorStream protected BlockDecompressorStream(InputStream in)                            throws IOException Throws: IOException Method Detail decompress protected int decompress(byte[] b,              int off,              int len)                   throws IOException Overrides: decompress in class DecompressorStream Throws: IOException getCompressedData protected int getCompressedData()                          throws IOException Overrides: getCompressedData in class DecompressorStream Throws: IOException resetState public void resetState()                 throws IOException Description copied from class: CompressionInputStream Reset the decompressor to its initial state and discard any buffered data,  as the underlying stream may have been repositioned. Overrides: resetState in class DecompressorStream Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BlockLocation (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BlockLocation (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class BlockLocation java.lang.Object org.apache.hadoop.fs.BlockLocation Direct Known Subclasses: BlockStorageLocation @InterfaceAudience.Public @InterfaceStability.Stable public class BlockLocation extends Object Represents the network location of a block, information about the hosts  that contain block replicas, and other block metadata (E.g. the file  offset associated with the block, length, whether it is corrupt, etc). Constructor Summary Constructors  Constructor and Description BlockLocation() Default Constructor BlockLocation(BlockLocation that) Copy constructor BlockLocation(String[] names,                           String[] hosts,                           long offset,                           long length) Constructor with host, name, offset and length BlockLocation(String[] names,                           String[] hosts,                           long offset,                           long length,                           boolean corrupt) Constructor with host, name, offset, length and corrupt flag BlockLocation(String[] names,                           String[] hosts,                           String[] topologyPaths,                           long offset,                           long length) Constructor with host, name, network topology, offset and length BlockLocation(String[] names,                           String[] hosts,                           String[] topologyPaths,                           long offset,                           long length,                           boolean corrupt) Constructor with host, name, network topology, offset, length   and corrupt flag BlockLocation(String[] names,                           String[] hosts,                           String[] cachedHosts,                           String[] topologyPaths,                           long offset,                           long length,                           boolean corrupt)  Method Summary Methods  Modifier and Type Method and Description String[] getCachedHosts() Get the list of hosts (hostname) hosting a cached replica of the block String[] getHosts() Get the list of hosts (hostname) hosting this block long getLength() Get the length of the block String[] getNames() Get the list of names (IP:xferPort) hosting this block long getOffset() Get the start offset of file associated with this block String[] getTopologyPaths() Get the list of network topology paths for each of the hosts. boolean isCorrupt() Get the corrupt flag. void setCachedHosts(String[] cachedHosts) Set the hosts hosting a cached replica of this block void setCorrupt(boolean corrupt) Set the corrupt flag. void setHosts(String[] hosts) Set the hosts hosting this block void setLength(long length) Set the length of block void setNames(String[] names) Set the names (host:port) hosting this block void setOffset(long offset) Set the start offset of file associated with this block void setTopologyPaths(String[] topologyPaths) Set the network topology paths of the hosts String toString()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail BlockLocation public BlockLocation() Default Constructor BlockLocation public BlockLocation(BlockLocation that) Copy constructor BlockLocation public BlockLocation(String[] names,              String[] hosts,              long offset,              long length) Constructor with host, name, offset and length BlockLocation public BlockLocation(String[] names,              String[] hosts,              long offset,              long length,              boolean corrupt) Constructor with host, name, offset, length and corrupt flag BlockLocation public BlockLocation(String[] names,              String[] hosts,              String[] topologyPaths,              long offset,              long length) Constructor with host, name, network topology, offset and length BlockLocation public BlockLocation(String[] names,              String[] hosts,              String[] topologyPaths,              long offset,              long length,              boolean corrupt) Constructor with host, name, network topology, offset, length   and corrupt flag BlockLocation public BlockLocation(String[] names,              String[] hosts,              String[] cachedHosts,              String[] topologyPaths,              long offset,              long length,              boolean corrupt) Method Detail getHosts public String[] getHosts()                   throws IOException Get the list of hosts (hostname) hosting this block Throws: IOException getCachedHosts public String[] getCachedHosts() Get the list of hosts (hostname) hosting a cached replica of the block getNames public String[] getNames()                   throws IOException Get the list of names (IP:xferPort) hosting this block Throws: IOException getTopologyPaths public String[] getTopologyPaths()                           throws IOException Get the list of network topology paths for each of the hosts.  The last component of the path is the "name" (IP:xferPort). Throws: IOException getOffset public long getOffset() Get the start offset of file associated with this block getLength public long getLength() Get the length of the block isCorrupt public boolean isCorrupt() Get the corrupt flag. setOffset public void setOffset(long offset) Set the start offset of file associated with this block setLength public void setLength(long length) Set the length of block setCorrupt public void setCorrupt(boolean corrupt) Set the corrupt flag. setHosts public void setHosts(String[] hosts)               throws IOException Set the hosts hosting this block Throws: IOException setCachedHosts public void setCachedHosts(String[] cachedHosts) Set the hosts hosting a cached replica of this block setNames public void setNames(String[] names)               throws IOException Set the names (host:port) hosting this block Throws: IOException setTopologyPaths public void setTopologyPaths(String[] topologyPaths)                       throws IOException Set the network topology paths of the hosts Throws: IOException toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BlockStorageLocation (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BlockStorageLocation (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class BlockStorageLocation java.lang.Object org.apache.hadoop.fs.BlockLocation org.apache.hadoop.fs.BlockStorageLocation @InterfaceStability.Unstable @InterfaceAudience.Public public class BlockStorageLocation extends BlockLocation Wrapper for BlockLocation that also adds VolumeId volume  location information for each replica. Constructor Summary Constructors  Constructor and Description BlockStorageLocation(BlockLocation loc,                                         VolumeId[] volumeIds)  Method Summary Methods  Modifier and Type Method and Description VolumeId[] getVolumeIds() Gets the list of VolumeId corresponding to the block's replicas. Methods inherited from class org.apache.hadoop.fs.BlockLocation getCachedHosts, getHosts, getLength, getNames, getOffset, getTopologyPaths, isCorrupt, setCachedHosts, setCorrupt, setHosts, setLength, setNames, setOffset, setTopologyPaths, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail BlockStorageLocation public BlockStorageLocation(BlockLocation loc,                     VolumeId[] volumeIds)                      throws IOException Throws: IOException Method Detail getVolumeIds public VolumeId[] getVolumeIds() Gets the list of VolumeId corresponding to the block's replicas. Returns:volumeIds list of VolumeId for the block's replicas Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BloomFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BloomFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util.bloom Class BloomFilter java.lang.Object org.apache.hadoop.util.bloom.Filter org.apache.hadoop.util.bloom.BloomFilter All Implemented Interfaces: Writable Direct Known Subclasses: RetouchedBloomFilter @InterfaceAudience.Public @InterfaceStability.Stable public class BloomFilter extends org.apache.hadoop.util.bloom.Filter Implements a Bloom filter, as defined by Bloom in 1970.    The Bloom filter is a data structure that was introduced in 1970 and that has been adopted by   the networking research community in the past decade thanks to the bandwidth efficiencies that it  offers for the transmission of set membership information between networked hosts.  A sender encodes   the information into a bit vector, the Bloom filter, that is more compact than a conventional   representation. Computation and space costs for construction are linear in the number of elements.    The receiver uses the filter to test whether various elements are members of the set. Though the   filter will occasionally return a false positive, it will never return a false negative. When creating   the filter, the sender can choose its desired point in a trade-off between the false positive rate and the size.       Originally created by  European Commission One-Lab Project 034819. See Also:The general behavior of a filter,  Space/Time Trade-Offs in Hash Coding with Allowable Errors Field Summary Fields inherited from class org.apache.hadoop.util.bloom.Filter hash, hashType, nbHash, vectorSize Constructor Summary Constructors  Constructor and Description BloomFilter() Default constructor - use with readFields BloomFilter(int vectorSize,                       int nbHash,                       int hashType) Constructor Method Summary Methods  Modifier and Type Method and Description void add(org.apache.hadoop.util.bloom.Key key) Adds a key to this filter. void and(org.apache.hadoop.util.bloom.Filter filter) Peforms a logical AND between this filter and a specified filter. int getVectorSize()  boolean membershipTest(org.apache.hadoop.util.bloom.Key key) Determines wether a specified key belongs to this filter. void not() Performs a logical NOT on this filter. void or(org.apache.hadoop.util.bloom.Filter filter) Peforms a logical OR between this filter and a specified filter. void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. void xor(org.apache.hadoop.util.bloom.Filter filter) Peforms a logical XOR between this filter and a specified filter. Methods inherited from class org.apache.hadoop.util.bloom.Filter add, add, add Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail BloomFilter public BloomFilter() Default constructor - use with readFields BloomFilter public BloomFilter(int vectorSize,            int nbHash,            int hashType) Constructor Parameters:vectorSize - The vector size of this filter.nbHash - The number of hash function to consider.hashType - type of the hashing function (see  Hash). Method Detail add public void add(org.apache.hadoop.util.bloom.Key key) Description copied from class: org.apache.hadoop.util.bloom.Filter Adds a key to this filter. Specified by: add in class org.apache.hadoop.util.bloom.Filter Parameters:key - The key to add. and public void and(org.apache.hadoop.util.bloom.Filter filter) Description copied from class: org.apache.hadoop.util.bloom.Filter Peforms a logical AND between this filter and a specified filter.    Invariant: The result is assigned to this filter. Specified by: and in class org.apache.hadoop.util.bloom.Filter Parameters:filter - The filter to AND with. membershipTest public boolean membershipTest(org.apache.hadoop.util.bloom.Key key) Description copied from class: org.apache.hadoop.util.bloom.Filter Determines wether a specified key belongs to this filter. Specified by: membershipTest in class org.apache.hadoop.util.bloom.Filter Parameters:key - The key to test. Returns:boolean True if the specified key belongs to this filter.                      False otherwise. not public void not() Description copied from class: org.apache.hadoop.util.bloom.Filter Performs a logical NOT on this filter.    The result is assigned to this filter. Specified by: not in class org.apache.hadoop.util.bloom.Filter or public void or(org.apache.hadoop.util.bloom.Filter filter) Description copied from class: org.apache.hadoop.util.bloom.Filter Peforms a logical OR between this filter and a specified filter.    Invariant: The result is assigned to this filter. Specified by: or in class org.apache.hadoop.util.bloom.Filter Parameters:filter - The filter to OR with. xor public void xor(org.apache.hadoop.util.bloom.Filter filter) Description copied from class: org.apache.hadoop.util.bloom.Filter Peforms a logical XOR between this filter and a specified filter.    Invariant: The result is assigned to this filter. Specified by: xor in class org.apache.hadoop.util.bloom.Filter Parameters:filter - The filter to XOR with. toString public String toString() Overrides: toString in class Object getVectorSize public int getVectorSize() Returns:size of the the bloomfilter write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Overrides: write in class org.apache.hadoop.util.bloom.Filter Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Overrides: readFields in class org.apache.hadoop.util.bloom.Filter Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BloomMapFile (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BloomMapFile (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class BloomMapFile java.lang.Object org.apache.hadoop.io.BloomMapFile @InterfaceAudience.Public @InterfaceStability.Stable public class BloomMapFile extends Object This class extends MapFile and provides very much the same  functionality. However, it uses dynamic Bloom filters to provide  quick membership test for keys, and it offers a fast version of   BloomMapFile.Reader.get(WritableComparable, Writable) operation, especially in  case of sparsely populated MapFile-s. Field Summary Fields  Modifier and Type Field and Description static String BLOOM_FILE_NAME  static int HASH_COUNT  Constructor Summary Constructors  Constructor and Description BloomMapFile()  Method Summary Methods  Modifier and Type Method and Description static void delete(FileSystem fs,             String name)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail BLOOM_FILE_NAME public static final String BLOOM_FILE_NAME See Also:Constant Field Values HASH_COUNT public static final int HASH_COUNT See Also:Constant Field Values Constructor Detail BloomMapFile public BloomMapFile() Method Detail delete public static void delete(FileSystem fs,           String name)                    throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BooleanSplitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BooleanSplitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class BooleanSplitter java.lang.Object org.apache.hadoop.mapreduce.lib.db.BooleanSplitter All Implemented Interfaces: DBSplitter @InterfaceAudience.Public @InterfaceStability.Evolving public class BooleanSplitter extends Object implements DBSplitter Implement DBSplitter over boolean values. Constructor Summary Constructors  Constructor and Description BooleanSplitter()  Method Summary Methods  Modifier and Type Method and Description List<InputSplit> split(Configuration conf,           ResultSet results,           String colName) Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail BooleanSplitter public BooleanSplitter() Method Detail split public List<InputSplit> split(Configuration conf,                      ResultSet results,                      String colName)                        throws SQLException Description copied from interface: DBSplitter Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Specified by: split in interface DBSplitter Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BooleanWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BooleanWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class BooleanWritable java.lang.Object org.apache.hadoop.io.BooleanWritable All Implemented Interfaces: Comparable<BooleanWritable>, Writable, WritableComparable<BooleanWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class BooleanWritable extends Object implements WritableComparable<BooleanWritable> A WritableComparable for booleans. Constructor Summary Constructors  Constructor and Description BooleanWritable()  BooleanWritable(boolean value)  Method Summary Methods  Modifier and Type Method and Description int compareTo(BooleanWritable o)  boolean equals(Object o)  boolean get() Returns the value of the BooleanWritable int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(boolean value) Set the value of the BooleanWritable String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail BooleanWritable public BooleanWritable() BooleanWritable public BooleanWritable(boolean value) Method Detail set public void set(boolean value) Set the value of the BooleanWritable get public boolean get() Returns the value of the BooleanWritable readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object o) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(BooleanWritable o) Specified by: compareTo in interface Comparable<BooleanWritable> toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Buffer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Buffer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class Buffer java.lang.Object org.apache.hadoop.record.Buffer All Implemented Interfaces: Cloneable, Comparable Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class Buffer extends Object implements Comparable, Cloneable A byte sequence that is used as a Java native type for buffer.  It is resizable and distinguishes between the count of the sequence and  the current capacity. Constructor Summary Constructors  Constructor and Description Buffer() Deprecated.  Create a zero-count sequence. Buffer(byte[] bytes) Deprecated.  Create a Buffer using the byte array as the initial value. Buffer(byte[] bytes,             int offset,             int length) Deprecated.  Create a Buffer using the byte range as the initial value. Method Summary Methods  Modifier and Type Method and Description void append(byte[] bytes) Deprecated.  Append specified bytes to the buffer void append(byte[] bytes,             int offset,             int length) Deprecated.  Append specified bytes to the buffer. Object clone() Deprecated.    int compareTo(Object other) Deprecated.  Define the sort order of the Buffer. void copy(byte[] bytes,         int offset,         int length) Deprecated.  Copy the specified byte array to the Buffer. boolean equals(Object other) Deprecated.    byte[] get() Deprecated.  Get the data from the Buffer. int getCapacity() Deprecated.  Get the capacity, which is the maximum count that could handled without  resizing the backing storage. int getCount() Deprecated.  Get the current count of the buffer. int hashCode() Deprecated.    void reset() Deprecated.  Reset the buffer to 0 size void set(byte[] bytes) Deprecated.  Use the specified bytes array as underlying sequence. void setCapacity(int newCapacity) Deprecated.  Change the capacity of the backing storage. String toString() Deprecated.    String toString(String charsetName) Deprecated.  Convert the byte buffer to a string an specific character encoding void truncate() Deprecated.  Change the capacity of the backing store to be the same as the current   count of buffer. Methods inherited from class java.lang.Object finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail Buffer public Buffer() Deprecated.  Create a zero-count sequence. Buffer public Buffer(byte[] bytes) Deprecated.  Create a Buffer using the byte array as the initial value. Parameters:bytes - This array becomes the backing storage for the object. Buffer public Buffer(byte[] bytes,       int offset,       int length) Deprecated.  Create a Buffer using the byte range as the initial value. Parameters:bytes - Copy of this array becomes the backing storage for the object.offset - offset into byte arraylength - length of data Method Detail set public void set(byte[] bytes) Deprecated.  Use the specified bytes array as underlying sequence. Parameters:bytes - byte sequence copy public final void copy(byte[] bytes,         int offset,         int length) Deprecated.  Copy the specified byte array to the Buffer. Replaces the current buffer. Parameters:bytes - byte array to be assignedoffset - offset into byte arraylength - length of data get public byte[] get() Deprecated.  Get the data from the Buffer. Returns:The data is only valid between 0 and getCount() - 1. getCount public int getCount() Deprecated.  Get the current count of the buffer. getCapacity public int getCapacity() Deprecated.  Get the capacity, which is the maximum count that could handled without  resizing the backing storage. Returns:The number of bytes setCapacity public void setCapacity(int newCapacity) Deprecated.  Change the capacity of the backing storage.  The data is preserved if newCapacity >= getCount(). Parameters:newCapacity - The new capacity in bytes. reset public void reset() Deprecated.  Reset the buffer to 0 size truncate public void truncate() Deprecated.  Change the capacity of the backing store to be the same as the current   count of buffer. append public void append(byte[] bytes,           int offset,           int length) Deprecated.  Append specified bytes to the buffer. Parameters:bytes - byte array to be appendedoffset - offset into byte arraylength - length of data append public void append(byte[] bytes) Deprecated.  Append specified bytes to the buffer Parameters:bytes - byte array to be appended hashCode public int hashCode() Deprecated.  Overrides: hashCode in class Object compareTo public int compareTo(Object other) Deprecated.  Define the sort order of the Buffer. Specified by: compareTo in interface Comparable Parameters:other - The other buffer Returns:Positive if this is bigger than other, 0 if they are equal, and          negative if this is smaller than other. equals public boolean equals(Object other) Deprecated.  Overrides: equals in class Object toString public String toString() Deprecated.  Overrides: toString in class Object toString public String toString(String charsetName)                 throws UnsupportedEncodingException Deprecated.  Convert the byte buffer to a string an specific character encoding Parameters:charsetName - Valid Java Character Set Name Throws: UnsupportedEncodingException clone public Object clone()              throws CloneNotSupportedException Deprecated.  Overrides: clone in class Object Throws: CloneNotSupportedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ByteBufferPool (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ByteBufferPool (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Interface ByteBufferPool All Known Implementing Classes: ElasticByteBufferPool @InterfaceAudience.Public @InterfaceStability.Stable public interface ByteBufferPool Method Summary Methods  Modifier and Type Method and Description ByteBuffer getBuffer(boolean direct,                   int length) Get a new direct ByteBuffer. void putBuffer(ByteBuffer buffer) Release a buffer back to the pool. Method Detail getBuffer ByteBuffer getBuffer(boolean direct,                    int length) Get a new direct ByteBuffer.  The pool can provide this from  removing a buffer from its internal cache, or by allocating a   new buffer. Parameters:direct - Whether the buffer should be direct.length - The minimum length the buffer will have. Returns:A new ByteBuffer.  This ByteBuffer must be direct.                    Its capacity can be less than what was requested, but                    must be at least 1 byte. putBuffer void putBuffer(ByteBuffer buffer) Release a buffer back to the pool.  The pool may choose to put this buffer into its cache. Parameters:buffer - a direct bytebuffer Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ByteWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ByteWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class ByteWritable java.lang.Object org.apache.hadoop.io.ByteWritable All Implemented Interfaces: Comparable<ByteWritable>, Writable, WritableComparable<ByteWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class ByteWritable extends Object implements WritableComparable<ByteWritable> A WritableComparable for a single byte. Constructor Summary Constructors  Constructor and Description ByteWritable()  ByteWritable(byte value)  Method Summary Methods  Modifier and Type Method and Description int compareTo(ByteWritable o) Compares two ByteWritables. boolean equals(Object o) Returns true iff o is a ByteWritable with the same value. byte get() Return the value of this ByteWritable. int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(byte value) Set the value of this ByteWritable. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail ByteWritable public ByteWritable() ByteWritable public ByteWritable(byte value) Method Detail set public void set(byte value) Set the value of this ByteWritable. get public byte get() Return the value of this ByteWritable. readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object o) Returns true iff o is a ByteWritable with the same value. Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(ByteWritable o) Compares two ByteWritables. Specified by: compareTo in interface Comparable<ByteWritable> toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  BytesWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="BytesWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class BytesWritable java.lang.Object org.apache.hadoop.io.BinaryComparable org.apache.hadoop.io.BytesWritable All Implemented Interfaces: Comparable<BinaryComparable>, Writable, WritableComparable<BinaryComparable> @InterfaceAudience.Public @InterfaceStability.Stable public class BytesWritable extends BinaryComparable implements WritableComparable<BinaryComparable> A byte sequence that is usable as a key or value.  It is resizable and distinguishes between the size of the sequence and  the current capacity. The hash function is the front of the md5 of the   buffer. The sort order is the same as memcmp. Constructor Summary Constructors  Constructor and Description BytesWritable() Create a zero-size sequence. BytesWritable(byte[] bytes) Create a BytesWritable using the byte array as the initial value. BytesWritable(byte[] bytes,                           int length) Create a BytesWritable using the byte array as the initial value  and length as the length. Method Summary Methods  Modifier and Type Method and Description byte[] copyBytes() Get a copy of the bytes that is exactly the length of the data. boolean equals(Object right_obj) Are the two byte sequences equal? byte[] get() Deprecated.  Use getBytes() instead. byte[] getBytes() Get the data backing the BytesWritable. int getCapacity() Get the capacity, which is the maximum size that could handled without  resizing the backing storage. int getLength() Get the current size of the buffer. int getSize() Deprecated.  Use getLength() instead. int hashCode() Return a hash of the bytes returned from {#getBytes()}. void readFields(DataInput in) Deserialize the fields of this object from in. void set(byte[] newData,       int offset,       int length) Set the value to a copy of the given byte range void set(BytesWritable newData) Set the BytesWritable to the contents of the given newData. void setCapacity(int new_cap) Change the capacity of the backing storage. void setSize(int size) Change the size of the buffer. String toString() Generate the stream of bytes as hex pairs separated by ' '. void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.io.BinaryComparable compareTo, compareTo Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Methods inherited from interface java.lang.Comparable compareTo Constructor Detail BytesWritable public BytesWritable() Create a zero-size sequence. BytesWritable public BytesWritable(byte[] bytes) Create a BytesWritable using the byte array as the initial value. Parameters:bytes - This array becomes the backing storage for the object. BytesWritable public BytesWritable(byte[] bytes,              int length) Create a BytesWritable using the byte array as the initial value  and length as the length. Use this constructor if the array is larger  than the value it represents. Parameters:bytes - This array becomes the backing storage for the object.length - The number of bytes to use from array. Method Detail copyBytes public byte[] copyBytes() Get a copy of the bytes that is exactly the length of the data.  See getBytes() for faster access to the underlying array. getBytes public byte[] getBytes() Get the data backing the BytesWritable. Please use copyBytes()  if you need the returned array to be precisely the length of the data. Specified by: getBytes in class BinaryComparable Returns:The data is only valid between 0 and getLength() - 1. get @Deprecated public byte[] get() Deprecated. Use getBytes() instead. Get the data from the BytesWritable. getLength public int getLength() Get the current size of the buffer. Specified by: getLength in class BinaryComparable getSize @Deprecated public int getSize() Deprecated. Use getLength() instead. Get the current size of the buffer. setSize public void setSize(int size) Change the size of the buffer. The values in the old range are preserved  and any new values are undefined. The capacity is changed if it is   necessary. Parameters:size - The new number of bytes getCapacity public int getCapacity() Get the capacity, which is the maximum size that could handled without  resizing the backing storage. Returns:The number of bytes setCapacity public void setCapacity(int new_cap) Change the capacity of the backing storage.  The data is preserved. Parameters:new_cap - The new capacity in bytes. set public void set(BytesWritable newData) Set the BytesWritable to the contents of the given newData. Parameters:newData - the value to set this BytesWritable to. set public void set(byte[] newData,        int offset,        int length) Set the value to a copy of the given byte range Parameters:newData - the new values to copy inoffset - the offset in newData to start atlength - the number of bytes to copy readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException hashCode public int hashCode() Description copied from class: BinaryComparable Return a hash of the bytes returned from {#getBytes()}. Overrides: hashCode in class BinaryComparable See Also:WritableComparator.hashBytes(byte[],int) equals public boolean equals(Object right_obj) Are the two byte sequences equal? Overrides: equals in class BinaryComparable toString public String toString() Generate the stream of bytes as hex pairs separated by ' '. Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CLI (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CLI (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.tools Class CLI java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.mapreduce.tools.CLI All Implemented Interfaces: Configurable, Tool Direct Known Subclasses: JobClient @InterfaceAudience.Public @InterfaceStability.Stable public class CLI extends Configured implements Tool Interprets the map reduce cli options Field Summary Fields  Modifier and Type Field and Description protected Cluster cluster  Constructor Summary Constructors  Constructor and Description CLI()  CLI(Configuration conf)  Method Summary Methods  Modifier and Type Method and Description void displayJobList(JobStatus[] jobs)  protected void displayTasks(Job job,                         String type,                         String state) Display the information about a job's tasks, of a particular type and  in a particular state protected long getCounter(Counters counters,                     String counterGroupName,                     String counterName)  protected static String getTaskLogURL(TaskAttemptID taskId,                           String baseUrl)  static void main(String[] argv)  int run(String[] argv) Execute the command with the given arguments. Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Field Detail cluster protected Cluster cluster Constructor Detail CLI public CLI() CLI public CLI(Configuration conf) Method Detail run public int run(String[] argv)         throws Exception Description copied from interface: Tool Execute the command with the given arguments. Specified by: run in interface Tool Parameters:argv - command specific arguments. Returns:exit code. Throws: Exception getCounter protected long getCounter(Counters counters,               String counterGroupName,               String counterName)                    throws IOException Throws: IOException getTaskLogURL protected static String getTaskLogURL(TaskAttemptID taskId,                    String baseUrl) displayTasks protected void displayTasks(Job job,                 String type,                 String state)                      throws IOException,                             InterruptedException Display the information about a job's tasks, of a particular type and  in a particular state Parameters:job - the jobtype - the type of the task (map/reduce/setup/cleanup)state - the state of the task   (pending/running/completed/failed/killed) Throws: IOException InterruptedException displayJobList public void displayJobList(JobStatus[] jobs)                     throws IOException,                            InterruptedException Throws: IOException InterruptedException main public static void main(String[] argv)                  throws Exception Throws: Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CacheFlag (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CacheFlag (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.fs Enum CacheFlag java.lang.Object java.lang.Enum<CacheFlag> org.apache.hadoop.fs.CacheFlag All Implemented Interfaces: Serializable, Comparable<CacheFlag> @InterfaceAudience.Public @InterfaceStability.Evolving public enum CacheFlag extends Enum<CacheFlag> Specifies semantics for CacheDirective operations. Multiple flags can  be combined in an EnumSet. Enum Constant Summary Enum Constants  Enum Constant and Description FORCE Ignore cache pool resource limits when performing this operation. Method Summary Methods  Modifier and Type Method and Description static CacheFlag valueOf(String name) Returns the enum constant of this type with the specified name. static CacheFlag[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail FORCE public static final CacheFlag FORCE Ignore cache pool resource limits when performing this operation. Method Detail values public static CacheFlag[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (CacheFlag c : CacheFlag.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static CacheFlag valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CachedDNSToSwitchMapping (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CachedDNSToSwitchMapping (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.net Class CachedDNSToSwitchMapping java.lang.Object org.apache.hadoop.net.AbstractDNSToSwitchMapping org.apache.hadoop.net.CachedDNSToSwitchMapping All Implemented Interfaces: Configurable, DNSToSwitchMapping Direct Known Subclasses: ScriptBasedMapping, TableMapping @InterfaceAudience.Public @InterfaceStability.Evolving public class CachedDNSToSwitchMapping extends AbstractDNSToSwitchMapping A cached implementation of DNSToSwitchMapping that takes an  raw DNSToSwitchMapping and stores the resolved network location in   a cache. The following calls to a resolved network location  will get its location from the cache. Field Summary Fields  Modifier and Type Field and Description protected DNSToSwitchMapping rawMapping The uncached mapping Constructor Summary Constructors  Constructor and Description CachedDNSToSwitchMapping(DNSToSwitchMapping rawMapping) cache a raw DNS mapping Method Summary Methods  Modifier and Type Method and Description Map<String,String> getSwitchMap() Get the (host x switch) map. boolean isSingleSwitch() Delegate the switch topology query to the raw mapping, via  AbstractDNSToSwitchMapping.isMappingSingleSwitch(DNSToSwitchMapping) void reloadCachedMappings() Reload all of the cached mappings. void reloadCachedMappings(List<String> names) Reload cached mappings on specific nodes. List<String> resolve(List<String> names) Resolves a list of DNS-names/IP-addresses and returns back a list of  switch information (network paths). String toString()  Methods inherited from class org.apache.hadoop.net.AbstractDNSToSwitchMapping dumpTopology, getConf, isMappingSingleSwitch, isSingleSwitchByScriptPolicy, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail rawMapping protected final DNSToSwitchMapping rawMapping The uncached mapping Constructor Detail CachedDNSToSwitchMapping public CachedDNSToSwitchMapping(DNSToSwitchMapping rawMapping) cache a raw DNS mapping Parameters:rawMapping - the raw mapping to cache Method Detail resolve public List<String> resolve(List<String> names) Description copied from interface: DNSToSwitchMapping Resolves a list of DNS-names/IP-addresses and returns back a list of  switch information (network paths). One-to-one correspondence must be   maintained between the elements in the lists.   Consider an element in the argument list - x.y.com. The switch information  that is returned must be a network path of the form /foo/rack,   where / is the root, and 'foo' is the switch where 'rack' is connected.  Note the hostname/ip-address is not part of the returned path.  The network topology of the cluster would determine the number of  components in the network path.    If a name cannot be resolved to a rack, the implementation  should return NetworkTopology.DEFAULT_RACK. This  is what the bundled implementations do, though it is not a formal requirement Parameters:names - the list of hosts to resolve (can be empty) Returns:list of resolved network paths.  If names is empty, the returned list is also empty getSwitchMap public Map<String,String> getSwitchMap() Get the (host x switch) map. Overrides: getSwitchMap in class AbstractDNSToSwitchMapping Returns:a copy of the cached map of hosts to rack toString public String toString() Overrides: toString in class Object isSingleSwitch public boolean isSingleSwitch() Delegate the switch topology query to the raw mapping, via  AbstractDNSToSwitchMapping.isMappingSingleSwitch(DNSToSwitchMapping) Overrides: isSingleSwitch in class AbstractDNSToSwitchMapping Returns:true iff the raw mapper is considered single-switch. reloadCachedMappings public void reloadCachedMappings() Description copied from interface: DNSToSwitchMapping Reload all of the cached mappings.  If there is a cache, this method will clear it, so that future accesses  will get a chance to see the new data. reloadCachedMappings public void reloadCachedMappings(List<String> names) Description copied from interface: DNSToSwitchMapping Reload cached mappings on specific nodes.  If there is a cache on these nodes, this method will clear it, so that   future accesses will see updated data. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CanSetDropBehind (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CanSetDropBehind (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Interface CanSetDropBehind All Known Implementing Classes: FSDataInputStream, FSDataOutputStream @InterfaceAudience.Public @InterfaceStability.Evolving public interface CanSetDropBehind Method Summary Methods  Modifier and Type Method and Description void setDropBehind(Boolean dropCache) Configure whether the stream should drop the cache. Method Detail setDropBehind void setDropBehind(Boolean dropCache)                    throws IOException,                           UnsupportedOperationException Configure whether the stream should drop the cache. Parameters:dropCache - Whether to drop the cache.  null means to use the                       default value. Throws: IOException - If there was an error changing the dropBehind                       setting.          UnsupportedOperationException  If this stream doesn't support                                         setting the drop-behind. UnsupportedOperationException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CanSetReadahead (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CanSetReadahead (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Interface CanSetReadahead All Known Implementing Classes: FSDataInputStream @InterfaceAudience.Public @InterfaceStability.Evolving public interface CanSetReadahead Method Summary Methods  Modifier and Type Method and Description void setReadahead(Long readahead) Set the readahead on this stream. Method Detail setReadahead void setReadahead(Long readahead)                   throws IOException,                          UnsupportedOperationException Set the readahead on this stream. Parameters:readahead - The readahead to use.  null means to use the default. Throws: IOException - If there was an error changing the dropBehind                       setting.          UnsupportedOperationException  If this stream doesn't support                                         setting readahead. UnsupportedOperationException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CancelDelegationTokenRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CancelDelegationTokenRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.v2.api.protocolrecords Interface CancelDelegationTokenRequest @InterfaceAudience.Public @InterfaceStability.Evolving public interface CancelDelegationTokenRequest The request issued by the client to the ResourceManager to cancel a  delegation token. Method Summary Methods  Modifier and Type Method and Description Token getDelegationToken()  void setDelegationToken(Token dToken)  Method Detail getDelegationToken Token getDelegationToken() setDelegationToken void setDelegationToken(Token dToken) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CancelDelegationTokenResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CancelDelegationTokenResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.v2.api.protocolrecords Interface CancelDelegationTokenResponse @InterfaceAudience.Public @InterfaceStability.Evolving public interface CancelDelegationTokenResponse The response from the ResourceManager to a cancelDelegationToken  request. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ChainMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ChainMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.chain Class ChainMapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> java.lang.Object org.apache.hadoop.mapreduce.Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> org.apache.hadoop.mapreduce.lib.chain.ChainMapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Stable public class ChainMapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> The ChainMapper class allows to use multiple Mapper classes within a single  Map task.      The Mapper classes are invoked in a chained (or piped) fashion, the output of  the first becomes the input of the second, and so on until the last Mapper,  the output of the last Mapper will be written to the task's output.      The key functionality of this feature is that the Mappers in the chain do not  need to be aware that they are executed in a chain. This enables having  reusable specialized Mappers that can be combined to perform composite  operations within a single task.      Special care has to be taken when creating chains that the key/values output  by a Mapper are valid for the following Mapper in the chain. It is assumed  all Mappers and the Reduce in the chain use matching output and input key and  value classes as no conversion is done by the chaining code.      Using the ChainMapper and the ChainReducer classes is possible to compose  Map/Reduce jobs that look like [MAP+ / REDUCE MAP*]. And  immediate benefit of this pattern is a dramatic reduction in disk IO.      IMPORTANT: There is no need to specify the output key/value classes for the  ChainMapper, this is done by the addMapper for the last mapper in the chain.    ChainMapper usage pattern:        ...  Job = new Job(conf);  Configuration mapAConf = new Configuration(false);  ...  ChainMapper.addMapper(job, AMap.class, LongWritable.class, Text.class,    Text.class, Text.class, true, mapAConf);  Configuration mapBConf = new Configuration(false);  ...  ChainMapper.addMapper(job, BMap.class, Text.class, Text.class,    LongWritable.class, Text.class, false, mapBConf);  ...  job.waitForComplettion(true);  ...   Constructor Summary Constructors  Constructor and Description ChainMapper()  Method Summary Methods  Modifier and Type Method and Description static void addMapper(Job job,                   Class<? extends Mapper> klass,                   Class<?> inputKeyClass,                   Class<?> inputValueClass,                   Class<?> outputKeyClass,                   Class<?> outputValueClass,                   Configuration mapperConf) Adds a Mapper class to the chain mapper. void run(org.apache.hadoop.mapreduce.Mapper.Context context) Expert users can override this method for more complete control over the  execution of the Mapper. protected void setup(org.apache.hadoop.mapreduce.Mapper.Context context) Called once at the beginning of the task. Methods inherited from class org.apache.hadoop.mapreduce.Mapper cleanup, map Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ChainMapper public ChainMapper() Method Detail addMapper public static void addMapper(Job job,              Class<? extends Mapper> klass,              Class<?> inputKeyClass,              Class<?> inputValueClass,              Class<?> outputKeyClass,              Class<?> outputValueClass,              Configuration mapperConf)                       throws IOException Adds a Mapper class to the chain mapper.      The key and values are passed from one element of the chain to the next, by  value. For the added Mapper the configuration given for it,  mapperConf, have precedence over the job's Configuration. This  precedence is in effect when the task is running.      IMPORTANT: There is no need to specify the output key/value classes for the  ChainMapper, this is done by the addMapper for the last mapper in the chain   Parameters:job - The job.klass - the Mapper class to add.inputKeyClass - mapper input key class.inputValueClass - mapper input value class.outputKeyClass - mapper output key class.outputValueClass - mapper output value class.mapperConf - a configuration for the Mapper class. It is recommended to use a           Configuration without default values using the           Configuration(boolean loadDefaults) constructor with           FALSE. Throws: IOException setup protected void setup(org.apache.hadoop.mapreduce.Mapper.Context context) Description copied from class: Mapper Called once at the beginning of the task. Overrides: setup in class Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> run public void run(org.apache.hadoop.mapreduce.Mapper.Context context)          throws IOException,                 InterruptedException Description copied from class: Mapper Expert users can override this method for more complete control over the  execution of the Mapper. Overrides: run in class Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ChainReducer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ChainReducer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.chain Class ChainReducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> java.lang.Object org.apache.hadoop.mapreduce.Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> org.apache.hadoop.mapreduce.lib.chain.ChainReducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Stable public class ChainReducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> The ChainReducer class allows to chain multiple Mapper classes after a  Reducer within the Reducer task.      For each record output by the Reducer, the Mapper classes are invoked in a  chained (or piped) fashion. The output of the reducer becomes the input of  the first mapper and output of first becomes the input of the second, and so  on until the last Mapper, the output of the last Mapper will be written to  the task's output.      The key functionality of this feature is that the Mappers in the chain do not  need to be aware that they are executed after the Reducer or in a chain. This  enables having reusable specialized Mappers that can be combined to perform  composite operations within a single task.      Special care has to be taken when creating chains that the key/values output  by a Mapper are valid for the following Mapper in the chain. It is assumed  all Mappers and the Reduce in the chain use matching output and input key and  value classes as no conversion is done by the chaining code.     Using the ChainMapper and the ChainReducer classes is possible to  compose Map/Reduce jobs that look like [MAP+ / REDUCE MAP*]. And  immediate benefit of this pattern is a dramatic reduction in disk IO.     IMPORTANT: There is no need to specify the output key/value classes for the  ChainReducer, this is done by the setReducer or the addMapper for the last  element in the chain.    ChainReducer usage pattern:        ...  Job = new Job(conf);  ....  Configuration reduceConf = new Configuration(false);  ...  ChainReducer.setReducer(job, XReduce.class, LongWritable.class, Text.class,    Text.class, Text.class, true, reduceConf);  ChainReducer.addMapper(job, CMap.class, Text.class, Text.class,    LongWritable.class, Text.class, false, null);  ChainReducer.addMapper(job, DMap.class, LongWritable.class, Text.class,    LongWritable.class, LongWritable.class, true, null);  ...  job.waitForCompletion(true);  ...   Constructor Summary Constructors  Constructor and Description ChainReducer()  Method Summary Methods  Modifier and Type Method and Description static void addMapper(Job job,                   Class<? extends Mapper> klass,                   Class<?> inputKeyClass,                   Class<?> inputValueClass,                   Class<?> outputKeyClass,                   Class<?> outputValueClass,                   Configuration mapperConf) Adds a Mapper class to the chain reducer. void run(org.apache.hadoop.mapreduce.Reducer.Context context) Advanced application writers can use the   Reducer.run(org.apache.hadoop.mapreduce.Reducer.Context) method to  control how the reduce task works. static void setReducer(Job job,                     Class<? extends Reducer> klass,                     Class<?> inputKeyClass,                     Class<?> inputValueClass,                     Class<?> outputKeyClass,                     Class<?> outputValueClass,                     Configuration reducerConf) Sets the Reducer class to the chain job. protected void setup(org.apache.hadoop.mapreduce.Reducer.Context context) Called once at the start of the task. Methods inherited from class org.apache.hadoop.mapreduce.Reducer cleanup, reduce Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ChainReducer public ChainReducer() Method Detail setReducer public static void setReducer(Job job,               Class<? extends Reducer> klass,               Class<?> inputKeyClass,               Class<?> inputValueClass,               Class<?> outputKeyClass,               Class<?> outputValueClass,               Configuration reducerConf) Sets the Reducer class to the chain job.      The key and values are passed from one element of the chain to the next, by  value. For the added Reducer the configuration given for it,  reducerConf, have precedence over the job's Configuration.  This precedence is in effect when the task is running.      IMPORTANT: There is no need to specify the output key/value classes for the  ChainReducer, this is done by the setReducer or the addMapper for the last  element in the chain.   Parameters:job - the jobklass - the Reducer class to add.inputKeyClass - reducer input key class.inputValueClass - reducer input value class.outputKeyClass - reducer output key class.outputValueClass - reducer output value class.reducerConf - a configuration for the Reducer class. It is recommended to use a           Configuration without default values using the           Configuration(boolean loadDefaults) constructor with           FALSE. addMapper public static void addMapper(Job job,              Class<? extends Mapper> klass,              Class<?> inputKeyClass,              Class<?> inputValueClass,              Class<?> outputKeyClass,              Class<?> outputValueClass,              Configuration mapperConf)                       throws IOException Adds a Mapper class to the chain reducer.      The key and values are passed from one element of the chain to the next, by  value For the added Mapper the configuration given for it,  mapperConf, have precedence over the job's Configuration. This  precedence is in effect when the task is running.      IMPORTANT: There is no need to specify the output key/value classes for the  ChainMapper, this is done by the addMapper for the last mapper in the  chain.   Parameters:job - The job.klass - the Mapper class to add.inputKeyClass - mapper input key class.inputValueClass - mapper input value class.outputKeyClass - mapper output key class.outputValueClass - mapper output value class.mapperConf - a configuration for the Mapper class. It is recommended to use a           Configuration without default values using the           Configuration(boolean loadDefaults) constructor with           FALSE. Throws: IOException setup protected void setup(org.apache.hadoop.mapreduce.Reducer.Context context) Description copied from class: Reducer Called once at the start of the task. Overrides: setup in class Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> run public void run(org.apache.hadoop.mapreduce.Reducer.Context context)          throws IOException,                 InterruptedException Description copied from class: Reducer Advanced application writers can use the   Reducer.run(org.apache.hadoop.mapreduce.Reducer.Context) method to  control how the reduce task works. Overrides: run in class Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Checkpointable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Checkpointable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Required |  Optional Detail:  Element org.apache.hadoop.mapreduce.task.annotation Annotation Type Checkpointable @Documented @Target(value=TYPE) @Retention(value=RUNTIME) @InterfaceAudience.Public @InterfaceStability.Evolving public @interface Checkpointable Contract representing to the framework that the task can be safely preempted  and restarted between invocations of the user-defined function.  This is often true when the result of a function does not rely on state  derived from previous elements in the record stream, but the guarantee is  left as an exercise to the implementor. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Required |  Optional Detail:  Element Copyright © 2016 Apache Software Foundation. All rights reserved.  ChecksumException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ChecksumException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class ChecksumException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.ChecksumException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class ChecksumException extends IOException Thrown for checksum errors. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ChecksumException(String description,                                   long pos)  Method Summary Methods  Modifier and Type Method and Description long getPos()  Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ChecksumException public ChecksumException(String description,                  long pos) Method Detail getPos public long getPos() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ChecksumFileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ChecksumFileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class ChecksumFileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem org.apache.hadoop.fs.FilterFileSystem org.apache.hadoop.fs.ChecksumFileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable Direct Known Subclasses: LocalFileSystem @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ChecksumFileSystem extends FilterFileSystem Abstract Checksumed FileSystem.  It provide a basic implementation of a Checksumed FileSystem,  which creates a checksum file for each raw file.  It generates & verifies checksums at the client side. Field Summary Fields inherited from class org.apache.hadoop.fs.FilterFileSystem fs, swapScheme Fields inherited from class org.apache.hadoop.fs.FileSystem DEFAULT_FS, FS_DEFAULT_NAME_KEY, LOG, SHUTDOWN_HOOK_PRIORITY, statistics Constructor Summary Constructors  Constructor and Description ChecksumFileSystem(FileSystem fs)  Method Summary Methods  Modifier and Type Method and Description FSDataOutputStream append(Path f,             int bufferSize,             Progressable progress) Append to an existing file (optional operation). void completeLocalOutput(Path fsOutputFile,                                       Path tmpLocalFile) Called when we're all done writing to the target. void copyFromLocalFile(boolean delSrc,                                   Path src,                                   Path dst) The src file is on the local disk. void copyToLocalFile(boolean delSrc,                               Path src,                               Path dst) The src file is under FS, and the dst is on the local disk. void copyToLocalFile(Path src,                               Path dst,                               boolean copyCrc) The src file is under FS, and the dst is on the local disk. FSDataOutputStream create(Path f,             FsPermission permission,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. boolean delete(Path f,             boolean recursive) Implement the delete(Path, boolean) in checksum  file system. static double getApproxChkSumLength(long size)  int getBytesPerSum() Return the bytes Per Checksum Path getChecksumFile(Path file) Return the name of the checksum file associated with a file. long getChecksumFileLength(Path file,                                           long fileSize) Return the length of the checksum file given the size of the   actual file. static long getChecksumLength(long size,                                   int bytesPerSum) Calculated the length of the checksum file in bytes. FileSystem getRawFileSystem() get the raw file system static boolean isChecksumFile(Path file) Return true iff file is a checksum file name. org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f) List the statuses of the files/directories in the given path if the path is  a directory. FileStatus[] listStatus(Path f) List the statuses of the files/directories in the given path if the path is  a directory. boolean mkdirs(Path f) Call FileSystem.mkdirs(Path, FsPermission) with default permission. FSDataInputStream open(Path f,         int bufferSize) Opens an FSDataInputStream at the indicated Path. boolean rename(Path src,             Path dst) Rename files/dirs boolean reportChecksumFailure(Path f,                                           FSDataInputStream in,                                           long inPos,                                           FSDataInputStream sums,                                           long sumsPos) Report a checksum error to the file system. void setConf(Configuration conf) Set the configuration to be used by this object. boolean setReplication(Path src,                             short replication) Set replication for an existing file. void setVerifyChecksum(boolean verifyChecksum) Set whether to verify checksum. void setWriteChecksum(boolean writeChecksum) Set the write checksum flag. Path startLocalOutput(Path fsOutputFile,                                 Path tmpLocalFile) Returns a local File that the user can write output to. boolean truncate(Path f,                 long newLength) Truncate the file in the indicated path to the indicated size. Methods inherited from class org.apache.hadoop.fs.FilterFileSystem access, canonicalizeUri, checkPath, close, concat, copyFromLocalFile, copyFromLocalFile, create, createNonRecursive, createSnapshot, createSymlink, deleteSnapshot, getAclStatus, getCanonicalUri, getChildFileSystems, getConf, getDefaultBlockSize, getDefaultBlockSize, getDefaultReplication, getDefaultReplication, getFileBlockLocations, getFileChecksum, getFileChecksum, getFileLinkStatus, getFileStatus, getHomeDirectory, getInitialWorkingDirectory, getLinkTarget, getServerDefaults, getServerDefaults, getStatus, getUri, getUsed, getWorkingDirectory, getXAttr, getXAttrs, getXAttrs, initialize, listCorruptFileBlocks, listStatusIterator, listXAttrs, makeQualified, mkdirs, modifyAclEntries, primitiveCreate, primitiveMkdir, removeAcl, removeAclEntries, removeDefaultAcl, removeXAttr, renameSnapshot, resolveLink, resolvePath, setAcl, setOwner, setPermission, setTimes, setWorkingDirectory, setXAttr, setXAttr, supportsSymlinks Methods inherited from class org.apache.hadoop.fs.FileSystem append, append, areSymlinksEnabled, cancelDeleteOnExit, clearStatistics, closeAll, closeAllForUGI, copyFromLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, create, createNewFile, createNonRecursive, createSnapshot, delete, deleteOnExit, enableSymlinks, exists, fixRelativePart, get, get, get, getAllStatistics, getBlockSize, getContentSummary, getDefaultPort, getDefaultUri, getFileBlockLocations, getFileSystemClass, getFSofPath, getLength, getLocal, getName, getNamed, getReplication, getScheme, getStatistics, getStatistics, getStatus, globStatus, globStatus, isDirectory, isFile, listFiles, listLocatedStatus, listStatus, listStatus, listStatus, mkdirs, moveFromLocalFile, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveMkdir, printStatistics, processDeleteOnExit, rename, setDefaultUri, setDefaultUri Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ChecksumFileSystem public ChecksumFileSystem(FileSystem fs) Method Detail getApproxChkSumLength public static double getApproxChkSumLength(long size) setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable Overrides: setConf in class Configured setVerifyChecksum public void setVerifyChecksum(boolean verifyChecksum) Set whether to verify checksum. Overrides: setVerifyChecksum in class FilterFileSystem setWriteChecksum public void setWriteChecksum(boolean writeChecksum) Description copied from class: FileSystem Set the write checksum flag. This is only applicable if the   corresponding FileSystem supports checksum. By default doesn't do anything. Overrides: setWriteChecksum in class FilterFileSystem getRawFileSystem public FileSystem getRawFileSystem() get the raw file system Overrides: getRawFileSystem in class FilterFileSystem Returns:FileSystem being filtered getChecksumFile public Path getChecksumFile(Path file) Return the name of the checksum file associated with a file. isChecksumFile public static boolean isChecksumFile(Path file) Return true iff file is a checksum file name. getChecksumFileLength public long getChecksumFileLength(Path file,                          long fileSize) Return the length of the checksum file given the size of the   actual file. getBytesPerSum public int getBytesPerSum() Return the bytes Per Checksum open public FSDataInputStream open(Path f,                      int bufferSize)                        throws IOException Opens an FSDataInputStream at the indicated Path. Overrides: open in class FilterFileSystem Parameters:f - the file name to openbufferSize - the size of the buffer to be used. Throws: IOException append public FSDataOutputStream append(Path f,                         int bufferSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Append to an existing file (optional operation). Overrides: append in class FilterFileSystem Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used.progress - for reporting progress if it is not null. Throws: IOException truncate public boolean truncate(Path f,                long newLength)                  throws IOException Description copied from class: FileSystem Truncate the file in the indicated path to the indicated size.    Fails if path is a directory.  Fails if path does not exist.  Fails if path is not closed.  Fails if new size is greater than current size.   Overrides: truncate in class FilterFileSystem Parameters:f - The path to the file to be truncatednewLength - The size the file is to be truncated to Returns:true if the file has been truncated to the desired  newLength and is immediately available to be reused for  write operations such as append, or  false if a background process of adjusting the length of  the last block has been started, and clients should wait for it to  complete before proceeding with further file updates. Throws: IOException getChecksumLength public static long getChecksumLength(long size,                      int bytesPerSum) Calculated the length of the checksum file in bytes. Parameters:size - the length of the data file in bytesbytesPerSum - the number of bytes in a checksum block Returns:the number of bytes in the checksum file create public FSDataOutputStream create(Path f,                         FsPermission permission,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Overrides: create in class FilterFileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) createNonRecursive public FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress)                                       throws IOException Description copied from class: FileSystem Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Overrides: createNonRecursive in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,  the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) setReplication public boolean setReplication(Path src,                      short replication)                        throws IOException Set replication for an existing file.  Implement the abstract setReplication of FileSystem Overrides: setReplication in class FilterFileSystem Parameters:src - file namereplication - new replication Returns:true if successful;          false if file does not exist or is a directory Throws: IOException rename public boolean rename(Path src,              Path dst)                throws IOException Rename files/dirs Overrides: rename in class FilterFileSystem Parameters:src - path to be renameddst - new path after rename Returns:true if rename is successful Throws: IOException - on failure delete public boolean delete(Path f,              boolean recursive)                throws IOException Implement the delete(Path, boolean) in checksum  file system. Overrides: delete in class FilterFileSystem Parameters:f - the path to delete.recursive - if path is a directory and set to   true, the directory is deleted else throws an exception. In  case of a file the recursive can be set to either true or false. Returns:true if delete is successful else false. Throws: IOException listStatus public FileStatus[] listStatus(Path f)                         throws IOException List the statuses of the files/directories in the given path if the path is  a directory. Overrides: listStatus in class FilterFileSystem Parameters:f - given path Returns:the statuses of the files/directories in the given path Throws: IOException FileNotFoundException - when the path does not exist;          IOException see specific implementation listLocatedStatus public org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f)                                                                          throws IOException List the statuses of the files/directories in the given path if the path is  a directory. Overrides: listLocatedStatus in class FilterFileSystem Parameters:f - given path Returns:the statuses of the files/directories in the given patch Throws: IOException FileNotFoundException - If f does not exist mkdirs public boolean mkdirs(Path f)                throws IOException Description copied from class: FileSystem Call FileSystem.mkdirs(Path, FsPermission) with default permission. Overrides: mkdirs in class FileSystem Throws: IOException copyFromLocalFile public void copyFromLocalFile(boolean delSrc,                      Path src,                      Path dst)                        throws IOException Description copied from class: FilterFileSystem The src file is on the local disk.  Add it to FS at  the given dst name.  delSrc indicates if the source should be removed Overrides: copyFromLocalFile in class FilterFileSystem Parameters:delSrc - whether to delete the srcsrc - pathdst - path Throws: IOException copyToLocalFile public void copyToLocalFile(boolean delSrc,                    Path src,                    Path dst)                      throws IOException The src file is under FS, and the dst is on the local disk.  Copy it from FS control to the local dst name. Overrides: copyToLocalFile in class FilterFileSystem Parameters:delSrc - whether to delete the srcsrc - pathdst - path Throws: IOException copyToLocalFile public void copyToLocalFile(Path src,                    Path dst,                    boolean copyCrc)                      throws IOException The src file is under FS, and the dst is on the local disk.  Copy it from FS control to the local dst name.  If src and dst are directories, the copyCrc parameter  determines whether to copy CRC files. Throws: IOException startLocalOutput public Path startLocalOutput(Path fsOutputFile,                     Path tmpLocalFile)                       throws IOException Description copied from class: FilterFileSystem Returns a local File that the user can write output to.  The caller  provides both the eventual FS target name and the local working  file.  If the FS is local, we write directly into the target.  If  the FS is remote, we write into the tmp local area. Overrides: startLocalOutput in class FilterFileSystem Parameters:fsOutputFile - path of output filetmpLocalFile - path of local tmp file Throws: IOException completeLocalOutput public void completeLocalOutput(Path fsOutputFile,                        Path tmpLocalFile)                          throws IOException Description copied from class: FilterFileSystem Called when we're all done writing to the target.  A local FS will  do nothing, because we've written to exactly the right place.  A remote  FS will copy the contents of tmpLocalFile to the correct target at  fsOutputFile. Overrides: completeLocalOutput in class FilterFileSystem Parameters:fsOutputFile - path of output filetmpLocalFile - path to local tmp file Throws: IOException reportChecksumFailure public boolean reportChecksumFailure(Path f,                             FSDataInputStream in,                             long inPos,                             FSDataInputStream sums,                             long sumsPos) Report a checksum error to the file system. Parameters:f - the file name containing the errorin - the stream open on the fileinPos - the position of the beginning of the bad data in the filesums - the stream open on the checksum filesumsPos - the position of the beginning of the bad data in the checksum file Returns:if retry is neccessary Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Client (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Client (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.applications.distributedshell Class Client java.lang.Object org.apache.hadoop.yarn.applications.distributedshell.Client @InterfaceAudience.Public @InterfaceStability.Unstable public class Client extends Object Client for Distributed Shell application submission to YARN.     The distributed shell client allows an application master to be launched that in turn would run   the provided shell command on a set of containers.     This client is meant to act as an example on how to write yarn-based applications.      To submit an application, a client first needs to connect to the ResourceManager   aka ApplicationsManager or ASM via the ApplicationClientProtocol. The ApplicationClientProtocol   provides a way for the client to get access to cluster information and to request for a  new ApplicationId.      For the actual job submission, the client first has to create an ApplicationSubmissionContext.   The ApplicationSubmissionContext defines the application details such as ApplicationId   and application name, the priority assigned to the application and the queue  to which this application needs to be assigned. In addition to this, the ApplicationSubmissionContext  also defines the ContainerLaunchContext which describes the Container with which   the ApplicationMaster is launched.      The ContainerLaunchContext in this scenario defines the resources to be allocated for the   ApplicationMaster's container, the local resources (jars, configuration files) to be made available   and the environment to be set for the ApplicationMaster and the commands to be executed to run the   ApplicationMaster.      Using the ApplicationSubmissionContext, the client submits the application to the   ResourceManager and then monitors the application by requesting the ResourceManager   for an ApplicationReport at regular time intervals. In case of the application taking too long, the client   kills the application by submitting a KillApplicationRequest to the ResourceManager.  Field Summary Fields  Modifier and Type Field and Description static String SCRIPT_PATH  Constructor Summary Constructors  Constructor and Description Client()  Client(Configuration conf)  Method Summary Methods  Modifier and Type Method and Description boolean init(String[] args) Parse command line options static void main(String[] args)  boolean run() Main run function for the client Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail SCRIPT_PATH public static final String SCRIPT_PATH See Also:Constant Field Values Constructor Detail Client public Client(Configuration conf)        throws Exception Throws: Exception Client public Client()        throws Exception Throws: Exception Method Detail main public static void main(String[] args) Parameters:args - Command line arguments init public boolean init(String[] args)              throws org.apache.commons.cli.ParseException Parse command line options Parameters:args - Parsed command line options Returns:Whether the init was successful to run the client Throws: org.apache.commons.cli.ParseException run public boolean run()             throws IOException,                    YarnException Main run function for the client Returns:true if application completed successfully Throws: IOException YarnException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ClientRMProxy (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ClientRMProxy (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client Class ClientRMProxy<T> java.lang.Object org.apache.hadoop.yarn.client.RMProxy<T> org.apache.hadoop.yarn.client.ClientRMProxy<T> @InterfaceAudience.Public @InterfaceStability.Stable public class ClientRMProxy<T> extends RMProxy<T> Method Summary Methods  Modifier and Type Method and Description static <T> T createRMProxy(Configuration configuration,                           Class<T> protocol) Create a proxy to the ResourceManager for the specified protocol. static Text getAMRMTokenService(Configuration conf)  static Text getRMDelegationTokenService(Configuration conf) Get the token service name to be used for RMDelegationToken. static Text getTokenService(Configuration conf,                               String address,                               String defaultAddr,                               int defaultPort)  Methods inherited from class org.apache.hadoop.yarn.client.RMProxy createRMProxy Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail createRMProxy public static <T> T createRMProxy(Configuration configuration,                   Class<T> protocol)                        throws IOException Create a proxy to the ResourceManager for the specified protocol. Type Parameters:T - Type of proxy.Parameters:configuration - Configuration with all the required information.protocol - Client protocol for which proxy is being requested. Returns:Proxy to the ResourceManager for the specified client protocol. Throws: IOException getRMDelegationTokenService @InterfaceStability.Unstable public static Text getRMDelegationTokenService(Configuration conf) Get the token service name to be used for RMDelegationToken. Depending  on whether HA is enabled or not, this method generates the appropriate  service name as a comma-separated list of service addresses. Parameters:conf - Configuration corresponding to the cluster we need the              RMDelegationToken for Returns:- Service name for RMDelegationToken getAMRMTokenService @InterfaceStability.Unstable public static Text getAMRMTokenService(Configuration conf) getTokenService @InterfaceStability.Unstable public static Text getTokenService(Configuration conf,                                                String address,                                                String defaultAddr,                                                int defaultPort) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ClientRMSecurityInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ClientRMSecurityInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.client Class ClientRMSecurityInfo java.lang.Object org.apache.hadoop.security.SecurityInfo org.apache.hadoop.yarn.security.client.ClientRMSecurityInfo @InterfaceAudience.Public @InterfaceStability.Stable public class ClientRMSecurityInfo extends org.apache.hadoop.security.SecurityInfo Constructor Summary Constructors  Constructor and Description ClientRMSecurityInfo()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                               Configuration conf) Get the KerberosInfo for a given protocol. org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                         Configuration conf) Get the TokenInfo for a given protocol. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ClientRMSecurityInfo public ClientRMSecurityInfo() Method Detail getKerberosInfo public org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the KerberosInfo for a given protocol. Specified by: getKerberosInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration Returns:KerberosInfo getTokenInfo public org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the TokenInfo for a given protocol. Specified by: getTokenInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration object. Returns:TokenInfo instance Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ClientSCMProtocol (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ClientSCMProtocol (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api Interface ClientSCMProtocol @InterfaceAudience.Public @InterfaceStability.Unstable public interface ClientSCMProtocol  The protocol between clients and the SharedCacheManager to claim  and release resources in the shared cache.   Method Summary Methods  Modifier and Type Method and Description ReleaseSharedCacheResourceResponse release(ReleaseSharedCacheResourceRequest request)  The interface used by clients to release a resource with the  SharedCacheManager. This method is called once an application  is no longer using a claimed resource in the shared cache. UseSharedCacheResourceResponse use(UseSharedCacheResourceRequest request)  The interface used by clients to claim a resource with the  SharedCacheManager. The client uses a checksum to identify the  resource and an ApplicationId to identify which application will be  using the resource. Method Detail use UseSharedCacheResourceResponse use(UseSharedCacheResourceRequest request)                                    throws YarnException,                                           IOException  The interface used by clients to claim a resource with the  SharedCacheManager. The client uses a checksum to identify the  resource and an ApplicationId to identify which application will be  using the resource.      The SharedCacheManager responds with whether or not the  resource exists in the cache. If the resource exists, a Path  to the resource in the shared cache is returned. If the resource does not  exist, the response is empty.   Parameters:request - request to claim a resource in the shared cache Returns:response indicating if the resource is already in the cache Throws: YarnException IOException release ReleaseSharedCacheResourceResponse release(ReleaseSharedCacheResourceRequest request)                                            throws YarnException,                                                   IOException  The interface used by clients to release a resource with the  SharedCacheManager. This method is called once an application  is no longer using a claimed resource in the shared cache. The client uses  a checksum to identify the resource and an ApplicationId to  identify which application is releasing the resource.      Note: This method is an optimization and the client is not required to call  it for correctness.      Currently the SharedCacheManager sends an empty response.   Parameters:request - request to release a resource in the shared cache Returns:(empty) response on releasing the resource Throws: YarnException IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ClientTimelineSecurityInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ClientTimelineSecurityInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.client Class ClientTimelineSecurityInfo java.lang.Object org.apache.hadoop.security.SecurityInfo org.apache.hadoop.yarn.security.client.ClientTimelineSecurityInfo @InterfaceAudience.Public @InterfaceStability.Unstable public class ClientTimelineSecurityInfo extends org.apache.hadoop.security.SecurityInfo Constructor Summary Constructors  Constructor and Description ClientTimelineSecurityInfo()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                               Configuration conf) Get the KerberosInfo for a given protocol. org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                         Configuration conf) Get the TokenInfo for a given protocol. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ClientTimelineSecurityInfo public ClientTimelineSecurityInfo() Method Detail getKerberosInfo public org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the KerberosInfo for a given protocol. Specified by: getKerberosInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration Returns:KerberosInfo getTokenInfo public org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the TokenInfo for a given protocol. Specified by: getTokenInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration object. Returns:TokenInfo instance Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ClientToAMTokenIdentifier (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ClientToAMTokenIdentifier (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.client Class ClientToAMTokenIdentifier java.lang.Object org.apache.hadoop.security.token.TokenIdentifier org.apache.hadoop.yarn.security.client.ClientToAMTokenIdentifier All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class ClientToAMTokenIdentifier extends org.apache.hadoop.security.token.TokenIdentifier Field Summary Fields  Modifier and Type Field and Description static Text KIND_NAME  Constructor Summary Constructors  Constructor and Description ClientToAMTokenIdentifier()  ClientToAMTokenIdentifier(ApplicationAttemptId id,                                                   String client)  Method Summary Methods  Modifier and Type Method and Description boolean equals(Object other)  ApplicationAttemptId getApplicationAttemptID()  String getClientName()  Text getKind() Get the token kind org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.ClientToAMTokenIdentifierProto getProto()  org.apache.hadoop.security.UserGroupInformation getUser() Get the Ugi with the username encoded in the token identifier int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.security.token.TokenIdentifier getBytes, getTrackingId Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail KIND_NAME public static final Text KIND_NAME Constructor Detail ClientToAMTokenIdentifier public ClientToAMTokenIdentifier() ClientToAMTokenIdentifier public ClientToAMTokenIdentifier(ApplicationAttemptId id,                          String client) Method Detail getApplicationAttemptID public ApplicationAttemptId getApplicationAttemptID() getClientName public String getClientName() getProto public org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.ClientToAMTokenIdentifierProto getProto() write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Parameters:in - DataInput to deseriablize this object from. Throws: IOException getKind public Text getKind() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the token kind Specified by: getKind in class org.apache.hadoop.security.token.TokenIdentifier Returns:the kind of the token getUser public org.apache.hadoop.security.UserGroupInformation getUser() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the Ugi with the username encoded in the token identifier Specified by: getUser in class org.apache.hadoop.security.token.TokenIdentifier Returns:the username. null is returned if username in the identifier is          empty or null. hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object other) Overrides: equals in class Object toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ClientToAMTokenSecretManager (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ClientToAMTokenSecretManager (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.client Class ClientToAMTokenSecretManager java.lang.Object org.apache.hadoop.security.token.SecretManager<ClientToAMTokenIdentifier> org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager org.apache.hadoop.yarn.security.client.ClientToAMTokenSecretManager @InterfaceAudience.Public @InterfaceStability.Evolving public class ClientToAMTokenSecretManager extends BaseClientToAMTokenSecretManager A simple SecretManager for AMs to validate Client-RM tokens issued to  clients by the RM using the underlying master-key shared by RM to the AMs on  their launch. All the methods are called by either Hadoop RPC or YARN, so  this class is strictly for the purpose of inherit/extend and register with  Hadoop RPC. Constructor Summary Constructors  Constructor and Description ClientToAMTokenSecretManager(ApplicationAttemptId applicationAttemptID,                                                         byte[] key)  Method Summary Methods  Modifier and Type Method and Description SecretKey getMasterKey(ApplicationAttemptId applicationAttemptID)  byte[] retrievePassword(ClientToAMTokenIdentifier identifier) Retrieve the password for the given token identifier. void setMasterKey(byte[] key)  Methods inherited from class org.apache.hadoop.security.token.SecretManager checkAvailableForRead, createPassword, createSecretKey, generateSecret, retriableRetrievePassword Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ClientToAMTokenSecretManager public ClientToAMTokenSecretManager(ApplicationAttemptId applicationAttemptID,                             byte[] key) Method Detail retrievePassword public byte[] retrievePassword(ClientToAMTokenIdentifier identifier)                         throws org.apache.hadoop.security.token.SecretManager.InvalidToken Description copied from class: org.apache.hadoop.security.token.SecretManager Retrieve the password for the given token identifier. Should check the date  or registry to make sure the token hasn't expired or been revoked. Returns   the relevant password. Parameters:identifier - the identifier to validate Returns:the password to use Throws: org.apache.hadoop.security.token.SecretManager.InvalidToken - the token was invalid getMasterKey public SecretKey getMasterKey(ApplicationAttemptId applicationAttemptID) setMasterKey public void setMasterKey(byte[] key) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Clock (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Clock (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.util Interface Clock All Known Implementing Classes: SystemClock, UTCClock @InterfaceAudience.Public @InterfaceStability.Stable public interface Clock A simple clock interface that gives you time. Method Summary Methods  Modifier and Type Method and Description long getTime()  Method Detail getTime long getTime() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Closeable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Closeable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Interface Closeable All Superinterfaces: AutoCloseable, Closeable All Known Subinterfaces: Mapper<K1,V1,K2,V2>, Reducer<K2,V2,K3,V3> All Known Implementing Classes: ChainMapper, ChainReducer, FieldSelectionMapReduce, IdentityMapper, IdentityReducer, InverseMapper, LongSumReducer, RegexMapper, TokenCountMapper, ValueAggregatorCombiner, ValueAggregatorJobBase, ValueAggregatorMapper, ValueAggregatorReducer Deprecated.  use java.io.Closeable @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public interface Closeable extends Closeable Method Summary Methods inherited from interface java.io.Closeable close Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Cluster (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Cluster (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class Cluster java.lang.Object org.apache.hadoop.mapreduce.Cluster @InterfaceAudience.Public @InterfaceStability.Evolving public class Cluster extends Object Provides a way to access information about the map/reduce cluster. Constructor Summary Constructors  Constructor and Description Cluster(Configuration conf)  Cluster(InetSocketAddress jobTrackAddr,               Configuration conf)  Method Summary Methods  Modifier and Type Method and Description void cancelDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> token) Deprecated.  Use Token.cancel(org.apache.hadoop.conf.Configuration) instead void close() Close the Cluster. TaskTrackerInfo[] getActiveTaskTrackers() Get all active trackers in the cluster. Job[] getAllJobs() Deprecated.  Use getAllJobStatuses() instead. JobStatus[] getAllJobStatuses() Get job status for all jobs in the cluster. TaskTrackerInfo[] getBlackListedTaskTrackers() Get blacklisted trackers. QueueInfo[] getChildQueues(String queueName) Returns immediate children of queueName. ClusterMetrics getClusterStatus() Get current cluster status. org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> getDelegationToken(Text renewer) Get a delegation token for the user from the JobTracker. FileSystem getFileSystem() Get the file system where job-specific files are stored Job getJob(JobID jobId) Get job corresponding to jobid. String getJobHistoryUrl(JobID jobId) Get the job history file path for a given job id. org.apache.hadoop.mapreduce.Cluster.JobTrackerStatus getJobTrackerStatus() Get the JobTracker's status. org.apache.hadoop.mapreduce.v2.LogParams getLogParams(JobID jobID,                         TaskAttemptID taskAttemptID) Get log parameters for the specified jobID or taskAttemptID QueueInfo getQueue(String name) Get queue information for the specified name. QueueAclsInfo[] getQueueAclsForCurrentUser() Gets the Queue ACLs for current user QueueInfo[] getQueues() Get all the queues in cluster. QueueInfo[] getRootQueues() Gets the root level queues. Path getStagingAreaDir() Grab the jobtracker's view of the staging directory path where   job-specific files will  be placed. Path getSystemDir() Grab the jobtracker system directory path where   job-specific files will  be placed. long getTaskTrackerExpiryInterval() Get the tasktracker expiry interval for the cluster long renewDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> token) Deprecated.  Use Token.renew(org.apache.hadoop.conf.Configuration) instead Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Cluster public Cluster(Configuration conf)         throws IOException Throws: IOException Cluster public Cluster(InetSocketAddress jobTrackAddr,        Configuration conf)         throws IOException Throws: IOException Method Detail close public void close()            throws IOException Close the Cluster. Throws: IOException getFileSystem public FileSystem getFileSystem()                          throws IOException,                                 InterruptedException Get the file system where job-specific files are stored Returns:object of FileSystem Throws: IOException InterruptedException getJob public Job getJob(JobID jobId)            throws IOException,                   InterruptedException Get job corresponding to jobid. Parameters:jobId -  Returns:object of Job Throws: IOException InterruptedException getQueues public QueueInfo[] getQueues()                       throws IOException,                              InterruptedException Get all the queues in cluster. Returns:array of QueueInfo Throws: IOException InterruptedException getQueue public QueueInfo getQueue(String name)                    throws IOException,                           InterruptedException Get queue information for the specified name. Parameters:name - queuename Returns:object of QueueInfo Throws: IOException InterruptedException getLogParams public org.apache.hadoop.mapreduce.v2.LogParams getLogParams(JobID jobID,                                                     TaskAttemptID taskAttemptID)                                                       throws IOException,                                                              InterruptedException Get log parameters for the specified jobID or taskAttemptID Parameters:jobID - the job id.taskAttemptID - the task attempt id. Optional. Returns:the LogParams Throws: IOException InterruptedException getClusterStatus public ClusterMetrics getClusterStatus()                                 throws IOException,                                        InterruptedException Get current cluster status. Returns:object of ClusterMetrics Throws: IOException InterruptedException getActiveTaskTrackers public TaskTrackerInfo[] getActiveTaskTrackers()                                         throws IOException,                                                InterruptedException Get all active trackers in the cluster. Returns:array of TaskTrackerInfo Throws: IOException InterruptedException getBlackListedTaskTrackers public TaskTrackerInfo[] getBlackListedTaskTrackers()                                              throws IOException,                                                     InterruptedException Get blacklisted trackers. Returns:array of TaskTrackerInfo Throws: IOException InterruptedException getAllJobs @Deprecated public Job[] getAllJobs()                  throws IOException,                         InterruptedException Deprecated. Use getAllJobStatuses() instead. Get all the jobs in cluster. Returns:array of Job Throws: IOException InterruptedException getAllJobStatuses public JobStatus[] getAllJobStatuses()                               throws IOException,                                      InterruptedException Get job status for all jobs in the cluster. Returns:job status for all jobs in cluster Throws: IOException InterruptedException getSystemDir public Path getSystemDir()                   throws IOException,                          InterruptedException Grab the jobtracker system directory path where   job-specific files will  be placed. Returns:the system directory where job-specific files are to be placed. Throws: IOException InterruptedException getStagingAreaDir public Path getStagingAreaDir()                        throws IOException,                               InterruptedException Grab the jobtracker's view of the staging directory path where   job-specific files will  be placed. Returns:the staging directory where job-specific files are to be placed. Throws: IOException InterruptedException getJobHistoryUrl public String getJobHistoryUrl(JobID jobId)                         throws IOException,                                InterruptedException Get the job history file path for a given job id. The job history file at   this path may or may not be existing depending on the job completion state.  The file is present only for the completed jobs. Parameters:jobId - the JobID of the job submitted by the current user. Returns:the file path of the job history file Throws: IOException InterruptedException getQueueAclsForCurrentUser public QueueAclsInfo[] getQueueAclsForCurrentUser()                                            throws IOException,                                                   InterruptedException Gets the Queue ACLs for current user Returns:array of QueueAclsInfo object for current user. Throws: IOException InterruptedException getRootQueues public QueueInfo[] getRootQueues()                           throws IOException,                                  InterruptedException Gets the root level queues. Returns:array of JobQueueInfo object. Throws: IOException InterruptedException getChildQueues public QueueInfo[] getChildQueues(String queueName)                            throws IOException,                                   InterruptedException Returns immediate children of queueName. Parameters:queueName -  Returns:array of JobQueueInfo which are children of queueName Throws: IOException InterruptedException getJobTrackerStatus public org.apache.hadoop.mapreduce.Cluster.JobTrackerStatus getJobTrackerStatus()                                                                          throws IOException,                                                                                 InterruptedException Get the JobTracker's status. Returns:Cluster.JobTrackerStatus of the JobTracker Throws: IOException InterruptedException getTaskTrackerExpiryInterval public long getTaskTrackerExpiryInterval()                                   throws IOException,                                          InterruptedException Get the tasktracker expiry interval for the cluster Returns:the expiry interval in msec Throws: IOException InterruptedException getDelegationToken public org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> getDelegationToken(Text renewer)                                                                                                                                            throws IOException,                                                                                                                                                   InterruptedException Get a delegation token for the user from the JobTracker. Parameters:renewer - the user who can renew the token Returns:the new token Throws: IOException InterruptedException renewDelegationToken public long renewDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> token)                           throws org.apache.hadoop.security.token.SecretManager.InvalidToken,                                  IOException,                                  InterruptedException Deprecated. Use Token.renew(org.apache.hadoop.conf.Configuration) instead Renew a delegation token Parameters:token - the token to renew Returns:the new expiration time Throws: org.apache.hadoop.security.token.SecretManager.InvalidToken IOException InterruptedException cancelDelegationToken public void cancelDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> token)                            throws IOException,                                   InterruptedException Deprecated. Use Token.cancel(org.apache.hadoop.conf.Configuration) instead Cancel a delegation token from the JobTracker Parameters:token - the token to cancel Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ClusterMetrics (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ClusterMetrics (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class ClusterMetrics java.lang.Object org.apache.hadoop.mapreduce.ClusterMetrics All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class ClusterMetrics extends Object implements Writable Status information on the current state of the Map-Reduce cluster.    ClusterMetrics provides clients with information such as:          Size of the cluster.              Number of blacklisted and decommissioned trackers.              Slot capacity of the cluster.             The number of currently occupied/reserved map and reduce slots.            The number of currently running map and reduce tasks.            The number of job submissions.          Clients can query for the latest ClusterMetrics, via   Cluster.getClusterStatus(). See Also:Cluster Constructor Summary Constructors  Constructor and Description ClusterMetrics()  ClusterMetrics(int runningMaps,                             int runningReduces,                             int occupiedMapSlots,                             int occupiedReduceSlots,                             int reservedMapSlots,                             int reservedReduceSlots,                             int mapSlots,                             int reduceSlots,                             int totalJobSubmissions,                             int numTrackers,                             int numBlacklistedTrackers,                             int numDecommissionedNodes)  ClusterMetrics(int runningMaps,                             int runningReduces,                             int occupiedMapSlots,                             int occupiedReduceSlots,                             int reservedMapSlots,                             int reservedReduceSlots,                             int mapSlots,                             int reduceSlots,                             int totalJobSubmissions,                             int numTrackers,                             int numBlacklistedTrackers,                             int numGraylistedTrackers,                             int numDecommissionedNodes)  Method Summary Methods  Modifier and Type Method and Description int getBlackListedTaskTrackerCount() Get the number of blacklisted trackers in the cluster. int getDecommissionedTaskTrackerCount() Get the number of decommissioned trackers in the cluster. int getGrayListedTaskTrackerCount() Get the number of graylisted trackers in the cluster. int getMapSlotCapacity() Get the total number of map slots in the cluster. int getOccupiedMapSlots() Get number of occupied map slots in the cluster. int getOccupiedReduceSlots() Get the number of occupied reduce slots in the cluster. int getReduceSlotCapacity() Get the total number of reduce slots in the cluster. int getReservedMapSlots() Get number of reserved map slots in the cluster. int getReservedReduceSlots() Get the number of reserved reduce slots in the cluster. int getRunningMaps() Get the number of running map tasks in the cluster. int getRunningReduces() Get the number of running reduce tasks in the cluster. int getTaskTrackerCount() Get the number of active trackers in the cluster. int getTotalJobSubmissions() Get the total number of job submissions in the cluster. void readFields(DataInput in) Deserialize the fields of this object from in. void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ClusterMetrics public ClusterMetrics() ClusterMetrics public ClusterMetrics(int runningMaps,               int runningReduces,               int occupiedMapSlots,               int occupiedReduceSlots,               int reservedMapSlots,               int reservedReduceSlots,               int mapSlots,               int reduceSlots,               int totalJobSubmissions,               int numTrackers,               int numBlacklistedTrackers,               int numDecommissionedNodes) ClusterMetrics public ClusterMetrics(int runningMaps,               int runningReduces,               int occupiedMapSlots,               int occupiedReduceSlots,               int reservedMapSlots,               int reservedReduceSlots,               int mapSlots,               int reduceSlots,               int totalJobSubmissions,               int numTrackers,               int numBlacklistedTrackers,               int numGraylistedTrackers,               int numDecommissionedNodes) Method Detail getRunningMaps public int getRunningMaps() Get the number of running map tasks in the cluster. Returns:running maps getRunningReduces public int getRunningReduces() Get the number of running reduce tasks in the cluster. Returns:running reduces getOccupiedMapSlots public int getOccupiedMapSlots() Get number of occupied map slots in the cluster. Returns:occupied map slot count getOccupiedReduceSlots public int getOccupiedReduceSlots() Get the number of occupied reduce slots in the cluster. Returns:occupied reduce slot count getReservedMapSlots public int getReservedMapSlots() Get number of reserved map slots in the cluster. Returns:reserved map slot count getReservedReduceSlots public int getReservedReduceSlots() Get the number of reserved reduce slots in the cluster. Returns:reserved reduce slot count getMapSlotCapacity public int getMapSlotCapacity() Get the total number of map slots in the cluster. Returns:map slot capacity getReduceSlotCapacity public int getReduceSlotCapacity() Get the total number of reduce slots in the cluster. Returns:reduce slot capacity getTotalJobSubmissions public int getTotalJobSubmissions() Get the total number of job submissions in the cluster. Returns:total number of job submissions getTaskTrackerCount public int getTaskTrackerCount() Get the number of active trackers in the cluster. Returns:active tracker count. getBlackListedTaskTrackerCount public int getBlackListedTaskTrackerCount() Get the number of blacklisted trackers in the cluster. Returns:blacklisted tracker count getGrayListedTaskTrackerCount public int getGrayListedTaskTrackerCount() Get the number of graylisted trackers in the cluster. Returns:graylisted tracker count getDecommissionedTaskTrackerCount public int getDecommissionedTaskTrackerCount() Get the number of decommissioned trackers in the cluster. Returns:decommissioned tracker count readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ClusterStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ClusterStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class ClusterStatus java.lang.Object org.apache.hadoop.mapred.ClusterStatus All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class ClusterStatus extends Object implements Writable Status information on the current state of the Map-Reduce cluster.    ClusterStatus provides clients with information such as:          Size of the cluster.             Name of the trackers.             Task capacity of the cluster.             The number of currently running map and reduce tasks.            State of the JobTracker.            Details regarding black listed trackers.          Clients can query for the latest ClusterStatus, via   JobClient.getClusterStatus(). See Also:JobClient Field Summary Fields  Modifier and Type Field and Description static long UNINITIALIZED_MEMORY_VALUE  Method Summary Methods  Modifier and Type Method and Description Collection<String> getActiveTrackerNames() Get the names of task trackers in the cluster. Collection<String> getBlacklistedTrackerNames() Get the names of task trackers in the cluster. int getBlacklistedTrackers() Get the number of blacklisted task trackers in the cluster. Collection<org.apache.hadoop.mapred.ClusterStatus.BlackListInfo> getBlackListedTrackersInfo() Gets the list of blacklisted trackers along with reasons for blacklisting. Collection<String> getGraylistedTrackerNames() Deprecated.  int getGraylistedTrackers() Deprecated.  org.apache.hadoop.mapred.JobTracker.State getJobTrackerState() Deprecated.  org.apache.hadoop.mapreduce.Cluster.JobTrackerStatus getJobTrackerStatus() Get the JobTracker's status. int getMapTasks() Get the number of currently running map tasks in the cluster. int getMaxMapTasks() Get the maximum capacity for running map tasks in the cluster. long getMaxMemory() Deprecated.  int getMaxReduceTasks() Get the maximum capacity for running reduce tasks in the cluster. int getNumExcludedNodes() Get the number of excluded hosts in the cluster. int getReduceTasks() Get the number of currently running reduce tasks in the cluster. int getTaskTrackers() Get the number of task trackers in the cluster. long getTTExpiryInterval() Get the tasktracker expiry interval for the cluster long getUsedMemory() Deprecated.  void readFields(DataInput in) Deserialize the fields of this object from in. void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail UNINITIALIZED_MEMORY_VALUE public static final long UNINITIALIZED_MEMORY_VALUE See Also:Constant Field Values Method Detail getTaskTrackers public int getTaskTrackers() Get the number of task trackers in the cluster. Returns:the number of task trackers in the cluster. getActiveTrackerNames public Collection<String> getActiveTrackerNames() Get the names of task trackers in the cluster. Returns:the active task trackers in the cluster. getBlacklistedTrackerNames public Collection<String> getBlacklistedTrackerNames() Get the names of task trackers in the cluster. Returns:the blacklisted task trackers in the cluster. getGraylistedTrackerNames @Deprecated public Collection<String> getGraylistedTrackerNames() Deprecated.  Get the names of graylisted task trackers in the cluster.  The gray list of trackers is no longer available on M/R 2.x. The function  is kept to be compatible with M/R 1.x applications. Returns:an empty graylisted task trackers in the cluster. getGraylistedTrackers @Deprecated public int getGraylistedTrackers() Deprecated.  Get the number of graylisted task trackers in the cluster.  The gray list of trackers is no longer available on M/R 2.x. The function  is kept to be compatible with M/R 1.x applications. Returns:0 graylisted task trackers in the cluster. getBlacklistedTrackers public int getBlacklistedTrackers() Get the number of blacklisted task trackers in the cluster. Returns:the number of blacklisted task trackers in the cluster. getNumExcludedNodes public int getNumExcludedNodes() Get the number of excluded hosts in the cluster. Returns:the number of excluded hosts in the cluster. getTTExpiryInterval public long getTTExpiryInterval() Get the tasktracker expiry interval for the cluster Returns:the expiry interval in msec getMapTasks public int getMapTasks() Get the number of currently running map tasks in the cluster. Returns:the number of currently running map tasks in the cluster. getReduceTasks public int getReduceTasks() Get the number of currently running reduce tasks in the cluster. Returns:the number of currently running reduce tasks in the cluster. getMaxMapTasks public int getMaxMapTasks() Get the maximum capacity for running map tasks in the cluster. Returns:the maximum capacity for running map tasks in the cluster. getMaxReduceTasks public int getMaxReduceTasks() Get the maximum capacity for running reduce tasks in the cluster. Returns:the maximum capacity for running reduce tasks in the cluster. getJobTrackerStatus public org.apache.hadoop.mapreduce.Cluster.JobTrackerStatus getJobTrackerStatus() Get the JobTracker's status. Returns:Cluster.JobTrackerStatus of the JobTracker getMaxMemory @Deprecated public long getMaxMemory() Deprecated.  Returns UNINITIALIZED_MEMORY_VALUE (-1) getUsedMemory @Deprecated public long getUsedMemory() Deprecated.  Returns UNINITIALIZED_MEMORY_VALUE (-1) getBlackListedTrackersInfo public Collection<org.apache.hadoop.mapred.ClusterStatus.BlackListInfo> getBlackListedTrackersInfo() Gets the list of blacklisted trackers along with reasons for blacklisting. Returns:the collection of ClusterStatus.BlackListInfo objects. getJobTrackerState @Deprecated public org.apache.hadoop.mapred.JobTracker.State getJobTrackerState() Deprecated.  Get the current state of the JobTracker,  as JobTracker.State  JobTracker.State should no longer be used on M/R 2.x. The function  is kept to be compatible with M/R 1.x applications. Returns:the invalid state of the JobTracker. write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CodeBuffer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CodeBuffer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class CodeBuffer java.lang.Object org.apache.hadoop.record.compiler.CodeBuffer Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class CodeBuffer extends Object A wrapper around StringBuffer that automatically does indentation Method Summary Methods  Modifier and Type Method and Description String toString() Deprecated.    Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Method Detail toString public String toString() Deprecated.  Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CodecPool (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CodecPool (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class CodecPool java.lang.Object org.apache.hadoop.io.compress.CodecPool @InterfaceAudience.Public @InterfaceStability.Evolving public class CodecPool extends Object A global compressor/decompressor pool used to save and reuse   (possibly native) compression/decompression codecs. Constructor Summary Constructors  Constructor and Description CodecPool()  Method Summary Methods  Modifier and Type Method and Description static Compressor getCompressor(CompressionCodec codec)  static Compressor getCompressor(CompressionCodec codec,                           Configuration conf) Get a Compressor for the given CompressionCodec from the   pool or a new one. static Decompressor getDecompressor(CompressionCodec codec) Get a Decompressor for the given CompressionCodec from the  pool or a new one. static int getLeasedCompressorsCount(CompressionCodec codec) Return the number of leased Compressors for this  CompressionCodec static int getLeasedDecompressorsCount(CompressionCodec codec) Return the number of leased Decompressors for this  CompressionCodec static void returnCompressor(Compressor compressor) Return the Compressor to the pool. static void returnDecompressor(Decompressor decompressor) Return the Decompressor to the pool. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail CodecPool public CodecPool() Method Detail getCompressor public static Compressor getCompressor(CompressionCodec codec,                        Configuration conf) Get a Compressor for the given CompressionCodec from the   pool or a new one. Parameters:codec - the CompressionCodec for which to get the                Compressorconf - the Configuration object which contains confs for creating or reinit the compressor Returns:Compressor for the given           CompressionCodec from the pool or a new one getCompressor public static Compressor getCompressor(CompressionCodec codec) getDecompressor public static Decompressor getDecompressor(CompressionCodec codec) Get a Decompressor for the given CompressionCodec from the  pool or a new one. Parameters:codec - the CompressionCodec for which to get the                Decompressor Returns:Decompressor for the given           CompressionCodec the pool or a new one returnCompressor public static void returnCompressor(Compressor compressor) Return the Compressor to the pool. Parameters:compressor - the Compressor to be returned to the pool returnDecompressor public static void returnDecompressor(Decompressor decompressor) Return the Decompressor to the pool. Parameters:decompressor - the Decompressor to be returned to the                       pool getLeasedCompressorsCount public static int getLeasedCompressorsCount(CompressionCodec codec) Return the number of leased Compressors for this  CompressionCodec getLeasedDecompressorsCount public static int getLeasedDecompressorsCount(CompressionCodec codec) Return the number of leased Decompressors for this  CompressionCodec Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CombineFileInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CombineFileInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class CombineFileInputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat<K,V> Direct Known Subclasses: CombineFileInputFormat, CombineSequenceFileInputFormat, CombineTextInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public abstract class CombineFileInputFormat<K,V> extends FileInputFormat<K,V> An abstract InputFormat that returns CombineFileSplit's in   InputFormat.getSplits(JobContext) method.     Splits are constructed from the files under the input paths.   A split cannot have files from different pools.  Each split returned may contain blocks from different files.  If a maxSplitSize is specified, then blocks on the same node are  combined to form a single split. Blocks that are left over are  then combined with other blocks in the same rack.   If maxSplitSize is not specified, then blocks from the same rack  are combined in a single split; no attempt is made to create  node-local splits.  If the maxSplitSize is equal to the block size, then this class  is similar to the default splitting behavior in Hadoop: each  block is a locally processed split.  Subclasses implement   InputFormat.createRecordReader(InputSplit, TaskAttemptContext)  to construct RecordReader's for   CombineFileSplit's. See Also:CombineFileSplit Field Summary Fields  Modifier and Type Field and Description static String SPLIT_MINSIZE_PERNODE  static String SPLIT_MINSIZE_PERRACK  Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description CombineFileInputFormat() default constructor Method Summary Methods  Modifier and Type Method and Description protected void createPool(List<PathFilter> filters) Create a new pool and add the filters to it. protected void createPool(PathFilter... filters) Create a new pool and add the filters to it. abstract RecordReader<K,V> createRecordReader(InputSplit split,                                     TaskAttemptContext context) This is not implemented yet. protected BlockLocation[] getFileBlockLocations(FileSystem fs,                                           FileStatus stat)  List<InputSplit> getSplits(JobContext job) Generate the list of files and make them into FileSplits. protected boolean isSplitable(JobContext context,                       Path file) Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be. protected void setMaxSplitSize(long maxSplitSize) Specify the maximum size (in bytes) of each split. protected void setMinSplitSizeNode(long minSplitSizeNode) Specify the minimum size (in bytes) of each split per node. protected void setMinSplitSizeRack(long minSplitSizeRack) Specify the minimum size (in bytes) of each split per rack. Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getFormatMinSplitSize, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, listStatus, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail SPLIT_MINSIZE_PERNODE public static final String SPLIT_MINSIZE_PERNODE See Also:Constant Field Values SPLIT_MINSIZE_PERRACK public static final String SPLIT_MINSIZE_PERRACK See Also:Constant Field Values Constructor Detail CombineFileInputFormat public CombineFileInputFormat() default constructor Method Detail setMaxSplitSize protected void setMaxSplitSize(long maxSplitSize) Specify the maximum size (in bytes) of each split. Each split is  approximately equal to the specified size. setMinSplitSizeNode protected void setMinSplitSizeNode(long minSplitSizeNode) Specify the minimum size (in bytes) of each split per node.  This applies to data that is left over after combining data on a single  node into splits that are of maximum size specified by maxSplitSize.  This leftover data will be combined into its own split if its size  exceeds minSplitSizeNode. setMinSplitSizeRack protected void setMinSplitSizeRack(long minSplitSizeRack) Specify the minimum size (in bytes) of each split per rack.  This applies to data that is left over after combining data on a single  rack into splits that are of maximum size specified by maxSplitSize.  This leftover data will be combined into its own split if its size  exceeds minSplitSizeRack. createPool protected void createPool(List<PathFilter> filters) Create a new pool and add the filters to it.  A split cannot have files from different pools. createPool protected void createPool(PathFilter... filters) Create a new pool and add the filters to it.   A pathname can satisfy any one of the specified filters.  A split cannot have files from different pools. isSplitable protected boolean isSplitable(JobContext context,                   Path file) Description copied from class: FileInputFormat Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be.    FileInputFormat implementations can override this and return  false to ensure that individual input files are never split-up  so that Mappers process entire files. Overrides: isSplitable in class FileInputFormat<K,V> Parameters:context - the job contextfile - the file name to check Returns:is this file splitable? getSplits public List<InputSplit> getSplits(JobContext job)                            throws IOException Description copied from class: FileInputFormat Generate the list of files and make them into FileSplits. Overrides: getSplits in class FileInputFormat<K,V> Parameters:job - the job context Returns:an array of InputSplits for the job. Throws: IOException createRecordReader public abstract RecordReader<K,V> createRecordReader(InputSplit split,                                    TaskAttemptContext context)                                               throws IOException This is not implemented yet. Specified by: createRecordReader in class InputFormat<K,V> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException getFileBlockLocations protected BlockLocation[] getFileBlockLocations(FileSystem fs,                                     FileStatus stat)                                          throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CombineFileRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CombineFileRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class CombineFileRecordReader<K,V> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader<K,V> All Implemented Interfaces: Closeable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Stable public class CombineFileRecordReader<K,V> extends RecordReader<K,V> A generic RecordReader that can hand out different recordReaders  for each chunk in a CombineFileSplit.  A CombineFileSplit can combine data chunks from multiple files.   This class allows using different RecordReaders for processing  these data chunks from different files. See Also:CombineFileSplit Field Summary Fields  Modifier and Type Field and Description protected TaskAttemptContext context  protected RecordReader<K,V> curReader  protected int idx  protected long progress  protected Constructor<? extends RecordReader<K,V>> rrConstructor  protected CombineFileSplit split  Constructor Summary Constructors  Constructor and Description CombineFileRecordReader(CombineFileSplit split,                                               TaskAttemptContext context,                                               Class<? extends RecordReader<K,V>> rrClass) A generic RecordReader that can hand out different recordReaders  for each chunk in the CombineFileSplit. Method Summary Methods  Modifier and Type Method and Description void close() Close the record reader. K getCurrentKey() Get the current key V getCurrentValue() Get the current value. float getProgress() return progress based on the amount of data processed so far. void initialize(InputSplit split,                     TaskAttemptContext context) Called once at initialization. protected boolean initNextRecordReader() Get the record reader for the next chunk in this CombineFileSplit. boolean nextKeyValue() Read the next key, value pair. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail split protected CombineFileSplit split rrConstructor protected Constructor<? extends RecordReader<K,V>> rrConstructor context protected TaskAttemptContext context idx protected int idx progress protected long progress curReader protected RecordReader<K,V> curReader Constructor Detail CombineFileRecordReader public CombineFileRecordReader(CombineFileSplit split,                        TaskAttemptContext context,                        Class<? extends RecordReader<K,V>> rrClass)                         throws IOException A generic RecordReader that can hand out different recordReaders  for each chunk in the CombineFileSplit. Throws: IOException Method Detail initialize public void initialize(InputSplit split,               TaskAttemptContext context)                 throws IOException,                        InterruptedException Description copied from class: RecordReader Called once at initialization. Specified by: initialize in class RecordReader<K,V> Parameters:split - the split that defines the range of records to readcontext - the information about the task Throws: IOException InterruptedException nextKeyValue public boolean nextKeyValue()                      throws IOException,                             InterruptedException Description copied from class: RecordReader Read the next key, value pair. Specified by: nextKeyValue in class RecordReader<K,V> Returns:true if a key/value pair was read Throws: IOException InterruptedException getCurrentKey public K getCurrentKey()                 throws IOException,                        InterruptedException Description copied from class: RecordReader Get the current key Specified by: getCurrentKey in class RecordReader<K,V> Returns:the current key or null if there is no current key Throws: IOException InterruptedException getCurrentValue public V getCurrentValue()                   throws IOException,                          InterruptedException Description copied from class: RecordReader Get the current value. Specified by: getCurrentValue in class RecordReader<K,V> Returns:the object that was read Throws: IOException InterruptedException close public void close()            throws IOException Description copied from class: RecordReader Close the record reader. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in class RecordReader<K,V> Throws: IOException getProgress public float getProgress()                   throws IOException,                          InterruptedException return progress based on the amount of data processed so far. Specified by: getProgress in class RecordReader<K,V> Returns:a number between 0.0 and 1.0 that is the fraction of the data read Throws: IOException InterruptedException initNextRecordReader protected boolean initNextRecordReader()                                 throws IOException Get the record reader for the next chunk in this CombineFileSplit. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CombineFileRecordReaderWrapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CombineFileRecordReaderWrapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class CombineFileRecordReaderWrapper<K,V> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper<K,V> All Implemented Interfaces: Closeable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Stable public abstract class CombineFileRecordReaderWrapper<K,V> extends RecordReader<K,V> A wrapper class for a record reader that handles a single file split. It  delegates most of the methods to the wrapped instance. A concrete subclass  needs to provide a constructor that calls this parent constructor with the  appropriate input format. The subclass constructor must satisfy the specific  constructor signature that is required by  CombineFileRecordReader.  Subclassing is needed to get a concrete record reader wrapper because of the  constructor requirement. See Also:CombineFileRecordReader,  CombineFileInputFormat Constructor Summary Constructors  Modifier Constructor and Description protected  CombineFileRecordReaderWrapper(FileInputFormat<K,V> inputFormat,                                                             CombineFileSplit split,                                                             TaskAttemptContext context,                                                             Integer idx)  Method Summary Methods  Modifier and Type Method and Description void close() Close the record reader. K getCurrentKey() Get the current key V getCurrentValue() Get the current value. float getProgress() The current progress of the record reader through its data. void initialize(InputSplit split,                     TaskAttemptContext context) Called once at initialization. boolean nextKeyValue() Read the next key, value pair. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail CombineFileRecordReaderWrapper protected CombineFileRecordReaderWrapper(FileInputFormat<K,V> inputFormat,                               CombineFileSplit split,                               TaskAttemptContext context,                               Integer idx)                                   throws IOException,                                          InterruptedException Throws: IOException InterruptedException Method Detail initialize public void initialize(InputSplit split,               TaskAttemptContext context)                 throws IOException,                        InterruptedException Description copied from class: RecordReader Called once at initialization. Specified by: initialize in class RecordReader<K,V> Parameters:split - the split that defines the range of records to readcontext - the information about the task Throws: IOException InterruptedException nextKeyValue public boolean nextKeyValue()                      throws IOException,                             InterruptedException Description copied from class: RecordReader Read the next key, value pair. Specified by: nextKeyValue in class RecordReader<K,V> Returns:true if a key/value pair was read Throws: IOException InterruptedException getCurrentKey public K getCurrentKey()                 throws IOException,                        InterruptedException Description copied from class: RecordReader Get the current key Specified by: getCurrentKey in class RecordReader<K,V> Returns:the current key or null if there is no current key Throws: IOException InterruptedException getCurrentValue public V getCurrentValue()                   throws IOException,                          InterruptedException Description copied from class: RecordReader Get the current value. Specified by: getCurrentValue in class RecordReader<K,V> Returns:the object that was read Throws: IOException InterruptedException getProgress public float getProgress()                   throws IOException,                          InterruptedException Description copied from class: RecordReader The current progress of the record reader through its data. Specified by: getProgress in class RecordReader<K,V> Returns:a number between 0.0 and 1.0 that is the fraction of the data read Throws: IOException InterruptedException close public void close()            throws IOException Description copied from class: RecordReader Close the record reader. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in class RecordReader<K,V> Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CombineFileSplit (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CombineFileSplit (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class CombineFileSplit java.lang.Object org.apache.hadoop.mapreduce.InputSplit org.apache.hadoop.mapreduce.lib.input.CombineFileSplit All Implemented Interfaces: Writable Direct Known Subclasses: CombineFileSplit @InterfaceAudience.Public @InterfaceStability.Stable public class CombineFileSplit extends InputSplit implements Writable A sub-collection of input files.     Unlike FileSplit, CombineFileSplit class does not represent   a split of a file, but a split of input files into smaller sets.   A split may contain blocks from different file but all   the blocks in the same split are probably local to some rack    CombineFileSplit can be used to implement RecordReader's,   with reading one record per file. See Also:FileSplit,  CombineFileInputFormat Constructor Summary Constructors  Constructor and Description CombineFileSplit() default constructor CombineFileSplit(CombineFileSplit old) Copy constructor CombineFileSplit(Path[] files,                                 long[] lengths)  CombineFileSplit(Path[] files,                                 long[] start,                                 long[] lengths,                                 String[] locations)  Method Summary Methods  Modifier and Type Method and Description long getLength() Get the size of the split, so that the input splits can be sorted by size. long getLength(int i) Returns the length of the ith Path long[] getLengths() Returns an array containing the lengths of the files in the split String[] getLocations() Returns all the Paths where this input-split resides int getNumPaths() Returns the number of Paths in the split long getOffset(int i) Returns the start offset of the ith Path Path getPath(int i) Returns the ith Path Path[] getPaths() Returns all the Paths in the split long[] getStartOffsets() Returns an array containing the start offsets of the files in the split void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.mapreduce.InputSplit getLocationInfo Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail CombineFileSplit public CombineFileSplit() default constructor CombineFileSplit public CombineFileSplit(Path[] files,                 long[] start,                 long[] lengths,                 String[] locations) CombineFileSplit public CombineFileSplit(Path[] files,                 long[] lengths) CombineFileSplit public CombineFileSplit(CombineFileSplit old)                  throws IOException Copy constructor Throws: IOException Method Detail getLength public long getLength() Description copied from class: InputSplit Get the size of the split, so that the input splits can be sorted by size. Specified by: getLength in class InputSplit Returns:the number of bytes in the split getStartOffsets public long[] getStartOffsets() Returns an array containing the start offsets of the files in the split getLengths public long[] getLengths() Returns an array containing the lengths of the files in the split getOffset public long getOffset(int i) Returns the start offset of the ith Path getLength public long getLength(int i) Returns the length of the ith Path getNumPaths public int getNumPaths() Returns the number of Paths in the split getPath public Path getPath(int i) Returns the ith Path getPaths public Path[] getPaths() Returns all the Paths in the split getLocations public String[] getLocations()                       throws IOException Returns all the Paths where this input-split resides Specified by: getLocations in class InputSplit Returns:a new array of the node nodes. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CombineSequenceFileInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CombineSequenceFileInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class CombineSequenceFileInputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class CombineSequenceFileInputFormat<K,V> extends CombineFileInputFormat<K,V> Input format that is a CombineFileInputFormat-equivalent for  SequenceFileInputFormat. See Also:CombineFileInputFormat Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat SPLIT_MINSIZE_PERNODE, SPLIT_MINSIZE_PERRACK Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description CombineSequenceFileInputFormat()  Method Summary Methods  Modifier and Type Method and Description RecordReader<K,V> createRecordReader(InputSplit split,                                     TaskAttemptContext context) This is not implemented yet. Methods inherited from class org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat createPool, createPool, getFileBlockLocations, getSplits, isSplitable, setMaxSplitSize, setMinSplitSizeNode, setMinSplitSizeRack Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getFormatMinSplitSize, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, listStatus, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail CombineSequenceFileInputFormat public CombineSequenceFileInputFormat() Method Detail createRecordReader public RecordReader<K,V> createRecordReader(InputSplit split,                                    TaskAttemptContext context)                                      throws IOException Description copied from class: CombineFileInputFormat This is not implemented yet. Specified by: createRecordReader in class CombineFileInputFormat<K,V> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CombineTextInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CombineTextInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class CombineTextInputFormat java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat<LongWritable,Text> org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class CombineTextInputFormat extends CombineFileInputFormat<LongWritable,Text> Input format that is a CombineFileInputFormat-equivalent for  TextInputFormat. See Also:CombineFileInputFormat Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat SPLIT_MINSIZE_PERNODE, SPLIT_MINSIZE_PERRACK Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description CombineTextInputFormat()  Method Summary Methods  Modifier and Type Method and Description RecordReader<LongWritable,Text> createRecordReader(InputSplit split,                                     TaskAttemptContext context) This is not implemented yet. Methods inherited from class org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat createPool, createPool, getFileBlockLocations, getSplits, isSplitable, setMaxSplitSize, setMinSplitSizeNode, setMinSplitSizeRack Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getFormatMinSplitSize, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, listStatus, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail CombineTextInputFormat public CombineTextInputFormat() Method Detail createRecordReader public RecordReader<LongWritable,Text> createRecordReader(InputSplit split,                                                  TaskAttemptContext context)                                                    throws IOException Description copied from class: CombineFileInputFormat This is not implemented yet. Specified by: createRecordReader in class CombineFileInputFormat<LongWritable,Text> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CommonConfigurationKeysPublic (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CommonConfigurationKeysPublic (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class CommonConfigurationKeysPublic java.lang.Object org.apache.hadoop.fs.CommonConfigurationKeysPublic @InterfaceAudience.Public public class CommonConfigurationKeysPublic extends Object This class contains constants for configuration keys used  in the common code.  It includes all publicly documented configuration keys. In general  this class should not be used directly (use CommonConfigurationKeys  instead) Field Summary Fields  Modifier and Type Field and Description static boolean FS_AUTOMATIC_CLOSE_DEFAULT Default value for FS_AUTOMATIC_CLOSE_KEY static String FS_AUTOMATIC_CLOSE_KEY See core-default.xml static boolean FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_DEFAULT Default value for FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_KEY static String FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_KEY See core-default.xml static String FS_DEFAULT_NAME_DEFAULT Default value for FS_DEFAULT_NAME_KEY static String FS_DEFAULT_NAME_KEY See core-default.xml static long FS_DF_INTERVAL_DEFAULT Default value for FS_DF_INTERVAL_KEY static String FS_DF_INTERVAL_KEY See core-default.xml static long FS_DU_INTERVAL_DEFAULT Default value for FS_DU_INTERVAL_KEY static String FS_DU_INTERVAL_KEY See core-default.xml static String FS_FILE_IMPL_KEY See core-default.xml static String FS_FTP_HOST_KEY See core-default.xml static String FS_FTP_HOST_PORT_KEY See core-default.xml static long FS_LOCAL_BLOCK_SIZE_DEFAULT Not used anywhere, looks like default value for FS_LOCAL_BLOCK_SIZE static long FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT Default value for FS_TRASH_CHECKPOINT_INTERVAL_KEY static String FS_TRASH_CHECKPOINT_INTERVAL_KEY See core-default.xml static long FS_TRASH_INTERVAL_DEFAULT Default value for FS_TRASH_INTERVAL_KEY static String FS_TRASH_INTERVAL_KEY See core-default.xml static String HADOOP_RPC_PROTECTION See core-default.xml static String HADOOP_RPC_SOCKET_FACTORY_CLASS_DEFAULT_DEFAULT  static String HADOOP_RPC_SOCKET_FACTORY_CLASS_DEFAULT_KEY See core-default.xml static String HADOOP_SECURITY_AUTH_TO_LOCAL See core-default.xml static String HADOOP_SECURITY_AUTHENTICATION See core-default.xml static String HADOOP_SECURITY_AUTHORIZATION See core-default.xml static int HADOOP_SECURITY_CRYPTO_BUFFER_SIZE_DEFAULT Defalt value for HADOOP_SECURITY_CRYPTO_BUFFER_SIZE_KEY static String HADOOP_SECURITY_CRYPTO_BUFFER_SIZE_KEY See core-default.xml static String HADOOP_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT  static String HADOOP_SECURITY_CRYPTO_CIPHER_SUITE_KEY See core-default.xml static String HADOOP_SECURITY_CRYPTO_CODEC_CLASSES_KEY_PREFIX  static String HADOOP_SECURITY_CRYPTO_JCE_PROVIDER_KEY See core-default.xml static String HADOOP_SECURITY_GROUP_MAPPING See core-default.xml static String HADOOP_SECURITY_GROUPS_CACHE_SECS See core-default.xml static long HADOOP_SECURITY_GROUPS_CACHE_SECS_DEFAULT See core-default.xml static String HADOOP_SECURITY_GROUPS_CACHE_WARN_AFTER_MS See core-default.xml static long HADOOP_SECURITY_GROUPS_CACHE_WARN_AFTER_MS_DEFAULT  static String HADOOP_SECURITY_GROUPS_NEGATIVE_CACHE_SECS See core-default.xml static long HADOOP_SECURITY_GROUPS_NEGATIVE_CACHE_SECS_DEFAULT See core-default.xml static String HADOOP_SECURITY_IMPERSONATION_PROVIDER_CLASS Class to override Impersonation provider static String HADOOP_SECURITY_INSTRUMENTATION_REQUIRES_ADMIN See core-default.xml static String HADOOP_SECURITY_JAVA_SECURE_RANDOM_ALGORITHM_DEFAULT Defalt value for HADOOP_SECURITY_JAVA_SECURE_RANDOM_ALGORITHM_KEY static String HADOOP_SECURITY_JAVA_SECURE_RANDOM_ALGORITHM_KEY See core-default.xml static String HADOOP_SECURITY_SASL_PROPS_RESOLVER_CLASS Class to override Sasl Properties for a connection static String HADOOP_SECURITY_SECURE_RANDOM_DEVICE_FILE_PATH_DEFAULT  static String HADOOP_SECURITY_SECURE_RANDOM_DEVICE_FILE_PATH_KEY See core-default.xml static String HADOOP_SECURITY_SECURE_RANDOM_IMPL_KEY See core-default.xml static String HADOOP_SECURITY_SERVICE_USER_NAME_KEY See core-default.xml static String HADOOP_SOCKS_SERVER_KEY See core-default.xml static boolean HADOOP_SSL_ENABLED_DEFAULT Deprecated.  static String HADOOP_SSL_ENABLED_KEY Deprecated.  static String HADOOP_UTIL_HASH_TYPE_DEFAULT Default value for HADOOP_UTIL_HASH_TYPE_KEY static String HADOOP_UTIL_HASH_TYPE_KEY See core-default.xml static String HTTP_POLICY_HTTP_ONLY Deprecated.  static String HTTP_POLICY_HTTPS_ONLY Deprecated.  static String IO_COMPRESSION_CODEC_LZO_CLASS_KEY Codec class that implements Lzo compression algorithm static int IO_FILE_BUFFER_SIZE_DEFAULT Default value for IO_FILE_BUFFER_SIZE_KEY static String IO_FILE_BUFFER_SIZE_KEY See core-default.xml static int IO_MAP_INDEX_INTERVAL_DEFAULT Default value for IO_MAP_INDEX_INTERVAL_DEFAULT static String IO_MAP_INDEX_INTERVAL_KEY See core-default.xml static int IO_MAP_INDEX_SKIP_DEFAULT Default value for IO_MAP_INDEX_SKIP_KEY static String IO_MAP_INDEX_SKIP_KEY See core-default.xml static float IO_MAPFILE_BLOOM_ERROR_RATE_DEFAULT Default value for IO_MAPFILE_BLOOM_ERROR_RATE_KEY static String IO_MAPFILE_BLOOM_ERROR_RATE_KEY See core-default.xml static int IO_MAPFILE_BLOOM_SIZE_DEFAULT Default value for IO_MAPFILE_BLOOM_SIZE_KEY static String IO_MAPFILE_BLOOM_SIZE_KEY See core-default.xml static boolean IO_NATIVE_LIB_AVAILABLE_DEFAULT Default value for IO_NATIVE_LIB_AVAILABLE_KEY static String IO_NATIVE_LIB_AVAILABLE_KEY See core-default.xml static int IO_SEQFILE_COMPRESS_BLOCKSIZE_DEFAULT Default value for IO_SEQFILE_COMPRESS_BLOCKSIZE_KEY static String IO_SEQFILE_COMPRESS_BLOCKSIZE_KEY See core-default.xml static String IO_SERIALIZATIONS_KEY See core-default.xml static boolean IO_SKIP_CHECKSUM_ERRORS_DEFAULT Default value for IO_SKIP_CHECKSUM_ERRORS_KEY static String IO_SKIP_CHECKSUM_ERRORS_KEY See core-default.xml static int IO_SORT_FACTOR_DEFAULT Default value for IO_SORT_FACTOR_DEFAULT static String IO_SORT_FACTOR_KEY Deprecated.  Moved to mapreduce, see mapreduce.task.io.sort.factor  in mapred-default.xml  See https://issues.apache.org/jira/browse/HADOOP-6801 static int IO_SORT_MB_DEFAULT Default value for IO_SORT_MB_DEFAULT static String IO_SORT_MB_KEY Deprecated.  Moved to mapreduce, see mapreduce.task.io.sort.mb  in mapred-default.xml  See https://issues.apache.org/jira/browse/HADOOP-6801 static int IPC_CLIENT_CONNECT_MAX_RETRIES_DEFAULT Default value for IPC_CLIENT_CONNECT_MAX_RETRIES_KEY static String IPC_CLIENT_CONNECT_MAX_RETRIES_KEY See core-default.xml static int IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_DEFAULT Default value for IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_KEY static String IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_KEY See core-default.xml static int IPC_CLIENT_CONNECT_RETRY_INTERVAL_DEFAULT Default value for IPC_CLIENT_CONNECT_RETRY_INTERVAL_KEY static String IPC_CLIENT_CONNECT_RETRY_INTERVAL_KEY See core-default.xml static int IPC_CLIENT_CONNECT_TIMEOUT_DEFAULT Default value for IPC_CLIENT_CONNECT_TIMEOUT_KEY static String IPC_CLIENT_CONNECT_TIMEOUT_KEY See core-default.xml static int IPC_CLIENT_CONNECTION_MAXIDLETIME_DEFAULT Default value for IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY static String IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY See core-default.xml static int IPC_CLIENT_IDLETHRESHOLD_DEFAULT Default value for IPC_CLIENT_IDLETHRESHOLD_DEFAULT static String IPC_CLIENT_IDLETHRESHOLD_KEY See core-default.xml static int IPC_CLIENT_KILL_MAX_DEFAULT Default value for IPC_CLIENT_KILL_MAX_KEY static String IPC_CLIENT_KILL_MAX_KEY See core-default.xml static boolean IPC_CLIENT_TCPNODELAY_DEFAULT Defalt value for IPC_CLIENT_TCPNODELAY_KEY static String IPC_CLIENT_TCPNODELAY_KEY See core-default.xml static int IPC_SERVER_LISTEN_QUEUE_SIZE_DEFAULT Default value for IPC_SERVER_LISTEN_QUEUE_SIZE_KEY static String IPC_SERVER_LISTEN_QUEUE_SIZE_KEY See core-default.xml static int IPC_SERVER_MAX_CONNECTIONS_DEFAULT Default value for IPC_SERVER_MAX_CONNECTIONS_KEY static String IPC_SERVER_MAX_CONNECTIONS_KEY See core-default.xml static boolean IPC_SERVER_TCPNODELAY_DEFAULT Default value for IPC_SERVER_TCPNODELAY_KEY static String IPC_SERVER_TCPNODELAY_KEY See core-default.xml static int KMS_CLIENT_ENC_KEY_CACHE_EXPIRY_DEFAULT Default value for KMS_CLIENT_ENC_KEY_CACHE_EXPIRY (12 hrs) static String KMS_CLIENT_ENC_KEY_CACHE_EXPIRY_MS See core-default.xml static String KMS_CLIENT_ENC_KEY_CACHE_LOW_WATERMARK See core-default.xml static float KMS_CLIENT_ENC_KEY_CACHE_LOW_WATERMARK_DEFAULT Default value for KMS_CLIENT_ENC_KEY_CACHE_LOW_WATERMARK static String KMS_CLIENT_ENC_KEY_CACHE_NUM_REFILL_THREADS See core-default.xml static int KMS_CLIENT_ENC_KEY_CACHE_NUM_REFILL_THREADS_DEFAULT Default value for KMS_CLIENT_ENC_KEY_NUM_REFILL_THREADS static String KMS_CLIENT_ENC_KEY_CACHE_SIZE See core-default.xml static int KMS_CLIENT_ENC_KEY_CACHE_SIZE_DEFAULT Default value for KMS_CLIENT_ENC_KEY_CACHE_SIZE static String NET_DEPENDENCY_SCRIPT_FILE_NAME_KEY  static String NET_TOPOLOGY_IMPL_KEY See core-default.xml static String NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY See core-default.xml static String NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY See core-default.xml static int NET_TOPOLOGY_SCRIPT_NUMBER_ARGS_DEFAULT Default value for NET_TOPOLOGY_SCRIPT_NUMBER_ARGS_KEY static String NET_TOPOLOGY_SCRIPT_NUMBER_ARGS_KEY See core-default.xml static String NET_TOPOLOGY_TABLE_MAPPING_FILE_KEY See core-default.xml static int TFILE_FS_INPUT_BUFFER_SIZE_DEFAULT Default value for TFILE_FS_INPUT_BUFFER_SIZE_KEY static String TFILE_FS_INPUT_BUFFER_SIZE_KEY See core-default.xml static int TFILE_FS_OUTPUT_BUFFER_SIZE_DEFAULT Default value for TFILE_FS_OUTPUT_BUFFER_SIZE_KEY static String TFILE_FS_OUTPUT_BUFFER_SIZE_KEY See core-default.xml static int TFILE_IO_CHUNK_SIZE_DEFAULT Default value for TFILE_IO_CHUNK_SIZE_DEFAULT static String TFILE_IO_CHUNK_SIZE_KEY See core-default.xml Constructor Summary Constructors  Constructor and Description CommonConfigurationKeysPublic()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail IO_NATIVE_LIB_AVAILABLE_KEY public static final String IO_NATIVE_LIB_AVAILABLE_KEY See core-default.xml See Also:Constant Field Values IO_NATIVE_LIB_AVAILABLE_DEFAULT public static final boolean IO_NATIVE_LIB_AVAILABLE_DEFAULT Default value for IO_NATIVE_LIB_AVAILABLE_KEY See Also:Constant Field Values NET_TOPOLOGY_SCRIPT_NUMBER_ARGS_KEY public static final String NET_TOPOLOGY_SCRIPT_NUMBER_ARGS_KEY See core-default.xml See Also:Constant Field Values NET_TOPOLOGY_SCRIPT_NUMBER_ARGS_DEFAULT public static final int NET_TOPOLOGY_SCRIPT_NUMBER_ARGS_DEFAULT Default value for NET_TOPOLOGY_SCRIPT_NUMBER_ARGS_KEY See Also:Constant Field Values FS_DEFAULT_NAME_KEY public static final String FS_DEFAULT_NAME_KEY See core-default.xml See Also:Constant Field Values FS_DEFAULT_NAME_DEFAULT public static final String FS_DEFAULT_NAME_DEFAULT Default value for FS_DEFAULT_NAME_KEY See Also:Constant Field Values FS_DF_INTERVAL_KEY public static final String FS_DF_INTERVAL_KEY See core-default.xml See Also:Constant Field Values FS_DF_INTERVAL_DEFAULT public static final long FS_DF_INTERVAL_DEFAULT Default value for FS_DF_INTERVAL_KEY See Also:Constant Field Values FS_DU_INTERVAL_KEY public static final String FS_DU_INTERVAL_KEY See core-default.xml See Also:Constant Field Values FS_DU_INTERVAL_DEFAULT public static final long FS_DU_INTERVAL_DEFAULT Default value for FS_DU_INTERVAL_KEY See Also:Constant Field Values FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_KEY public static final String FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_KEY See core-default.xml See Also:Constant Field Values FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_DEFAULT public static final boolean FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_DEFAULT Default value for FS_CLIENT_RESOLVE_REMOTE_SYMLINKS_KEY See Also:Constant Field Values NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY public static final String NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY See core-default.xml See Also:Constant Field Values NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY public static final String NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY See core-default.xml See Also:Constant Field Values NET_TOPOLOGY_IMPL_KEY public static final String NET_TOPOLOGY_IMPL_KEY See core-default.xml See Also:Constant Field Values NET_TOPOLOGY_TABLE_MAPPING_FILE_KEY public static final String NET_TOPOLOGY_TABLE_MAPPING_FILE_KEY See core-default.xml See Also:Constant Field Values NET_DEPENDENCY_SCRIPT_FILE_NAME_KEY public static final String NET_DEPENDENCY_SCRIPT_FILE_NAME_KEY See Also:Constant Field Values FS_TRASH_CHECKPOINT_INTERVAL_KEY public static final String FS_TRASH_CHECKPOINT_INTERVAL_KEY See core-default.xml See Also:Constant Field Values FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT public static final long FS_TRASH_CHECKPOINT_INTERVAL_DEFAULT Default value for FS_TRASH_CHECKPOINT_INTERVAL_KEY See Also:Constant Field Values FS_LOCAL_BLOCK_SIZE_DEFAULT public static final long FS_LOCAL_BLOCK_SIZE_DEFAULT Not used anywhere, looks like default value for FS_LOCAL_BLOCK_SIZE See Also:Constant Field Values FS_AUTOMATIC_CLOSE_KEY public static final String FS_AUTOMATIC_CLOSE_KEY See core-default.xml See Also:Constant Field Values FS_AUTOMATIC_CLOSE_DEFAULT public static final boolean FS_AUTOMATIC_CLOSE_DEFAULT Default value for FS_AUTOMATIC_CLOSE_KEY See Also:Constant Field Values FS_FILE_IMPL_KEY public static final String FS_FILE_IMPL_KEY See core-default.xml See Also:Constant Field Values FS_FTP_HOST_KEY public static final String FS_FTP_HOST_KEY See core-default.xml See Also:Constant Field Values FS_FTP_HOST_PORT_KEY public static final String FS_FTP_HOST_PORT_KEY See core-default.xml See Also:Constant Field Values FS_TRASH_INTERVAL_KEY public static final String FS_TRASH_INTERVAL_KEY See core-default.xml See Also:Constant Field Values FS_TRASH_INTERVAL_DEFAULT public static final long FS_TRASH_INTERVAL_DEFAULT Default value for FS_TRASH_INTERVAL_KEY See Also:Constant Field Values IO_MAPFILE_BLOOM_SIZE_KEY public static final String IO_MAPFILE_BLOOM_SIZE_KEY See core-default.xml See Also:Constant Field Values IO_MAPFILE_BLOOM_SIZE_DEFAULT public static final int IO_MAPFILE_BLOOM_SIZE_DEFAULT Default value for IO_MAPFILE_BLOOM_SIZE_KEY See Also:Constant Field Values IO_MAPFILE_BLOOM_ERROR_RATE_KEY public static final String IO_MAPFILE_BLOOM_ERROR_RATE_KEY See core-default.xml See Also:Constant Field Values IO_MAPFILE_BLOOM_ERROR_RATE_DEFAULT public static final float IO_MAPFILE_BLOOM_ERROR_RATE_DEFAULT Default value for IO_MAPFILE_BLOOM_ERROR_RATE_KEY See Also:Constant Field Values IO_COMPRESSION_CODEC_LZO_CLASS_KEY public static final String IO_COMPRESSION_CODEC_LZO_CLASS_KEY Codec class that implements Lzo compression algorithm See Also:Constant Field Values IO_MAP_INDEX_INTERVAL_KEY public static final String IO_MAP_INDEX_INTERVAL_KEY See core-default.xml See Also:Constant Field Values IO_MAP_INDEX_INTERVAL_DEFAULT public static final int IO_MAP_INDEX_INTERVAL_DEFAULT Default value for IO_MAP_INDEX_INTERVAL_DEFAULT See Also:Constant Field Values IO_MAP_INDEX_SKIP_KEY public static final String IO_MAP_INDEX_SKIP_KEY See core-default.xml See Also:Constant Field Values IO_MAP_INDEX_SKIP_DEFAULT public static final int IO_MAP_INDEX_SKIP_DEFAULT Default value for IO_MAP_INDEX_SKIP_KEY See Also:Constant Field Values IO_SEQFILE_COMPRESS_BLOCKSIZE_KEY public static final String IO_SEQFILE_COMPRESS_BLOCKSIZE_KEY See core-default.xml See Also:Constant Field Values IO_SEQFILE_COMPRESS_BLOCKSIZE_DEFAULT public static final int IO_SEQFILE_COMPRESS_BLOCKSIZE_DEFAULT Default value for IO_SEQFILE_COMPRESS_BLOCKSIZE_KEY See Also:Constant Field Values IO_FILE_BUFFER_SIZE_KEY public static final String IO_FILE_BUFFER_SIZE_KEY See core-default.xml See Also:Constant Field Values IO_FILE_BUFFER_SIZE_DEFAULT public static final int IO_FILE_BUFFER_SIZE_DEFAULT Default value for IO_FILE_BUFFER_SIZE_KEY See Also:Constant Field Values IO_SKIP_CHECKSUM_ERRORS_KEY public static final String IO_SKIP_CHECKSUM_ERRORS_KEY See core-default.xml See Also:Constant Field Values IO_SKIP_CHECKSUM_ERRORS_DEFAULT public static final boolean IO_SKIP_CHECKSUM_ERRORS_DEFAULT Default value for IO_SKIP_CHECKSUM_ERRORS_KEY See Also:Constant Field Values IO_SORT_MB_KEY public static final String IO_SORT_MB_KEY Deprecated. Moved to mapreduce, see mapreduce.task.io.sort.mb  in mapred-default.xml  See https://issues.apache.org/jira/browse/HADOOP-6801 See Also:Constant Field Values IO_SORT_MB_DEFAULT public static final int IO_SORT_MB_DEFAULT Default value for IO_SORT_MB_DEFAULT See Also:Constant Field Values IO_SORT_FACTOR_KEY public static final String IO_SORT_FACTOR_KEY Deprecated. Moved to mapreduce, see mapreduce.task.io.sort.factor  in mapred-default.xml  See https://issues.apache.org/jira/browse/HADOOP-6801 See Also:Constant Field Values IO_SORT_FACTOR_DEFAULT public static final int IO_SORT_FACTOR_DEFAULT Default value for IO_SORT_FACTOR_DEFAULT See Also:Constant Field Values IO_SERIALIZATIONS_KEY public static final String IO_SERIALIZATIONS_KEY See core-default.xml See Also:Constant Field Values TFILE_IO_CHUNK_SIZE_KEY public static final String TFILE_IO_CHUNK_SIZE_KEY See core-default.xml See Also:Constant Field Values TFILE_IO_CHUNK_SIZE_DEFAULT public static final int TFILE_IO_CHUNK_SIZE_DEFAULT Default value for TFILE_IO_CHUNK_SIZE_DEFAULT See Also:Constant Field Values TFILE_FS_INPUT_BUFFER_SIZE_KEY public static final String TFILE_FS_INPUT_BUFFER_SIZE_KEY See core-default.xml See Also:Constant Field Values TFILE_FS_INPUT_BUFFER_SIZE_DEFAULT public static final int TFILE_FS_INPUT_BUFFER_SIZE_DEFAULT Default value for TFILE_FS_INPUT_BUFFER_SIZE_KEY See Also:Constant Field Values TFILE_FS_OUTPUT_BUFFER_SIZE_KEY public static final String TFILE_FS_OUTPUT_BUFFER_SIZE_KEY See core-default.xml See Also:Constant Field Values TFILE_FS_OUTPUT_BUFFER_SIZE_DEFAULT public static final int TFILE_FS_OUTPUT_BUFFER_SIZE_DEFAULT Default value for TFILE_FS_OUTPUT_BUFFER_SIZE_KEY See Also:Constant Field Values IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY public static final String IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY See core-default.xml See Also:Constant Field Values IPC_CLIENT_CONNECTION_MAXIDLETIME_DEFAULT public static final int IPC_CLIENT_CONNECTION_MAXIDLETIME_DEFAULT Default value for IPC_CLIENT_CONNECTION_MAXIDLETIME_KEY See Also:Constant Field Values IPC_CLIENT_CONNECT_TIMEOUT_KEY public static final String IPC_CLIENT_CONNECT_TIMEOUT_KEY See core-default.xml See Also:Constant Field Values IPC_CLIENT_CONNECT_TIMEOUT_DEFAULT public static final int IPC_CLIENT_CONNECT_TIMEOUT_DEFAULT Default value for IPC_CLIENT_CONNECT_TIMEOUT_KEY See Also:Constant Field Values IPC_CLIENT_CONNECT_MAX_RETRIES_KEY public static final String IPC_CLIENT_CONNECT_MAX_RETRIES_KEY See core-default.xml See Also:Constant Field Values IPC_CLIENT_CONNECT_MAX_RETRIES_DEFAULT public static final int IPC_CLIENT_CONNECT_MAX_RETRIES_DEFAULT Default value for IPC_CLIENT_CONNECT_MAX_RETRIES_KEY See Also:Constant Field Values IPC_CLIENT_CONNECT_RETRY_INTERVAL_KEY public static final String IPC_CLIENT_CONNECT_RETRY_INTERVAL_KEY See core-default.xml See Also:Constant Field Values IPC_CLIENT_CONNECT_RETRY_INTERVAL_DEFAULT public static final int IPC_CLIENT_CONNECT_RETRY_INTERVAL_DEFAULT Default value for IPC_CLIENT_CONNECT_RETRY_INTERVAL_KEY See Also:Constant Field Values IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_KEY public static final String IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_KEY See core-default.xml See Also:Constant Field Values IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_DEFAULT public static final int IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_DEFAULT Default value for IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_KEY See Also:Constant Field Values IPC_CLIENT_TCPNODELAY_KEY public static final String IPC_CLIENT_TCPNODELAY_KEY See core-default.xml See Also:Constant Field Values IPC_CLIENT_TCPNODELAY_DEFAULT public static final boolean IPC_CLIENT_TCPNODELAY_DEFAULT Defalt value for IPC_CLIENT_TCPNODELAY_KEY See Also:Constant Field Values IPC_SERVER_LISTEN_QUEUE_SIZE_KEY public static final String IPC_SERVER_LISTEN_QUEUE_SIZE_KEY See core-default.xml See Also:Constant Field Values IPC_SERVER_LISTEN_QUEUE_SIZE_DEFAULT public static final int IPC_SERVER_LISTEN_QUEUE_SIZE_DEFAULT Default value for IPC_SERVER_LISTEN_QUEUE_SIZE_KEY See Also:Constant Field Values IPC_CLIENT_KILL_MAX_KEY public static final String IPC_CLIENT_KILL_MAX_KEY See core-default.xml See Also:Constant Field Values IPC_CLIENT_KILL_MAX_DEFAULT public static final int IPC_CLIENT_KILL_MAX_DEFAULT Default value for IPC_CLIENT_KILL_MAX_KEY See Also:Constant Field Values IPC_CLIENT_IDLETHRESHOLD_KEY public static final String IPC_CLIENT_IDLETHRESHOLD_KEY See core-default.xml See Also:Constant Field Values IPC_CLIENT_IDLETHRESHOLD_DEFAULT public static final int IPC_CLIENT_IDLETHRESHOLD_DEFAULT Default value for IPC_CLIENT_IDLETHRESHOLD_DEFAULT See Also:Constant Field Values IPC_SERVER_TCPNODELAY_KEY public static final String IPC_SERVER_TCPNODELAY_KEY See core-default.xml See Also:Constant Field Values IPC_SERVER_TCPNODELAY_DEFAULT public static final boolean IPC_SERVER_TCPNODELAY_DEFAULT Default value for IPC_SERVER_TCPNODELAY_KEY See Also:Constant Field Values IPC_SERVER_MAX_CONNECTIONS_KEY public static final String IPC_SERVER_MAX_CONNECTIONS_KEY See core-default.xml See Also:Constant Field Values IPC_SERVER_MAX_CONNECTIONS_DEFAULT public static final int IPC_SERVER_MAX_CONNECTIONS_DEFAULT Default value for IPC_SERVER_MAX_CONNECTIONS_KEY See Also:Constant Field Values HADOOP_RPC_SOCKET_FACTORY_CLASS_DEFAULT_KEY public static final String HADOOP_RPC_SOCKET_FACTORY_CLASS_DEFAULT_KEY See core-default.xml See Also:Constant Field Values HADOOP_RPC_SOCKET_FACTORY_CLASS_DEFAULT_DEFAULT public static final String HADOOP_RPC_SOCKET_FACTORY_CLASS_DEFAULT_DEFAULT See Also:Constant Field Values HADOOP_SOCKS_SERVER_KEY public static final String HADOOP_SOCKS_SERVER_KEY See core-default.xml See Also:Constant Field Values HADOOP_UTIL_HASH_TYPE_KEY public static final String HADOOP_UTIL_HASH_TYPE_KEY See core-default.xml See Also:Constant Field Values HADOOP_UTIL_HASH_TYPE_DEFAULT public static final String HADOOP_UTIL_HASH_TYPE_DEFAULT Default value for HADOOP_UTIL_HASH_TYPE_KEY See Also:Constant Field Values HADOOP_SECURITY_GROUP_MAPPING public static final String HADOOP_SECURITY_GROUP_MAPPING See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_GROUPS_CACHE_SECS public static final String HADOOP_SECURITY_GROUPS_CACHE_SECS See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_GROUPS_CACHE_SECS_DEFAULT public static final long HADOOP_SECURITY_GROUPS_CACHE_SECS_DEFAULT See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_GROUPS_NEGATIVE_CACHE_SECS public static final String HADOOP_SECURITY_GROUPS_NEGATIVE_CACHE_SECS See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_GROUPS_NEGATIVE_CACHE_SECS_DEFAULT public static final long HADOOP_SECURITY_GROUPS_NEGATIVE_CACHE_SECS_DEFAULT See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_GROUPS_CACHE_WARN_AFTER_MS public static final String HADOOP_SECURITY_GROUPS_CACHE_WARN_AFTER_MS See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_GROUPS_CACHE_WARN_AFTER_MS_DEFAULT public static final long HADOOP_SECURITY_GROUPS_CACHE_WARN_AFTER_MS_DEFAULT See Also:Constant Field Values HADOOP_SECURITY_AUTHENTICATION public static final String HADOOP_SECURITY_AUTHENTICATION See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_AUTHORIZATION public static final String HADOOP_SECURITY_AUTHORIZATION See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_INSTRUMENTATION_REQUIRES_ADMIN public static final String HADOOP_SECURITY_INSTRUMENTATION_REQUIRES_ADMIN See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_SERVICE_USER_NAME_KEY public static final String HADOOP_SECURITY_SERVICE_USER_NAME_KEY See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_AUTH_TO_LOCAL public static final String HADOOP_SECURITY_AUTH_TO_LOCAL See core-default.xml See Also:Constant Field Values HADOOP_SSL_ENABLED_KEY @Deprecated public static final String HADOOP_SSL_ENABLED_KEY Deprecated.  See Also:Constant Field Values HADOOP_SSL_ENABLED_DEFAULT @Deprecated public static final boolean HADOOP_SSL_ENABLED_DEFAULT Deprecated.  See Also:Constant Field Values HTTP_POLICY_HTTP_ONLY @Deprecated public static final String HTTP_POLICY_HTTP_ONLY Deprecated.  See Also:Constant Field Values HTTP_POLICY_HTTPS_ONLY @Deprecated public static final String HTTP_POLICY_HTTPS_ONLY Deprecated.  See Also:Constant Field Values HADOOP_RPC_PROTECTION public static final String HADOOP_RPC_PROTECTION See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_SASL_PROPS_RESOLVER_CLASS public static final String HADOOP_SECURITY_SASL_PROPS_RESOLVER_CLASS Class to override Sasl Properties for a connection See Also:Constant Field Values HADOOP_SECURITY_CRYPTO_CODEC_CLASSES_KEY_PREFIX public static final String HADOOP_SECURITY_CRYPTO_CODEC_CLASSES_KEY_PREFIX See Also:Constant Field Values HADOOP_SECURITY_CRYPTO_CIPHER_SUITE_KEY public static final String HADOOP_SECURITY_CRYPTO_CIPHER_SUITE_KEY See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT public static final String HADOOP_SECURITY_CRYPTO_CIPHER_SUITE_DEFAULT See Also:Constant Field Values HADOOP_SECURITY_CRYPTO_JCE_PROVIDER_KEY public static final String HADOOP_SECURITY_CRYPTO_JCE_PROVIDER_KEY See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_CRYPTO_BUFFER_SIZE_KEY public static final String HADOOP_SECURITY_CRYPTO_BUFFER_SIZE_KEY See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_CRYPTO_BUFFER_SIZE_DEFAULT public static final int HADOOP_SECURITY_CRYPTO_BUFFER_SIZE_DEFAULT Defalt value for HADOOP_SECURITY_CRYPTO_BUFFER_SIZE_KEY See Also:Constant Field Values HADOOP_SECURITY_IMPERSONATION_PROVIDER_CLASS public static final String HADOOP_SECURITY_IMPERSONATION_PROVIDER_CLASS Class to override Impersonation provider See Also:Constant Field Values KMS_CLIENT_ENC_KEY_CACHE_SIZE public static final String KMS_CLIENT_ENC_KEY_CACHE_SIZE See core-default.xml See Also:Constant Field Values KMS_CLIENT_ENC_KEY_CACHE_SIZE_DEFAULT public static final int KMS_CLIENT_ENC_KEY_CACHE_SIZE_DEFAULT Default value for KMS_CLIENT_ENC_KEY_CACHE_SIZE See Also:Constant Field Values KMS_CLIENT_ENC_KEY_CACHE_LOW_WATERMARK public static final String KMS_CLIENT_ENC_KEY_CACHE_LOW_WATERMARK See core-default.xml See Also:Constant Field Values KMS_CLIENT_ENC_KEY_CACHE_LOW_WATERMARK_DEFAULT public static final float KMS_CLIENT_ENC_KEY_CACHE_LOW_WATERMARK_DEFAULT Default value for KMS_CLIENT_ENC_KEY_CACHE_LOW_WATERMARK See Also:Constant Field Values KMS_CLIENT_ENC_KEY_CACHE_NUM_REFILL_THREADS public static final String KMS_CLIENT_ENC_KEY_CACHE_NUM_REFILL_THREADS See core-default.xml See Also:Constant Field Values KMS_CLIENT_ENC_KEY_CACHE_NUM_REFILL_THREADS_DEFAULT public static final int KMS_CLIENT_ENC_KEY_CACHE_NUM_REFILL_THREADS_DEFAULT Default value for KMS_CLIENT_ENC_KEY_NUM_REFILL_THREADS See Also:Constant Field Values KMS_CLIENT_ENC_KEY_CACHE_EXPIRY_MS public static final String KMS_CLIENT_ENC_KEY_CACHE_EXPIRY_MS See core-default.xml See Also:Constant Field Values KMS_CLIENT_ENC_KEY_CACHE_EXPIRY_DEFAULT public static final int KMS_CLIENT_ENC_KEY_CACHE_EXPIRY_DEFAULT Default value for KMS_CLIENT_ENC_KEY_CACHE_EXPIRY (12 hrs) See Also:Constant Field Values HADOOP_SECURITY_JAVA_SECURE_RANDOM_ALGORITHM_KEY public static final String HADOOP_SECURITY_JAVA_SECURE_RANDOM_ALGORITHM_KEY See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_JAVA_SECURE_RANDOM_ALGORITHM_DEFAULT public static final String HADOOP_SECURITY_JAVA_SECURE_RANDOM_ALGORITHM_DEFAULT Defalt value for HADOOP_SECURITY_JAVA_SECURE_RANDOM_ALGORITHM_KEY See Also:Constant Field Values HADOOP_SECURITY_SECURE_RANDOM_IMPL_KEY public static final String HADOOP_SECURITY_SECURE_RANDOM_IMPL_KEY See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_SECURE_RANDOM_DEVICE_FILE_PATH_KEY public static final String HADOOP_SECURITY_SECURE_RANDOM_DEVICE_FILE_PATH_KEY See core-default.xml See Also:Constant Field Values HADOOP_SECURITY_SECURE_RANDOM_DEVICE_FILE_PATH_DEFAULT public static final String HADOOP_SECURITY_SECURE_RANDOM_DEVICE_FILE_PATH_DEFAULT See Also:Constant Field Values Constructor Detail CommonConfigurationKeysPublic public CommonConfigurationKeysPublic() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ComposableInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ComposableInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class ComposableInputFormat<K extends WritableComparable<?>,V extends Writable> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableInputFormat<K,V> Direct Known Subclasses: Parser.Node @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ComposableInputFormat<K extends WritableComparable<?>,V extends Writable> extends InputFormat<K,V> Refinement of InputFormat requiring implementors to provide  ComposableRecordReader instead of RecordReader. Constructor Summary Constructors  Constructor and Description ComposableInputFormat()  Method Summary Methods  Modifier and Type Method and Description abstract ComposableRecordReader<K,V> createRecordReader(InputSplit split,                                     TaskAttemptContext context) Create a record reader for a given split. Methods inherited from class org.apache.hadoop.mapreduce.InputFormat getSplits Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ComposableInputFormat public ComposableInputFormat() Method Detail createRecordReader public abstract ComposableRecordReader<K,V> createRecordReader(InputSplit split,                                              TaskAttemptContext context)                                                                                                        throws IOException,                                                                                                               InterruptedException Description copied from class: InputFormat Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Specified by: createRecordReader in class InputFormat<K extends WritableComparable<?>,V extends Writable> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ComposableRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ComposableRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class ComposableRecordReader<K extends WritableComparable<?>,V extends Writable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader<K,V> All Implemented Interfaces: Closeable, AutoCloseable, Comparable<ComposableRecordReader<K,?>> Direct Known Subclasses: CompositeRecordReader, WrappedRecordReader @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ComposableRecordReader<K extends WritableComparable<?>,V extends Writable> extends RecordReader<K,V> implements Comparable<ComposableRecordReader<K,?>> Additional operations required of a RecordReader to participate in a join. Constructor Summary Constructors  Constructor and Description ComposableRecordReader()  Method Summary Methods inherited from class org.apache.hadoop.mapreduce.RecordReader close, getCurrentKey, getCurrentValue, getProgress, initialize, nextKeyValue Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface java.lang.Comparable compareTo Constructor Detail ComposableRecordReader public ComposableRecordReader() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompositeContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompositeContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.spi Class CompositeContext java.lang.Object org.apache.hadoop.metrics.spi.AbstractMetricsContext org.apache.hadoop.metrics.spi.CompositeContext All Implemented Interfaces: org.apache.hadoop.metrics.MetricsContext @InterfaceAudience.Public @InterfaceStability.Evolving public class CompositeContext extends AbstractMetricsContext Field Summary Fields inherited from interface org.apache.hadoop.metrics.MetricsContext DEFAULT_PERIOD Constructor Summary Constructors  Constructor and Description CompositeContext()  Method Summary Methods inherited from class org.apache.hadoop.metrics.spi.AbstractMetricsContext createRecord, getAllRecords, getAttribute, getAttributeTable, getContextFactory, getContextName, getPeriod, parseAndSetPeriod, remove, setPeriod, update Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail CompositeContext @InterfaceAudience.Private public CompositeContext() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompositeInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompositeInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class CompositeInputFormat<K extends WritableComparable> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,TupleWritable> org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat<K> @InterfaceAudience.Public @InterfaceStability.Stable public class CompositeInputFormat<K extends WritableComparable> extends InputFormat<K,TupleWritable> An InputFormat capable of performing joins over a set of data sources sorted  and partitioned the same way.  A user may define new join types by setting the property  mapreduce.join.define.<ident> to a classname.   In the expression mapreduce.join.expr, the identifier will be  assumed to be a ComposableRecordReader.  mapreduce.join.keycomparator can be a classname used to compare   keys in the join. See Also:setFormat(org.apache.hadoop.conf.Configuration),  JoinRecordReader,  MultiFilterRecordReader Field Summary Fields  Modifier and Type Field and Description static String JOIN_COMPARATOR  static String JOIN_EXPR  Constructor Summary Constructors  Constructor and Description CompositeInputFormat()  Method Summary Methods  Modifier and Type Method and Description protected void addDefaults() Adds the default set of identifiers to the parser. static String compose(Class<? extends InputFormat> inf,               String path) Convenience method for constructing composite formats. static String compose(String op,               Class<? extends InputFormat> inf,               Path... path) Convenience method for constructing composite formats. static String compose(String op,               Class<? extends InputFormat> inf,               String... path) Convenience method for constructing composite formats. RecordReader<K,TupleWritable> createRecordReader(InputSplit split,                                     TaskAttemptContext taskContext) Construct a CompositeRecordReader for the children of this InputFormat  as defined in the init expression. List<InputSplit> getSplits(JobContext job) Build a CompositeInputSplit from the child InputFormats by assigning the  ith split from each child to the ith composite split. void setFormat(Configuration conf) Interpret a given string as a composite expression. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail JOIN_EXPR public static final String JOIN_EXPR See Also:Constant Field Values JOIN_COMPARATOR public static final String JOIN_COMPARATOR See Also:Constant Field Values Constructor Detail CompositeInputFormat public CompositeInputFormat() Method Detail setFormat public void setFormat(Configuration conf)                throws IOException Interpret a given string as a composite expression.  func  ::= <ident>([<func>,]*<func>)    func  ::= tbl(<class>,"<path>")    class ::= @see java.lang.Class#forName(java.lang.String)    path  ::= @see org.apache.hadoop.fs.Path#Path(java.lang.String)    Reads expression from the mapreduce.join.expr property and  user-supplied join types from mapreduce.join.define.<ident>   types. Paths supplied to tbl are given as input paths to the  InputFormat class listed. Throws: IOExceptionSee Also:compose(java.lang.String, java.lang.Class, java.lang.String...) addDefaults protected void addDefaults() Adds the default set of identifiers to the parser. getSplits public List<InputSplit> getSplits(JobContext job)                            throws IOException,                                   InterruptedException Build a CompositeInputSplit from the child InputFormats by assigning the  ith split from each child to the ith composite split. Specified by: getSplits in class InputFormat<K extends WritableComparable,TupleWritable> Parameters:job - job configuration. Returns:an array of InputSplits for the job. Throws: IOException InterruptedException createRecordReader public RecordReader<K,TupleWritable> createRecordReader(InputSplit split,                                                TaskAttemptContext taskContext)                                                                             throws IOException,                                                                                    InterruptedException Construct a CompositeRecordReader for the children of this InputFormat  as defined in the init expression.  The outermost join need only be composable, not necessarily a composite.  Mandating TupleWritable isn't strictly correct. Specified by: createRecordReader in class InputFormat<K extends WritableComparable,TupleWritable> Parameters:split - the split to be readtaskContext - the information about the task Returns:a new record reader Throws: IOException InterruptedException compose public static String compose(Class<? extends InputFormat> inf,              String path) Convenience method for constructing composite formats.  Given InputFormat class (inf), path (p) return:  tbl(<inf>, <p>)  compose public static String compose(String op,              Class<? extends InputFormat> inf,              String... path) Convenience method for constructing composite formats.  Given operation (op), Object class (inf), set of paths (p) return:  <op>(tbl(<inf>,<p1>),tbl(<inf>,<p2>),...,tbl(<inf>,<pn>))  compose public static String compose(String op,              Class<? extends InputFormat> inf,              Path... path) Convenience method for constructing composite formats.  Given operation (op), Object class (inf), set of paths (p) return:  <op>(tbl(<inf>,<p1>),tbl(<inf>,<p2>),...,tbl(<inf>,<pn>))  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompositeInputSplit (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompositeInputSplit (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class CompositeInputSplit java.lang.Object org.apache.hadoop.mapreduce.InputSplit org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class CompositeInputSplit extends InputSplit implements Writable This InputSplit contains a set of child InputSplits. Any InputSplit inserted  into this collection must have a public default constructor. Constructor Summary Constructors  Constructor and Description CompositeInputSplit()  CompositeInputSplit(int capacity)  Method Summary Methods  Modifier and Type Method and Description void add(InputSplit s) Add an InputSplit to this collection. InputSplit get(int i) Get ith child InputSplit. long getLength() Return the aggregate length of all child InputSplits currently added. long getLength(int i) Get the length of ith child InputSplit. String[] getLocation(int i) getLocations from ith InputSplit. String[] getLocations() Collect a set of hosts from all child InputSplits. void readFields(DataInput in) Deserialize the fields of this object from in. void write(DataOutput out) Write splits in the following format. Methods inherited from class org.apache.hadoop.mapreduce.InputSplit getLocationInfo Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail CompositeInputSplit public CompositeInputSplit() CompositeInputSplit public CompositeInputSplit(int capacity) Method Detail add public void add(InputSplit s)          throws IOException,                 InterruptedException Add an InputSplit to this collection. Throws: IOException - If capacity was not specified during construction                      or if capacity has been reached. InterruptedException get public InputSplit get(int i) Get ith child InputSplit. getLength public long getLength()                throws IOException Return the aggregate length of all child InputSplits currently added. Specified by: getLength in class InputSplit Returns:the number of bytes in the split Throws: IOException getLength public long getLength(int i)                throws IOException,                       InterruptedException Get the length of ith child InputSplit. Throws: IOException InterruptedException getLocations public String[] getLocations()                       throws IOException,                              InterruptedException Collect a set of hosts from all child InputSplits. Specified by: getLocations in class InputSplit Returns:a new array of the node nodes. Throws: IOException InterruptedException getLocation public String[] getLocation(int i)                      throws IOException,                             InterruptedException getLocations from ith InputSplit. Throws: IOException InterruptedException write public void write(DataOutput out)            throws IOException Write splits in the following format.  <count><class1><class2>...<classn><split1><split2>...<splitn>   Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException - If the child InputSplit cannot be read, typically                      for failing access checks. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompositeRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompositeRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class CompositeRecordReader<K extends WritableComparable<?>,V extends Writable,X extends Writable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader<K,X> org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader<K,V,X> All Implemented Interfaces: Closeable, AutoCloseable, Comparable<ComposableRecordReader<K,?>>, Configurable Direct Known Subclasses: JoinRecordReader, MultiFilterRecordReader @InterfaceAudience.Public @InterfaceStability.Stable public abstract class CompositeRecordReader<K extends WritableComparable<?>,V extends Writable,X extends Writable> extends ComposableRecordReader<K,X> implements Configurable A RecordReader that can effect joins of RecordReaders sharing a common key  type and partitioning. Field Summary Fields  Modifier and Type Field and Description protected Configuration conf  protected org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector jc  protected K key  protected Class<? extends WritableComparable> keyclass  protected ComposableRecordReader<K,? extends V>[] kids  protected X value  Constructor Summary Constructors  Constructor and Description CompositeRecordReader(int id,                                           int capacity,                                           Class<? extends WritableComparator> cmpcl) Create a RecordReader with capacity children to position  id in the parent reader. Method Summary Methods  Modifier and Type Method and Description void accept(org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector jc,             K key) If key provided matches that of this Composite, give JoinCollector  iterator over values it may emit. void add(ComposableRecordReader<K,? extends V> rr) Add a RecordReader to this collection. void close() Close all child RRs. protected abstract boolean combine(Object[] srcs,               TupleWritable value)  int compareTo(ComposableRecordReader<K,?> other) Implement Comparable contract (compare key of join or head of heap  with that of another). protected K createKey() Create a new key common to all child RRs. protected TupleWritable createTupleWritable() Create a value to be used internally for joins. protected void fillJoinCollector(K iterkey) For all child RRs offering the key provided, obtain an iterator  at that position in the JoinCollector. protected WritableComparator getComparator() Return comparator defining the ordering for RecordReaders in this  composite. Configuration getConf() Return the configuration used by this object. K getCurrentKey() Get the current key X getCurrentValue() Get the current value. protected abstract ResetableIterator<X> getDelegate() Obtain an iterator over the child RRs apropos of the value type  ultimately emitted from this join. float getProgress() Report progress as the minimum of all child RR progress. protected PriorityQueue<ComposableRecordReader<K,?>> getRecordReaderQueue() Return sorted list of RecordReaders for this composite. boolean hasNext() Return true if it is possible that this could emit more values. int id() Return the position in the collector this class occupies. void initialize(InputSplit split,                     TaskAttemptContext context) Called once at initialization. K key() Return the key for the current join or the value at the top of the  RecordReader heap. void key(K key) Clone the key at the top of this RR into the given object. void setConf(Configuration conf) Set the configuration to be used by this object. void skip(K key) Pass skip key to child RRs. Methods inherited from class org.apache.hadoop.mapreduce.RecordReader nextKeyValue Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail conf protected Configuration conf keyclass protected Class<? extends WritableComparable> keyclass jc protected final org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector jc kids protected final ComposableRecordReader<K extends WritableComparable<?>,? extends V extends Writable>[] kids key protected K extends WritableComparable<?> key value protected X extends Writable value Constructor Detail CompositeRecordReader public CompositeRecordReader(int id,                      int capacity,                      Class<? extends WritableComparator> cmpcl)                       throws IOException Create a RecordReader with capacity children to position  id in the parent reader.  The id of a root CompositeRecordReader is -1 by convention, but relying  on this is not recommended. Throws: IOException Method Detail combine protected abstract boolean combine(Object[] srcs,               TupleWritable value) initialize public void initialize(InputSplit split,               TaskAttemptContext context)                 throws IOException,                        InterruptedException Description copied from class: RecordReader Called once at initialization. Specified by: initialize in class RecordReader<K extends WritableComparable<?>,X extends Writable> Parameters:split - the split that defines the range of records to readcontext - the information about the task Throws: IOException InterruptedException id public int id() Return the position in the collector this class occupies. setConf public void setConf(Configuration conf) Set the configuration to be used by this object. Specified by: setConf in interface Configurable getConf public Configuration getConf() Return the configuration used by this object. Specified by: getConf in interface Configurable getRecordReaderQueue protected PriorityQueue<ComposableRecordReader<K,?>> getRecordReaderQueue() Return sorted list of RecordReaders for this composite. getComparator protected WritableComparator getComparator() Return comparator defining the ordering for RecordReaders in this  composite. add public void add(ComposableRecordReader<K,? extends V> rr)          throws IOException,                 InterruptedException Add a RecordReader to this collection.  The id() of a RecordReader determines where in the Tuple its  entry will appear. Adding RecordReaders with the same id has  undefined behavior. Throws: IOException InterruptedException key public K key() Return the key for the current join or the value at the top of the  RecordReader heap. key public void key(K key)          throws IOException Clone the key at the top of this RR into the given object. Throws: IOException getCurrentKey public K getCurrentKey() Description copied from class: RecordReader Get the current key Specified by: getCurrentKey in class RecordReader<K extends WritableComparable<?>,X extends Writable> Returns:the current key or null if there is no current key hasNext public boolean hasNext() Return true if it is possible that this could emit more values. skip public void skip(K key)           throws IOException,                  InterruptedException Pass skip key to child RRs. Throws: IOException InterruptedException getDelegate protected abstract ResetableIterator<X> getDelegate() Obtain an iterator over the child RRs apropos of the value type  ultimately emitted from this join. accept public void accept(org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector jc,           K key)             throws IOException,                    InterruptedException If key provided matches that of this Composite, give JoinCollector  iterator over values it may emit. Throws: IOException InterruptedException fillJoinCollector protected void fillJoinCollector(K iterkey)                           throws IOException,                                  InterruptedException For all child RRs offering the key provided, obtain an iterator  at that position in the JoinCollector. Throws: IOException InterruptedException compareTo public int compareTo(ComposableRecordReader<K,?> other) Implement Comparable contract (compare key of join or head of heap  with that of another). Specified by: compareTo in interface Comparable<ComposableRecordReader<K extends WritableComparable<?>,?>> createKey protected K createKey() Create a new key common to all child RRs. Throws: ClassCastException - if key classes differ. createTupleWritable protected TupleWritable createTupleWritable() Create a value to be used internally for joins. getCurrentValue public X getCurrentValue()                                    throws IOException,                                           InterruptedException Get the current value. Specified by: getCurrentValue in class RecordReader<K extends WritableComparable<?>,X extends Writable> Returns:the object that was read Throws: IOException InterruptedException close public void close()            throws IOException Close all child RRs. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in class RecordReader<K extends WritableComparable<?>,X extends Writable> Throws: IOException getProgress public float getProgress()                   throws IOException,                          InterruptedException Report progress as the minimum of all child RR progress. Specified by: getProgress in class RecordReader<K extends WritableComparable<?>,X extends Writable> Returns:a number between 0.0 and 1.0 that is the fraction of the data read Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompositeService (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompositeService (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.service Class CompositeService java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.service.CompositeService All Implemented Interfaces: Closeable, AutoCloseable, Service Direct Known Subclasses: AddingCompositeService, org.apache.hadoop.registry.client.impl.zk.CuratorService @InterfaceAudience.Public @InterfaceStability.Evolving public class CompositeService extends AbstractService Composition of services. Field Summary Fields  Modifier and Type Field and Description protected static boolean STOP_ONLY_STARTED_SERVICES Policy on shutdown: attempt to close everything (purest) or  only try to close started services (which assumes  that the service implementations may not handle the stop() operation  except when started. Constructor Summary Constructors  Constructor and Description CompositeService(String name)  Method Summary Methods  Modifier and Type Method and Description protected boolean addIfService(Object object) If the passed object is an instance of Service,  add it to the list of services managed by this CompositeService protected void addService(Service service) Add the passed Service to the list of services managed by this  CompositeService List<Service> getServices() Get a cloned list of services protected boolean removeService(Service service)  protected void serviceInit(Configuration conf) All initialization code needed by a service. protected void serviceStart() Actions called during the INITED to STARTED transition. protected void serviceStop() Actions called during the transition to the STOPPED state. Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail STOP_ONLY_STARTED_SERVICES protected static final boolean STOP_ONLY_STARTED_SERVICES Policy on shutdown: attempt to close everything (purest) or  only try to close started services (which assumes  that the service implementations may not handle the stop() operation  except when started.  Irrespective of this policy, if a child service fails during  its init() or start() operations, it will have stop() called on it. See Also:Constant Field Values Constructor Detail CompositeService public CompositeService(String name) Method Detail getServices public List<Service> getServices() Get a cloned list of services Returns:a list of child services at the time of invocation -  added services will not be picked up. addService protected void addService(Service service) Add the passed Service to the list of services managed by this  CompositeService Parameters:service - the Service to be added addIfService protected boolean addIfService(Object object) If the passed object is an instance of Service,  add it to the list of services managed by this CompositeService Parameters:object -  Returns:true if a service is added, false otherwise. removeService protected boolean removeService(Service service) serviceInit protected void serviceInit(Configuration conf)                     throws Exception Description copied from class: AbstractService All initialization code needed by a service.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.init(Configuration) prevents re-entrancy.  The base implementation checks to see if the subclass has created  a new configuration instance, and if so, updates the base class value Overrides: serviceInit in class AbstractService Parameters:conf - configuration Throws: Exception - on a failure -these will be caught,  possibly wrapped, and wil; trigger a service stop serviceStart protected void serviceStart()                      throws Exception Description copied from class: AbstractService Actions called during the INITED to STARTED transition.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.start() prevents re-entrancy. Overrides: serviceStart in class AbstractService Throws: Exception - if needed -these will be caught,  wrapped, and trigger a service stop serviceStop protected void serviceStop()                     throws Exception Description copied from class: AbstractService Actions called during the transition to the STOPPED state.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.stop() prevents re-entrancy.  Implementations MUST write this to be robust against failures, including  checks for null references -and for the first failure to not stop other  attempts to shut down parts of the service. Overrides: serviceStop in class AbstractService Throws: Exception - if needed -these will be caught and logged. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompressedWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompressedWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class CompressedWritable java.lang.Object org.apache.hadoop.io.CompressedWritable All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public abstract class CompressedWritable extends Object implements Writable A base-class for Writables which store themselves compressed and lazily  inflate on field access.  This is useful for large objects whose fields are  not be altered during a map or reduce operation: leaving the field data  compressed makes copying the instance from one file to another much  faster. Constructor Summary Constructors  Constructor and Description CompressedWritable()  Method Summary Methods  Modifier and Type Method and Description protected void ensureInflated() Must be called by all methods which access fields to ensure that the data  has been uncompressed. void readFields(DataInput in) Deserialize the fields of this object from in. protected abstract void readFieldsCompressed(DataInput in) Subclasses implement this instead of readFields(DataInput). void write(DataOutput out) Serialize the fields of this object to out. protected abstract void writeCompressed(DataOutput out) Subclasses implement this instead of write(DataOutput). Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail CompressedWritable public CompressedWritable() Method Detail readFields public final void readFields(DataInput in)                       throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException ensureInflated protected void ensureInflated() Must be called by all methods which access fields to ensure that the data  has been uncompressed. readFieldsCompressed protected abstract void readFieldsCompressed(DataInput in)                                       throws IOException Subclasses implement this instead of readFields(DataInput). Throws: IOException write public final void write(DataOutput out)                  throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException writeCompressed protected abstract void writeCompressed(DataOutput out)                                  throws IOException Subclasses implement this instead of write(DataOutput). Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompressionCodec (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompressionCodec (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Interface CompressionCodec All Known Subinterfaces: DirectDecompressionCodec, SplittableCompressionCodec All Known Implementing Classes: BZip2Codec, DefaultCodec, GzipCodec @InterfaceAudience.Public @InterfaceStability.Evolving public interface CompressionCodec This class encapsulates a streaming compression/decompression pair. Method Summary Methods  Modifier and Type Method and Description Compressor createCompressor() Create a new Compressor for use by this CompressionCodec. Decompressor createDecompressor() Create a new Decompressor for use by this CompressionCodec. CompressionInputStream createInputStream(InputStream in) Create a CompressionInputStream that will read from the given  input stream. CompressionInputStream createInputStream(InputStream in,                                   Decompressor decompressor) Create a CompressionInputStream that will read from the given   InputStream with the given Decompressor. CompressionOutputStream createOutputStream(OutputStream out) Create a CompressionOutputStream that will write to the given   OutputStream. CompressionOutputStream createOutputStream(OutputStream out,                                     Compressor compressor) Create a CompressionOutputStream that will write to the given   OutputStream with the given Compressor. Class<? extends Compressor> getCompressorType() Get the type of Compressor needed by this CompressionCodec. Class<? extends Decompressor> getDecompressorType() Get the type of Decompressor needed by this CompressionCodec. String getDefaultExtension() Get the default filename extension for this kind of compression. Method Detail createOutputStream CompressionOutputStream createOutputStream(OutputStream out)                                            throws IOException Create a CompressionOutputStream that will write to the given   OutputStream. Parameters:out - the location for the final output stream Returns:a stream the user can write uncompressed data to have it compressed Throws: IOException createOutputStream CompressionOutputStream createOutputStream(OutputStream out,                                          Compressor compressor)                                            throws IOException Create a CompressionOutputStream that will write to the given   OutputStream with the given Compressor. Parameters:out - the location for the final output streamcompressor - compressor to use Returns:a stream the user can write uncompressed data to have it compressed Throws: IOException getCompressorType Class<? extends Compressor> getCompressorType() Get the type of Compressor needed by this CompressionCodec. Returns:the type of compressor needed by this codec. createCompressor Compressor createCompressor() Create a new Compressor for use by this CompressionCodec. Returns:a new compressor for use by this codec createInputStream CompressionInputStream createInputStream(InputStream in)                                          throws IOException Create a CompressionInputStream that will read from the given  input stream. Parameters:in - the stream to read compressed bytes from Returns:a stream to read uncompressed bytes from Throws: IOException createInputStream CompressionInputStream createInputStream(InputStream in,                                        Decompressor decompressor)                                          throws IOException Create a CompressionInputStream that will read from the given   InputStream with the given Decompressor. Parameters:in - the stream to read compressed bytes fromdecompressor - decompressor to use Returns:a stream to read uncompressed bytes from Throws: IOException getDecompressorType Class<? extends Decompressor> getDecompressorType() Get the type of Decompressor needed by this CompressionCodec. Returns:the type of decompressor needed by this codec. createDecompressor Decompressor createDecompressor() Create a new Decompressor for use by this CompressionCodec. Returns:a new decompressor for use by this codec getDefaultExtension String getDefaultExtension() Get the default filename extension for this kind of compression. Returns:the extension including the '.' Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompressionCodecFactory (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompressionCodecFactory (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class CompressionCodecFactory java.lang.Object org.apache.hadoop.io.compress.CompressionCodecFactory @InterfaceAudience.Public @InterfaceStability.Evolving public class CompressionCodecFactory extends Object A factory that will find the correct codec for a given filename. Field Summary Fields  Modifier and Type Field and Description static org.apache.commons.logging.Log LOG  Constructor Summary Constructors  Constructor and Description CompressionCodecFactory(Configuration conf) Find the codecs specified in the config value io.compression.codecs   and register them. Method Summary Methods  Modifier and Type Method and Description CompressionCodec getCodec(Path file) Find the relevant compression codec for the given file based on its  filename suffix. CompressionCodec getCodecByClassName(String classname) Find the relevant compression codec for the codec's canonical class name. CompressionCodec getCodecByName(String codecName) Find the relevant compression codec for the codec's canonical class name  or by codec alias. Class<? extends CompressionCodec> getCodecClassByName(String codecName) Find the relevant compression codec for the codec's canonical class name  or by codec alias and returns its implemetation class. static List<Class<? extends CompressionCodec>> getCodecClasses(Configuration conf) Get the list of codecs discovered via a Java ServiceLoader, or  listed in the configuration. static void main(String[] args) A little test program. static String removeSuffix(String filename,                         String suffix) Removes a suffix from a filename, if it has it. static void setCodecClasses(Configuration conf,                               List<Class> classes) Sets a list of codec classes in the configuration. String toString() Print the extension map out as a string. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail LOG public static final org.apache.commons.logging.Log LOG Constructor Detail CompressionCodecFactory public CompressionCodecFactory(Configuration conf) Find the codecs specified in the config value io.compression.codecs   and register them. Defaults to gzip and deflate. Method Detail toString public String toString() Print the extension map out as a string. Overrides: toString in class Object getCodecClasses public static List<Class<? extends CompressionCodec>> getCodecClasses(Configuration conf) Get the list of codecs discovered via a Java ServiceLoader, or  listed in the configuration. Codecs specified in configuration come  later in the returned list, and are considered to override those  from the ServiceLoader. Parameters:conf - the configuration to look in Returns:a list of the CompressionCodec classes setCodecClasses public static void setCodecClasses(Configuration conf,                    List<Class> classes) Sets a list of codec classes in the configuration. In addition to any  classes specified using this method, CompressionCodec classes on  the classpath are discovered using a Java ServiceLoader. Parameters:conf - the configuration to modifyclasses - the list of classes to set getCodec public CompressionCodec getCodec(Path file) Find the relevant compression codec for the given file based on its  filename suffix. Parameters:file - the filename to check Returns:the codec object getCodecByClassName public CompressionCodec getCodecByClassName(String classname) Find the relevant compression codec for the codec's canonical class name. Parameters:classname - the canonical class name of the codec Returns:the codec object getCodecByName public CompressionCodec getCodecByName(String codecName) Find the relevant compression codec for the codec's canonical class name  or by codec alias.    Codec aliases are case insensitive.    The code alias is the short class name (without the package name).  If the short class name ends with 'Codec', then there are two aliases for  the codec, the complete short class name and the short class name without  the 'Codec' ending. For example for the 'GzipCodec' codec class name the  alias are 'gzip' and 'gzipcodec'. Parameters:codecName - the canonical class name of the codec Returns:the codec object getCodecClassByName public Class<? extends CompressionCodec> getCodecClassByName(String codecName) Find the relevant compression codec for the codec's canonical class name  or by codec alias and returns its implemetation class.    Codec aliases are case insensitive.    The code alias is the short class name (without the package name).  If the short class name ends with 'Codec', then there are two aliases for  the codec, the complete short class name and the short class name without  the 'Codec' ending. For example for the 'GzipCodec' codec class name the  alias are 'gzip' and 'gzipcodec'. Parameters:codecName - the canonical class name of the codec Returns:the codec class removeSuffix public static String removeSuffix(String filename,                   String suffix) Removes a suffix from a filename, if it has it. Parameters:filename - the filename to stripsuffix - the suffix to remove Returns:the shortened filename main public static void main(String[] args)                  throws Exception A little test program. Parameters:args -  Throws: Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompressionInputStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompressionInputStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class CompressionInputStream java.lang.Object java.io.InputStream org.apache.hadoop.io.compress.CompressionInputStream All Implemented Interfaces: Closeable, AutoCloseable, Seekable Direct Known Subclasses: DecompressorStream, SplitCompressionInputStream @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class CompressionInputStream extends InputStream implements Seekable A compression input stream.  Implementations are assumed to be buffered.  This permits clients to  reposition the underlying input stream then call resetState(),  without having to also synchronize client buffers. Field Summary Fields  Modifier and Type Field and Description protected InputStream in The input stream to be compressed. protected long maxAvailableData  Constructor Summary Constructors  Modifier Constructor and Description protected  CompressionInputStream(InputStream in) Create a compression input stream that reads  the decompressed bytes from the given stream. Method Summary Methods  Modifier and Type Method and Description void close()  long getPos() This method returns the current position in the stream. abstract int read(byte[] b,         int off,         int len) Read bytes from the stream. abstract void resetState() Reset the decompressor to its initial state and discard any buffered data,  as the underlying stream may have been repositioned. void seek(long pos) This method is current not supported. boolean seekToNewSource(long targetPos) This method is current not supported. Methods inherited from class java.io.InputStream available, mark, markSupported, read, read, reset, skip Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail in protected final InputStream in The input stream to be compressed. maxAvailableData protected long maxAvailableData Constructor Detail CompressionInputStream protected CompressionInputStream(InputStream in)                           throws IOException Create a compression input stream that reads  the decompressed bytes from the given stream. Parameters:in - The input stream to be compressed. Throws: IOException Method Detail close public void close()            throws IOException Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Overrides: close in class InputStream Throws: IOException read public abstract int read(byte[] b,        int off,        int len)                   throws IOException Read bytes from the stream.  Made abstract to prevent leakage to underlying stream. Overrides: read in class InputStream Throws: IOException resetState public abstract void resetState()                          throws IOException Reset the decompressor to its initial state and discard any buffered data,  as the underlying stream may have been repositioned. Throws: IOException getPos public long getPos()             throws IOException This method returns the current position in the stream. Specified by: getPos in interface Seekable Returns:Current position in stream as a long Throws: IOException seek public void seek(long pos)           throws UnsupportedOperationException This method is current not supported. Specified by: seek in interface Seekable Throws: UnsupportedOperationException seekToNewSource public boolean seekToNewSource(long targetPos)                         throws UnsupportedOperationException This method is current not supported. Specified by: seekToNewSource in interface Seekable Throws: UnsupportedOperationException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompressionOutputStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompressionOutputStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class CompressionOutputStream java.lang.Object java.io.OutputStream org.apache.hadoop.io.compress.CompressionOutputStream All Implemented Interfaces: Closeable, Flushable, AutoCloseable Direct Known Subclasses: CompressorStream @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class CompressionOutputStream extends OutputStream A compression output stream. Field Summary Fields  Modifier and Type Field and Description protected OutputStream out The output stream to be compressed. Constructor Summary Constructors  Modifier Constructor and Description protected  CompressionOutputStream(OutputStream out) Create a compression output stream that writes  the compressed bytes to the given stream. Method Summary Methods  Modifier and Type Method and Description void close()  abstract void finish() Finishes writing compressed data to the output stream   without closing the underlying stream. void flush()  abstract void resetState() Reset the compression to the initial state. abstract void write(byte[] b,           int off,           int len) Write compressed bytes to the stream. Methods inherited from class java.io.OutputStream write, write Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail out protected final OutputStream out The output stream to be compressed. Constructor Detail CompressionOutputStream protected CompressionOutputStream(OutputStream out) Create a compression output stream that writes  the compressed bytes to the given stream. Parameters:out -  Method Detail close public void close()            throws IOException Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Overrides: close in class OutputStream Throws: IOException flush public void flush()            throws IOException Specified by: flush in interface Flushable Overrides: flush in class OutputStream Throws: IOException write public abstract void write(byte[] b,          int off,          int len)                     throws IOException Write compressed bytes to the stream.  Made abstract to prevent leakage to underlying stream. Overrides: write in class OutputStream Throws: IOException finish public abstract void finish()                      throws IOException Finishes writing compressed data to the output stream   without closing the underlying stream. Throws: IOException resetState public abstract void resetState()                          throws IOException Reset the compression to the initial state.   Does not reset the underlying stream. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Compressor (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Compressor (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Interface Compressor @InterfaceAudience.Public @InterfaceStability.Evolving public interface Compressor Specification of a stream-based 'compressor' which can be    plugged into a CompressionOutputStream to compress data.  This is modelled after Deflater Method Summary Methods  Modifier and Type Method and Description int compress(byte[] b,                 int off,                 int len) Fills specified buffer with compressed data. void end() Closes the compressor and discards any unprocessed input. void finish() When called, indicates that compression should end  with the current contents of the input buffer. boolean finished() Returns true if the end of the compressed   data output stream has been reached. long getBytesRead() Return number of uncompressed bytes input so far. long getBytesWritten() Return number of compressed bytes output so far. boolean needsInput() Returns true if the input data buffer is empty and   #setInput() should be called to provide more input. void reinit(Configuration conf) Prepare the compressor to be used in a new stream with settings defined in  the given Configuration void reset() Resets compressor so that a new set of input data can be processed. void setDictionary(byte[] b,                           int off,                           int len) Sets preset dictionary for compression. void setInput(byte[] b,                 int off,                 int len) Sets input data for compression. Method Detail setInput void setInput(byte[] b,             int off,             int len) Sets input data for compression.   This should be called whenever #needsInput() returns   true indicating that more input data is required. Parameters:b - Input dataoff - Start offsetlen - Length needsInput boolean needsInput() Returns true if the input data buffer is empty and   #setInput() should be called to provide more input. Returns:true if the input data buffer is empty and   #setInput() should be called in order to provide more input. setDictionary void setDictionary(byte[] b,                  int off,                  int len) Sets preset dictionary for compression. A preset dictionary   is used when the history buffer can be predetermined. Parameters:b - Dictionary data bytesoff - Start offsetlen - Length getBytesRead long getBytesRead() Return number of uncompressed bytes input so far. getBytesWritten long getBytesWritten() Return number of compressed bytes output so far. finish void finish() When called, indicates that compression should end  with the current contents of the input buffer. finished boolean finished() Returns true if the end of the compressed   data output stream has been reached. Returns:true if the end of the compressed  data output stream has been reached. compress int compress(byte[] b,            int off,            int len)              throws IOException Fills specified buffer with compressed data. Returns actual number  of bytes of compressed data. A return value of 0 indicates that  needsInput() should be called in order to determine if more input  data is required. Parameters:b - Buffer for the compressed dataoff - Start offset of the datalen - Size of the buffer Returns:The actual number of bytes of compressed data. Throws: IOException reset void reset() Resets compressor so that a new set of input data can be processed. end void end() Closes the compressor and discards any unprocessed input. reinit void reinit(Configuration conf) Prepare the compressor to be used in a new stream with settings defined in  the given Configuration Parameters:conf - Configuration from which new setting are fetched Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CompressorStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CompressorStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class CompressorStream java.lang.Object java.io.OutputStream org.apache.hadoop.io.compress.CompressionOutputStream org.apache.hadoop.io.compress.CompressorStream All Implemented Interfaces: Closeable, Flushable, AutoCloseable Direct Known Subclasses: BlockCompressorStream @InterfaceAudience.Public @InterfaceStability.Evolving public class CompressorStream extends CompressionOutputStream Field Summary Fields  Modifier and Type Field and Description protected byte[] buffer  protected boolean closed  protected Compressor compressor  Fields inherited from class org.apache.hadoop.io.compress.CompressionOutputStream out Constructor Summary Constructors  Modifier Constructor and Description protected  CompressorStream(OutputStream out) Allow derived classes to directly set the underlying stream.   CompressorStream(OutputStream out,                                 Compressor compressor)    CompressorStream(OutputStream out,                                 Compressor compressor,                                 int bufferSize)  Method Summary Methods  Modifier and Type Method and Description void close()  protected void compress()  void finish() Finishes writing compressed data to the output stream   without closing the underlying stream. void resetState() Reset the compression to the initial state. void write(byte[] b,           int off,           int len) Write compressed bytes to the stream. void write(int b)  Methods inherited from class org.apache.hadoop.io.compress.CompressionOutputStream flush Methods inherited from class java.io.OutputStream write Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail compressor protected Compressor compressor buffer protected byte[] buffer closed protected boolean closed Constructor Detail CompressorStream public CompressorStream(OutputStream out,                 Compressor compressor,                 int bufferSize) CompressorStream public CompressorStream(OutputStream out,                 Compressor compressor) CompressorStream protected CompressorStream(OutputStream out) Allow derived classes to directly set the underlying stream. Parameters:out - Underlying output stream. Method Detail write public void write(byte[] b,          int off,          int len)            throws IOException Description copied from class: CompressionOutputStream Write compressed bytes to the stream.  Made abstract to prevent leakage to underlying stream. Specified by: write in class CompressionOutputStream Throws: IOException compress protected void compress()                  throws IOException Throws: IOException finish public void finish()             throws IOException Description copied from class: CompressionOutputStream Finishes writing compressed data to the output stream   without closing the underlying stream. Specified by: finish in class CompressionOutputStream Throws: IOException resetState public void resetState()                 throws IOException Description copied from class: CompressionOutputStream Reset the compression to the initial state.   Does not reset the underlying stream. Specified by: resetState in class CompressionOutputStream Throws: IOException close public void close()            throws IOException Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Overrides: close in class CompressionOutputStream Throws: IOException write public void write(int b)            throws IOException Specified by: write in class OutputStream Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Configurable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Configurable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.conf Interface Configurable All Known Subinterfaces: ImpersonationProvider, Tool All Known Implementing Classes: AbstractDNSToSwitchMapping, AbstractMapWritable, AvroReflectSerialization, AvroSerialization, AvroSpecificSerialization, BinaryPartitioner, BinaryPartitioner, BZip2Codec, CachedDNSToSwitchMapping, ChecksumFileSystem, CLI, CompositeRecordReader, CompositeRecordReader, Configured, DataDrivenDBInputFormat, DBInputFormat, DBInputFormat, DefaultCodec, DefaultImpersonationProvider, DistCp, EnumSetWritable, FileSystem, FilterFileSystem, FTPFileSystem, GenericWritable, GzipCodec, InnerJoinRecordReader, InnerJoinRecordReader, InputSampler, InputSampler, JobClient, JoinRecordReader, JoinRecordReader, KeyFieldBasedComparator, KeyFieldBasedComparator, KeyFieldBasedPartitioner, KeyFieldBasedPartitioner, LocalFileSystem, LogsCLI, MapWritable, MigrationTool, MultiFilterRecordReader, MultiFilterRecordReader, NativeAzureFileSystem, NativeS3FileSystem, ObjectWritable, OracleDataDrivenDBInputFormat, OuterJoinRecordReader, OuterJoinRecordReader, OverrideRecordReader, OverrideRecordReader, RawLocalFileSystem, RecordComparator, ResourceCalculatorProcessTree, S3FileSystem, ScriptBasedMapping, SocksSocketFactory, SortedMapWritable, Submitter, TableMapping, TotalOrderPartitioner, TotalOrderPartitioner, Trash, TrashPolicy, ViewFileSystem, WasbFsck, WrappedRecordReader, WritableComparator, WritableSerialization @InterfaceAudience.Public @InterfaceStability.Stable public interface Configurable Something that may be configured with a Configuration. Method Summary Methods  Modifier and Type Method and Description Configuration getConf() Return the configuration used by this object. void setConf(Configuration conf) Set the configuration to be used by this object. Method Detail setConf void setConf(Configuration conf) Set the configuration to be used by this object. getConf Configuration getConf() Return the configuration used by this object. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Configuration (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Configuration (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.conf Class Configuration java.lang.Object org.apache.hadoop.conf.Configuration All Implemented Interfaces: Iterable<Map.Entry<String,String>>, Writable Direct Known Subclasses: JobConf, YarnConfiguration @InterfaceAudience.Public @InterfaceStability.Stable public class Configuration extends Object implements Iterable<Map.Entry<String,String>>, Writable Provides access to configuration parameters.  Resources  Configurations are specified by resources. A resource contains a set of  name/value pairs as XML data. Each resource is named by either a   String or by a Path. If named by a String,   then the classpath is examined for a file with that name.  If named by a   Path, then the local filesystem is examined directly, without   referring to the classpath.  Unless explicitly turned off, Hadoop by default specifies two   resources, loaded in-order from the classpath:       core-default.xml: Read-only defaults for hadoop.  core-site.xml: Site-specific configuration for a given hadoop  installation.    Applications may add additional resources, which are loaded  subsequent to these resources in the order they are added.    Final Parameters  Configuration parameters may be declared final.   Once a resource declares a value final, no subsequently-loaded   resource can alter that value.    For example, one might define a final parameter with:     <property>     <name>dfs.hosts.include</name>     <value>/etc/hadoop/conf/hosts.include</value>     <final>true</final>   </property>  Administrators typically define parameters as final in   core-site.xml for values that user applications may not alter.  Variable Expansion  Value strings are first processed for variable expansion. The  available properties are:  Other properties defined in this Configuration; and, if a name is  undefined here,  Properties in System.getProperties().    For example, if a configuration resource contains the following property  definitions:      <property>     <name>basedir</name>     <value>/user/${user.name}</value>   </property>      <property>     <name>tempdir</name>     <value>${basedir}/tmp</value>   </property>  When conf.get("tempdir") is called, then ${basedir}  will be resolved to another property in this Configuration, while  ${user.name} would then ordinarily be resolved to the value  of the System property with that name.  By default, warnings will be given to any deprecated configuration   parameters and these are suppressible by configuring  log4j.logger.org.apache.hadoop.conf.Configuration.deprecation in  log4j.properties file. Constructor Summary Constructors  Constructor and Description Configuration() A new configuration. Configuration(boolean loadDefaults) A new configuration where the behavior of reading from the default   resources can be turned off. Configuration(Configuration other) A new configuration with the same settings cloned from another. Method Summary Methods  Modifier and Type Method and Description static void addDefaultResource(String name) Add a default resource. static void addDeprecation(String key,                             String newKey) Adds the deprecated key to the global deprecation map when no custom  message is provided. static void addDeprecation(String key,                             String[] newKeys) Deprecated.  use addDeprecation(String key, String newKey) instead static void addDeprecation(String key,                             String[] newKeys,                             String customMessage) Deprecated.  use addDeprecation(String key, String newKey,       String customMessage) instead static void addDeprecation(String key,                             String newKey,                             String customMessage) Adds the deprecated key to the global deprecation map. static void addDeprecations(org.apache.hadoop.conf.Configuration.DeprecationDelta[] deltas) Adds a set of deprecated keys to the global deprecations. void addResource(Configuration conf) Add a configuration resource. void addResource(InputStream in) Add a configuration resource. void addResource(InputStream in,                       String name) Add a configuration resource. void addResource(Path file) Add a configuration resource. void addResource(String name) Add a configuration resource. void addResource(URL url) Add a configuration resource. void clear() Clears all keys from the configuration. static void dumpConfiguration(Configuration config,                                   Writer out) Writes out all the parameters and their properties (final and resource) to   the given Writer   The format of the output would be    { "properties" : [ {key1,value1,key1.isFinal,key1.resource}, {key2,value2,   key2.isFinal,key2.resource}... static void dumpDeprecatedKeys()  String get(String name) Get the value of the name property, null if  no such property exists. String get(String name,       String defaultValue) Get the value of the name. boolean getBoolean(String name,                     boolean defaultValue) Get the value of the name property as a boolean. Class<?> getClass(String name,                 Class<?> defaultValue) Get the value of the name property as a Class. <U> Class<? extends U> getClass(String name,                 Class<? extends U> defaultValue,                 Class<U> xface) Get the value of the name property as a Class  implementing the interface specified by xface. Class<?> getClassByName(String name) Load a class by name. Class<?> getClassByNameOrNull(String name) Load a class by name, returning null rather than throwing an exception  if it couldn't be loaded. Class<?>[] getClasses(String name,                     Class<?>... defaultValue) Get the value of the name property  as an array of Class. ClassLoader getClassLoader() Get the ClassLoader for this job. InputStream getConfResourceAsInputStream(String name) Get an input stream attached to the configuration resource with the  given name. Reader getConfResourceAsReader(String name) Get a Reader attached to the configuration resource with the  given name. double getDouble(String name,                   double defaultValue) Get the value of the name property as a double. <T extends Enum<T>> T getEnum(String name,               T defaultValue) Return value matching this enumerated type. File getFile(String dirsProp,               String path) Get a local file name under a directory named in dirsProp with  the given path. Set<String> getFinalParameters() Get the set of parameters marked final. float getFloat(String name,                 float defaultValue) Get the value of the name property as a float. <U> List<U> getInstances(String name,                         Class<U> xface) Get the value of the name property as a List  of objects implementing the interface specified by xface. int getInt(String name,             int defaultValue) Get the value of the name property as an int. int[] getInts(String name) Get the value of the name property as a set of comma-delimited  int values. Path getLocalPath(String dirsProp,                         String path) Get a local file under a directory named by dirsProp with  the given path. long getLong(String name,               long defaultValue) Get the value of the name property as a long. long getLongBytes(String name,                         long defaultValue) Get the value of the name property as a long or  human readable format. char[] getPassword(String name) Get the value for a known password configuration element. protected char[] getPasswordFromConfig(String name) Fallback to clear text passwords in configuration. protected char[] getPasswordFromCredentialProviders(String name) Try and resolve the provided element name as a credential provider  alias. Pattern getPattern(String name,                     Pattern defaultValue) Get the value of the name property as a Pattern. String[] getPropertySources(String name) Gets information about why a property was set. protected Properties getProps()  org.apache.hadoop.conf.Configuration.IntegerRanges getRange(String name,                 String defaultValue) Parse the given attribute as a set of integer ranges String getRaw(String name) Get the value of the name property, without doing  variable expansion.If the key is   deprecated, it returns the value of the first key which replaces   the deprecated key and is not null. URL getResource(String name) Get the URL for the named resource. InetSocketAddress getSocketAddr(String name,                           String defaultAddress,                           int defaultPort) Get the socket address for name property as a  InetSocketAddress. InetSocketAddress getSocketAddr(String hostProperty,                           String addressProperty,                           String defaultAddressValue,                           int defaultPort) Get the socket address for hostProperty as a  InetSocketAddress. Collection<String> getStringCollection(String name) Get the comma delimited values of the name property as   a collection of Strings. String[] getStrings(String name) Get the comma delimited values of the name property as   an array of Strings. String[] getStrings(String name,                     String... defaultValue) Get the comma delimited values of the name property as   an array of Strings. long getTimeDuration(String name,                               long defaultValue,                               TimeUnit unit) Return time duration in the given time unit. String getTrimmed(String name) Get the value of the name property as a trimmed String,   null if no such property exists. String getTrimmed(String name,                     String defaultValue) Get the value of the name property as a trimmed String,   defaultValue if no such property exists. Collection<String> getTrimmedStringCollection(String name) Get the comma delimited values of the name property as   a collection of Strings, trimmed of the leading and trailing whitespace. String[] getTrimmedStrings(String name) Get the comma delimited values of the name property as   an array of Strings, trimmed of the leading and trailing whitespace. String[] getTrimmedStrings(String name,                                   String... defaultValue) Get the comma delimited values of the name property as   an array of Strings, trimmed of the leading and trailing whitespace. Map<String,String> getValByRegex(String regex) get keys matching the the regex static boolean hasWarnedDeprecation(String name) Returns whether or not a deprecated name has been warned. static boolean isDeprecated(String key) checks whether the given key is deprecated. Iterator<Map.Entry<String,String>> iterator() Get an Iterator to go through the list of String   key-value pairs in the configuration. static void main(String[] args) For debugging. boolean onlyKeyExists(String name) Return existence of the name property, but only for  names which have no valid value, usually non-existent or commented  out in XML. void readFields(DataInput in) Deserialize the fields of this object from in. void reloadConfiguration() Reload configuration from previously added resources. void set(String name,       String value) Set the value of the name property. void set(String name,       String value,       String source) Set the value of the name property. void setAllowNullValueProperties(boolean val) Set Configuration to allow keys without values during setup. void setBoolean(String name,                     boolean value) Set the value of the name property to a boolean. void setBooleanIfUnset(String name,                                   boolean value) Set the given property, if it is currently unset. void setClass(String name,                 Class<?> theClass,                 Class<?> xface) Set the value of the name property to the name of a   theClass implementing the given interface xface. void setClassLoader(ClassLoader classLoader) Set the class loader that will be used to load the various objects. void setDeprecatedProperties() Sets all deprecated properties that are not currently set but have a  corresponding new property that is set. void setDouble(String name,                   double value) Set the value of the name property to a double. <T extends Enum<T>> void setEnum(String name,               T value) Set the value of the name property to the given type. void setFloat(String name,                 float value) Set the value of the name property to a float. void setIfUnset(String name,                     String value) Sets a property if it is currently unset. void setInt(String name,             int value) Set the value of the name property to an int. void setLong(String name,               long value) Set the value of the name property to a long. void setPattern(String name,                     Pattern pattern) Set the given property to Pattern. void setQuietMode(boolean quietmode) Set the quietness-mode. void setSocketAddr(String name,                           InetSocketAddress addr) Set the socket address for the name property as  a host:port. void setStrings(String name,                     String... values) Set the array of string values for the name property as   as comma delimited values. void setTimeDuration(String name,                               long value,                               TimeUnit unit) Set the value of name to the given time duration. int size() Return the number of keys in the configuration. String toString()  void unset(String name) Unset a previously set property. InetSocketAddress updateConnectAddr(String name,                                   InetSocketAddress addr) Set the socket address a client can use to connect for the  name property as a host:port. InetSocketAddress updateConnectAddr(String hostProperty,                                   String addressProperty,                                   String defaultAddressValue,                                   InetSocketAddress addr) Set the socket address a client can use to connect for the  name property as a host:port. void write(DataOutput out) Serialize the fields of this object to out. void writeXml(OutputStream out) Write out the non-default properties in this configuration to the given  OutputStream using UTF-8 encoding. void writeXml(Writer out) Write out the non-default properties in this configuration to the given  Writer. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail Configuration public Configuration() A new configuration. Configuration public Configuration(boolean loadDefaults) A new configuration where the behavior of reading from the default   resources can be turned off.    If the parameter loadDefaults is false, the new instance  will not load resources from the default files. Parameters:loadDefaults - specifies whether to load from the default files Configuration public Configuration(Configuration other) A new configuration with the same settings cloned from another. Parameters:other - the configuration from which to clone settings. Method Detail addDeprecations public static void addDeprecations(org.apache.hadoop.conf.Configuration.DeprecationDelta[] deltas) Adds a set of deprecated keys to the global deprecations.  This method is lockless.  It works by means of creating a new  DeprecationContext based on the old one, and then atomically swapping in  the new context.  If someone else updated the context in between us reading  the old context and swapping in the new one, we try again until we win the  race. Parameters:deltas - The deprecations to add. addDeprecation @Deprecated public static void addDeprecation(String key,                              String[] newKeys,                              String customMessage) Deprecated. use addDeprecation(String key, String newKey,       String customMessage) instead Adds the deprecated key to the global deprecation map.  It does not override any existing entries in the deprecation map.  This is to be used only by the developers in order to add deprecation of  keys, and attempts to call this method after loading resources once,  would lead to UnsupportedOperationException    If a key is deprecated in favor of multiple keys, they are all treated as   aliases of each other, and setting any one of them resets all the others   to the new value.  If you have multiple deprecation entries to add, it is more efficient to  use #addDeprecations(DeprecationDelta[] deltas) instead. Parameters:key - newKeys - customMessage -  addDeprecation public static void addDeprecation(String key,                   String newKey,                   String customMessage) Adds the deprecated key to the global deprecation map.  It does not override any existing entries in the deprecation map.  This is to be used only by the developers in order to add deprecation of  keys, and attempts to call this method after loading resources once,  would lead to UnsupportedOperationException    If you have multiple deprecation entries to add, it is more efficient to  use #addDeprecations(DeprecationDelta[] deltas) instead. Parameters:key - newKey - customMessage -  addDeprecation @Deprecated public static void addDeprecation(String key,                              String[] newKeys) Deprecated. use addDeprecation(String key, String newKey) instead Adds the deprecated key to the global deprecation map when no custom  message is provided.  It does not override any existing entries in the deprecation map.  This is to be used only by the developers in order to add deprecation of  keys, and attempts to call this method after loading resources once,  would lead to UnsupportedOperationException    If a key is deprecated in favor of multiple keys, they are all treated as   aliases of each other, and setting any one of them resets all the others   to the new value.    If you have multiple deprecation entries to add, it is more efficient to  use #addDeprecations(DeprecationDelta[] deltas) instead. Parameters:key - Key that is to be deprecatednewKeys - list of keys that take up the values of deprecated key addDeprecation public static void addDeprecation(String key,                   String newKey) Adds the deprecated key to the global deprecation map when no custom  message is provided.  It does not override any existing entries in the deprecation map.  This is to be used only by the developers in order to add deprecation of  keys, and attempts to call this method after loading resources once,  would lead to UnsupportedOperationException    If you have multiple deprecation entries to add, it is more efficient to  use #addDeprecations(DeprecationDelta[] deltas) instead. Parameters:key - Key that is to be deprecatednewKey - key that takes up the value of deprecated key isDeprecated public static boolean isDeprecated(String key) checks whether the given key is deprecated. Parameters:key - the parameter which is to be checked for deprecation Returns:true if the key is deprecated and           false otherwise. setDeprecatedProperties public void setDeprecatedProperties() Sets all deprecated properties that are not currently set but have a  corresponding new property that is set. Useful for iterating the  properties when all deprecated properties for currently set properties  need to be present. addDefaultResource public static void addDefaultResource(String name) Add a default resource. Resources are loaded in the order of the resources   added. Parameters:name - file name. File should be present in the classpath. addResource public void addResource(String name) Add a configuration resource.     The properties of this resource will override properties of previously   added resources, unless they were marked final. Parameters:name - resource to be added, the classpath is examined for a file               with that name. addResource public void addResource(URL url) Add a configuration resource.     The properties of this resource will override properties of previously   added resources, unless they were marked final. Parameters:url - url of the resource to be added, the local filesystem is              examined directly to find the resource, without referring to              the classpath. addResource public void addResource(Path file) Add a configuration resource.     The properties of this resource will override properties of previously   added resources, unless they were marked final. Parameters:file - file-path of resource to be added, the local filesystem is              examined directly to find the resource, without referring to               the classpath. addResource public void addResource(InputStream in) Add a configuration resource.     The properties of this resource will override properties of previously   added resources, unless they were marked final.     WARNING: The contents of the InputStream will be cached, by this method.   So use this sparingly because it does increase the memory consumption. Parameters:in - InputStream to deserialize the object from. In will be read from  when a get or set is called next.  After it is read the stream will be  closed. addResource public void addResource(InputStream in,                String name) Add a configuration resource.     The properties of this resource will override properties of previously   added resources, unless they were marked final. Parameters:in - InputStream to deserialize the object from.name - the name of the resource because InputStream.toString is not  very descriptive some times. addResource public void addResource(Configuration conf) Add a configuration resource.  The properties of this resource will override properties of previously  added resources, unless they were marked final. Parameters:conf - Configuration object from which to load properties reloadConfiguration public void reloadConfiguration() Reload configuration from previously added resources.  This method will clear all the configuration read from the added   resources, and final parameters. This will make the resources to   be read again before accessing the values. Values that are added  via set methods will overlay values read from the resources. get public String get(String name) Get the value of the name property, null if  no such property exists. If the key is deprecated, it returns the value of  the first key which replaces the deprecated key and is not null.    Values are processed for variable expansion   before being returned. Parameters:name - the property name, will be trimmed before get value. Returns:the value of the name or its replacing property,           or null if no such property exists. setAllowNullValueProperties public void setAllowNullValueProperties(boolean val) Set Configuration to allow keys without values during setup.  Intended  for use during testing. Parameters:val - If true, will allow Configuration to store keys without values onlyKeyExists public boolean onlyKeyExists(String name) Return existence of the name property, but only for  names which have no valid value, usually non-existent or commented  out in XML. Parameters:name - the property name Returns:true if the property name exists without value getTrimmed public String getTrimmed(String name) Get the value of the name property as a trimmed String,   null if no such property exists.   If the key is deprecated, it returns the value of  the first key which replaces the deprecated key and is not null    Values are processed for variable expansion   before being returned. Parameters:name - the property name. Returns:the value of the name or its replacing property,           or null if no such property exists. getTrimmed public String getTrimmed(String name,                 String defaultValue) Get the value of the name property as a trimmed String,   defaultValue if no such property exists.   See @{Configuration#getTrimmed} for more details. Parameters:name - the property name.defaultValue - the property default value. Returns:the value of the name or defaultValue                       if it is not set. getRaw public String getRaw(String name) Get the value of the name property, without doing  variable expansion.If the key is   deprecated, it returns the value of the first key which replaces   the deprecated key and is not null. Parameters:name - the property name. Returns:the value of the name property or           its replacing property and null if no such property exists. set public void set(String name,        String value) Set the value of the name property. If   name is deprecated or there is a deprecated name associated to it,  it sets the value to both names. Name will be trimmed before put into  configuration. Parameters:name - property name.value - property value. set public void set(String name,        String value,        String source) Set the value of the name property. If   name is deprecated, it also sets the value to  the keys that replace the deprecated key. Name will be trimmed before put  into configuration. Parameters:name - property name.value - property value.source - the place that this configuration value came from   (For debugging). Throws: IllegalArgumentException - when the value or name is null. unset public void unset(String name) Unset a previously set property. setIfUnset public void setIfUnset(String name,               String value) Sets a property if it is currently unset. Parameters:name - the property namevalue - the new value get public String get(String name,          String defaultValue) Get the value of the name. If the key is deprecated,  it returns the value of the first key which replaces the deprecated key  and is not null.  If no such property exists,  then defaultValue is returned. Parameters:name - property name, will be trimmed before get value.defaultValue - default value. Returns:property value, or defaultValue if the property           doesn't exist. getInt public int getInt(String name,          int defaultValue) Get the value of the name property as an int.      If no such property exists, the provided default value is returned,  or if the specified value is not a valid int,  then an error is thrown. Parameters:name - property name.defaultValue - default value. Returns:property value as an int,           or defaultValue. Throws: NumberFormatException - when the value is invalid getInts public int[] getInts(String name) Get the value of the name property as a set of comma-delimited  int values.    If no such property exists, an empty array is returned. Parameters:name - property name Returns:property value interpreted as an array of comma-delimited          int values setInt public void setInt(String name,           int value) Set the value of the name property to an int. Parameters:name - property name.value - int value of the property. getLong public long getLong(String name,            long defaultValue) Get the value of the name property as a long.    If no such property exists, the provided default value is returned,  or if the specified value is not a valid long,  then an error is thrown. Parameters:name - property name.defaultValue - default value. Returns:property value as a long,           or defaultValue. Throws: NumberFormatException - when the value is invalid getLongBytes public long getLongBytes(String name,                 long defaultValue) Get the value of the name property as a long or  human readable format. If no such property exists, the provided default  value is returned, or if the specified value is not a valid  long or human readable format, then an error is thrown. You  can use the following suffix (case insensitive): k(kilo), m(mega), g(giga),  t(tera), p(peta), e(exa) Parameters:name - property name.defaultValue - default value. Returns:property value as a long,          or defaultValue. Throws: NumberFormatException - when the value is invalid setLong public void setLong(String name,            long value) Set the value of the name property to a long. Parameters:name - property name.value - long value of the property. getFloat public float getFloat(String name,              float defaultValue) Get the value of the name property as a float.    If no such property exists, the provided default value is returned,  or if the specified value is not a valid float,  then an error is thrown. Parameters:name - property name.defaultValue - default value. Returns:property value as a float,           or defaultValue. Throws: NumberFormatException - when the value is invalid setFloat public void setFloat(String name,             float value) Set the value of the name property to a float. Parameters:name - property name.value - property value. getDouble public double getDouble(String name,                double defaultValue) Get the value of the name property as a double.    If no such property exists, the provided default value is returned,  or if the specified value is not a valid double,  then an error is thrown. Parameters:name - property name.defaultValue - default value. Returns:property value as a double,           or defaultValue. Throws: NumberFormatException - when the value is invalid setDouble public void setDouble(String name,              double value) Set the value of the name property to a double. Parameters:name - property name.value - property value. getBoolean public boolean getBoolean(String name,                  boolean defaultValue) Get the value of the name property as a boolean.    If no such property is specified, or if the specified value is not a valid  boolean, then defaultValue is returned. Parameters:name - property name.defaultValue - default value. Returns:property value as a boolean,           or defaultValue. setBoolean public void setBoolean(String name,               boolean value) Set the value of the name property to a boolean. Parameters:name - property name.value - boolean value of the property. setBooleanIfUnset public void setBooleanIfUnset(String name,                      boolean value) Set the given property, if it is currently unset. Parameters:name - property namevalue - new value setEnum public <T extends Enum<T>> void setEnum(String name,                                T value) Set the value of the name property to the given type. This  is equivalent to set(<name>, value.toString()). Parameters:name - property namevalue - new value getEnum public <T extends Enum<T>> T getEnum(String name,                             T defaultValue) Return value matching this enumerated type.  Note that the returned value is trimmed by this method. Parameters:name - Property namedefaultValue - Value returned if no mapping exists Throws: IllegalArgumentException - If mapping is illegal for the type  provided setTimeDuration public void setTimeDuration(String name,                    long value,                    TimeUnit unit) Set the value of name to the given time duration. This  is equivalent to set(<name>, value + <time suffix>). Parameters:name - Property namevalue - Time durationunit - Unit of time getTimeDuration public long getTimeDuration(String name,                    long defaultValue,                    TimeUnit unit) Return time duration in the given time unit. Valid units are encoded in  properties as suffixes: nanoseconds (ns), microseconds (us), milliseconds  (ms), seconds (s), minutes (m), hours (h), and days (d). Parameters:name - Property namedefaultValue - Value returned if no mapping exists.unit - Unit to convert the stored property, if it exists. Throws: NumberFormatException - If the property stripped of its unit is not          a number getPattern public Pattern getPattern(String name,                  Pattern defaultValue) Get the value of the name property as a Pattern.  If no such property is specified, or if the specified value is not a valid  Pattern, then DefaultValue is returned.  Note that the returned value is NOT trimmed by this method. Parameters:name - property namedefaultValue - default value Returns:property value as a compiled Pattern, or defaultValue setPattern public void setPattern(String name,               Pattern pattern) Set the given property to Pattern.  If the pattern is passed as null, sets the empty pattern which results in  further calls to getPattern(...) returning the default value. Parameters:name - property namepattern - new value getPropertySources @InterfaceStability.Unstable public String[] getPropertySources(String name) Gets information about why a property was set.  Typically this is the   path to the resource objects (file, URL, etc.) the property came from, but  it can also indicate that it was set programatically, or because of the  command line. Parameters:name - - The property name to get the source of. Returns:null - If the property or its source wasn't found. Otherwise,   returns a list of the sources of the resource.  The older sources are  the first ones in the list.  So for example if a configuration is set from  the command line, and then written out to a file that is read back in the  first entry would indicate that it was set from the command line, while  the second one would indicate the file that the new configuration was read  in from. getRange public org.apache.hadoop.conf.Configuration.IntegerRanges getRange(String name,                                                           String defaultValue) Parse the given attribute as a set of integer ranges Parameters:name - the attribute namedefaultValue - the default value if it is not set Returns:a new set of ranges from the configured value getStringCollection public Collection<String> getStringCollection(String name) Get the comma delimited values of the name property as   a collection of Strings.    If no such property is specified then empty collection is returned.    This is an optimized version of getStrings(String) Parameters:name - property name. Returns:property value as a collection of Strings. getStrings public String[] getStrings(String name) Get the comma delimited values of the name property as   an array of Strings.    If no such property is specified then null is returned. Parameters:name - property name. Returns:property value as an array of Strings,           or null. getStrings public String[] getStrings(String name,                   String... defaultValue) Get the comma delimited values of the name property as   an array of Strings.    If no such property is specified then default value is returned. Parameters:name - property name.defaultValue - The default value Returns:property value as an array of Strings,           or default value. getTrimmedStringCollection public Collection<String> getTrimmedStringCollection(String name) Get the comma delimited values of the name property as   a collection of Strings, trimmed of the leading and trailing whitespace.    If no such property is specified then empty Collection is returned. Parameters:name - property name. Returns:property value as a collection of Strings, or empty Collection getTrimmedStrings public String[] getTrimmedStrings(String name) Get the comma delimited values of the name property as   an array of Strings, trimmed of the leading and trailing whitespace.  If no such property is specified then an empty array is returned. Parameters:name - property name. Returns:property value as an array of trimmed Strings,           or empty array. getTrimmedStrings public String[] getTrimmedStrings(String name,                          String... defaultValue) Get the comma delimited values of the name property as   an array of Strings, trimmed of the leading and trailing whitespace.  If no such property is specified then default value is returned. Parameters:name - property name.defaultValue - The default value Returns:property value as an array of trimmed Strings,           or default value. setStrings public void setStrings(String name,               String... values) Set the array of string values for the name property as   as comma delimited values. Parameters:name - property name.values - The values getPassword public char[] getPassword(String name)                    throws IOException Get the value for a known password configuration element.  In order to enable the elimination of clear text passwords in config,  this method attempts to resolve the property name as an alias through  the CredentialProvider API and conditionally fallsback to config. Parameters:name - property name Returns:password Throws: IOException getPasswordFromCredentialProviders protected char[] getPasswordFromCredentialProviders(String name)                                              throws IOException Try and resolve the provided element name as a credential provider  alias. Parameters:name - alias of the provisioned credential Returns:password or null if not found Throws: IOException getPasswordFromConfig protected char[] getPasswordFromConfig(String name) Fallback to clear text passwords in configuration. Parameters:name -  Returns:clear text password or null getSocketAddr public InetSocketAddress getSocketAddr(String hostProperty,                               String addressProperty,                               String defaultAddressValue,                               int defaultPort) Get the socket address for hostProperty as a  InetSocketAddress. If hostProperty is  null, addressProperty will be used. This  is useful for cases where we want to differentiate between host  bind address and address clients should use to establish connection. Parameters:hostProperty - bind host property name.addressProperty - address property name.defaultAddressValue - the default valuedefaultPort - the default port Returns:InetSocketAddress getSocketAddr public InetSocketAddress getSocketAddr(String name,                               String defaultAddress,                               int defaultPort) Get the socket address for name property as a  InetSocketAddress. Parameters:name - property name.defaultAddress - the default valuedefaultPort - the default port Returns:InetSocketAddress setSocketAddr public void setSocketAddr(String name,                  InetSocketAddress addr) Set the socket address for the name property as  a host:port. updateConnectAddr public InetSocketAddress updateConnectAddr(String hostProperty,                                   String addressProperty,                                   String defaultAddressValue,                                   InetSocketAddress addr) Set the socket address a client can use to connect for the  name property as a host:port.  The wildcard  address is replaced with the local host's address. If the host and address  properties are configured the host component of the address will be combined  with the port component of the addr to generate the address.  This is to allow  optional control over which host name is used in multi-home bind-host  cases where a host can have multiple names Parameters:hostProperty - the bind-host configuration nameaddressProperty - the service address configuration namedefaultAddressValue - the service default address configuration valueaddr - InetSocketAddress of the service listener Returns:InetSocketAddress for clients to connect updateConnectAddr public InetSocketAddress updateConnectAddr(String name,                                   InetSocketAddress addr) Set the socket address a client can use to connect for the  name property as a host:port.  The wildcard  address is replaced with the local host's address. Parameters:name - property name.addr - InetSocketAddress of a listener to store in the given property Returns:InetSocketAddress for clients to connect getClassByName public Class<?> getClassByName(String name)                         throws ClassNotFoundException Load a class by name. Parameters:name - the class name. Returns:the class object. Throws: ClassNotFoundException - if the class is not found. getClassByNameOrNull public Class<?> getClassByNameOrNull(String name) Load a class by name, returning null rather than throwing an exception  if it couldn't be loaded. This is to avoid the overhead of creating  an exception. Parameters:name - the class name Returns:the class object, or null if it could not be found. getClasses public Class<?>[] getClasses(String name,                     Class<?>... defaultValue) Get the value of the name property  as an array of Class.  The value of the property specifies a list of comma separated class names.    If no such property is specified, then defaultValue is   returned. Parameters:name - the property name.defaultValue - default value. Returns:property value as a Class[],           or defaultValue. getClass public Class<?> getClass(String name,                 Class<?> defaultValue) Get the value of the name property as a Class.    If no such property is specified, then defaultValue is   returned. Parameters:name - the class name.defaultValue - default value. Returns:property value as a Class,           or defaultValue. getClass public <U> Class<? extends U> getClass(String name,                               Class<? extends U> defaultValue,                               Class<U> xface) Get the value of the name property as a Class  implementing the interface specified by xface.      If no such property is specified, then defaultValue is   returned.    An exception is thrown if the returned class does not implement the named  interface. Parameters:name - the class name.defaultValue - default value.xface - the interface implemented by the named class. Returns:property value as a Class,           or defaultValue. getInstances public <U> List<U> getInstances(String name,                        Class<U> xface) Get the value of the name property as a List  of objects implementing the interface specified by xface.    An exception is thrown if any of the classes does not exist, or if it does  not implement the named interface. Parameters:name - the property name.xface - the interface implemented by the classes named by         name. Returns:a List of objects implementing xface. setClass public void setClass(String name,             Class<?> theClass,             Class<?> xface) Set the value of the name property to the name of a   theClass implementing the given interface xface.    An exception is thrown if theClass does not implement the   interface xface. Parameters:name - property name.theClass - property value.xface - the interface implemented by the named class. getLocalPath public Path getLocalPath(String dirsProp,                 String path)                   throws IOException Get a local file under a directory named by dirsProp with  the given path.  If dirsProp contains multiple directories,  then one is chosen based on path's hash code.  If the selected  directory does not exist, an attempt is made to create it. Parameters:dirsProp - directory in which to locate the file.path - file-path. Returns:local file under the directory with the given path. Throws: IOException getFile public File getFile(String dirsProp,            String path)              throws IOException Get a local file name under a directory named in dirsProp with  the given path.  If dirsProp contains multiple directories,  then one is chosen based on path's hash code.  If the selected  directory does not exist, an attempt is made to create it. Parameters:dirsProp - directory in which to locate the file.path - file-path. Returns:local file under the directory with the given path. Throws: IOException getResource public URL getResource(String name) Get the URL for the named resource. Parameters:name - resource name. Returns:the url for the named resource. getConfResourceAsInputStream public InputStream getConfResourceAsInputStream(String name) Get an input stream attached to the configuration resource with the  given name. Parameters:name - configuration resource name. Returns:an input stream attached to the resource. getConfResourceAsReader public Reader getConfResourceAsReader(String name) Get a Reader attached to the configuration resource with the  given name. Parameters:name - configuration resource name. Returns:a reader attached to the resource. getFinalParameters public Set<String> getFinalParameters() Get the set of parameters marked final. Returns:final parameter set. getProps protected Properties getProps() size public int size() Return the number of keys in the configuration. Returns:number of keys in the configuration. clear public void clear() Clears all keys from the configuration. iterator public Iterator<Map.Entry<String,String>> iterator() Get an Iterator to go through the list of String   key-value pairs in the configuration. Specified by: iterator in interface Iterable<Map.Entry<String,String>> Returns:an iterator over the entries. writeXml public void writeXml(OutputStream out)               throws IOException Write out the non-default properties in this configuration to the given  OutputStream using UTF-8 encoding. Parameters:out - the output stream to write to. Throws: IOException writeXml public void writeXml(Writer out)               throws IOException Write out the non-default properties in this configuration to the given  Writer. Parameters:out - the writer to write to. Throws: IOException dumpConfiguration public static void dumpConfiguration(Configuration config,                      Writer out)                               throws IOException Writes out all the parameters and their properties (final and resource) to   the given Writer   The format of the output would be    { "properties" : [ {key1,value1,key1.isFinal,key1.resource}, {key2,value2,   key2.isFinal,key2.resource}... ] }    It does not output the parameters of the configuration object which is    loaded from an input stream. Parameters:out - the Writer to write to Throws: IOException getClassLoader public ClassLoader getClassLoader() Get the ClassLoader for this job. Returns:the correct class loader. setClassLoader public void setClassLoader(ClassLoader classLoader) Set the class loader that will be used to load the various objects. Parameters:classLoader - the new class loader. toString public String toString() Overrides: toString in class Object setQuietMode public void setQuietMode(boolean quietmode) Set the quietness-mode.     In the quiet-mode, error and informational messages might not be logged. Parameters:quietmode - true to set quiet-mode on, false               to turn it off. main public static void main(String[] args)                  throws Exception For debugging.  List non-default properties to the terminal and exit. Throws: Exception readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException getValByRegex public Map<String,String> getValByRegex(String regex) get keys matching the the regex Parameters:regex -  Returns:Map with matching keys dumpDeprecatedKeys public static void dumpDeprecatedKeys() hasWarnedDeprecation public static boolean hasWarnedDeprecation(String name) Returns whether or not a deprecated name has been warned. If the name is not  deprecated then always return false Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Configured (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Configured (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.conf Class Configured java.lang.Object org.apache.hadoop.conf.Configured All Implemented Interfaces: Configurable Direct Known Subclasses: AvroSerialization, CLI, DistCp, FileSystem, InputSampler, LogsCLI, MigrationTool, ResourceCalculatorProcessTree, Submitter, Trash, TrashPolicy, WasbFsck, WritableSerialization @InterfaceAudience.Public @InterfaceStability.Stable public class Configured extends Object implements Configurable Base class for things that may be configured with a Configuration. Constructor Summary Constructors  Constructor and Description Configured() Construct a Configured. Configured(Configuration conf) Construct a Configured. Method Summary Methods  Modifier and Type Method and Description Configuration getConf() Return the configuration used by this object. void setConf(Configuration conf) Set the configuration to be used by this object. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Configured public Configured() Construct a Configured. Configured public Configured(Configuration conf) Construct a Configured. Method Detail setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ConnectTimeoutException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ConnectTimeoutException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.net Class ConnectTimeoutException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException java.io.InterruptedIOException java.net.SocketTimeoutException org.apache.hadoop.net.ConnectTimeoutException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class ConnectTimeoutException extends SocketTimeoutException Thrown by NetUtils.connect(java.net.Socket, java.net.SocketAddress, int)  if it times out while connecting to the remote host. See Also:Serialized Form Field Summary Fields inherited from class java.io.InterruptedIOException bytesTransferred Constructor Summary Constructors  Constructor and Description ConnectTimeoutException(String msg)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ConnectTimeoutException public ConnectTimeoutException(String msg) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Consts (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Consts (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class Consts java.lang.Object org.apache.hadoop.record.compiler.Consts Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class Consts extends Object const definitions for Record I/O compiler Field Summary Fields  Modifier and Type Field and Description static String RECORD_INPUT Deprecated.    static String RECORD_OUTPUT Deprecated.    static String RIO_PREFIX Deprecated.    static String RTI_FILTER Deprecated.    static String RTI_FILTER_FIELDS Deprecated.    static String RTI_VAR Deprecated.    static String TAG Deprecated.    Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail RIO_PREFIX public static final String RIO_PREFIX Deprecated.  See Also:Constant Field Values RTI_VAR public static final String RTI_VAR Deprecated.  See Also:Constant Field Values RTI_FILTER public static final String RTI_FILTER Deprecated.  See Also:Constant Field Values RTI_FILTER_FIELDS public static final String RTI_FILTER_FIELDS Deprecated.  See Also:Constant Field Values RECORD_OUTPUT public static final String RECORD_OUTPUT Deprecated.  See Also:Constant Field Values RECORD_INPUT public static final String RECORD_INPUT Deprecated.  See Also:Constant Field Values TAG public static final String TAG Deprecated.  See Also:Constant Field Values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Container (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Container (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class Container java.lang.Object org.apache.hadoop.yarn.api.records.Container All Implemented Interfaces: Comparable<Container> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class Container extends Object implements Comparable<Container> Container represents an allocated resource in the cluster.    The ResourceManager is the sole authority to allocate any  Container to applications. The allocated Container  is always on a single node and has a unique ContainerId. It has  a specific amount of Resource allocated.    It includes details such as:      ContainerId for the container, which is globally unique.          NodeId of the node on which it is allocated.        HTTP uri of the node.    Resource allocated to the container.    Priority at which the container was allocated.          Container Token of the container, used to securely verify      authenticity of the allocation.          Typically, an ApplicationMaster receives the Container  from the ResourceManager during resource-negotiation and then  talks to the NodeManager to start/stop containers. See Also:ApplicationMasterProtocol.allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest),  ContainerManagementProtocol.startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest),  ContainerManagementProtocol.stopContainers(org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest) Constructor Summary Constructors  Constructor and Description Container()  Method Summary Methods  Modifier and Type Method and Description abstract Token getContainerToken() Get the ContainerToken for the container. abstract ContainerId getId() Get the globally unique identifier for the container. abstract String getNodeHttpAddress() Get the http uri of the node on which the container is allocated. abstract NodeId getNodeId() Get the identifier of the node on which the container is allocated. abstract Priority getPriority() Get the Priority at which the Container was  allocated. abstract Resource getResource() Get the Resource allocated to the container. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface java.lang.Comparable compareTo Constructor Detail Container public Container() Method Detail getId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ContainerId getId() Get the globally unique identifier for the container. Returns:globally unique identifier for the container getNodeId @InterfaceAudience.Public @InterfaceStability.Stable public abstract NodeId getNodeId() Get the identifier of the node on which the container is allocated. Returns:identifier of the node on which the container is allocated getNodeHttpAddress @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getNodeHttpAddress() Get the http uri of the node on which the container is allocated. Returns:http uri of the node on which the container is allocated getResource @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getResource() Get the Resource allocated to the container. Returns:Resource allocated to the container getPriority @InterfaceAudience.Public @InterfaceStability.Stable public abstract Priority getPriority() Get the Priority at which the Container was  allocated. Returns:Priority at which the Container was          allocated getContainerToken @InterfaceAudience.Public @InterfaceStability.Stable public abstract Token getContainerToken() Get the ContainerToken for the container.  ContainerToken is the security token used by the framework  to verify authenticity of any Container.  The ResourceManager, on container allocation provides a  secure token which is verified by the NodeManager on  container launch.  Applications do not need to care about ContainerToken, they  are transparently handled by the framework - the allocated  Container includes the ContainerToken. Returns:ContainerToken for the containerSee Also:ApplicationMasterProtocol.allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest),  ContainerManagementProtocol.startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerExitStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerExitStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ContainerExitStatus java.lang.Object org.apache.hadoop.yarn.api.records.ContainerExitStatus @InterfaceAudience.Public @InterfaceStability.Unstable public class ContainerExitStatus extends Object Container exit statuses indicating special exit circumstances. Field Summary Fields  Modifier and Type Field and Description static int ABORTED Containers killed by the framework, either due to being released by  the application or being 'lost' due to node failures etc. static int DISKS_FAILED When threshold number of the nodemanager-local-directories or  threshold number of the nodemanager-log-directories become bad. static int INVALID  static int KILLED_AFTER_APP_COMPLETION Container was terminated after the application finished. static int KILLED_BY_APPMASTER Container was terminated by stop request by the app master. static int KILLED_BY_RESOURCEMANAGER Container was terminated by the resource manager. static int KILLED_EXCEEDED_PMEM Container terminated because of exceeding allocated physical memory. static int KILLED_EXCEEDED_VMEM Container terminated because of exceeding allocated virtual memory. static int PREEMPTED Containers preempted by the framework. static int SUCCESS  Constructor Summary Constructors  Constructor and Description ContainerExitStatus()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail SUCCESS public static final int SUCCESS See Also:Constant Field Values INVALID public static final int INVALID See Also:Constant Field Values ABORTED public static final int ABORTED Containers killed by the framework, either due to being released by  the application or being 'lost' due to node failures etc. See Also:Constant Field Values DISKS_FAILED public static final int DISKS_FAILED When threshold number of the nodemanager-local-directories or  threshold number of the nodemanager-log-directories become bad. See Also:Constant Field Values PREEMPTED public static final int PREEMPTED Containers preempted by the framework. See Also:Constant Field Values KILLED_EXCEEDED_VMEM public static final int KILLED_EXCEEDED_VMEM Container terminated because of exceeding allocated virtual memory. See Also:Constant Field Values KILLED_EXCEEDED_PMEM public static final int KILLED_EXCEEDED_PMEM Container terminated because of exceeding allocated physical memory. See Also:Constant Field Values KILLED_BY_APPMASTER public static final int KILLED_BY_APPMASTER Container was terminated by stop request by the app master. See Also:Constant Field Values KILLED_BY_RESOURCEMANAGER public static final int KILLED_BY_RESOURCEMANAGER Container was terminated by the resource manager. See Also:Constant Field Values KILLED_AFTER_APP_COMPLETION public static final int KILLED_AFTER_APP_COMPLETION Container was terminated after the application finished. See Also:Constant Field Values Constructor Detail ContainerExitStatus public ContainerExitStatus() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerId (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerId (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ContainerId java.lang.Object org.apache.hadoop.yarn.api.records.ContainerId All Implemented Interfaces: Comparable<ContainerId> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ContainerId extends Object implements Comparable<ContainerId> ContainerId represents a globally unique identifier  for a Container in the cluster. Field Summary Fields  Modifier and Type Field and Description static long CONTAINER_ID_BITMASK  Constructor Summary Constructors  Constructor and Description ContainerId()  Method Summary Methods  Modifier and Type Method and Description protected abstract void build()  int compareTo(ContainerId other)  boolean equals(Object obj)  static ContainerId fromString(String containerIdStr)  abstract ApplicationAttemptId getApplicationAttemptId() Get the ApplicationAttemptId of the application to which the  Container was assigned. abstract long getContainerId() Get the identifier of the ContainerId. abstract int getId() Deprecated.  int hashCode()  String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail CONTAINER_ID_BITMASK public static final long CONTAINER_ID_BITMASK See Also:Constant Field Values Constructor Detail ContainerId public ContainerId() Method Detail getApplicationAttemptId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationAttemptId getApplicationAttemptId() Get the ApplicationAttemptId of the application to which the  Container was assigned.    Note: If containers are kept alive across application attempts via  ApplicationSubmissionContext.setKeepContainersAcrossApplicationAttempts(boolean)  the ContainerId does not necessarily contain the current  running application attempt's ApplicationAttemptId This  container can be allocated by previously exited application attempt and  managed by the current running attempt thus have the previous application  attempt's ApplicationAttemptId.   Returns:ApplicationAttemptId of the application to which the          Container was assigned getId @InterfaceAudience.Public @Deprecated @InterfaceStability.Stable public abstract int getId() Deprecated.  Get the lower 32 bits of identifier of the ContainerId,  which doesn't include epoch. Note that this method will be marked as  deprecated, so please use getContainerId instead. Returns:lower 32 bits of identifier of the ContainerId getContainerId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getContainerId() Get the identifier of the ContainerId. Upper 24 bits are  reserved as epoch of cluster, and lower 40 bits are reserved as  sequential number of containers. Returns:identifier of the ContainerId hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object compareTo public int compareTo(ContainerId other) Specified by: compareTo in interface Comparable<ContainerId> toString public String toString() Overrides: toString in class Object Returns:A string representation of containerId. The format is  container_e*epoch*_*clusterTimestamp*_*appId*_*attemptId*_*containerId*  when epoch is larger than 0  (e.g. container_e17_1410901177871_0001_01_000005).  *epoch* is increased when RM restarts or fails over.  When epoch is 0, epoch is omitted  (e.g. container_1410901177871_0001_01_000005). fromString @InterfaceAudience.Public @InterfaceStability.Unstable public static ContainerId fromString(String containerIdStr) build protected abstract void build() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerLaunchContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerLaunchContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ContainerLaunchContext java.lang.Object org.apache.hadoop.yarn.api.records.ContainerLaunchContext @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ContainerLaunchContext extends Object ContainerLaunchContext represents all of the information  needed by the NodeManager to launch a container.    It includes details such as:      ContainerId of the container.    Resource allocated to the container.    User to whom the container is allocated.    Security tokens (if security is enabled).          LocalResource necessary for running the container such      as binaries, jar, shared-objects, side-files etc.        Optional, application-specific binary service data.    Environment variables for the launched process.    Command to launch the container.   See Also:ContainerManagementProtocol.startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest) Constructor Summary Constructors  Constructor and Description ContainerLaunchContext()  Method Summary Methods  Modifier and Type Method and Description abstract Map<ApplicationAccessType,String> getApplicationACLs() Get the ApplicationACLs for the application. abstract List<String> getCommands() Get the list of commands for launching the container. abstract Map<String,String> getEnvironment() Get environment variables for the container. abstract Map<String,LocalResource> getLocalResources() Get LocalResource required by the container. abstract Map<String,ByteBuffer> getServiceData()  Get application-specific binary service data. abstract ByteBuffer getTokens() Get all the tokens needed by this container. static ContainerLaunchContext newInstance(Map<String,LocalResource> localResources,                       Map<String,String> environment,                       List<String> commands,                       Map<String,ByteBuffer> serviceData,                       ByteBuffer tokens,                       Map<ApplicationAccessType,String> acls)  abstract void setApplicationACLs(Map<ApplicationAccessType,String> acls) Set the ApplicationACLs for the application. abstract void setCommands(List<String> commands) Add the list of commands for launching the container. abstract void setEnvironment(Map<String,String> environment) Add environment variables for the container. abstract void setLocalResources(Map<String,LocalResource> localResources) Set LocalResource required by the container. abstract void setServiceData(Map<String,ByteBuffer> serviceData)  Set application-specific binary service data. abstract void setTokens(ByteBuffer tokens) Set security tokens needed by this container. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ContainerLaunchContext public ContainerLaunchContext() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ContainerLaunchContext newInstance(Map<String,LocalResource> localResources,                                                                                     Map<String,String> environment,                                                                                     List<String> commands,                                                                                     Map<String,ByteBuffer> serviceData,                                                                                     ByteBuffer tokens,                                                                                     Map<ApplicationAccessType,String> acls) getTokens @InterfaceAudience.Public @InterfaceStability.Stable public abstract ByteBuffer getTokens() Get all the tokens needed by this container. It may include file-system  tokens, ApplicationMaster related tokens if this container is an  ApplicationMaster or framework level tokens needed by this container to  communicate to various services in a secure manner. Returns:tokens needed by this container. setTokens @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setTokens(ByteBuffer tokens) Set security tokens needed by this container. Parameters:tokens - security tokens getLocalResources @InterfaceAudience.Public @InterfaceStability.Stable public abstract Map<String,LocalResource> getLocalResources() Get LocalResource required by the container. Returns:all LocalResource required by the container setLocalResources @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setLocalResources(Map<String,LocalResource> localResources) Set LocalResource required by the container. All pre-existing  Map entries are cleared before adding the new Map Parameters:localResources - LocalResource required by the container getServiceData @InterfaceAudience.Public @InterfaceStability.Stable public abstract Map<String,ByteBuffer> getServiceData()  Get application-specific binary service data. This is a map keyed  by the name of each AuxiliaryService that is configured on a  NodeManager and value correspond to the application specific data targeted  for the keyed AuxiliaryService.        This will be used to initialize this application on the specific  AuxiliaryService running on the NodeManager by calling  AuxiliaryService.initializeApplication(ApplicationInitializationContext)   Returns:application-specific binary service data setServiceData @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setServiceData(Map<String,ByteBuffer> serviceData)  Set application-specific binary service data. This is a map keyed  by the name of each AuxiliaryService that is configured on a  NodeManager and value correspond to the application specific data targeted  for the keyed AuxiliaryService. All pre-existing Map entries are  preserved.   Parameters:serviceData - application-specific binary service data getEnvironment @InterfaceAudience.Public @InterfaceStability.Stable public abstract Map<String,String> getEnvironment() Get environment variables for the container. Returns:environment variables for the container setEnvironment @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setEnvironment(Map<String,String> environment) Add environment variables for the container. All pre-existing Map  entries are cleared before adding the new Map Parameters:environment - environment variables for the container getCommands @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<String> getCommands() Get the list of commands for launching the container. Returns:the list of commands for launching the container setCommands @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setCommands(List<String> commands) Add the list of commands for launching the container. All  pre-existing List entries are cleared before adding the new List Parameters:commands - the list of commands for launching the container getApplicationACLs @InterfaceAudience.Public @InterfaceStability.Stable public abstract Map<ApplicationAccessType,String> getApplicationACLs() Get the ApplicationACLs for the application. Returns:all the ApplicationACLs setApplicationACLs @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setApplicationACLs(Map<ApplicationAccessType,String> acls) Set the ApplicationACLs for the application. All pre-existing  Map entries are cleared before adding the new Map Parameters:acls - ApplicationACLs for the application Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerLogAppender (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerLogAppender (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn Class ContainerLogAppender java.lang.Object org.apache.log4j.AppenderSkeleton org.apache.log4j.WriterAppender org.apache.log4j.FileAppender org.apache.hadoop.yarn.ContainerLogAppender All Implemented Interfaces: Flushable, org.apache.log4j.Appender, org.apache.log4j.spi.OptionHandler @InterfaceAudience.Public @InterfaceStability.Unstable public class ContainerLogAppender extends org.apache.log4j.FileAppender implements Flushable A simple log4j-appender for container's logs. Field Summary Fields inherited from class org.apache.log4j.FileAppender bufferedIO, bufferSize, fileAppend, fileName Fields inherited from class org.apache.log4j.WriterAppender encoding, immediateFlush, qw Fields inherited from class org.apache.log4j.AppenderSkeleton closed, errorHandler, headFilter, layout, name, tailFilter, threshold Constructor Summary Constructors  Constructor and Description ContainerLogAppender()  Method Summary Methods  Modifier and Type Method and Description void activateOptions()  void append(org.apache.log4j.spi.LoggingEvent event)  void close()  void flush()  String getContainerLogDir() Getter/Setter methods for log4j. String getContainerLogFile()  long getTotalLogFileSize()  void setContainerLogDir(String containerLogDir)  void setContainerLogFile(String containerLogFile)  void setTotalLogFileSize(long logSize)  Methods inherited from class org.apache.log4j.FileAppender closeFile, getAppend, getBufferedIO, getBufferSize, getFile, reset, setAppend, setBufferedIO, setBufferSize, setFile, setFile, setQWForFiles Methods inherited from class org.apache.log4j.WriterAppender checkEntryConditions, closeWriter, createWriter, getEncoding, getImmediateFlush, requiresLayout, setEncoding, setErrorHandler, setImmediateFlush, setWriter, shouldFlush, subAppend, writeFooter, writeHeader Methods inherited from class org.apache.log4j.AppenderSkeleton addFilter, clearFilters, doAppend, finalize, getErrorHandler, getFilter, getFirstFilter, getLayout, getName, getThreshold, isAsSevereAsThreshold, setLayout, setName, setThreshold Methods inherited from class java.lang.Object clone, equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ContainerLogAppender public ContainerLogAppender() Method Detail activateOptions public void activateOptions() Specified by: activateOptions in interface org.apache.log4j.spi.OptionHandler Overrides: activateOptions in class org.apache.log4j.FileAppender append public void append(org.apache.log4j.spi.LoggingEvent event) Overrides: append in class org.apache.log4j.WriterAppender flush public void flush() Specified by: flush in interface Flushable close public void close() Specified by: close in interface org.apache.log4j.Appender Overrides: close in class org.apache.log4j.WriterAppender getContainerLogDir public String getContainerLogDir() Getter/Setter methods for log4j. setContainerLogDir public void setContainerLogDir(String containerLogDir) getContainerLogFile public String getContainerLogFile() setContainerLogFile public void setContainerLogFile(String containerLogFile) getTotalLogFileSize public long getTotalLogFileSize() setTotalLogFileSize public void setTotalLogFileSize(long logSize) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerManagementProtocol (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerManagementProtocol (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api Interface ContainerManagementProtocol @InterfaceAudience.Public @InterfaceStability.Stable public interface ContainerManagementProtocol The protocol between an ApplicationMaster and a   NodeManager to start/stop containers and to get status  of running containers.    If security is enabled the NodeManager verifies that the  ApplicationMaster has truly been allocated the container  by the ResourceManager and also verifies all interactions such   as stopping the container or obtaining status information for the container.   Method Summary Methods  Modifier and Type Method and Description GetContainerStatusesResponse getContainerStatuses(GetContainerStatusesRequest request)  The API used by the ApplicationMaster to request for current  statuses of Containers from the NodeManager. StartContainersResponse startContainers(StartContainersRequest request)  The ApplicationMaster provides a list of  StartContainerRequests to a NodeManager to  start Containers allocated to it using this interface. StopContainersResponse stopContainers(StopContainersRequest request)  The ApplicationMaster requests a NodeManager to  stop a list of Containers allocated to it using this  interface. Method Detail startContainers @InterfaceAudience.Public @InterfaceStability.Stable StartContainersResponse startContainers(StartContainersRequest request)                                         throws YarnException,                                                IOException  The ApplicationMaster provides a list of  StartContainerRequests to a NodeManager to  start Containers allocated to it using this interface.        The ApplicationMaster has to provide details such as allocated  resource capability, security tokens (if enabled), command to be executed  to start the container, environment for the process, necessary  binaries/jar/shared-objects etc. via the ContainerLaunchContext in  the StartContainerRequest.        The NodeManager sends a response via  StartContainersResponse which includes a list of  Containers of successfully launched Containers, a  containerId-to-exception map for each failed StartContainerRequest in  which the exception indicates errors from per container and a  allServicesMetaData map between the names of auxiliary services and their  corresponding meta-data. Note: None-container-specific exceptions will  still be thrown by the API method itself.      The ApplicationMaster can use  getContainerStatuses(GetContainerStatusesRequest) to get updated  statuses of the to-be-launched or launched containers.   Parameters:request - request to start a list of containers Returns:response including conatinerIds of all successfully launched          containers, a containerId-to-exception map for failed requests and          a allServicesMetaData map. Throws: YarnException IOException org.apache.hadoop.yarn.exceptions.NMNotYetReadyException - This exception is thrown when NM starts from scratch but has not            yet connected with RM. stopContainers @InterfaceAudience.Public @InterfaceStability.Stable StopContainersResponse stopContainers(StopContainersRequest request)                                       throws YarnException,                                              IOException  The ApplicationMaster requests a NodeManager to  stop a list of Containers allocated to it using this  interface.        The ApplicationMaster sends a StopContainersRequest  which includes the ContainerIds of the containers to be stopped.        The NodeManager sends a response via  StopContainersResponse which includes a list of ContainerId  s of successfully stopped containers, a containerId-to-exception map for  each failed request in which the exception indicates errors from per  container. Note: None-container-specific exceptions will still be thrown by  the API method itself. ApplicationMaster can use  getContainerStatuses(GetContainerStatusesRequest) to get updated  statuses of the containers.   Parameters:request - request to stop a list of containers Returns:response which includes a list of containerIds of successfully          stopped containers, a containerId-to-exception map for failed          requests. Throws: YarnException IOException getContainerStatuses @InterfaceAudience.Public @InterfaceStability.Stable GetContainerStatusesResponse getContainerStatuses(GetContainerStatusesRequest request)                                                   throws YarnException,                                                          IOException  The API used by the ApplicationMaster to request for current  statuses of Containers from the NodeManager.        The ApplicationMaster sends a  GetContainerStatusesRequest which includes the ContainerIds  of all containers whose statuses are needed.        The NodeManager responds with  GetContainerStatusesResponse which includes a list of  ContainerStatus of the successfully queried containers and a  containerId-to-exception map for each failed request in which the exception  indicates errors from per container. Note: None-container-specific  exceptions will still be thrown by the API method itself.   Parameters:request - request to get ContainerStatuses of containers with           the specified ContainerIds Returns:response containing the list of ContainerStatus of the          successfully queried containers and a containerId-to-exception map          for failed requests. Throws: YarnException IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerManagerSecurityInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerManagerSecurityInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security Class ContainerManagerSecurityInfo java.lang.Object org.apache.hadoop.security.SecurityInfo org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo @InterfaceAudience.Public @InterfaceStability.Stable public class ContainerManagerSecurityInfo extends org.apache.hadoop.security.SecurityInfo Constructor Summary Constructors  Constructor and Description ContainerManagerSecurityInfo()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                               Configuration conf) Get the KerberosInfo for a given protocol. org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                         Configuration conf) Get the TokenInfo for a given protocol. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ContainerManagerSecurityInfo public ContainerManagerSecurityInfo() Method Detail getKerberosInfo public org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the KerberosInfo for a given protocol. Specified by: getKerberosInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration Returns:KerberosInfo getTokenInfo public org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the TokenInfo for a given protocol. Specified by: getTokenInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration object. Returns:TokenInfo instance Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerNotFoundException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerNotFoundException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.exceptions Class ContainerNotFoundException java.lang.Object java.lang.Throwable java.lang.Exception org.apache.hadoop.yarn.exceptions.YarnException org.apache.hadoop.yarn.exceptions.ContainerNotFoundException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Unstable public class ContainerNotFoundException extends YarnException This exception is thrown on  (GetContainerReportRequest)  API when the container doesn't exist in AHS See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ContainerNotFoundException(String message)  ContainerNotFoundException(String message,                                                     Throwable cause)  ContainerNotFoundException(Throwable cause)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ContainerNotFoundException public ContainerNotFoundException(Throwable cause) ContainerNotFoundException public ContainerNotFoundException(String message) ContainerNotFoundException public ContainerNotFoundException(String message,                           Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerReport (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerReport (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ContainerReport java.lang.Object org.apache.hadoop.yarn.api.records.ContainerReport @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ContainerReport extends Object ContainerReport is a report of an container.    It includes details such as:      ContainerId of the container.    Allocated Resources to the container.    Assigned Node id.    Assigned Priority.    Creation Time.    Finish Time.    Container Exit Status.    ContainerState of the container.    Diagnostic information in case of errors.    Log URL.    nodeHttpAddress   Constructor Summary Constructors  Constructor and Description ContainerReport()  Method Summary Methods  Modifier and Type Method and Description abstract Resource getAllocatedResource() Get the allocated Resource of the container. abstract NodeId getAssignedNode() Get the allocated NodeId where container is running. abstract int getContainerExitStatus() Get the final exit status of the container. abstract ContainerId getContainerId() Get the ContainerId of the container. abstract ContainerState getContainerState() Get the final ContainerState of the container. abstract long getCreationTime() Get the creation time of the container. abstract String getDiagnosticsInfo() Get the DiagnosticsInfo of the container. abstract long getFinishTime() Get the Finish time of the container. abstract String getLogUrl() Get the LogURL of the container. abstract String getNodeHttpAddress() Get the Node Http address of the container abstract Priority getPriority() Get the allocated Priority of the container. abstract void setAllocatedResource(Resource resource)  abstract void setAssignedNode(NodeId nodeId)  abstract void setContainerExitStatus(int containerExitStatus)  abstract void setContainerId(ContainerId containerId)  abstract void setContainerState(ContainerState containerState)  abstract void setCreationTime(long creationTime)  abstract void setDiagnosticsInfo(String diagnosticsInfo)  abstract void setFinishTime(long finishTime)  abstract void setLogUrl(String logUrl)  abstract void setPriority(Priority priority)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ContainerReport public ContainerReport() Method Detail getContainerId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ContainerId getContainerId() Get the ContainerId of the container. Returns:ContainerId of the container. setContainerId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setContainerId(ContainerId containerId) getAllocatedResource @InterfaceAudience.Public @InterfaceStability.Unstable public abstract Resource getAllocatedResource() Get the allocated Resource of the container. Returns:allocated Resource of the container. setAllocatedResource @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setAllocatedResource(Resource resource) getAssignedNode @InterfaceAudience.Public @InterfaceStability.Unstable public abstract NodeId getAssignedNode() Get the allocated NodeId where container is running. Returns:allocated NodeId where container is running. setAssignedNode @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setAssignedNode(NodeId nodeId) getPriority @InterfaceAudience.Public @InterfaceStability.Unstable public abstract Priority getPriority() Get the allocated Priority of the container. Returns:allocated Priority of the container. setPriority @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setPriority(Priority priority) getCreationTime @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getCreationTime() Get the creation time of the container. Returns:creation time of the container setCreationTime @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setCreationTime(long creationTime) getFinishTime @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getFinishTime() Get the Finish time of the container. Returns:Finish time of the container setFinishTime @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setFinishTime(long finishTime) getDiagnosticsInfo @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getDiagnosticsInfo() Get the DiagnosticsInfo of the container. Returns:DiagnosticsInfo of the container setDiagnosticsInfo @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setDiagnosticsInfo(String diagnosticsInfo) getLogUrl @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getLogUrl() Get the LogURL of the container. Returns:LogURL of the container setLogUrl @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setLogUrl(String logUrl) getContainerState @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ContainerState getContainerState() Get the final ContainerState of the container. Returns:final ContainerState of the container. setContainerState @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setContainerState(ContainerState containerState) getContainerExitStatus @InterfaceAudience.Public @InterfaceStability.Unstable public abstract int getContainerExitStatus() Get the final exit status of the container. Returns:final exit status of the container. setContainerExitStatus @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setContainerExitStatus(int containerExitStatus) getNodeHttpAddress @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getNodeHttpAddress() Get the Node Http address of the container Returns:the node http address of the container Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerResourceIncreaseRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerResourceIncreaseRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ContainerResourceIncreaseRequest java.lang.Object org.apache.hadoop.yarn.api.records.ContainerResourceIncreaseRequest @InterfaceAudience.Public public abstract class ContainerResourceIncreaseRequest extends Object Used by Application Master, send a container resource increase request to  Resource Manager Constructor Summary Constructors  Constructor and Description ContainerResourceIncreaseRequest()  Method Summary Methods  Modifier and Type Method and Description boolean equals(Object other)  abstract Resource getCapability()  abstract ContainerId getContainerId()  int hashCode()  static ContainerResourceIncreaseRequest newInstance(ContainerId existingContainerId,                       Resource targetCapability)  abstract void setCapability(Resource capability)  abstract void setContainerId(ContainerId containerId)  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail ContainerResourceIncreaseRequest public ContainerResourceIncreaseRequest() Method Detail newInstance @InterfaceAudience.Public public static ContainerResourceIncreaseRequest newInstance(ContainerId existingContainerId,                                                                     Resource targetCapability) getContainerId @InterfaceAudience.Public public abstract ContainerId getContainerId() setContainerId @InterfaceAudience.Public public abstract void setContainerId(ContainerId containerId) getCapability @InterfaceAudience.Public public abstract Resource getCapability() setCapability @InterfaceAudience.Public public abstract void setCapability(Resource capability) hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object other) Overrides: equals in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerRollingLogAppender (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerRollingLogAppender (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn Class ContainerRollingLogAppender java.lang.Object org.apache.log4j.AppenderSkeleton org.apache.log4j.WriterAppender org.apache.log4j.FileAppender org.apache.log4j.RollingFileAppender org.apache.hadoop.yarn.ContainerRollingLogAppender All Implemented Interfaces: Flushable, org.apache.log4j.Appender, org.apache.log4j.spi.OptionHandler @InterfaceAudience.Public @InterfaceStability.Unstable public class ContainerRollingLogAppender extends org.apache.log4j.RollingFileAppender implements Flushable A simple log4j-appender for container's logs. Field Summary Fields inherited from class org.apache.log4j.RollingFileAppender maxBackupIndex, maxFileSize Fields inherited from class org.apache.log4j.FileAppender bufferedIO, bufferSize, fileAppend, fileName Fields inherited from class org.apache.log4j.WriterAppender encoding, immediateFlush, qw Fields inherited from class org.apache.log4j.AppenderSkeleton closed, errorHandler, headFilter, layout, name, tailFilter, threshold Constructor Summary Constructors  Constructor and Description ContainerRollingLogAppender()  Method Summary Methods  Modifier and Type Method and Description void activateOptions()  void flush()  String getContainerLogDir() Getter/Setter methods for log4j. String getContainerLogFile()  void setContainerLogDir(String containerLogDir)  void setContainerLogFile(String containerLogFile)  Methods inherited from class org.apache.log4j.RollingFileAppender getMaxBackupIndex, getMaximumFileSize, rollOver, setFile, setMaxBackupIndex, setMaxFileSize, setMaximumFileSize, setQWForFiles, subAppend Methods inherited from class org.apache.log4j.FileAppender closeFile, getAppend, getBufferedIO, getBufferSize, getFile, reset, setAppend, setBufferedIO, setBufferSize, setFile Methods inherited from class org.apache.log4j.WriterAppender append, checkEntryConditions, close, closeWriter, createWriter, getEncoding, getImmediateFlush, requiresLayout, setEncoding, setErrorHandler, setImmediateFlush, setWriter, shouldFlush, writeFooter, writeHeader Methods inherited from class org.apache.log4j.AppenderSkeleton addFilter, clearFilters, doAppend, finalize, getErrorHandler, getFilter, getFirstFilter, getLayout, getName, getThreshold, isAsSevereAsThreshold, setLayout, setName, setThreshold Methods inherited from class java.lang.Object clone, equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ContainerRollingLogAppender public ContainerRollingLogAppender() Method Detail activateOptions public void activateOptions() Specified by: activateOptions in interface org.apache.log4j.spi.OptionHandler Overrides: activateOptions in class org.apache.log4j.FileAppender flush public void flush() Specified by: flush in interface Flushable getContainerLogDir public String getContainerLogDir() Getter/Setter methods for log4j. setContainerLogDir public void setContainerLogDir(String containerLogDir) getContainerLogFile public String getContainerLogFile() setContainerLogFile public void setContainerLogFile(String containerLogFile) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerState (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerState (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum ContainerState java.lang.Object java.lang.Enum<ContainerState> org.apache.hadoop.yarn.api.records.ContainerState All Implemented Interfaces: Serializable, Comparable<ContainerState> @InterfaceAudience.Public @InterfaceStability.Stable public enum ContainerState extends Enum<ContainerState> State of a Container. Enum Constant Summary Enum Constants  Enum Constant and Description COMPLETE Completed container NEW New container RUNNING Running container Method Summary Methods  Modifier and Type Method and Description static ContainerState valueOf(String name) Returns the enum constant of this type with the specified name. static ContainerState[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail NEW public static final ContainerState NEW New container RUNNING public static final ContainerState RUNNING Running container COMPLETE public static final ContainerState COMPLETE Completed container Method Detail values public static ContainerState[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (ContainerState c : ContainerState.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static ContainerState valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ContainerStatus java.lang.Object org.apache.hadoop.yarn.api.records.ContainerStatus @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ContainerStatus extends Object ContainerStatus represents the current status of a  Container.    It provides details such as:      ContainerId of the container.    ContainerState of the container.    Exit status of a completed container.    Diagnostic message for a failed container.   Constructor Summary Constructors  Constructor and Description ContainerStatus()  Method Summary Methods  Modifier and Type Method and Description abstract ContainerId getContainerId() Get the ContainerId of the container. abstract String getDiagnostics() Get diagnostic messages for failed containers. abstract int getExitStatus() Get the exit status for the container. abstract ContainerState getState() Get the ContainerState of the container. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ContainerStatus public ContainerStatus() Method Detail getContainerId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ContainerId getContainerId() Get the ContainerId of the container. Returns:ContainerId of the container getState @InterfaceAudience.Public @InterfaceStability.Stable public abstract ContainerState getState() Get the ContainerState of the container. Returns:ContainerState of the container getExitStatus @InterfaceAudience.Public @InterfaceStability.Unstable public abstract int getExitStatus() Get the exit status for the container.     Note: This is valid only for completed containers i.e. containers  with state ContainerState.COMPLETE.   Otherwise, it returns an ContainerExitStatus.INVALID.      Containers killed by the framework, either due to being released by  the application or being 'lost' due to node failures etc. have a special  exit code of ContainerExitStatus.ABORTED.    When threshold number of the nodemanager-local-directories or  threshold number of the nodemanager-log-directories become bad, then  container is not launched and is exited with ContainersExitStatus.DISKS_FAILED.   Returns:exit status for the container getDiagnostics @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getDiagnostics() Get diagnostic messages for failed containers. Returns:diagnostic messages for failed containers Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerTokenIdentifier (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerTokenIdentifier (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security Class ContainerTokenIdentifier java.lang.Object org.apache.hadoop.security.token.TokenIdentifier org.apache.hadoop.yarn.security.ContainerTokenIdentifier All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class ContainerTokenIdentifier extends org.apache.hadoop.security.token.TokenIdentifier TokenIdentifier for a container. Encodes ContainerId,  Resource needed by the container and the target NMs host-address. Field Summary Fields  Modifier and Type Field and Description static Text KIND  Constructor Summary Constructors  Constructor and Description ContainerTokenIdentifier() Default constructor needed by RPC layer/SecretManager. ContainerTokenIdentifier(ContainerId containerID,                                                 String hostName,                                                 String appSubmitter,                                                 Resource r,                                                 long expiryTimeStamp,                                                 int masterKeyId,                                                 long rmIdentifier,                                                 Priority priority,                                                 long creationTime)  ContainerTokenIdentifier(ContainerId containerID,                                                 String hostName,                                                 String appSubmitter,                                                 Resource r,                                                 long expiryTimeStamp,                                                 int masterKeyId,                                                 long rmIdentifier,                                                 Priority priority,                                                 long creationTime,                                                 LogAggregationContext logAggregationContext)  Method Summary Methods  Modifier and Type Method and Description boolean equals(Object other)  String getApplicationSubmitter()  ContainerId getContainerID()  long getCreationTime()  long getExpiryTimeStamp()  Text getKind() Get the token kind LogAggregationContext getLogAggregationContext()  int getMasterKeyId()  String getNmHostAddress()  Priority getPriority()  org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.ContainerTokenIdentifierProto getProto()  Resource getResource()  long getRMIdentifier() Get the RMIdentifier of RM in which containers are allocated org.apache.hadoop.security.UserGroupInformation getUser() Get the Ugi with the username encoded in the token identifier int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.security.token.TokenIdentifier getBytes, getTrackingId Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail KIND public static final Text KIND Constructor Detail ContainerTokenIdentifier public ContainerTokenIdentifier(ContainerId containerID,                         String hostName,                         String appSubmitter,                         Resource r,                         long expiryTimeStamp,                         int masterKeyId,                         long rmIdentifier,                         Priority priority,                         long creationTime) ContainerTokenIdentifier public ContainerTokenIdentifier(ContainerId containerID,                         String hostName,                         String appSubmitter,                         Resource r,                         long expiryTimeStamp,                         int masterKeyId,                         long rmIdentifier,                         Priority priority,                         long creationTime,                         LogAggregationContext logAggregationContext) ContainerTokenIdentifier public ContainerTokenIdentifier() Default constructor needed by RPC layer/SecretManager. Method Detail getContainerID public ContainerId getContainerID() getApplicationSubmitter public String getApplicationSubmitter() getNmHostAddress public String getNmHostAddress() getResource public Resource getResource() getExpiryTimeStamp public long getExpiryTimeStamp() getMasterKeyId public int getMasterKeyId() getPriority public Priority getPriority() getCreationTime public long getCreationTime() getRMIdentifier public long getRMIdentifier() Get the RMIdentifier of RM in which containers are allocated Returns:RMIdentifier getProto public org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.ContainerTokenIdentifierProto getProto() getLogAggregationContext public LogAggregationContext getLogAggregationContext() write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Parameters:in - DataInput to deseriablize this object from. Throws: IOException getKind public Text getKind() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the token kind Specified by: getKind in class org.apache.hadoop.security.token.TokenIdentifier Returns:the kind of the token getUser public org.apache.hadoop.security.UserGroupInformation getUser() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the Ugi with the username encoded in the token identifier Specified by: getUser in class org.apache.hadoop.security.token.TokenIdentifier Returns:the username. null is returned if username in the identifier is          empty or null. hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object other) Overrides: equals in class Object toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContainerTokenSelector (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContainerTokenSelector (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security Class ContainerTokenSelector java.lang.Object org.apache.hadoop.yarn.security.ContainerTokenSelector All Implemented Interfaces: org.apache.hadoop.security.token.TokenSelector<ContainerTokenIdentifier> @InterfaceAudience.Public @InterfaceStability.Stable public class ContainerTokenSelector extends Object implements org.apache.hadoop.security.token.TokenSelector<ContainerTokenIdentifier> Constructor Summary Constructors  Constructor and Description ContainerTokenSelector()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.token.Token<ContainerTokenIdentifier> selectToken(Text service,                       Collection<org.apache.hadoop.security.token.Token<? extends org.apache.hadoop.security.token.TokenIdentifier>> tokens)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ContainerTokenSelector public ContainerTokenSelector() Method Detail selectToken public org.apache.hadoop.security.token.Token<ContainerTokenIdentifier> selectToken(Text service,                                                                            Collection<org.apache.hadoop.security.token.Token<? extends org.apache.hadoop.security.token.TokenIdentifier>> tokens) Specified by: selectToken in interface org.apache.hadoop.security.token.TokenSelector<ContainerTokenIdentifier> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ContentSummary (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ContentSummary (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class ContentSummary java.lang.Object org.apache.hadoop.fs.ContentSummary All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class ContentSummary extends Object implements Writable Store the summary of a content (a directory or a file). Constructor Summary Constructors  Constructor and Description ContentSummary() Deprecated.  ContentSummary(long length,                             long fileCount,                             long directoryCount) Deprecated.  ContentSummary(long length,                             long fileCount,                             long directoryCount,                             long quota,                             long spaceConsumed,                             long spaceQuota) Deprecated.  Method Summary Methods  Modifier and Type Method and Description long getDirectoryCount()  long getFileCount()  static String getHeader(boolean qOption) Return the header of the output. long getLength()  long getQuota() Return the directory quota long getSpaceConsumed() Retuns storage space consumed long getSpaceQuota() Returns storage space quota long getTypeConsumed(StorageType type) Returns storage type consumed long getTypeQuota(StorageType type) Returns storage type quota boolean isTypeConsumedAvailable() Returns true if any storage type consumption information is available boolean isTypeQuotaSet() Returns true if any storage type quota has been set String toString()  String toString(boolean qOption) Return the string representation of the object in the output format. String toString(boolean qOption,                 boolean hOption) Return the string representation of the object in the output format. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ContentSummary @Deprecated public ContentSummary() Deprecated.  Constructor deprecated by ContentSummary.Builder ContentSummary @Deprecated public ContentSummary(long length,                          long fileCount,                          long directoryCount) Deprecated.  Constructor, deprecated by ContentSummary.Builder   This constructor implicitly set spaceConsumed the same as length.   spaceConsumed and length must be set explicitly with   ContentSummary.Builder ContentSummary @Deprecated public ContentSummary(long length,                          long fileCount,                          long directoryCount,                          long quota,                          long spaceConsumed,                          long spaceQuota) Deprecated.  Constructor, deprecated by ContentSummary.Builder Method Detail getLength public long getLength() Returns:the length getDirectoryCount public long getDirectoryCount() Returns:the directory count getFileCount public long getFileCount() Returns:the file count getQuota public long getQuota() Return the directory quota getSpaceConsumed public long getSpaceConsumed() Retuns storage space consumed getSpaceQuota public long getSpaceQuota() Returns storage space quota getTypeQuota public long getTypeQuota(StorageType type) Returns storage type quota getTypeConsumed public long getTypeConsumed(StorageType type) Returns storage type consumed isTypeQuotaSet public boolean isTypeQuotaSet() Returns true if any storage type quota has been set isTypeConsumedAvailable public boolean isTypeConsumedAvailable() Returns true if any storage type consumption information is available getHeader public static String getHeader(boolean qOption) Return the header of the output.  if qOption is false, output directory count, file count, and content size;  if qOption is true, output quota and remaining quota as well. Parameters:qOption - a flag indicating if quota needs to be printed or not Returns:the header of the output toString public String toString() Overrides: toString in class Object toString public String toString(boolean qOption) Return the string representation of the object in the output format.  if qOption is false, output directory count, file count, and content size;  if qOption is true, output quota and remaining quota as well. Parameters:qOption - a flag indicating if quota needs to be printed or not Returns:the string representation of the object toString public String toString(boolean qOption,               boolean hOption) Return the string representation of the object in the output format.  if qOption is false, output directory count, file count, and content size;  if qOption is true, output quota and remaining quota as well.  if hOption is false file sizes are returned in bytes  if hOption is true file sizes are returned in human readable Parameters:qOption - a flag indicating if quota needs to be printed or nothOption - a flag indicating if human readable output if to be used Returns:the string representation of the object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ControlledJob (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ControlledJob (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.jobcontrol Class ControlledJob java.lang.Object org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob Direct Known Subclasses: Job @InterfaceAudience.Public @InterfaceStability.Evolving public class ControlledJob extends Object This class encapsulates a MapReduce job and its dependency. It monitors    the states of the depending jobs and updates the state of this job.   A job starts in the WAITING state. If it does not have any depending jobs,   or all of the depending jobs are in SUCCESS state, then the job state    will become READY. If any depending jobs fail, the job will fail too.    When in READY state, the job can be submitted to Hadoop for execution, with   the state changing into RUNNING state. From RUNNING state, the job    can get into SUCCESS or FAILED state, depending    the status of the job execution. Field Summary Fields  Modifier and Type Field and Description static String CREATE_DIR  Constructor Summary Constructors  Constructor and Description ControlledJob(Configuration conf) Construct a job. ControlledJob(Job job,                           List<ControlledJob> dependingJobs) Construct a job. Method Summary Methods  Modifier and Type Method and Description boolean addDependingJob(ControlledJob dependingJob) Add a job to this jobs' dependency list. void failJob(String message)  List<ControlledJob> getDependentJobs()  Job getJob()  String getJobID()  String getJobName()  org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.State getJobState()  JobID getMapredJobId()  String getMessage()  boolean isCompleted()  boolean isReady()  void killJob()  void setJob(Job job) Set the mapreduce job void setJobID(String id) Set the job ID for  this job. void setJobName(String jobName) Set the job name for  this job. protected void setJobState(org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.State state) Set the state for this job. void setMessage(String message) Set the message for this job. protected void submit() Submit this job to mapred. String toString()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail CREATE_DIR public static final String CREATE_DIR See Also:Constant Field Values Constructor Detail ControlledJob public ControlledJob(Job job,              List<ControlledJob> dependingJobs)               throws IOException Construct a job. Parameters:job - a mapreduce job to be executed.dependingJobs - an array of jobs the current job depends on Throws: IOException ControlledJob public ControlledJob(Configuration conf)               throws IOException Construct a job. Parameters:conf - mapred job configuration representing a job to be executed. Throws: IOException Method Detail toString public String toString() Overrides: toString in class Object getJobName public String getJobName() Returns:the job name of this job setJobName public void setJobName(String jobName) Set the job name for  this job. Parameters:jobName - the job name getJobID public String getJobID() Returns:the job ID of this job assigned by JobControl setJobID public void setJobID(String id) Set the job ID for  this job. Parameters:id - the job ID getMapredJobId public JobID getMapredJobId() Returns:the mapred ID of this job as assigned by the mapred framework. getJob public Job getJob() Returns:the mapreduce job setJob public void setJob(Job job) Set the mapreduce job Parameters:job - the mapreduce job for this job. getJobState public org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.State getJobState() Returns:the state of this job setJobState protected void setJobState(org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.State state) Set the state for this job. Parameters:state - the new state for this job. getMessage public String getMessage() Returns:the message of this job setMessage public void setMessage(String message) Set the message for this job. Parameters:message - the message for this job. getDependentJobs public List<ControlledJob> getDependentJobs() Returns:the depending jobs of this job addDependingJob public boolean addDependingJob(ControlledJob dependingJob) Add a job to this jobs' dependency list.   Dependent jobs can only be added while a Job   is waiting to run, not during or afterwards. Parameters:dependingJob - Job that this Job depends on. Returns:true if the Job was added. isCompleted public boolean isCompleted() Returns:true if this job is in a complete state isReady public boolean isReady() Returns:true if this job is in READY state killJob public void killJob()              throws IOException,                     InterruptedException Throws: IOException InterruptedException failJob public void failJob(String message)              throws IOException,                     InterruptedException Throws: IOException InterruptedException submit protected void submit() Submit this job to mapred. The state becomes RUNNING if submission   is successful, FAILED otherwise. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Counter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Counter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Interface Counter All Superinterfaces: Writable All Known Implementing Classes: Counters.Counter @InterfaceAudience.Public @InterfaceStability.Stable public interface Counter extends Writable A named counter that tracks the progress of a map/reduce job.  Counters represent global counters, defined either by the  Map-Reduce framework or applications. Each Counter is named by  an Enum and has a long for the value.  Counters are bunched into Groups, each comprising of  counters from a particular Enum class. Method Summary Methods  Modifier and Type Method and Description String getDisplayName() Get the display name of the counter. String getName()  long getValue() What is the current value of this counter? void increment(long incr) Increment this counter by the given value void setDisplayName(String displayName) Deprecated.  (and no-op by default) void setValue(long value) Set this counter by the given value Methods inherited from interface org.apache.hadoop.io.Writable readFields, write Method Detail setDisplayName @Deprecated void setDisplayName(String displayName) Deprecated. (and no-op by default) Set the display name of the counter Parameters:displayName - of the counter getName String getName() Returns:the name of the counter getDisplayName String getDisplayName() Get the display name of the counter. Returns:the user facing name of the counter getValue long getValue() What is the current value of this counter? Returns:the current value setValue void setValue(long value) Set this counter by the given value Parameters:value - the value to set increment void increment(long incr) Increment this counter by the given value Parameters:incr - the value to increase this counter by Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CounterGroup (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CounterGroup (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Interface CounterGroup All Superinterfaces: CounterGroupBase<Counter>, Iterable<Counter>, Writable @InterfaceAudience.Public @InterfaceStability.Stable public interface CounterGroup extends CounterGroupBase<Counter> A group of Counters that logically belong together. Typically,  it is an Enum subclass and the counters are the values. Method Summary Methods inherited from interface org.apache.hadoop.mapreduce.counters.CounterGroupBase addCounter, addCounter, findCounter, findCounter, findCounter, getDisplayName, getName, incrAllCounters, setDisplayName, size Methods inherited from interface org.apache.hadoop.io.Writable readFields, write Methods inherited from interface java.lang.Iterable iterator Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CounterGroupBase (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CounterGroupBase (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.counters Interface CounterGroupBase<T extends Counter> Type Parameters:T - type of the counter for the group All Superinterfaces: Iterable<T>, Writable All Known Subinterfaces: CounterGroup All Known Implementing Classes: Counters.Group @InterfaceAudience.Public @InterfaceStability.Evolving public interface CounterGroupBase<T extends Counter> extends Writable, Iterable<T> The common counter group interface. Method Summary Methods  Modifier and Type Method and Description T addCounter(String name,                     String displayName,                     long value) Add a counter to this group void addCounter(T counter) Add a counter to this group. T findCounter(String counterName) Find a counter in the group. T findCounter(String counterName,                       boolean create) Find a counter in the group T findCounter(String counterName,                       String displayName) Find a counter in the group. String getDisplayName() Get the display name of the group. String getName() Get the internal name of the group void incrAllCounters(CounterGroupBase<T> rightGroup) Increment all counters by a group of counters void setDisplayName(String displayName) Set the display name of the group int size()  Methods inherited from interface org.apache.hadoop.io.Writable readFields, write Methods inherited from interface java.lang.Iterable iterator Method Detail getName String getName() Get the internal name of the group Returns:the internal name getDisplayName String getDisplayName() Get the display name of the group. Returns:the human readable name setDisplayName void setDisplayName(String displayName) Set the display name of the group Parameters:displayName - of the group addCounter void addCounter(T counter) Add a counter to this group. Parameters:counter - to add addCounter T addCounter(String name,            String displayName,            long value) Add a counter to this group Parameters:name - of the counterdisplayName - of the countervalue - of the counter Returns:the counter findCounter T findCounter(String counterName,             String displayName) Find a counter in the group. Parameters:counterName - the name of the counterdisplayName - the display name of the counter Returns:the counter that was found or added findCounter T findCounter(String counterName,             boolean create) Find a counter in the group Parameters:counterName - the name of the countercreate - create the counter if not found if true Returns:the counter that was found or added or null if create is false findCounter T findCounter(String counterName) Find a counter in the group. Parameters:counterName - the name of the counter Returns:the counter that was found or added size int size() Returns:the number of counters in this group. incrAllCounters void incrAllCounters(CounterGroupBase<T> rightGroup) Increment all counters by a group of counters Parameters:rightGroup - the group to be added to this group Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Counters.Counter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Counters.Counter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class Counters.Counter java.lang.Object org.apache.hadoop.mapred.Counters.Counter All Implemented Interfaces: Writable, Counter Enclosing class: Counters @InterfaceAudience.Public @InterfaceStability.Stable public static class Counters.Counter extends Object implements Counter A counter record, comprising its name and value. Constructor Summary Constructors  Constructor and Description Counters.Counter()  Method Summary Methods  Modifier and Type Method and Description boolean contentEquals(Counters.Counter counter) Deprecated.   boolean equals(Object genericRight)  long getCounter()  String getDisplayName() Get the display name of the counter. String getName()  Counter getUnderlyingCounter()  long getValue() What is the current value of this counter? int hashCode()  void increment(long incr) Increment this counter by the given value String makeEscapedCompactString() Returns the compact stringified version of the counter in the format  [(actual-name)(display-name)(value)] void readFields(DataInput in) Deserialize the fields of this object from in. void setDisplayName(String displayName) Set the display name of the counter void setValue(long value) Set this counter by the given value void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail Counters.Counter public Counters.Counter() Method Detail setDisplayName public void setDisplayName(String displayName) Description copied from interface: Counter Set the display name of the counter Specified by: setDisplayName in interface Counter Parameters:displayName - of the counter getName public String getName() Specified by: getName in interface Counter Returns:the name of the counter getDisplayName public String getDisplayName() Description copied from interface: Counter Get the display name of the counter. Specified by: getDisplayName in interface Counter Returns:the user facing name of the counter getValue public long getValue() Description copied from interface: Counter What is the current value of this counter? Specified by: getValue in interface Counter Returns:the current value setValue public void setValue(long value) Description copied from interface: Counter Set this counter by the given value Specified by: setValue in interface Counter Parameters:value - the value to set increment public void increment(long incr) Description copied from interface: Counter Increment this counter by the given value Specified by: increment in interface Counter Parameters:incr - the value to increase this counter by write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException makeEscapedCompactString public String makeEscapedCompactString() Returns the compact stringified version of the counter in the format  [(actual-name)(display-name)(value)] Returns:the stringified result contentEquals @Deprecated public boolean contentEquals(Counters.Counter counter) Deprecated.  Checks for (content) equality of two (basic) counters Parameters:counter - to compare Returns:true if content equals getCounter public long getCounter() Returns:the value of the counter getUnderlyingCounter public Counter getUnderlyingCounter() Specified by: getUnderlyingCounter in interface Counter equals public boolean equals(Object genericRight) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Counters.Group (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Counters.Group (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class Counters.Group java.lang.Object org.apache.hadoop.mapred.Counters.Group All Implemented Interfaces: Iterable<Counters.Counter>, Writable, CounterGroupBase<Counters.Counter> Enclosing class: Counters @InterfaceAudience.Public @InterfaceStability.Stable public static class Counters.Group extends Object implements CounterGroupBase<Counters.Counter> Group of counters, comprising of counters from a particular   counter Enum class.   Grouphandles localization of the class name and the   counter names. Constructor Summary Constructors  Modifier Constructor and Description protected  Counters.Group()  Method Summary Methods  Modifier and Type Method and Description void addCounter(Counters.Counter counter) Add a counter to this group. Counters.Counter addCounter(String name,                     String displayName,                     long value) Add a counter to this group boolean equals(Object genericRight)  Counters.Counter findCounter(String counterName) Find a counter in the group. Counters.Counter findCounter(String counterName,                       boolean create) Find a counter in the group Counters.Counter findCounter(String counterName,                       String displayName) Find a counter in the group. Counters.Counter getCounter(int id,                     String name) Deprecated.  use findCounter(String) instead long getCounter(String counterName)  Counters.Counter getCounterForName(String name) Get the counter for the given name and create it if it doesn't exist. String getDisplayName() Get the display name of the group. String getName() Get the internal name of the group CounterGroupBase<Counters.Counter> getUnderlyingGroup()  int hashCode()  void incrAllCounters(CounterGroupBase<Counters.Counter> rightGroup) Increment all counters by a group of counters Iterator<Counters.Counter> iterator()  String makeEscapedCompactString()  void readFields(DataInput in) Deserialize the fields of this object from in. void setDisplayName(String displayName) Set the display name of the group int size()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail Counters.Group protected Counters.Group() Method Detail getCounter public long getCounter(String counterName) Parameters:counterName - the name of the counter Returns:the value of the specified counter, or 0 if the counter does  not exist. makeEscapedCompactString public String makeEscapedCompactString() Returns:the compact stringified version of the group in the format  {(actual-name)(display-name)(value)[][][]} where [] are compact strings  for the counters within. getCounter @Deprecated public Counters.Counter getCounter(int id,                                      String name) Deprecated. use findCounter(String) instead Get the counter for the given id and create it if it doesn't exist. Parameters:id - the numeric id of the counter within the groupname - the internal counter name Returns:the counter getCounterForName public Counters.Counter getCounterForName(String name) Get the counter for the given name and create it if it doesn't exist. Parameters:name - the internal counter name Returns:the counter write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException iterator public Iterator<Counters.Counter> iterator() Specified by: iterator in interface Iterable<Counters.Counter> getName public String getName() Description copied from interface: CounterGroupBase Get the internal name of the group Specified by: getName in interface CounterGroupBase<Counters.Counter> Returns:the internal name getDisplayName public String getDisplayName() Description copied from interface: CounterGroupBase Get the display name of the group. Specified by: getDisplayName in interface CounterGroupBase<Counters.Counter> Returns:the human readable name setDisplayName public void setDisplayName(String displayName) Description copied from interface: CounterGroupBase Set the display name of the group Specified by: setDisplayName in interface CounterGroupBase<Counters.Counter> Parameters:displayName - of the group addCounter public void addCounter(Counters.Counter counter) Description copied from interface: CounterGroupBase Add a counter to this group. Specified by: addCounter in interface CounterGroupBase<Counters.Counter> Parameters:counter - to add addCounter public Counters.Counter addCounter(String name,                           String displayName,                           long value) Description copied from interface: CounterGroupBase Add a counter to this group Specified by: addCounter in interface CounterGroupBase<Counters.Counter> Parameters:name - of the counterdisplayName - of the countervalue - of the counter Returns:the counter findCounter public Counters.Counter findCounter(String counterName,                            String displayName) Description copied from interface: CounterGroupBase Find a counter in the group. Specified by: findCounter in interface CounterGroupBase<Counters.Counter> Parameters:counterName - the name of the counterdisplayName - the display name of the counter Returns:the counter that was found or added findCounter public Counters.Counter findCounter(String counterName,                            boolean create) Description copied from interface: CounterGroupBase Find a counter in the group Specified by: findCounter in interface CounterGroupBase<Counters.Counter> Parameters:counterName - the name of the countercreate - create the counter if not found if true Returns:the counter that was found or added or null if create is false findCounter public Counters.Counter findCounter(String counterName) Description copied from interface: CounterGroupBase Find a counter in the group. Specified by: findCounter in interface CounterGroupBase<Counters.Counter> Parameters:counterName - the name of the counter Returns:the counter that was found or added size public int size() Specified by: size in interface CounterGroupBase<Counters.Counter> Returns:the number of counters in this group. incrAllCounters public void incrAllCounters(CounterGroupBase<Counters.Counter> rightGroup) Description copied from interface: CounterGroupBase Increment all counters by a group of counters Specified by: incrAllCounters in interface CounterGroupBase<Counters.Counter> Parameters:rightGroup - the group to be added to this group getUnderlyingGroup public CounterGroupBase<Counters.Counter> getUnderlyingGroup() Specified by: getUnderlyingGroup in interface CounterGroupBase<Counters.Counter> equals public boolean equals(Object genericRight) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Counters (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Counters (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class Counters java.lang.Object org.apache.hadoop.mapreduce.counters.AbstractCounters<Counter,CounterGroup> org.apache.hadoop.mapreduce.Counters All Implemented Interfaces: Iterable<CounterGroup>, Writable @InterfaceAudience.Public @InterfaceStability.Stable public class Counters extends AbstractCounters<Counter,CounterGroup> Counters holds per job/task counters, defined either by the  Map-Reduce framework or applications. Each Counter can be of  any Enum type.  Counters are bunched into CounterGroups, each  comprising of counters from a particular Enum class. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.counters.AbstractCounters LOG Constructor Summary Constructors  Constructor and Description Counters() Default constructor Counters(AbstractCounters<C,G> counters) Construct the Counters object from the another counters object Method Summary Methods inherited from class org.apache.hadoop.mapreduce.counters.AbstractCounters countCounters, equals, findCounter, findCounter, getGroup, getGroupNames, hashCode, incrAllCounters, iterator, readFields, toString, write Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail Counters public Counters() Default constructor Counters public Counters(AbstractCounters<C,G> counters) Construct the Counters object from the another counters object Type Parameters:C - the type of counterG - the type of counter groupParameters:counters - the old counters object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CountingBloomFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CountingBloomFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util.bloom Class CountingBloomFilter java.lang.Object org.apache.hadoop.util.bloom.Filter org.apache.hadoop.util.bloom.CountingBloomFilter All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public final class CountingBloomFilter extends org.apache.hadoop.util.bloom.Filter Implements a counting Bloom filter, as defined by Fan et al. in a ToN  2000 paper.    A counting Bloom filter is an improvement to standard a Bloom filter as it  allows dynamic additions and deletions of set membership information.  This   is achieved through the use of a counting vector instead of a bit vector.    Originally created by  European Commission One-Lab Project 034819. See Also:The general behavior of a filter,  Summary cache: a scalable wide-area web cache sharing protocol Field Summary Fields inherited from class org.apache.hadoop.util.bloom.Filter hash, hashType, nbHash, vectorSize Constructor Summary Constructors  Constructor and Description CountingBloomFilter() Default constructor - use with readFields CountingBloomFilter(int vectorSize,                                       int nbHash,                                       int hashType) Constructor Method Summary Methods  Modifier and Type Method and Description void add(org.apache.hadoop.util.bloom.Key key) Adds a key to this filter. void and(org.apache.hadoop.util.bloom.Filter filter) Peforms a logical AND between this filter and a specified filter. int approximateCount(org.apache.hadoop.util.bloom.Key key) This method calculates an approximate count of the key, i.e. void delete(org.apache.hadoop.util.bloom.Key key) Removes a specified key from this counting Bloom filter. boolean membershipTest(org.apache.hadoop.util.bloom.Key key) Determines wether a specified key belongs to this filter. void not() Performs a logical NOT on this filter. void or(org.apache.hadoop.util.bloom.Filter filter) Peforms a logical OR between this filter and a specified filter. void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. void xor(org.apache.hadoop.util.bloom.Filter filter) Peforms a logical XOR between this filter and a specified filter. Methods inherited from class org.apache.hadoop.util.bloom.Filter add, add, add Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail CountingBloomFilter public CountingBloomFilter() Default constructor - use with readFields CountingBloomFilter public CountingBloomFilter(int vectorSize,                    int nbHash,                    int hashType) Constructor Parameters:vectorSize - The vector size of this filter.nbHash - The number of hash function to consider.hashType - type of the hashing function (see  Hash). Method Detail add public void add(org.apache.hadoop.util.bloom.Key key) Description copied from class: org.apache.hadoop.util.bloom.Filter Adds a key to this filter. Specified by: add in class org.apache.hadoop.util.bloom.Filter Parameters:key - The key to add. delete public void delete(org.apache.hadoop.util.bloom.Key key) Removes a specified key from this counting Bloom filter.    Invariant: nothing happens if the specified key does not belong to this counter Bloom filter. Parameters:key - The key to remove. and public void and(org.apache.hadoop.util.bloom.Filter filter) Description copied from class: org.apache.hadoop.util.bloom.Filter Peforms a logical AND between this filter and a specified filter.    Invariant: The result is assigned to this filter. Specified by: and in class org.apache.hadoop.util.bloom.Filter Parameters:filter - The filter to AND with. membershipTest public boolean membershipTest(org.apache.hadoop.util.bloom.Key key) Description copied from class: org.apache.hadoop.util.bloom.Filter Determines wether a specified key belongs to this filter. Specified by: membershipTest in class org.apache.hadoop.util.bloom.Filter Parameters:key - The key to test. Returns:boolean True if the specified key belongs to this filter.                      False otherwise. approximateCount public int approximateCount(org.apache.hadoop.util.bloom.Key key) This method calculates an approximate count of the key, i.e. how many  times the key was added to the filter. This allows the filter to be  used as an approximate key -> count map.  NOTE: due to the bucket size of this filter, inserting the same  key more than 15 times will cause an overflow at all filter positions  associated with this key, and it will significantly increase the error  rate for this and other keys. For this reason the filter can only be  used to store small count values 0 <= N << 15. Parameters:key - key to be tested Returns:0 if the key is not present. Otherwise, a positive value v will  be returned such that v == count with probability equal to the  error rate of this filter, and v > count otherwise.  Additionally, if the filter experienced an underflow as a result of  delete(Key) operation, the return value may be lower than the  count with the probability of the false negative rate of such  filter. not public void not() Description copied from class: org.apache.hadoop.util.bloom.Filter Performs a logical NOT on this filter.    The result is assigned to this filter. Specified by: not in class org.apache.hadoop.util.bloom.Filter or public void or(org.apache.hadoop.util.bloom.Filter filter) Description copied from class: org.apache.hadoop.util.bloom.Filter Peforms a logical OR between this filter and a specified filter.    Invariant: The result is assigned to this filter. Specified by: or in class org.apache.hadoop.util.bloom.Filter Parameters:filter - The filter to OR with. xor public void xor(org.apache.hadoop.util.bloom.Filter filter) Description copied from class: org.apache.hadoop.util.bloom.Filter Peforms a logical XOR between this filter and a specified filter.    Invariant: The result is assigned to this filter. Specified by: xor in class org.apache.hadoop.util.bloom.Filter Parameters:filter - The filter to XOR with. toString public String toString() Overrides: toString in class Object write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Overrides: write in class org.apache.hadoop.util.bloom.Filter Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Overrides: readFields in class org.apache.hadoop.util.bloom.Filter Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CreateFlag (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CreateFlag (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.fs Enum CreateFlag java.lang.Object java.lang.Enum<CreateFlag> org.apache.hadoop.fs.CreateFlag All Implemented Interfaces: Serializable, Comparable<CreateFlag> @InterfaceAudience.Public @InterfaceStability.Evolving public enum CreateFlag extends Enum<CreateFlag> CreateFlag specifies the file create semantic. Users can combine flags like:     EnumSet.of(CreateFlag.CREATE, CreateFlag.APPEND)        Use the CreateFlag as follows:     CREATE - to create a file if it does not exist,   else throw FileAlreadyExists.   APPEND - to append to a file if it exists,   else throw FileNotFoundException.   OVERWRITE - to truncate a file if it exists,   else throw FileNotFoundException.   CREATE|APPEND - to create a file if it does not exist,   else append to an existing file.   CREATE|OVERWRITE - to create a file if it does not exist,   else overwrite an existing file.   SYNC_BLOCK - to force closed blocks to the disk device.  In addition Syncable.hsync() should be called after each write,  if true synchronous behavior is required.   LAZY_PERSIST - Create the block on transient storage (RAM) if  available.   APPEND_NEWBLOCK - Append data to a new block instead of end of the last  partial block.      Following combination is not valid and will result in   HadoopIllegalArgumentException:     APPEND|OVERWRITE   CREATE|APPEND|OVERWRITE   Enum Constant Summary Enum Constants  Enum Constant and Description APPEND Append to a file. CREATE Create a file. LAZY_PERSIST Create the block on transient storage (RAM) if available. NEW_BLOCK Append data to a new block instead of the end of the last partial block. OVERWRITE Truncate/overwrite a file. SYNC_BLOCK Force closed blocks to disk. Method Summary Methods  Modifier and Type Method and Description static void validate(EnumSet<CreateFlag> flag) Validate the CreateFlag and throw exception if it is invalid static void validate(Object path,                 boolean pathExists,                 EnumSet<CreateFlag> flag) Validate the CreateFlag for create operation static void validateForAppend(EnumSet<CreateFlag> flag) Validate the CreateFlag for the append operation. static CreateFlag valueOf(String name) Returns the enum constant of this type with the specified name. static CreateFlag[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail CREATE public static final CreateFlag CREATE Create a file. See javadoc for more description  already exists OVERWRITE public static final CreateFlag OVERWRITE Truncate/overwrite a file. Same as POSIX O_TRUNC. See javadoc for description. APPEND public static final CreateFlag APPEND Append to a file. See javadoc for more description. SYNC_BLOCK public static final CreateFlag SYNC_BLOCK Force closed blocks to disk. Similar to POSIX O_SYNC. See javadoc for description. LAZY_PERSIST public static final CreateFlag LAZY_PERSIST Create the block on transient storage (RAM) if available. If  transient storage is unavailable then the block will be created  on disk.  HDFS will make a best effort to lazily write these files to persistent  storage, however file contents may be lost at any time due to process/  node restarts, hence there is no guarantee of data durability.  This flag must only be used for intermediate data whose loss can be  tolerated by the application. NEW_BLOCK public static final CreateFlag NEW_BLOCK Append data to a new block instead of the end of the last partial block.  This is only useful for APPEND. Method Detail values public static CreateFlag[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (CreateFlag c : CreateFlag.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static CreateFlag valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null validate public static void validate(EnumSet<CreateFlag> flag) Validate the CreateFlag and throw exception if it is invalid Parameters:flag - set of CreateFlag Throws: HadoopIllegalArgumentException - if the CreateFlag is invalid validate public static void validate(Object path,             boolean pathExists,             EnumSet<CreateFlag> flag)                      throws IOException Validate the CreateFlag for create operation Parameters:path - Object representing the path; usually String or PathpathExists - pass true if the path exists in the file systemflag - set of CreateFlag Throws: IOException - on error HadoopIllegalArgumentException - if the CreateFlag is invalid validateForAppend public static void validateForAppend(EnumSet<CreateFlag> flag) Validate the CreateFlag for the append operation. The flag must contain  APPEND, and cannot contain OVERWRITE. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CredentialProvider (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CredentialProvider (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.security.alias Class CredentialProvider java.lang.Object org.apache.hadoop.security.alias.CredentialProvider @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class CredentialProvider extends Object A provider of credentials or password for Hadoop applications. Provides an  abstraction to separate credential storage from users of them. It  is intended to support getting or storing passwords in a variety of ways,  including third party bindings. Field Summary Fields  Modifier and Type Field and Description static String CLEAR_TEXT_FALLBACK  Constructor Summary Constructors  Constructor and Description CredentialProvider()  Method Summary Methods  Modifier and Type Method and Description abstract org.apache.hadoop.security.alias.CredentialProvider.CredentialEntry createCredentialEntry(String name,                                           char[] credential) Create a new credential. abstract void deleteCredentialEntry(String name) Delete the given credential. abstract void flush() Ensures that any changes to the credentials are written to persistent store. abstract List<String> getAliases() Get the aliases for all credentials. abstract org.apache.hadoop.security.alias.CredentialProvider.CredentialEntry getCredentialEntry(String alias) Get the credential entry for a specific alias. boolean isTransient() Indicates whether this provider represents a store  that is intended for transient use - such as the UserProvider  is. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail CLEAR_TEXT_FALLBACK public static final String CLEAR_TEXT_FALLBACK See Also:Constant Field Values Constructor Detail CredentialProvider public CredentialProvider() Method Detail isTransient public boolean isTransient() Indicates whether this provider represents a store  that is intended for transient use - such as the UserProvider  is. These providers are generally used to provide job access to  passwords rather than for long term storage. Returns:true if transient, false otherwise flush public abstract void flush()                     throws IOException Ensures that any changes to the credentials are written to persistent store. Throws: IOException getCredentialEntry public abstract org.apache.hadoop.security.alias.CredentialProvider.CredentialEntry getCredentialEntry(String alias)                                                                                                 throws IOException Get the credential entry for a specific alias. Parameters:alias - the name of a specific credential Returns:the credentialEntry Throws: IOException getAliases public abstract List<String> getAliases()                                  throws IOException Get the aliases for all credentials. Returns:the list of alias names Throws: IOException createCredentialEntry public abstract org.apache.hadoop.security.alias.CredentialProvider.CredentialEntry createCredentialEntry(String name,                                                                                         char[] credential)                                                                                                    throws IOException Create a new credential. The given alias must not already exist. Parameters:name - the alias of the credentialcredential - the credential value for the alias. Throws: IOException deleteCredentialEntry public abstract void deleteCredentialEntry(String name)                                     throws IOException Delete the given credential. Parameters:name - the alias of the credential to delete Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CredentialProviderFactory (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CredentialProviderFactory (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.security.alias Class CredentialProviderFactory java.lang.Object org.apache.hadoop.security.alias.CredentialProviderFactory @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class CredentialProviderFactory extends Object A factory to create a list of CredentialProvider based on the path given in a  Configuration. It uses a service loader interface to find the available  CredentialProviders and create them based on the list of URIs. Field Summary Fields  Modifier and Type Field and Description static String CREDENTIAL_PROVIDER_PATH  Constructor Summary Constructors  Constructor and Description CredentialProviderFactory()  Method Summary Methods  Modifier and Type Method and Description abstract CredentialProvider createProvider(URI providerName,                             Configuration conf)  static List<CredentialProvider> getProviders(Configuration conf)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail CREDENTIAL_PROVIDER_PATH public static final String CREDENTIAL_PROVIDER_PATH See Also:Constant Field Values Constructor Detail CredentialProviderFactory public CredentialProviderFactory() Method Detail createProvider public abstract CredentialProvider createProvider(URI providerName,                                 Configuration conf)                                            throws IOException Throws: IOException getProviders public static List<CredentialProvider> getProviders(Configuration conf)                                              throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CsvRecordInput (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CsvRecordInput (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class CsvRecordInput java.lang.Object org.apache.hadoop.record.CsvRecordInput All Implemented Interfaces: RecordInput Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class CsvRecordInput extends Object implements RecordInput Constructor Summary Constructors  Constructor and Description CsvRecordInput(InputStream in) Deprecated.  Creates a new instance of CsvRecordInput Method Summary Methods  Modifier and Type Method and Description void endMap(String tag) Deprecated.  Check the mark for end of the serialized map. void endRecord(String tag) Deprecated.  Check the mark for end of the serialized record. void endVector(String tag) Deprecated.  Check the mark for end of the serialized vector. boolean readBool(String tag) Deprecated.  Read a boolean from serialized record. Buffer readBuffer(String tag) Deprecated.  Read byte array from serialized record. byte readByte(String tag) Deprecated.  Read a byte from serialized record. double readDouble(String tag) Deprecated.  Read a double-precision number from serialized record. float readFloat(String tag) Deprecated.  Read a single-precision float from serialized record. int readInt(String tag) Deprecated.  Read an integer from serialized record. long readLong(String tag) Deprecated.  Read a long integer from serialized record. String readString(String tag) Deprecated.  Read a UTF-8 encoded string from serialized record. Index startMap(String tag) Deprecated.  Check the mark for start of the serialized map. void startRecord(String tag) Deprecated.  Check the mark for start of the serialized record. Index startVector(String tag) Deprecated.  Check the mark for start of the serialized vector. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail CsvRecordInput public CsvRecordInput(InputStream in) Deprecated.  Creates a new instance of CsvRecordInput Method Detail readByte public byte readByte(String tag)               throws IOException Deprecated.  Description copied from interface: RecordInput Read a byte from serialized record. Specified by: readByte in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readBool public boolean readBool(String tag)                  throws IOException Deprecated.  Description copied from interface: RecordInput Read a boolean from serialized record. Specified by: readBool in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readInt public int readInt(String tag)             throws IOException Deprecated.  Description copied from interface: RecordInput Read an integer from serialized record. Specified by: readInt in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readLong public long readLong(String tag)               throws IOException Deprecated.  Description copied from interface: RecordInput Read a long integer from serialized record. Specified by: readLong in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readFloat public float readFloat(String tag)                 throws IOException Deprecated.  Description copied from interface: RecordInput Read a single-precision float from serialized record. Specified by: readFloat in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readDouble public double readDouble(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Read a double-precision number from serialized record. Specified by: readDouble in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readString public String readString(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Read a UTF-8 encoded string from serialized record. Specified by: readString in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readBuffer public Buffer readBuffer(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Read byte array from serialized record. Specified by: readBuffer in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException startRecord public void startRecord(String tag)                  throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for start of the serialized record. Specified by: startRecord in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException endRecord public void endRecord(String tag)                throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for end of the serialized record. Specified by: endRecord in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException startVector public Index startVector(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for start of the serialized vector. Specified by: startVector in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:Index that is used to count the number of elements. Throws: IOException endVector public void endVector(String tag)                throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for end of the serialized vector. Specified by: endVector in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException startMap public Index startMap(String tag)                throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for start of the serialized map. Specified by: startMap in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:Index that is used to count the number of map entries. Throws: IOException endMap public void endMap(String tag)             throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for end of the serialized map. Specified by: endMap in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  CsvRecordOutput (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="CsvRecordOutput (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class CsvRecordOutput java.lang.Object org.apache.hadoop.record.CsvRecordOutput All Implemented Interfaces: RecordOutput Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class CsvRecordOutput extends Object implements RecordOutput Constructor Summary Constructors  Constructor and Description CsvRecordOutput(OutputStream out) Deprecated.  Creates a new instance of CsvRecordOutput Method Summary Methods  Modifier and Type Method and Description void endMap(TreeMap v,             String tag) Deprecated.  Mark the end of a serialized map. void endRecord(Record r,                   String tag) Deprecated.  Mark the end of a serialized record. void endVector(ArrayList v,                   String tag) Deprecated.  Mark the end of a serialized vector. void startMap(TreeMap v,                 String tag) Deprecated.  Mark the start of a map to be serialized. void startRecord(Record r,                       String tag) Deprecated.  Mark the start of a record to be serialized. void startVector(ArrayList v,                       String tag) Deprecated.  Mark the start of a vector to be serialized. void writeBool(boolean b,                   String tag) Deprecated.  Write a boolean to serialized record. void writeBuffer(Buffer buf,                       String tag) Deprecated.  Write a buffer to serialized record. void writeByte(byte b,                   String tag) Deprecated.  Write a byte to serialized record. void writeDouble(double d,                       String tag) Deprecated.  Write a double precision floating point number to serialized record. void writeFloat(float f,                     String tag) Deprecated.  Write a single-precision float to serialized record. void writeInt(int i,                 String tag) Deprecated.  Write an integer to serialized record. void writeLong(long l,                   String tag) Deprecated.  Write a long integer to serialized record. void writeString(String s,                       String tag) Deprecated.  Write a unicode string to serialized record. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail CsvRecordOutput public CsvRecordOutput(OutputStream out) Deprecated.  Creates a new instance of CsvRecordOutput Method Detail writeByte public void writeByte(byte b,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Write a byte to serialized record. Specified by: writeByte in interface RecordOutput Parameters:b - Byte to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeBool public void writeBool(boolean b,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Write a boolean to serialized record. Specified by: writeBool in interface RecordOutput Parameters:b - Boolean to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeInt public void writeInt(int i,             String tag)               throws IOException Deprecated.  Description copied from interface: RecordOutput Write an integer to serialized record. Specified by: writeInt in interface RecordOutput Parameters:i - Integer to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeLong public void writeLong(long l,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Write a long integer to serialized record. Specified by: writeLong in interface RecordOutput Parameters:l - Long to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeFloat public void writeFloat(float f,               String tag)                 throws IOException Deprecated.  Description copied from interface: RecordOutput Write a single-precision float to serialized record. Specified by: writeFloat in interface RecordOutput Parameters:f - Float to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeDouble public void writeDouble(double d,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Write a double precision floating point number to serialized record. Specified by: writeDouble in interface RecordOutput Parameters:d - Double to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeString public void writeString(String s,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Write a unicode string to serialized record. Specified by: writeString in interface RecordOutput Parameters:s - String to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeBuffer public void writeBuffer(Buffer buf,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Write a buffer to serialized record. Specified by: writeBuffer in interface RecordOutput Parameters:buf - Buffer to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startRecord public void startRecord(Record r,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the start of a record to be serialized. Specified by: startRecord in interface RecordOutput Parameters:r - Record to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endRecord public void endRecord(Record r,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the end of a serialized record. Specified by: endRecord in interface RecordOutput Parameters:r - Record to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startVector public void startVector(ArrayList v,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the start of a vector to be serialized. Specified by: startVector in interface RecordOutput Parameters:v - Vector to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endVector public void endVector(ArrayList v,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the end of a serialized vector. Specified by: endVector in interface RecordOutput Parameters:v - Vector to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startMap public void startMap(TreeMap v,             String tag)               throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the start of a map to be serialized. Specified by: startMap in interface RecordOutput Parameters:v - Map to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endMap public void endMap(TreeMap v,           String tag)             throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the end of a serialized map. Specified by: endMap in interface RecordOutput Parameters:v - Map to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DBConfiguration (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DBConfiguration (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class DBConfiguration java.lang.Object org.apache.hadoop.mapreduce.lib.db.DBConfiguration Direct Known Subclasses: DBConfiguration @InterfaceAudience.Public @InterfaceStability.Stable public class DBConfiguration extends Object A container for configuration property names for jobs with DB input/output.     The job can be configured using the static methods in this class,   DBInputFormat, and DBOutputFormat.   Alternatively, the properties can be set in the configuration with proper  values. See Also:configureDB(Configuration, String, String, String, String),  DBInputFormat.setInput(Job, Class, String, String),  DBInputFormat.setInput(Job, Class, String, String, String, String...),  DBOutputFormat.setOutput(Job, String, String...) Field Summary Fields  Modifier and Type Field and Description static String DRIVER_CLASS_PROPERTY The JDBC Driver class name static String INPUT_BOUNDING_QUERY Input query to get the max and min values of the jdbc.input.query static String INPUT_CLASS_PROPERTY Class name implementing DBWritable which will hold input tuples static String INPUT_CONDITIONS_PROPERTY WHERE clause in the input SELECT statement static String INPUT_COUNT_QUERY Input query to get the count of records static String INPUT_FIELD_NAMES_PROPERTY Field names in the Input table static String INPUT_ORDER_BY_PROPERTY ORDER BY clause in the input SELECT statement static String INPUT_QUERY Whole input query, exluding LIMIT...OFFSET static String INPUT_TABLE_NAME_PROPERTY Input table name static String OUTPUT_FIELD_COUNT_PROPERTY Number of fields in the Output table static String OUTPUT_FIELD_NAMES_PROPERTY Field names in the Output table static String OUTPUT_TABLE_NAME_PROPERTY Output table name static String PASSWORD_PROPERTY Password to access the database static String URL_PROPERTY JDBC Database access URL static String USERNAME_PROPERTY User name to access the database Constructor Summary Constructors  Constructor and Description DBConfiguration(Configuration job)  Method Summary Methods  Modifier and Type Method and Description static void configureDB(Configuration job,                       String driverClass,                       String dbUrl) Sets the DB access related fields in the JobConf. static void configureDB(Configuration conf,                       String driverClass,                       String dbUrl,                       String userName,                       String passwd) Sets the DB access related fields in the Configuration. Configuration getConf()  Connection getConnection() Returns a connection object o the DB String getInputBoundingQuery()  Class<?> getInputClass()  String getInputConditions()  String getInputCountQuery()  String[] getInputFieldNames()  String getInputOrderBy()  String getInputQuery()  String getInputTableName()  int getOutputFieldCount()  String[] getOutputFieldNames()  String getOutputTableName()  void setInputBoundingQuery(String query)  void setInputClass(Class<? extends DBWritable> inputClass)  void setInputConditions(String conditions)  void setInputCountQuery(String query)  void setInputFieldNames(String... fieldNames)  void setInputOrderBy(String orderby)  void setInputQuery(String query)  void setInputTableName(String tableName)  void setOutputFieldCount(int fieldCount)  void setOutputFieldNames(String... fieldNames)  void setOutputTableName(String tableName)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail DRIVER_CLASS_PROPERTY public static final String DRIVER_CLASS_PROPERTY The JDBC Driver class name See Also:Constant Field Values URL_PROPERTY public static final String URL_PROPERTY JDBC Database access URL See Also:Constant Field Values USERNAME_PROPERTY public static final String USERNAME_PROPERTY User name to access the database See Also:Constant Field Values PASSWORD_PROPERTY public static final String PASSWORD_PROPERTY Password to access the database See Also:Constant Field Values INPUT_TABLE_NAME_PROPERTY public static final String INPUT_TABLE_NAME_PROPERTY Input table name See Also:Constant Field Values INPUT_FIELD_NAMES_PROPERTY public static final String INPUT_FIELD_NAMES_PROPERTY Field names in the Input table See Also:Constant Field Values INPUT_CONDITIONS_PROPERTY public static final String INPUT_CONDITIONS_PROPERTY WHERE clause in the input SELECT statement See Also:Constant Field Values INPUT_ORDER_BY_PROPERTY public static final String INPUT_ORDER_BY_PROPERTY ORDER BY clause in the input SELECT statement See Also:Constant Field Values INPUT_QUERY public static final String INPUT_QUERY Whole input query, exluding LIMIT...OFFSET See Also:Constant Field Values INPUT_COUNT_QUERY public static final String INPUT_COUNT_QUERY Input query to get the count of records See Also:Constant Field Values INPUT_BOUNDING_QUERY public static final String INPUT_BOUNDING_QUERY Input query to get the max and min values of the jdbc.input.query See Also:Constant Field Values INPUT_CLASS_PROPERTY public static final String INPUT_CLASS_PROPERTY Class name implementing DBWritable which will hold input tuples See Also:Constant Field Values OUTPUT_TABLE_NAME_PROPERTY public static final String OUTPUT_TABLE_NAME_PROPERTY Output table name See Also:Constant Field Values OUTPUT_FIELD_NAMES_PROPERTY public static final String OUTPUT_FIELD_NAMES_PROPERTY Field names in the Output table See Also:Constant Field Values OUTPUT_FIELD_COUNT_PROPERTY public static final String OUTPUT_FIELD_COUNT_PROPERTY Number of fields in the Output table See Also:Constant Field Values Constructor Detail DBConfiguration public DBConfiguration(Configuration job) Method Detail configureDB public static void configureDB(Configuration conf,                String driverClass,                String dbUrl,                String userName,                String passwd) Sets the DB access related fields in the Configuration. Parameters:conf - the configurationdriverClass - JDBC Driver class namedbUrl - JDBC DB access URL.userName - DB access usernamepasswd - DB access passwd configureDB public static void configureDB(Configuration job,                String driverClass,                String dbUrl) Sets the DB access related fields in the JobConf. Parameters:job - the jobdriverClass - JDBC Driver class namedbUrl - JDBC DB access URL. getConnection public Connection getConnection()                          throws ClassNotFoundException,                                 SQLException Returns a connection object o the DB Throws: ClassNotFoundException SQLException getConf public Configuration getConf() getInputTableName public String getInputTableName() setInputTableName public void setInputTableName(String tableName) getInputFieldNames public String[] getInputFieldNames() setInputFieldNames public void setInputFieldNames(String... fieldNames) getInputConditions public String getInputConditions() setInputConditions public void setInputConditions(String conditions) getInputOrderBy public String getInputOrderBy() setInputOrderBy public void setInputOrderBy(String orderby) getInputQuery public String getInputQuery() setInputQuery public void setInputQuery(String query) getInputCountQuery public String getInputCountQuery() setInputCountQuery public void setInputCountQuery(String query) setInputBoundingQuery public void setInputBoundingQuery(String query) getInputBoundingQuery public String getInputBoundingQuery() getInputClass public Class<?> getInputClass() setInputClass public void setInputClass(Class<? extends DBWritable> inputClass) getOutputTableName public String getOutputTableName() setOutputTableName public void setOutputTableName(String tableName) getOutputFieldNames public String[] getOutputFieldNames() setOutputFieldNames public void setOutputFieldNames(String... fieldNames) setOutputFieldCount public void setOutputFieldCount(int fieldCount) getOutputFieldCount public int getOutputFieldCount() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DBInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DBInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class DBInputFormat<T extends DBWritable> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<LongWritable,T> org.apache.hadoop.mapreduce.lib.db.DBInputFormat<T> All Implemented Interfaces: Configurable Direct Known Subclasses: DataDrivenDBInputFormat, DBInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class DBInputFormat<T extends DBWritable> extends InputFormat<LongWritable,T> implements Configurable A InputFormat that reads input data from an SQL table.    DBInputFormat emits LongWritables containing the record number as   key and DBWritables as value.     The SQL query, and input class can be using one of the two   setInput methods. Field Summary Fields  Modifier and Type Field and Description protected String conditions  protected Connection connection  protected DBConfiguration dbConf  protected String dbProductName  protected String[] fieldNames  protected String tableName  Constructor Summary Constructors  Constructor and Description DBInputFormat()  Method Summary Methods  Modifier and Type Method and Description protected void closeConnection()  Connection createConnection()  protected RecordReader<LongWritable,T> createDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                         Configuration conf)  RecordReader<LongWritable,T> createRecordReader(InputSplit split,                                     TaskAttemptContext context) Create a record reader for a given split. Configuration getConf() Return the configuration used by this object. Connection getConnection()  protected String getCountQuery() Returns the query for getting the total number of rows,   subclasses can override this for custom behaviour. DBConfiguration getDBConf()  String getDBProductName()  List<InputSplit> getSplits(JobContext job) Logically split the set of input files for the job. void setConf(Configuration conf) Set the configuration to be used by this object. static void setInput(Job job,                 Class<? extends DBWritable> inputClass,                 String inputQuery,                 String inputCountQuery) Initializes the map-part of the job with the appropriate input settings. static void setInput(Job job,                 Class<? extends DBWritable> inputClass,                 String tableName,                 String conditions,                 String orderBy,                 String... fieldNames) Initializes the map-part of the job with the appropriate input settings. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail dbProductName protected String dbProductName conditions protected String conditions connection protected Connection connection tableName protected String tableName fieldNames protected String[] fieldNames dbConf protected DBConfiguration dbConf Constructor Detail DBInputFormat public DBInputFormat() Method Detail setConf public void setConf(Configuration conf) Set the configuration to be used by this object. Specified by: setConf in interface Configurable getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable getDBConf public DBConfiguration getDBConf() getConnection public Connection getConnection() createConnection public Connection createConnection() getDBProductName public String getDBProductName() createDBRecordReader protected RecordReader<LongWritable,T> createDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                                 Configuration conf)                                                                         throws IOException Throws: IOException createRecordReader public RecordReader<LongWritable,T> createRecordReader(InputSplit split,                                               TaskAttemptContext context)                                                                    throws IOException,                                                                           InterruptedException Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Specified by: createRecordReader in class InputFormat<LongWritable,T extends DBWritable> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException InterruptedException getSplits public List<InputSplit> getSplits(JobContext job)                            throws IOException Logically split the set of input files for the job.      Each InputSplit is then assigned to an individual Mapper  for processing.  Note: The split is a logical split of the inputs and the  input files are not physically split into chunks. For e.g. a split could  be <input-file-path, start, offset> tuple. The InputFormat  also creates the RecordReader to read the InputSplit. Specified by: getSplits in class InputFormat<LongWritable,T extends DBWritable> Parameters:job - job configuration. Returns:an array of InputSplits for the job. Throws: IOException getCountQuery protected String getCountQuery() Returns the query for getting the total number of rows,   subclasses can override this for custom behaviour. setInput public static void setInput(Job job,             Class<? extends DBWritable> inputClass,             String tableName,             String conditions,             String orderBy,             String... fieldNames) Initializes the map-part of the job with the appropriate input settings. Parameters:job - The map-reduce jobinputClass - the class object implementing DBWritable, which is the   Java object holding tuple fields.tableName - The table to read data fromconditions - The condition which to select data with,   eg. '(updated > 20070101 AND length > 0)'orderBy - the fieldNames in the orderBy clause.fieldNames - The field names in the tableSee Also:setInput(Job, Class, String, String) setInput public static void setInput(Job job,             Class<? extends DBWritable> inputClass,             String inputQuery,             String inputCountQuery) Initializes the map-part of the job with the appropriate input settings. Parameters:job - The map-reduce jobinputClass - the class object implementing DBWritable, which is the   Java object holding tuple fields.inputQuery - the input query to select fields. Example :   "SELECT f1, f2, f3 FROM Mytable ORDER BY f1"inputCountQuery - the input query that returns   the number of records in the table.   Example : "SELECT COUNT(f1) FROM Mytable"See Also:setInput(Job, Class, String, String, String, String...) closeConnection protected void closeConnection() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DBOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DBOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class DBOutputFormat<K extends DBWritable,V> java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> org.apache.hadoop.mapreduce.lib.db.DBOutputFormat<K,V> Direct Known Subclasses: DBOutputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class DBOutputFormat<K extends DBWritable,V> extends OutputFormat<K,V> A OutputFormat that sends the reduce output to a SQL table.     DBOutputFormat accepts <key,value> pairs, where   key has a type extending DBWritable. Returned RecordWriter   writes only the key to the database with a batch SQL query. Constructor Summary Constructors  Constructor and Description DBOutputFormat()  Method Summary Methods  Modifier and Type Method and Description void checkOutputSpecs(JobContext context) Check for validity of the output-specification for the job. String constructQuery(String table,                             String[] fieldNames) Constructs the query used as the prepared statement to insert data. OutputCommitter getOutputCommitter(TaskAttemptContext context) Get the output committer for this output format. RecordWriter<K,V> getRecordWriter(TaskAttemptContext context) Get the RecordWriter for the given task. static void setOutput(Job job,                   String tableName,                   int fieldCount) Initializes the reduce-part of the job   with the appropriate output settings static void setOutput(Job job,                   String tableName,                   String... fieldNames) Initializes the reduce-part of the job with   the appropriate output settings Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail DBOutputFormat public DBOutputFormat() Method Detail checkOutputSpecs public void checkOutputSpecs(JobContext context)                       throws IOException,                              InterruptedException Description copied from class: OutputFormat Check for validity of the output-specification for the job.     This is to validate the output specification for the job when it is  a job is submitted.  Typically checks that it does not already exist,  throwing an exception when it already exists, so that output is not  overwritten. Specified by: checkOutputSpecs in class OutputFormat<K extends DBWritable,V> Parameters:context - information about the job Throws: IOException - when output should not be attempted InterruptedException getOutputCommitter public OutputCommitter getOutputCommitter(TaskAttemptContext context)                                    throws IOException,                                           InterruptedException Description copied from class: OutputFormat Get the output committer for this output format. This is responsible  for ensuring the output is committed correctly. Specified by: getOutputCommitter in class OutputFormat<K extends DBWritable,V> Parameters:context - the task context Returns:an output committer Throws: IOException InterruptedException constructQuery public String constructQuery(String table,                     String[] fieldNames) Constructs the query used as the prepared statement to insert data. Parameters:table - the table to insert intofieldNames - the fields to insert into. If field names are unknown, supply an           array of nulls. getRecordWriter public RecordWriter<K,V> getRecordWriter(TaskAttemptContext context)                                                      throws IOException Get the RecordWriter for the given task. Specified by: getRecordWriter in class OutputFormat<K extends DBWritable,V> Parameters:context - the information about the current task. Returns:a RecordWriter to write the output for the job. Throws: IOException setOutput public static void setOutput(Job job,              String tableName,              String... fieldNames)                       throws IOException Initializes the reduce-part of the job with   the appropriate output settings Parameters:job - The jobtableName - The table to insert data intofieldNames - The field names in the table. Throws: IOException setOutput public static void setOutput(Job job,              String tableName,              int fieldCount)                       throws IOException Initializes the reduce-part of the job   with the appropriate output settings Parameters:job - The jobtableName - The table to insert data intofieldCount - the number of fields in the table. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DBRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DBRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class DBRecordReader<T extends DBWritable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<LongWritable,T> org.apache.hadoop.mapreduce.lib.db.DBRecordReader<T> All Implemented Interfaces: Closeable, AutoCloseable Direct Known Subclasses: DataDrivenDBRecordReader, MySQLDBRecordReader, OracleDBRecordReader @InterfaceAudience.Public @InterfaceStability.Evolving public class DBRecordReader<T extends DBWritable> extends RecordReader<LongWritable,T> A RecordReader that reads records from a SQL table.  Emits LongWritables containing the record number as   key and DBWritables as value. Field Summary Fields  Modifier and Type Field and Description protected PreparedStatement statement  Constructor Summary Constructors  Constructor and Description DBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                             Class<T> inputClass,                             Configuration conf,                             Connection conn,                             DBConfiguration dbConfig,                             String cond,                             String[] fields,                             String table)  Method Summary Methods  Modifier and Type Method and Description void close() Close the record reader. T createValue() Deprecated.   protected ResultSet executeQuery(String query)  protected String getConditions()  protected Connection getConnection()  LongWritable getCurrentKey() Get the current key T getCurrentValue() Get the current value. protected DBConfiguration getDBConf()  protected String[] getFieldNames()  long getPos() Deprecated.   float getProgress() The current progress of the record reader through its data. protected String getSelectQuery() Returns the query for selecting the records,   subclasses can override this for custom behaviour. protected org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit getSplit()  protected PreparedStatement getStatement()  protected String getTableName()  void initialize(InputSplit split,                     TaskAttemptContext context) Called once at initialization. boolean next(LongWritable key,         T value) Deprecated.  Use nextKeyValue() boolean nextKeyValue() Read the next key, value pair. protected void setStatement(PreparedStatement stmt)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail statement protected PreparedStatement statement Constructor Detail DBRecordReader public DBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,               Class<T> inputClass,               Configuration conf,               Connection conn,               DBConfiguration dbConfig,               String cond,               String[] fields,               String table)                throws SQLException Parameters:split - The InputSplit to read data for Throws: SQLException Method Detail executeQuery protected ResultSet executeQuery(String query)                           throws SQLException Throws: SQLException getSelectQuery protected String getSelectQuery() Returns the query for selecting the records,   subclasses can override this for custom behaviour. close public void close()            throws IOException Close the record reader. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in class RecordReader<LongWritable,T extends DBWritable> Throws: IOException initialize public void initialize(InputSplit split,               TaskAttemptContext context)                 throws IOException,                        InterruptedException Description copied from class: RecordReader Called once at initialization. Specified by: initialize in class RecordReader<LongWritable,T extends DBWritable> Parameters:split - the split that defines the range of records to readcontext - the information about the task Throws: IOException InterruptedException getCurrentKey public LongWritable getCurrentKey() Get the current key Specified by: getCurrentKey in class RecordReader<LongWritable,T extends DBWritable> Returns:the current key or null if there is no current key getCurrentValue public T getCurrentValue() Get the current value. Specified by: getCurrentValue in class RecordReader<LongWritable,T extends DBWritable> Returns:the object that was read createValue @Deprecated public T createValue() Deprecated.  getPos @Deprecated public long getPos()             throws IOException Deprecated.  Throws: IOException next @Deprecated public boolean next(LongWritable key,                       T value)              throws IOException Deprecated. Use nextKeyValue() Throws: IOException getProgress public float getProgress()                   throws IOException The current progress of the record reader through its data. Specified by: getProgress in class RecordReader<LongWritable,T extends DBWritable> Returns:a number between 0.0 and 1.0 that is the fraction of the data read Throws: IOException nextKeyValue public boolean nextKeyValue()                      throws IOException Read the next key, value pair. Specified by: nextKeyValue in class RecordReader<LongWritable,T extends DBWritable> Returns:true if a key/value pair was read Throws: IOException getSplit protected org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit getSplit() getFieldNames protected String[] getFieldNames() getTableName protected String getTableName() getConditions protected String getConditions() getDBConf protected DBConfiguration getDBConf() getConnection protected Connection getConnection() getStatement protected PreparedStatement getStatement() setStatement protected void setStatement(PreparedStatement stmt) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DBSplitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DBSplitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Interface DBSplitter All Known Implementing Classes: BigDecimalSplitter, BooleanSplitter, DateSplitter, FloatSplitter, IntegerSplitter, OracleDateSplitter, TextSplitter @InterfaceAudience.Public @InterfaceStability.Evolving public interface DBSplitter DBSplitter will generate DBInputSplits to use with DataDrivenDBInputFormat.  DataDrivenDBInputFormat needs to interpolate between two values that  represent the lowest and highest valued records to import. Depending  on the data-type of the column, this requires different behavior.  DBSplitter implementations should perform this for a data type or family  of data types. Method Summary Methods  Modifier and Type Method and Description List<InputSplit> split(Configuration conf,           ResultSet results,           String colName) Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Method Detail split List<InputSplit> split(Configuration conf,                      ResultSet results,                      String colName)                        throws SQLException Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DBWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DBWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Interface DBWritable All Known Subinterfaces: DBWritable @InterfaceAudience.Public @InterfaceStability.Stable public interface DBWritable Objects that are read from/written to a database should implement  DBWritable. DBWritable, is similar to Writable   except that the write(PreparedStatement) method takes a   PreparedStatement, and readFields(ResultSet)   takes a ResultSet.     Implementations are responsible for writing the fields of the object   to PreparedStatement, and reading the fields of the object from the   ResultSet.     Example:  If we have the following table in the database :    CREATE TABLE MyTable (    counter        INTEGER NOT NULL,    timestamp      BIGINT  NOT NULL,  );    then we can read/write the tuples from/to the table with :    public class MyWritable implements Writable, DBWritable {    // Some data         private int counter;    private long timestamp;            //Writable#write() implementation    public void write(DataOutput out) throws IOException {      out.writeInt(counter);      out.writeLong(timestamp);    }            //Writable#readFields() implementation    public void readFields(DataInput in) throws IOException {      counter = in.readInt();      timestamp = in.readLong();    }            public void write(PreparedStatement statement) throws SQLException {      statement.setInt(1, counter);      statement.setLong(2, timestamp);    }            public void readFields(ResultSet resultSet) throws SQLException {      counter = resultSet.getInt(1);      timestamp = resultSet.getLong(2);    }   }   Method Summary Methods  Modifier and Type Method and Description void readFields(ResultSet resultSet) Reads the fields of the object from the ResultSet. void write(PreparedStatement statement) Sets the fields of the object in the PreparedStatement. Method Detail write void write(PreparedStatement statement)            throws SQLException Sets the fields of the object in the PreparedStatement. Parameters:statement - the statement that the fields are put into. Throws: SQLException readFields void readFields(ResultSet resultSet)                 throws SQLException Reads the fields of the object from the ResultSet. Parameters:resultSet - the ResultSet to get the fields from. Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DNSToSwitchMapping (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DNSToSwitchMapping (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.net Interface DNSToSwitchMapping All Known Implementing Classes: AbstractDNSToSwitchMapping, CachedDNSToSwitchMapping, ScriptBasedMapping, TableMapping @InterfaceAudience.Public @InterfaceStability.Evolving public interface DNSToSwitchMapping An interface that must be implemented to allow pluggable  DNS-name/IP-address to RackID resolvers. Method Summary Methods  Modifier and Type Method and Description void reloadCachedMappings() Reload all of the cached mappings. void reloadCachedMappings(List<String> names) Reload cached mappings on specific nodes. List<String> resolve(List<String> names) Resolves a list of DNS-names/IP-addresses and returns back a list of  switch information (network paths). Method Detail resolve List<String> resolve(List<String> names) Resolves a list of DNS-names/IP-addresses and returns back a list of  switch information (network paths). One-to-one correspondence must be   maintained between the elements in the lists.   Consider an element in the argument list - x.y.com. The switch information  that is returned must be a network path of the form /foo/rack,   where / is the root, and 'foo' is the switch where 'rack' is connected.  Note the hostname/ip-address is not part of the returned path.  The network topology of the cluster would determine the number of  components in the network path.    If a name cannot be resolved to a rack, the implementation  should return NetworkTopology.DEFAULT_RACK. This  is what the bundled implementations do, though it is not a formal requirement Parameters:names - the list of hosts to resolve (can be empty) Returns:list of resolved network paths.  If names is empty, the returned list is also empty reloadCachedMappings void reloadCachedMappings() Reload all of the cached mappings.  If there is a cache, this method will clear it, so that future accesses  will get a chance to see the new data. reloadCachedMappings void reloadCachedMappings(List<String> names) Reload cached mappings on specific nodes.  If there is a cache on these nodes, this method will clear it, so that   future accesses will see updated data. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DSConstants (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DSConstants (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.applications.distributedshell Class DSConstants java.lang.Object org.apache.hadoop.yarn.applications.distributedshell.DSConstants @InterfaceAudience.Public @InterfaceStability.Unstable public class DSConstants extends Object Constants used in both Client and Application Master Field Summary Fields  Modifier and Type Field and Description static String DISTRIBUTEDSHELLSCRIPTLEN Environment key name denoting the file content length for the shell script. static String DISTRIBUTEDSHELLSCRIPTLOCATION Environment key name pointing to the shell script's location static String DISTRIBUTEDSHELLSCRIPTTIMESTAMP Environment key name denoting the file timestamp for the shell script. static String DISTRIBUTEDSHELLTIMELINEDOMAIN Environment key name denoting the timeline domain ID. Constructor Summary Constructors  Constructor and Description DSConstants()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail DISTRIBUTEDSHELLSCRIPTLOCATION public static final String DISTRIBUTEDSHELLSCRIPTLOCATION Environment key name pointing to the shell script's location See Also:Constant Field Values DISTRIBUTEDSHELLSCRIPTTIMESTAMP public static final String DISTRIBUTEDSHELLSCRIPTTIMESTAMP Environment key name denoting the file timestamp for the shell script.   Used to validate the local resource. See Also:Constant Field Values DISTRIBUTEDSHELLSCRIPTLEN public static final String DISTRIBUTEDSHELLSCRIPTLEN Environment key name denoting the file content length for the shell script.   Used to validate the local resource. See Also:Constant Field Values DISTRIBUTEDSHELLTIMELINEDOMAIN public static final String DISTRIBUTEDSHELLTIMELINEDOMAIN Environment key name denoting the timeline domain ID. See Also:Constant Field Values Constructor Detail DSConstants public DSConstants() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DataDrivenDBInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DataDrivenDBInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class DataDrivenDBInputFormat<T extends DBWritable> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<LongWritable,T> org.apache.hadoop.mapreduce.lib.db.DBInputFormat<T> org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat<T> All Implemented Interfaces: Configurable Direct Known Subclasses: OracleDataDrivenDBInputFormat @InterfaceAudience.Public @InterfaceStability.Evolving public class DataDrivenDBInputFormat<T extends DBWritable> extends DBInputFormat<T> implements Configurable A InputFormat that reads input data from an SQL table.  Operates like DBInputFormat, but instead of using LIMIT and OFFSET to demarcate  splits, it tries to generate WHERE clauses which separate the data into roughly  equivalent shards. Field Summary Fields  Modifier and Type Field and Description static String SUBSTITUTE_TOKEN If users are providing their own query, the following string is expected to       appear in the WHERE clause, which will be substituted with a pair of conditions       on the input to allow input splits to parallelise the import. Fields inherited from class org.apache.hadoop.mapreduce.lib.db.DBInputFormat conditions, connection, dbConf, dbProductName, fieldNames, tableName Constructor Summary Constructors  Constructor and Description DataDrivenDBInputFormat()  Method Summary Methods  Modifier and Type Method and Description protected RecordReader<LongWritable,T> createDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                         Configuration conf)  protected String getBoundingValsQuery()  List<InputSplit> getSplits(JobContext job) Logically split the set of input files for the job. protected DBSplitter getSplitter(int sqlDataType)  static void setBoundingQuery(Configuration conf,                                 String query) Set the user-defined bounding query to use with a user-defined query. static void setInput(Job job,                 Class<? extends DBWritable> inputClass,                 String inputQuery,                 String inputBoundingQuery) setInput() takes a custom query and a separate "bounding query" to use       instead of the custom "count query" used by DBInputFormat. static void setInput(Job job,                 Class<? extends DBWritable> inputClass,                 String tableName,                 String conditions,                 String splitBy,                 String... fieldNames) Note that the "orderBy" column is called the "splitBy" in this version. Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DBInputFormat closeConnection, createConnection, createRecordReader, getConf, getConnection, getCountQuery, getDBConf, getDBProductName, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Field Detail SUBSTITUTE_TOKEN public static final String SUBSTITUTE_TOKEN If users are providing their own query, the following string is expected to       appear in the WHERE clause, which will be substituted with a pair of conditions       on the input to allow input splits to parallelise the import. See Also:Constant Field Values Constructor Detail DataDrivenDBInputFormat public DataDrivenDBInputFormat() Method Detail getSplitter protected DBSplitter getSplitter(int sqlDataType) Returns:the DBSplitter implementation to use to divide the table/query into InputSplits. getSplits public List<InputSplit> getSplits(JobContext job)                            throws IOException Logically split the set of input files for the job.      Each InputSplit is then assigned to an individual Mapper  for processing.  Note: The split is a logical split of the inputs and the  input files are not physically split into chunks. For e.g. a split could  be <input-file-path, start, offset> tuple. The InputFormat  also creates the RecordReader to read the InputSplit. Overrides: getSplits in class DBInputFormat<T extends DBWritable> Parameters:job - job configuration. Returns:an array of InputSplits for the job. Throws: IOException getBoundingValsQuery protected String getBoundingValsQuery() Returns:a query which returns the minimum and maximum values for  the order-by column.  The min value should be in the first column, and the  max value should be in the second column of the results. setBoundingQuery public static void setBoundingQuery(Configuration conf,                     String query) Set the user-defined bounding query to use with a user-defined query.       This *must* include the substring "$CONDITIONS"       (DataDrivenDBInputFormat.SUBSTITUTE_TOKEN) inside the WHERE clause,       so that DataDrivenDBInputFormat knows where to insert split clauses.       e.g., "SELECT foo FROM mytable WHERE $CONDITIONS"       This will be expanded to something like:         SELECT foo FROM mytable WHERE (id > 100) AND (id < 250)       inside each split. createDBRecordReader protected RecordReader<LongWritable,T> createDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                                 Configuration conf)                                                                         throws IOException Overrides: createDBRecordReader in class DBInputFormat<T extends DBWritable> Throws: IOException setInput public static void setInput(Job job,             Class<? extends DBWritable> inputClass,             String tableName,             String conditions,             String splitBy,             String... fieldNames) Note that the "orderBy" column is called the "splitBy" in this version.  We reuse the same field, but it's not strictly ordering it -- just partitioning  the results. setInput public static void setInput(Job job,             Class<? extends DBWritable> inputClass,             String inputQuery,             String inputBoundingQuery) setInput() takes a custom query and a separate "bounding query" to use       instead of the custom "count query" used by DBInputFormat. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DataDrivenDBRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DataDrivenDBRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class DataDrivenDBRecordReader<T extends DBWritable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<LongWritable,T> org.apache.hadoop.mapreduce.lib.db.DBRecordReader<T> org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader<T> All Implemented Interfaces: Closeable, AutoCloseable Direct Known Subclasses: MySQLDataDrivenDBRecordReader, OracleDataDrivenDBRecordReader @InterfaceAudience.Public @InterfaceStability.Evolving public class DataDrivenDBRecordReader<T extends DBWritable> extends DBRecordReader<T> A RecordReader that reads records from a SQL table,  using data-driven WHERE clause splits.  Emits LongWritables containing the record number as  key and DBWritables as value. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader statement Constructor Summary Constructors  Constructor and Description DataDrivenDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                                 Class<T> inputClass,                                                 Configuration conf,                                                 Connection conn,                                                 DBConfiguration dbConfig,                                                 String cond,                                                 String[] fields,                                                 String table,                                                 String dbProduct)  Method Summary Methods  Modifier and Type Method and Description protected String getSelectQuery() Returns the query for selecting the records,  subclasses can override this for custom behaviour. Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader close, createValue, executeQuery, getConditions, getConnection, getCurrentKey, getCurrentValue, getDBConf, getFieldNames, getPos, getProgress, getSplit, getStatement, getTableName, initialize, next, nextKeyValue, setStatement Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail DataDrivenDBRecordReader public DataDrivenDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                         Class<T> inputClass,                         Configuration conf,                         Connection conn,                         DBConfiguration dbConfig,                         String cond,                         String[] fields,                         String table,                         String dbProduct)                          throws SQLException Parameters:split - The InputSplit to read data for Throws: SQLException Method Detail getSelectQuery protected String getSelectQuery() Returns the query for selecting the records,  subclasses can override this for custom behaviour. Overrides: getSelectQuery in class DBRecordReader<T extends DBWritable> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DataOutputOutputStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DataOutputOutputStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class DataOutputOutputStream java.lang.Object java.io.OutputStream org.apache.hadoop.io.DataOutputOutputStream All Implemented Interfaces: Closeable, Flushable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Unstable public class DataOutputOutputStream extends OutputStream OutputStream implementation that wraps a DataOutput. Method Summary Methods  Modifier and Type Method and Description static OutputStream constructOutputStream(DataOutput out) Construct an OutputStream from the given DataOutput. void write(byte[] b)  void write(byte[] b,           int off,           int len)  void write(int b)  Methods inherited from class java.io.OutputStream close, flush Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail constructOutputStream public static OutputStream constructOutputStream(DataOutput out) Construct an OutputStream from the given DataOutput. If 'out'  is already an OutputStream, simply returns it. Otherwise, wraps  it in an OutputStream. Parameters:out - the DataOutput to wrap Returns:an OutputStream instance that outputs to 'out' write public void write(int b)            throws IOException Specified by: write in class OutputStream Throws: IOException write public void write(byte[] b,          int off,          int len)            throws IOException Overrides: write in class OutputStream Throws: IOException write public void write(byte[] b)            throws IOException Overrides: write in class OutputStream Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DateSplitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DateSplitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class DateSplitter java.lang.Object org.apache.hadoop.mapreduce.lib.db.IntegerSplitter org.apache.hadoop.mapreduce.lib.db.DateSplitter All Implemented Interfaces: DBSplitter Direct Known Subclasses: OracleDateSplitter @InterfaceAudience.Public @InterfaceStability.Evolving public class DateSplitter extends IntegerSplitter Implement DBSplitter over date/time values.  Make use of logic from IntegerSplitter, since date/time are just longs  in Java. Constructor Summary Constructors  Constructor and Description DateSplitter()  Method Summary Methods  Modifier and Type Method and Description protected String dateToString(Date d) Given a Date 'd', format it as a string for use in a SQL date  comparison operation. List<InputSplit> split(Configuration conf,           ResultSet results,           String colName) Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail DateSplitter public DateSplitter() Method Detail split public List<InputSplit> split(Configuration conf,                      ResultSet results,                      String colName)                        throws SQLException Description copied from interface: DBSplitter Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Specified by: split in interface DBSplitter Overrides: split in class IntegerSplitter Throws: SQLException dateToString protected String dateToString(Date d) Given a Date 'd', format it as a string for use in a SQL date  comparison operation. Parameters:d - the date to format. Returns:the string representing this date in SQL with any appropriate  quotation characters, etc. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Decompressor (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Decompressor (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Interface Decompressor @InterfaceAudience.Public @InterfaceStability.Evolving public interface Decompressor Specification of a stream-based 'de-compressor' which can be    plugged into a CompressionInputStream to compress data.  This is modelled after Inflater Method Summary Methods  Modifier and Type Method and Description int decompress(byte[] b,                     int off,                     int len) Fills specified buffer with uncompressed data. void end() Closes the decompressor and discards any unprocessed input. boolean finished() Returns true if the end of the decompressed   data output stream has been reached. int getRemaining() Returns the number of bytes remaining in the compressed data buffer. boolean needsDictionary() Returns true if a preset dictionary is needed for decompression. boolean needsInput() Returns true if the input data buffer is empty and   setInput(byte[], int, int) should be called to  provide more input. void reset() Resets decompressor and input and output buffers so that a new set of  input data can be processed. void setDictionary(byte[] b,                           int off,                           int len) Sets preset dictionary for compression. void setInput(byte[] b,                 int off,                 int len) Sets input data for decompression. Method Detail setInput void setInput(byte[] b,             int off,             int len) Sets input data for decompression.   This should be called if and only if needsInput() returns   true indicating that more input data is required.  (Both native and non-native versions of various Decompressors require  that the data passed in via b[] remain unmodified until  the caller is explicitly notified--via needsInput()--that the  buffer may be safely modified.  With this requirement, an extra  buffer-copy can be avoided.) Parameters:b - Input dataoff - Start offsetlen - Length needsInput boolean needsInput() Returns true if the input data buffer is empty and   setInput(byte[], int, int) should be called to  provide more input. Returns:true if the input data buffer is empty and   setInput(byte[], int, int) should be called in  order to provide more input. setDictionary void setDictionary(byte[] b,                  int off,                  int len) Sets preset dictionary for compression. A preset dictionary  is used when the history buffer can be predetermined. Parameters:b - Dictionary data bytesoff - Start offsetlen - Length needsDictionary boolean needsDictionary() Returns true if a preset dictionary is needed for decompression. Returns:true if a preset dictionary is needed for decompression finished boolean finished() Returns true if the end of the decompressed   data output stream has been reached. Indicates a concatenated data stream  when finished() returns true and getRemaining()  returns a positive value. finished() will be reset with the  reset() method. Returns:true if the end of the decompressed  data output stream has been reached. decompress int decompress(byte[] b,              int off,              int len)                throws IOException Fills specified buffer with uncompressed data. Returns actual number  of bytes of uncompressed data. A return value of 0 indicates that  needsInput() should be called in order to determine if more  input data is required. Parameters:b - Buffer for the compressed dataoff - Start offset of the datalen - Size of the buffer Returns:The actual number of bytes of compressed data. Throws: IOException getRemaining int getRemaining() Returns the number of bytes remaining in the compressed data buffer.  Indicates a concatenated data stream if finished() returns  true and getRemaining() returns a positive value. If  finished() returns true and getRemaining() returns  a zero value, indicates that the end of data stream has been reached and  is not a concatenated data stream. Returns:The number of bytes remaining in the compressed data buffer. reset void reset() Resets decompressor and input and output buffers so that a new set of  input data can be processed. If finished()} returns  true and getRemaining() returns a positive value,  reset() is called before processing of the next data stream in the  concatenated data stream. finished() will be reset and will  return false when reset() is called. end void end() Closes the decompressor and discards any unprocessed input. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DecompressorStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DecompressorStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class DecompressorStream java.lang.Object java.io.InputStream org.apache.hadoop.io.compress.CompressionInputStream org.apache.hadoop.io.compress.DecompressorStream All Implemented Interfaces: Closeable, AutoCloseable, Seekable Direct Known Subclasses: BlockDecompressorStream @InterfaceAudience.Public @InterfaceStability.Evolving public class DecompressorStream extends CompressionInputStream Field Summary Fields  Modifier and Type Field and Description protected byte[] buffer  protected boolean closed  protected Decompressor decompressor  protected boolean eof  Fields inherited from class org.apache.hadoop.io.compress.CompressionInputStream in, maxAvailableData Constructor Summary Constructors  Modifier Constructor and Description protected  DecompressorStream(InputStream in) Allow derived classes to directly set the underlying stream.   DecompressorStream(InputStream in,                                     Decompressor decompressor)    DecompressorStream(InputStream in,                                     Decompressor decompressor,                                     int bufferSize)  Method Summary Methods  Modifier and Type Method and Description int available()  protected void checkStream()  void close()  protected int decompress(byte[] b,                     int off,                     int len)  protected int getCompressedData()  void mark(int readlimit)  boolean markSupported()  int read()  int read(byte[] b,         int off,         int len) Read bytes from the stream. void reset()  void resetState() Reset the decompressor to its initial state and discard any buffered data,  as the underlying stream may have been repositioned. long skip(long n)  Methods inherited from class org.apache.hadoop.io.compress.CompressionInputStream getPos, seek, seekToNewSource Methods inherited from class java.io.InputStream read Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail decompressor protected Decompressor decompressor buffer protected byte[] buffer eof protected boolean eof closed protected boolean closed Constructor Detail DecompressorStream public DecompressorStream(InputStream in,                   Decompressor decompressor,                   int bufferSize)                    throws IOException Throws: IOException DecompressorStream public DecompressorStream(InputStream in,                   Decompressor decompressor)                    throws IOException Throws: IOException DecompressorStream protected DecompressorStream(InputStream in)                       throws IOException Allow derived classes to directly set the underlying stream. Parameters:in - Underlying input stream. Throws: IOException Method Detail read public int read()          throws IOException Specified by: read in class InputStream Throws: IOException read public int read(byte[] b,        int off,        int len)          throws IOException Description copied from class: CompressionInputStream Read bytes from the stream.  Made abstract to prevent leakage to underlying stream. Specified by: read in class CompressionInputStream Throws: IOException decompress protected int decompress(byte[] b,              int off,              int len)                   throws IOException Throws: IOException getCompressedData protected int getCompressedData()                          throws IOException Throws: IOException checkStream protected void checkStream()                     throws IOException Throws: IOException resetState public void resetState()                 throws IOException Description copied from class: CompressionInputStream Reset the decompressor to its initial state and discard any buffered data,  as the underlying stream may have been repositioned. Specified by: resetState in class CompressionInputStream Throws: IOException skip public long skip(long n)           throws IOException Overrides: skip in class InputStream Throws: IOException available public int available()               throws IOException Overrides: available in class InputStream Throws: IOException close public void close()            throws IOException Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Overrides: close in class CompressionInputStream Throws: IOException markSupported public boolean markSupported() Overrides: markSupported in class InputStream mark public void mark(int readlimit) Overrides: mark in class InputStream reset public void reset()            throws IOException Overrides: reset in class InputStream Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DefaultCodec (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DefaultCodec (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class DefaultCodec java.lang.Object org.apache.hadoop.io.compress.DefaultCodec All Implemented Interfaces: Configurable, CompressionCodec, DirectDecompressionCodec Direct Known Subclasses: GzipCodec @InterfaceAudience.Public @InterfaceStability.Evolving public class DefaultCodec extends Object implements Configurable, CompressionCodec, DirectDecompressionCodec Constructor Summary Constructors  Constructor and Description DefaultCodec()  Method Summary Methods  Modifier and Type Method and Description Compressor createCompressor() Create a new Compressor for use by this CompressionCodec. Decompressor createDecompressor() Create a new Decompressor for use by this CompressionCodec. DirectDecompressor createDirectDecompressor() Create a new DirectDecompressor for use by this DirectDecompressionCodec. CompressionInputStream createInputStream(InputStream in) Create a CompressionInputStream that will read from the given  input stream. CompressionInputStream createInputStream(InputStream in,                                   Decompressor decompressor) Create a CompressionInputStream that will read from the given   InputStream with the given Decompressor. CompressionOutputStream createOutputStream(OutputStream out) Create a CompressionOutputStream that will write to the given   OutputStream. CompressionOutputStream createOutputStream(OutputStream out,                                     Compressor compressor) Create a CompressionOutputStream that will write to the given   OutputStream with the given Compressor. Class<? extends Compressor> getCompressorType() Get the type of Compressor needed by this CompressionCodec. Configuration getConf() Return the configuration used by this object. Class<? extends Decompressor> getDecompressorType() Get the type of Decompressor needed by this CompressionCodec. String getDefaultExtension() Get the default filename extension for this kind of compression. void setConf(Configuration conf) Set the configuration to be used by this object. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail DefaultCodec public DefaultCodec() Method Detail setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable createOutputStream public CompressionOutputStream createOutputStream(OutputStream out)                                            throws IOException Description copied from interface: CompressionCodec Create a CompressionOutputStream that will write to the given   OutputStream. Specified by: createOutputStream in interface CompressionCodec Parameters:out - the location for the final output stream Returns:a stream the user can write uncompressed data to have it compressed Throws: IOException createOutputStream public CompressionOutputStream createOutputStream(OutputStream out,                                          Compressor compressor)                                            throws IOException Description copied from interface: CompressionCodec Create a CompressionOutputStream that will write to the given   OutputStream with the given Compressor. Specified by: createOutputStream in interface CompressionCodec Parameters:out - the location for the final output streamcompressor - compressor to use Returns:a stream the user can write uncompressed data to have it compressed Throws: IOException getCompressorType public Class<? extends Compressor> getCompressorType() Description copied from interface: CompressionCodec Get the type of Compressor needed by this CompressionCodec. Specified by: getCompressorType in interface CompressionCodec Returns:the type of compressor needed by this codec. createCompressor public Compressor createCompressor() Description copied from interface: CompressionCodec Create a new Compressor for use by this CompressionCodec. Specified by: createCompressor in interface CompressionCodec Returns:a new compressor for use by this codec createInputStream public CompressionInputStream createInputStream(InputStream in)                                          throws IOException Description copied from interface: CompressionCodec Create a CompressionInputStream that will read from the given  input stream. Specified by: createInputStream in interface CompressionCodec Parameters:in - the stream to read compressed bytes from Returns:a stream to read uncompressed bytes from Throws: IOException createInputStream public CompressionInputStream createInputStream(InputStream in,                                        Decompressor decompressor)                                          throws IOException Description copied from interface: CompressionCodec Create a CompressionInputStream that will read from the given   InputStream with the given Decompressor. Specified by: createInputStream in interface CompressionCodec Parameters:in - the stream to read compressed bytes fromdecompressor - decompressor to use Returns:a stream to read uncompressed bytes from Throws: IOException getDecompressorType public Class<? extends Decompressor> getDecompressorType() Description copied from interface: CompressionCodec Get the type of Decompressor needed by this CompressionCodec. Specified by: getDecompressorType in interface CompressionCodec Returns:the type of decompressor needed by this codec. createDecompressor public Decompressor createDecompressor() Description copied from interface: CompressionCodec Create a new Decompressor for use by this CompressionCodec. Specified by: createDecompressor in interface CompressionCodec Returns:a new decompressor for use by this codec createDirectDecompressor public DirectDecompressor createDirectDecompressor() Create a new DirectDecompressor for use by this DirectDecompressionCodec. Specified by: createDirectDecompressor in interface DirectDecompressionCodec Returns:a new direct decompressor for use by this codec getDefaultExtension public String getDefaultExtension() Description copied from interface: CompressionCodec Get the default filename extension for this kind of compression. Specified by: getDefaultExtension in interface CompressionCodec Returns:the extension including the '.' Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DefaultMetricsSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DefaultMetricsSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.metrics2.lib Enum DefaultMetricsSystem java.lang.Object java.lang.Enum<DefaultMetricsSystem> org.apache.hadoop.metrics2.lib.DefaultMetricsSystem All Implemented Interfaces: Serializable, Comparable<DefaultMetricsSystem> @InterfaceAudience.Public @InterfaceStability.Evolving public enum DefaultMetricsSystem extends Enum<DefaultMetricsSystem> The default metrics system singleton Enum Constant Summary Enum Constants  Enum Constant and Description INSTANCE  Method Summary Methods  Modifier and Type Method and Description static MetricsSystem initialize(String prefix) Convenience method to initialize the metrics system static MetricsSystem instance()  static void shutdown() Shutdown the metrics system static DefaultMetricsSystem valueOf(String name) Returns the enum constant of this type with the specified name. static DefaultMetricsSystem[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail INSTANCE public static final DefaultMetricsSystem INSTANCE Method Detail values public static DefaultMetricsSystem[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (DefaultMetricsSystem c : DefaultMetricsSystem.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static DefaultMetricsSystem valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null initialize public static MetricsSystem initialize(String prefix) Convenience method to initialize the metrics system Parameters:prefix - for the metrics system configuration Returns:the metrics system instance instance public static MetricsSystem instance() Returns:the metrics system object shutdown public static void shutdown() Shutdown the metrics system Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DefaultStringifier (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DefaultStringifier (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class DefaultStringifier<T> java.lang.Object org.apache.hadoop.io.DefaultStringifier<T> Type Parameters:T - the class of the objects to stringify All Implemented Interfaces: Closeable, AutoCloseable, Stringifier<T> @InterfaceAudience.Public @InterfaceStability.Stable public class DefaultStringifier<T> extends Object implements Stringifier<T> DefaultStringifier is the default implementation of the Stringifier  interface which stringifies the objects using base64 encoding of the  serialized version of the objects. The Serializer and  Deserializer are obtained from the SerializationFactory.    DefaultStringifier offers convenience methods to store/load objects to/from  the configuration. Constructor Summary Constructors  Constructor and Description DefaultStringifier(Configuration conf,                                     Class<T> c)  Method Summary Methods  Modifier and Type Method and Description void close() Closes this object. T fromString(String str) Restores the object from its string representation. static <K> K load(Configuration conf,         String keyName,         Class<K> itemClass) Restores the object from the configuration. static <K> K[] loadArray(Configuration conf,                   String keyName,                   Class<K> itemClass) Restores the array of objects from the configuration. static <K> void store(Configuration conf,           K item,           String keyName) Stores the item in the configuration with the given keyName. static <K> void storeArray(Configuration conf,                     K[] items,                     String keyName) Stores the array of items in the configuration with the given keyName. String toString(T obj) Converts the object to a string representation Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail DefaultStringifier public DefaultStringifier(Configuration conf,                   Class<T> c) Method Detail fromString public T fromString(String str)              throws IOException Description copied from interface: Stringifier Restores the object from its string representation. Specified by: fromString in interface Stringifier<T> Parameters:str - the string representation of the object Returns:restored object Throws: IOException - if the object cannot be restored toString public String toString(T obj)                 throws IOException Description copied from interface: Stringifier Converts the object to a string representation Specified by: toString in interface Stringifier<T> Parameters:obj - the object to convert Returns:the string representation of the object Throws: IOException - if the object cannot be converted close public void close()            throws IOException Description copied from interface: Stringifier Closes this object. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in interface Stringifier<T> Throws: IOException - if an I/O error occurs store public static <K> void store(Configuration conf,              K item,              String keyName)                   throws IOException Stores the item in the configuration with the given keyName. Type Parameters:K - the class of the itemParameters:conf - the configuration to storeitem - the object to be storedkeyName - the name of the key to use Throws: IOException - : forwards Exceptions from the underlying   Serialization classes. load public static <K> K load(Configuration conf,          String keyName,          Class<K> itemClass)               throws IOException Restores the object from the configuration. Type Parameters:K - the class of the itemParameters:conf - the configuration to usekeyName - the name of the key to useitemClass - the class of the item Returns:restored object Throws: IOException - : forwards Exceptions from the underlying   Serialization classes. storeArray public static <K> void storeArray(Configuration conf,                   K[] items,                   String keyName)                        throws IOException Stores the array of items in the configuration with the given keyName. Type Parameters:K - the class of the itemParameters:conf - the configuration to useitems - the objects to be storedkeyName - the name of the key to use Throws: IndexOutOfBoundsException - if the items array is empty IOException - : forwards Exceptions from the underlying   Serialization classes. loadArray public static <K> K[] loadArray(Configuration conf,                 String keyName,                 Class<K> itemClass)                      throws IOException Restores the array of objects from the configuration. Type Parameters:K - the class of the itemParameters:conf - the configuration to usekeyName - the name of the key to useitemClass - the class of the item Returns:restored object Throws: IOException - : forwards Exceptions from the underlying   Serialization classes. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DelegationTokenAuthenticatedURL.Token (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DelegationTokenAuthenticatedURL.Token (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.security.token.delegation.web Class DelegationTokenAuthenticatedURL.Token java.lang.Object org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL.Token Enclosing class: DelegationTokenAuthenticatedURL @InterfaceAudience.Public @InterfaceStability.Unstable public static class DelegationTokenAuthenticatedURL.Token extends org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token Client side authentication token that handles Delegation Tokens. Constructor Summary Constructors  Constructor and Description DelegationTokenAuthenticatedURL.Token()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken()  void setDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> delegationToken)  Methods inherited from class org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token isSet, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail DelegationTokenAuthenticatedURL.Token public DelegationTokenAuthenticatedURL.Token() Method Detail getDelegationToken public org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken() setDelegationToken public void setDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> delegationToken) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DelegationTokenAuthenticatedURL (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DelegationTokenAuthenticatedURL (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.security.token.delegation.web Class DelegationTokenAuthenticatedURL java.lang.Object org.apache.hadoop.security.authentication.client.AuthenticatedURL org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL @InterfaceAudience.Public @InterfaceStability.Unstable public class DelegationTokenAuthenticatedURL extends org.apache.hadoop.security.authentication.client.AuthenticatedURL The DelegationTokenAuthenticatedURL is a  AuthenticatedURL sub-class with built-in Hadoop Delegation Token  functionality.    The authentication mechanisms supported by default are Hadoop Simple  authentication (also known as pseudo authentication) and Kerberos SPNEGO  authentication.    Additional authentication mechanisms can be supported via DelegationTokenAuthenticator implementations.    The default DelegationTokenAuthenticator is the KerberosDelegationTokenAuthenticator class which supports  automatic fallback from Kerberos SPNEGO to Hadoop Simple authentication via  the PseudoDelegationTokenAuthenticator class.    AuthenticatedURL instances are not thread-safe. Nested Class Summary Nested Classes  Modifier and Type Class and Description static class  DelegationTokenAuthenticatedURL.Token Client side authentication token that handles Delegation Tokens. Field Summary Fields inherited from class org.apache.hadoop.security.authentication.client.AuthenticatedURL AUTH_COOKIE Constructor Summary Constructors  Constructor and Description DelegationTokenAuthenticatedURL() Creates an DelegationTokenAuthenticatedURL. DelegationTokenAuthenticatedURL(org.apache.hadoop.security.authentication.client.ConnectionConfigurator connConfigurator) Creates an DelegationTokenAuthenticatedURL using the default  DelegationTokenAuthenticator class. DelegationTokenAuthenticatedURL(DelegationTokenAuthenticator authenticator) Creates an DelegationTokenAuthenticatedURL. DelegationTokenAuthenticatedURL(DelegationTokenAuthenticator authenticator,                                                               org.apache.hadoop.security.authentication.client.ConnectionConfigurator connConfigurator) Creates an DelegationTokenAuthenticatedURL. Method Summary Methods  Modifier and Type Method and Description void cancelDelegationToken(URL url,                                           DelegationTokenAuthenticatedURL.Token token) Cancels a delegation token from the server end-point. void cancelDelegationToken(URL url,                                           DelegationTokenAuthenticatedURL.Token token,                                           String doAsUser) Cancels a delegation token from the server end-point. static Class<? extends DelegationTokenAuthenticator> getDefaultDelegationTokenAuthenticator() Returns the default DelegationTokenAuthenticator class to use when  an DelegationTokenAuthenticatedURL instance is created without  specifying one. org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken(URL url,                                     DelegationTokenAuthenticatedURL.Token token,                                     String renewer) Requests a delegation token using the configured Authenticator  for authentication. org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken(URL url,                                     DelegationTokenAuthenticatedURL.Token token,                                     String renewer,                                     String doAsUser) Requests a delegation token using the configured Authenticator  for authentication. HttpURLConnection openConnection(URL url,                             org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token) Returns an authenticated HttpURLConnection, it uses a Delegation  Token only if the given auth token is an instance of DelegationTokenAuthenticatedURL.Token and  it contains a Delegation Token, otherwise use the configured  DelegationTokenAuthenticator to authenticate the connection. HttpURLConnection openConnection(URL url,                             DelegationTokenAuthenticatedURL.Token token) Returns an authenticated HttpURLConnection. HttpURLConnection openConnection(URL url,                             DelegationTokenAuthenticatedURL.Token token,                             String doAs) Returns an authenticated HttpURLConnection. long renewDelegationToken(URL url,                                         DelegationTokenAuthenticatedURL.Token token) Renews a delegation token from the server end-point using the  configured Authenticator for authentication. long renewDelegationToken(URL url,                                         DelegationTokenAuthenticatedURL.Token token,                                         String doAsUser) Renews a delegation token from the server end-point using the  configured Authenticator for authentication. static void setDefaultDelegationTokenAuthenticator(Class<? extends DelegationTokenAuthenticator> authenticator) Sets the default DelegationTokenAuthenticator class to use when an  DelegationTokenAuthenticatedURL instance is created without  specifying one. protected void setUseQueryStringForDelegationToken(boolean useQueryString) Deprecated.  boolean useQueryStringForDelegationToken() Returns if delegation token is transmitted as a HTTP header. Methods inherited from class org.apache.hadoop.security.authentication.client.AuthenticatedURL extractToken, getAuthenticator, getDefaultAuthenticator, injectToken, setDefaultAuthenticator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail DelegationTokenAuthenticatedURL public DelegationTokenAuthenticatedURL() Creates an DelegationTokenAuthenticatedURL.    An instance of the default DelegationTokenAuthenticator will be  used. DelegationTokenAuthenticatedURL public DelegationTokenAuthenticatedURL(DelegationTokenAuthenticator authenticator) Creates an DelegationTokenAuthenticatedURL. Parameters:authenticator - the DelegationTokenAuthenticator instance to  use, if null the default one will be used. DelegationTokenAuthenticatedURL public DelegationTokenAuthenticatedURL(org.apache.hadoop.security.authentication.client.ConnectionConfigurator connConfigurator) Creates an DelegationTokenAuthenticatedURL using the default  DelegationTokenAuthenticator class. Parameters:connConfigurator - a connection configurator. DelegationTokenAuthenticatedURL public DelegationTokenAuthenticatedURL(DelegationTokenAuthenticator authenticator,                                org.apache.hadoop.security.authentication.client.ConnectionConfigurator connConfigurator) Creates an DelegationTokenAuthenticatedURL. Parameters:authenticator - the DelegationTokenAuthenticator instance to  use, if null the default one will be used.connConfigurator - a connection configurator. Method Detail setDefaultDelegationTokenAuthenticator public static void setDefaultDelegationTokenAuthenticator(Class<? extends DelegationTokenAuthenticator> authenticator) Sets the default DelegationTokenAuthenticator class to use when an  DelegationTokenAuthenticatedURL instance is created without  specifying one.  The default class is KerberosDelegationTokenAuthenticator Parameters:authenticator - the authenticator class to use as default. getDefaultDelegationTokenAuthenticator public static Class<? extends DelegationTokenAuthenticator> getDefaultDelegationTokenAuthenticator() Returns the default DelegationTokenAuthenticator class to use when  an DelegationTokenAuthenticatedURL instance is created without  specifying one.    The default class is KerberosDelegationTokenAuthenticator Returns:the delegation token authenticator class to use as default. setUseQueryStringForDelegationToken @Deprecated protected void setUseQueryStringForDelegationToken(boolean useQueryString) Deprecated.  Sets if delegation token should be transmitted in the URL query string.  By default it is transmitted using the  DelegationTokenAuthenticator.DELEGATION_TOKEN_HEADER HTTP header.    This method is provided to enable WebHDFS backwards compatibility. Parameters:useQueryString - TRUE if the token is transmitted in the  URL query string, FALSE if the delegation token is transmitted  using the DelegationTokenAuthenticator.DELEGATION_TOKEN_HEADER HTTP  header. useQueryStringForDelegationToken public boolean useQueryStringForDelegationToken() Returns if delegation token is transmitted as a HTTP header. Returns:TRUE if the token is transmitted in the URL query  string, FALSE if the delegation token is transmitted using the  DelegationTokenAuthenticator.DELEGATION_TOKEN_HEADER HTTP header. openConnection public HttpURLConnection openConnection(URL url,                                org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token)                                  throws IOException,                                         org.apache.hadoop.security.authentication.client.AuthenticationException Returns an authenticated HttpURLConnection, it uses a Delegation  Token only if the given auth token is an instance of DelegationTokenAuthenticatedURL.Token and  it contains a Delegation Token, otherwise use the configured  DelegationTokenAuthenticator to authenticate the connection. Overrides: openConnection in class org.apache.hadoop.security.authentication.client.AuthenticatedURL Parameters:url - the URL to connect to. Only HTTP/S URLs are supported.token - the authentication token being used for the user. Returns:an authenticated HttpURLConnection. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. openConnection public HttpURLConnection openConnection(URL url,                                DelegationTokenAuthenticatedURL.Token token)                                  throws IOException,                                         org.apache.hadoop.security.authentication.client.AuthenticationException Returns an authenticated HttpURLConnection. If the Delegation  Token is present, it will be used taking precedence over the configured  Authenticator. Parameters:url - the URL to connect to. Only HTTP/S URLs are supported.token - the authentication token being used for the user. Returns:an authenticated HttpURLConnection. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. openConnection public HttpURLConnection openConnection(URL url,                                DelegationTokenAuthenticatedURL.Token token,                                String doAs)                                  throws IOException,                                         org.apache.hadoop.security.authentication.client.AuthenticationException Returns an authenticated HttpURLConnection. If the Delegation  Token is present, it will be used taking precedence over the configured  Authenticator. If the doAs parameter is not NULL,  the request will be done on behalf of the specified doAs user. Parameters:url - the URL to connect to. Only HTTP/S URLs are supported.token - the authentication token being used for the user.doAs - user to do the the request on behalf of, if NULL the request is  as self. Returns:an authenticated HttpURLConnection. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. getDelegationToken public org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken(URL url,                                                                                                                                        DelegationTokenAuthenticatedURL.Token token,                                                                                                                                        String renewer)                                                                                                                                          throws IOException,                                                                                                                                                 org.apache.hadoop.security.authentication.client.AuthenticationException Requests a delegation token using the configured Authenticator  for authentication. Parameters:url - the URL to get the delegation token from. Only HTTP/S URLs are  supported.token - the authentication token being used for the user where the  Delegation token will be stored.renewer - the renewer user. Returns:a delegation token. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. getDelegationToken public org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken(URL url,                                                                                                                                        DelegationTokenAuthenticatedURL.Token token,                                                                                                                                        String renewer,                                                                                                                                        String doAsUser)                                                                                                                                          throws IOException,                                                                                                                                                 org.apache.hadoop.security.authentication.client.AuthenticationException Requests a delegation token using the configured Authenticator  for authentication. Parameters:url - the URL to get the delegation token from. Only HTTP/S URLs are  supported.token - the authentication token being used for the user where the  Delegation token will be stored.renewer - the renewer user.doAsUser - the user to do as, which will be the token owner. Returns:a delegation token. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. renewDelegationToken public long renewDelegationToken(URL url,                         DelegationTokenAuthenticatedURL.Token token)                           throws IOException,                                  org.apache.hadoop.security.authentication.client.AuthenticationException Renews a delegation token from the server end-point using the  configured Authenticator for authentication. Parameters:url - the URL to renew the delegation token from. Only HTTP/S URLs are  supported.token - the authentication token with the Delegation Token to renew. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. renewDelegationToken public long renewDelegationToken(URL url,                         DelegationTokenAuthenticatedURL.Token token,                         String doAsUser)                           throws IOException,                                  org.apache.hadoop.security.authentication.client.AuthenticationException Renews a delegation token from the server end-point using the  configured Authenticator for authentication. Parameters:url - the URL to renew the delegation token from. Only HTTP/S URLs are  supported.token - the authentication token with the Delegation Token to renew.doAsUser - the user to do as, which will be the token owner. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. cancelDelegationToken public void cancelDelegationToken(URL url,                          DelegationTokenAuthenticatedURL.Token token)                            throws IOException Cancels a delegation token from the server end-point. It does not require  being authenticated by the configured Authenticator. Parameters:url - the URL to cancel the delegation token from. Only HTTP/S URLs  are supported.token - the authentication token with the Delegation Token to cancel. Throws: IOException - if an IO error occurred. cancelDelegationToken public void cancelDelegationToken(URL url,                          DelegationTokenAuthenticatedURL.Token token,                          String doAsUser)                            throws IOException Cancels a delegation token from the server end-point. It does not require  being authenticated by the configured Authenticator. Parameters:url - the URL to cancel the delegation token from. Only HTTP/S URLs  are supported.token - the authentication token with the Delegation Token to cancel.doAsUser - the user to do as, which will be the token owner. Throws: IOException - if an IO error occurred. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DelegationTokenAuthenticator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DelegationTokenAuthenticator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.security.token.delegation.web Class DelegationTokenAuthenticator java.lang.Object org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator All Implemented Interfaces: org.apache.hadoop.security.authentication.client.Authenticator Direct Known Subclasses: KerberosDelegationTokenAuthenticator, PseudoDelegationTokenAuthenticator @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class DelegationTokenAuthenticator extends Object implements org.apache.hadoop.security.authentication.client.Authenticator Authenticator wrapper that enhances an Authenticator with  Delegation Token support. Field Summary Fields  Modifier and Type Field and Description static String DELEGATION_PARAM  static String DELEGATION_TOKEN_HEADER  static String DELEGATION_TOKEN_JSON  static String DELEGATION_TOKEN_URL_STRING_JSON  static String OP_PARAM  static String RENEW_DELEGATION_TOKEN_JSON  static String RENEWER_PARAM  static String TOKEN_PARAM  Constructor Summary Constructors  Constructor and Description DelegationTokenAuthenticator(org.apache.hadoop.security.authentication.client.Authenticator authenticator)  Method Summary Methods  Modifier and Type Method and Description void authenticate(URL url,                         org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token) Authenticates against a URL and returns a AuthenticatedURL.Token to be  used by subsequent requests. void cancelDelegationToken(URL url,                                           org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                                           org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> dToken) Cancels a delegation token from the server end-point. void cancelDelegationToken(URL url,                                           org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                                           org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> dToken,                                           String doAsUser) Cancels a delegation token from the server end-point. org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken(URL url,                                     org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                                     String renewer) Requests a delegation token using the configured Authenticator  for authentication. org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken(URL url,                                     org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                                     String renewer,                                     String doAsUser) Requests a delegation token using the configured Authenticator  for authentication. long renewDelegationToken(URL url,                                         org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                                         org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> dToken) Renews a delegation token from the server end-point using the  configured Authenticator for authentication. long renewDelegationToken(URL url,                                         org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                                         org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> dToken,                                         String doAsUser) Renews a delegation token from the server end-point using the  configured Authenticator for authentication. void setConnectionConfigurator(org.apache.hadoop.security.authentication.client.ConnectionConfigurator configurator) Sets a ConnectionConfigurator instance to use for  configuring connections. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail OP_PARAM public static final String OP_PARAM See Also:Constant Field Values DELEGATION_TOKEN_HEADER public static final String DELEGATION_TOKEN_HEADER See Also:Constant Field Values DELEGATION_PARAM public static final String DELEGATION_PARAM See Also:Constant Field Values TOKEN_PARAM public static final String TOKEN_PARAM See Also:Constant Field Values RENEWER_PARAM public static final String RENEWER_PARAM See Also:Constant Field Values DELEGATION_TOKEN_JSON public static final String DELEGATION_TOKEN_JSON See Also:Constant Field Values DELEGATION_TOKEN_URL_STRING_JSON public static final String DELEGATION_TOKEN_URL_STRING_JSON See Also:Constant Field Values RENEW_DELEGATION_TOKEN_JSON public static final String RENEW_DELEGATION_TOKEN_JSON See Also:Constant Field Values Constructor Detail DelegationTokenAuthenticator public DelegationTokenAuthenticator(org.apache.hadoop.security.authentication.client.Authenticator authenticator) Method Detail setConnectionConfigurator public void setConnectionConfigurator(org.apache.hadoop.security.authentication.client.ConnectionConfigurator configurator) Description copied from interface: org.apache.hadoop.security.authentication.client.Authenticator Sets a ConnectionConfigurator instance to use for  configuring connections. Specified by: setConnectionConfigurator in interface org.apache.hadoop.security.authentication.client.Authenticator Parameters:configurator - the ConnectionConfigurator instance. authenticate public void authenticate(URL url,                 org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token)                   throws IOException,                          org.apache.hadoop.security.authentication.client.AuthenticationException Description copied from interface: org.apache.hadoop.security.authentication.client.Authenticator Authenticates against a URL and returns a AuthenticatedURL.Token to be  used by subsequent requests. Specified by: authenticate in interface org.apache.hadoop.security.authentication.client.Authenticator Parameters:url - the URl to authenticate against.token - the authentication token being used for the user. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication error occurred. getDelegationToken public org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken(URL url,                                                                                                                                        org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                                                                                                                                        String renewer)                                                                                                                                          throws IOException,                                                                                                                                                 org.apache.hadoop.security.authentication.client.AuthenticationException Requests a delegation token using the configured Authenticator  for authentication. Parameters:url - the URL to get the delegation token from. Only HTTP/S URLs are  supported.token - the authentication token being used for the user where the  Delegation token will be stored.renewer - the renewer user. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. getDelegationToken public org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> getDelegationToken(URL url,                                                                                                                                        org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                                                                                                                                        String renewer,                                                                                                                                        String doAsUser)                                                                                                                                          throws IOException,                                                                                                                                                 org.apache.hadoop.security.authentication.client.AuthenticationException Requests a delegation token using the configured Authenticator  for authentication. Parameters:url - the URL to get the delegation token from. Only HTTP/S URLs are  supported.token - the authentication token being used for the user where the  Delegation token will be stored.renewer - the renewer user.doAsUser - the user to do as, which will be the token owner. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. renewDelegationToken public long renewDelegationToken(URL url,                         org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                         org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> dToken)                           throws IOException,                                  org.apache.hadoop.security.authentication.client.AuthenticationException Renews a delegation token from the server end-point using the  configured Authenticator for authentication. Parameters:url - the URL to renew the delegation token from. Only HTTP/S URLs are  supported.token - the authentication token with the Delegation Token to renew. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. renewDelegationToken public long renewDelegationToken(URL url,                         org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                         org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> dToken,                         String doAsUser)                           throws IOException,                                  org.apache.hadoop.security.authentication.client.AuthenticationException Renews a delegation token from the server end-point using the  configured Authenticator for authentication. Parameters:url - the URL to renew the delegation token from. Only HTTP/S URLs are  supported.token - the authentication token with the Delegation Token to renew.doAsUser - the user to do as, which will be the token owner. Throws: IOException - if an IO error occurred. org.apache.hadoop.security.authentication.client.AuthenticationException - if an authentication exception occurred. cancelDelegationToken public void cancelDelegationToken(URL url,                          org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                          org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> dToken)                            throws IOException Cancels a delegation token from the server end-point. It does not require  being authenticated by the configured Authenticator. Parameters:url - the URL to cancel the delegation token from. Only HTTP/S URLs  are supported.token - the authentication token with the Delegation Token to cancel. Throws: IOException - if an IO error occurred. cancelDelegationToken public void cancelDelegationToken(URL url,                          org.apache.hadoop.security.authentication.client.AuthenticatedURL.Token token,                          org.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier> dToken,                          String doAsUser)                            throws IOException Cancels a delegation token from the server end-point. It does not require  being authenticated by the configured Authenticator. Parameters:url - the URL to cancel the delegation token from. Only HTTP/S URLs  are supported.token - the authentication token with the Delegation Token to cancel.doAsUser - the user to do as, which will be the token owner. Throws: IOException - if an IO error occurred. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DirectDecompressionCodec (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DirectDecompressionCodec (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Interface DirectDecompressionCodec All Superinterfaces: CompressionCodec All Known Implementing Classes: DefaultCodec, GzipCodec @InterfaceAudience.Public @InterfaceStability.Evolving public interface DirectDecompressionCodec extends CompressionCodec This class encapsulates a codec which can decompress direct bytebuffers. Method Summary Methods  Modifier and Type Method and Description DirectDecompressor createDirectDecompressor() Create a new DirectDecompressor for use by this DirectDecompressionCodec. Methods inherited from interface org.apache.hadoop.io.compress.CompressionCodec createCompressor, createDecompressor, createInputStream, createInputStream, createOutputStream, createOutputStream, getCompressorType, getDecompressorType, getDefaultExtension Method Detail createDirectDecompressor DirectDecompressor createDirectDecompressor() Create a new DirectDecompressor for use by this DirectDecompressionCodec. Returns:a new direct decompressor for use by this codec Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DirectDecompressor (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DirectDecompressor (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Interface DirectDecompressor @InterfaceAudience.Public @InterfaceStability.Evolving public interface DirectDecompressor Specification of a direct ByteBuffer 'de-compressor'. Method Summary Methods  Modifier and Type Method and Description void decompress(ByteBuffer src,                     ByteBuffer dst)  Method Detail decompress void decompress(ByteBuffer src,               ByteBuffer dst)                 throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Dispatcher (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Dispatcher (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.event Interface Dispatcher All Known Implementing Classes: AsyncDispatcher @InterfaceAudience.Public @InterfaceStability.Evolving public interface Dispatcher Event Dispatcher interface. It dispatches events to registered   event handlers based on event types. Field Summary Fields  Modifier and Type Field and Description static boolean DEFAULT_DISPATCHER_EXIT_ON_ERROR  static String DISPATCHER_EXIT_ON_ERROR_KEY  Method Summary Methods  Modifier and Type Method and Description EventHandler getEventHandler()  void register(Class<? extends Enum> eventType,                 EventHandler handler)  Field Detail DISPATCHER_EXIT_ON_ERROR_KEY static final String DISPATCHER_EXIT_ON_ERROR_KEY See Also:Constant Field Values DEFAULT_DISPATCHER_EXIT_ON_ERROR static final boolean DEFAULT_DISPATCHER_EXIT_ON_ERROR See Also:Constant Field Values Method Detail getEventHandler EventHandler getEventHandler() register void register(Class<? extends Enum> eventType,             EventHandler handler) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DistributedCache (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DistributedCache (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.filecache Class DistributedCache java.lang.Object org.apache.hadoop.mapreduce.filecache.DistributedCache org.apache.hadoop.filecache.DistributedCache Deprecated. @InterfaceAudience.Public @InterfaceStability.Stable @Deprecated public class DistributedCache extends org.apache.hadoop.mapreduce.filecache.DistributedCache Distribute application-specific large, read-only files efficiently.    DistributedCache is a facility provided by the Map-Reduce  framework to cache files (text, archives, jars etc.) needed by applications.      Applications specify the files, via urls (hdfs:// or http://) to be cached   via the JobConf. The  DistributedCache assumes that the files specified via urls are  already present on the FileSystem at the path specified by the url  and are accessible by every machine in the cluster.    The framework will copy the necessary files on to the slave node before   any tasks for the job are executed on that node. Its efficiency stems from   the fact that the files are only copied once per job and the ability to   cache archives which are un-archived on the slaves.   DistributedCache can be used to distribute simple, read-only  data/text files and/or more complex types such as archives, jars etc.   Archives (zip, tar and tgz/tar.gz files) are un-archived at the slave nodes.   Jars may be optionally added to the classpath of the tasks, a rudimentary   software distribution mechanism.  Files have execution permissions.  In older version of Hadoop Map/Reduce users could optionally ask for symlinks  to be created in the working directory of the child task.  In the current   version symlinks are always created.  If the URL does not have a fragment   the name of the file or directory will be used. If multiple files or   directories map to the same link name, the last one added, will be used.  All  others will not even be downloaded.    DistributedCache tracks modification timestamps of the cache   files. Clearly the cache files should not be modified by the application   or externally while the job is executing.    Here is an illustrative example on how to use the   DistributedCache:        // Setting up the cache for the application            1. Copy the requisite files to the FileSystem:            $ bin/hadoop fs -copyFromLocal lookup.dat /myapp/lookup.dat        $ bin/hadoop fs -copyFromLocal map.zip /myapp/map.zip        $ bin/hadoop fs -copyFromLocal mylib.jar /myapp/mylib.jar      $ bin/hadoop fs -copyFromLocal mytar.tar /myapp/mytar.tar      $ bin/hadoop fs -copyFromLocal mytgz.tgz /myapp/mytgz.tgz      $ bin/hadoop fs -copyFromLocal mytargz.tar.gz /myapp/mytargz.tar.gz            2. Setup the application's JobConf:            JobConf job = new JobConf();      DistributedCache.addCacheFile(new URI("/myapp/lookup.dat#lookup.dat"),                                     job);      DistributedCache.addCacheArchive(new URI("/myapp/map.zip", job);      DistributedCache.addFileToClassPath(new Path("/myapp/mylib.jar"), job);      DistributedCache.addCacheArchive(new URI("/myapp/mytar.tar", job);      DistributedCache.addCacheArchive(new URI("/myapp/mytgz.tgz", job);      DistributedCache.addCacheArchive(new URI("/myapp/mytargz.tar.gz", job);            3. Use the cached files in the Mapper      or Reducer:            public static class MapClass extends MapReduceBase        implements Mapper<K, V, K, V> {              private Path[] localArchives;        private Path[] localFiles;                public void configure(JobConf job) {          // Get the cached archives/files          File f = new File("./map.zip/some/file/in/zip.txt");        }                public void map(K key, V value,                         OutputCollector<K, V> output, Reporter reporter)         throws IOException {          // Use data from the cached archives/files here          // ...          // ...          output.collect(k, v);        }      }          It is also very common to use the DistributedCache by using  GenericOptionsParser.  This class includes methods that should be used by users  (specifically those mentioned in the example above, as well  as DistributedCache.addArchiveToClassPath(Path, Configuration)),  as well as methods intended for use by the MapReduce framework  (e.g., JobClient). See Also:JobConf,  JobClient,  Job Field Summary Fields  Modifier and Type Field and Description static String CACHE_ARCHIVES Deprecated.  static String CACHE_ARCHIVES_SIZES Deprecated.  static String CACHE_ARCHIVES_TIMESTAMPS Deprecated.  static String CACHE_FILES Deprecated.  static String CACHE_FILES_SIZES Deprecated.  static String CACHE_FILES_TIMESTAMPS Deprecated.  static String CACHE_LOCALARCHIVES Deprecated.  static String CACHE_LOCALFILES Deprecated.  static String CACHE_SYMLINK Deprecated.  Constructor Summary Constructors  Constructor and Description DistributedCache() Deprecated.    Method Summary Methods  Modifier and Type Method and Description static void addLocalArchives(Configuration conf,                                 String str) Deprecated.  static void addLocalFiles(Configuration conf,                           String str) Deprecated.  static void createAllSymlink(Configuration conf,                                 File jobCacheDir,                                 File workDir) Deprecated.  Internal to MapReduce framework.  Use DistributedCacheManager  instead. static FileStatus getFileStatus(Configuration conf,                           URI cache) Deprecated.  static long getTimestamp(Configuration conf,                         URI cache) Deprecated.  static void setArchiveTimestamps(Configuration conf,                                         String timestamps) Deprecated.  static void setFileTimestamps(Configuration conf,                                   String timestamps) Deprecated.  static void setLocalArchives(Configuration conf,                                 String str) Deprecated.  static void setLocalFiles(Configuration conf,                           String str) Deprecated.  Methods inherited from class org.apache.hadoop.mapreduce.filecache.DistributedCache addArchiveToClassPath, addArchiveToClassPath, addCacheArchive, addCacheFile, addFileToClassPath, addFileToClassPath, checkURIs, createSymlink, getArchiveClassPaths, getArchiveTimestamps, getArchiveVisibilities, getCacheArchives, getCacheFiles, getFileClassPaths, getFileTimestamps, getFileVisibilities, getLocalCacheArchives, getLocalCacheFiles, getSymlink, setCacheArchives, setCacheFiles Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail CACHE_FILES_SIZES @Deprecated public static final String CACHE_FILES_SIZES Deprecated.  Warning: CACHE_FILES_SIZES is not a *public* constant.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.CACHE_FILES_SIZES See Also:Constant Field Values CACHE_ARCHIVES_SIZES @Deprecated public static final String CACHE_ARCHIVES_SIZES Deprecated.  Warning: CACHE_ARCHIVES_SIZES is not a *public* constant.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.CACHE_ARCHIVES_SIZES See Also:Constant Field Values CACHE_ARCHIVES_TIMESTAMPS @Deprecated public static final String CACHE_ARCHIVES_TIMESTAMPS Deprecated.  Warning: CACHE_ARCHIVES_TIMESTAMPS is not a *public* constant.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.CACHE_ARCHIVES_TIMESTAMPS See Also:Constant Field Values CACHE_FILES_TIMESTAMPS @Deprecated public static final String CACHE_FILES_TIMESTAMPS Deprecated.  Warning: CACHE_FILES_TIMESTAMPS is not a *public* constant.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.CACHE_FILE_TIMESTAMPS See Also:Constant Field Values CACHE_ARCHIVES @Deprecated public static final String CACHE_ARCHIVES Deprecated.  Warning: CACHE_ARCHIVES is not a *public* constant.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.CACHE_ARCHIVES See Also:Constant Field Values CACHE_FILES @Deprecated public static final String CACHE_FILES Deprecated.  Warning: CACHE_FILES is not a *public* constant.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.CACHE_FILES See Also:Constant Field Values CACHE_LOCALARCHIVES @Deprecated public static final String CACHE_LOCALARCHIVES Deprecated.  Warning: CACHE_LOCALARCHIVES is not a *public* constant.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.CACHE_LOCALARCHIVES See Also:Constant Field Values CACHE_LOCALFILES @Deprecated public static final String CACHE_LOCALFILES Deprecated.  Warning: CACHE_LOCALFILES is not a *public* constant.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.CACHE_LOCALFILES See Also:Constant Field Values CACHE_SYMLINK @Deprecated public static final String CACHE_SYMLINK Deprecated.  Warning: CACHE_SYMLINK is not a *public* constant.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.CACHE_SYMLINK See Also:Constant Field Values Constructor Detail DistributedCache public DistributedCache() Deprecated.  Method Detail addLocalArchives @Deprecated public static void addLocalArchives(Configuration conf,                                String str) Deprecated.  Add a archive that has been localized to the conf.  Used  by internal DistributedCache code. Parameters:conf - The conf to modify to contain the localized cachesstr - a comma separated list of local archives addLocalFiles @Deprecated public static void addLocalFiles(Configuration conf,                             String str) Deprecated.  Add a file that has been localized to the conf..  Used  by internal DistributedCache code. Parameters:conf - The conf to modify to contain the localized cachesstr - a comma separated list of local files createAllSymlink @Deprecated public static void createAllSymlink(Configuration conf,                                File jobCacheDir,                                File workDir)                              throws IOException Deprecated. Internal to MapReduce framework.  Use DistributedCacheManager  instead. This method create symlinks for all files in a given dir in another  directory. Currently symlinks cannot be disabled. This is a NO-OP. Parameters:conf - the configurationjobCacheDir - the target directory for creating symlinksworkDir - the directory in which the symlinks are created Throws: IOException getFileStatus @Deprecated public static FileStatus getFileStatus(Configuration conf,                                   URI cache)                                 throws IOException Deprecated.  Returns FileStatus of a given cache file on hdfs. Internal to  MapReduce. Parameters:conf - configurationcache - cache file Returns:FileStatus of a given cache file on hdfs Throws: IOException getTimestamp @Deprecated public static long getTimestamp(Configuration conf,                            URI cache)                          throws IOException Deprecated.  Returns mtime of a given cache file on hdfs. Internal to MapReduce. Parameters:conf - configurationcache - cache file Returns:mtime of a given cache file on hdfs Throws: IOException setArchiveTimestamps @Deprecated public static void setArchiveTimestamps(Configuration conf,                                    String timestamps) Deprecated.  This is to check the timestamp of the archives to be localized.  Used by internal MapReduce code. Parameters:conf - Configuration which stores the timestamp'stimestamps - comma separated list of timestamps of archives.  The order should be the same as the order in which the archives are added. setFileTimestamps @Deprecated public static void setFileTimestamps(Configuration conf,                                 String timestamps) Deprecated.  This is to check the timestamp of the files to be localized.  Used by internal MapReduce code. Parameters:conf - Configuration which stores the timestamp'stimestamps - comma separated list of timestamps of files.  The order should be the same as the order in which the files are added. setLocalArchives @Deprecated public static void setLocalArchives(Configuration conf,                                String str) Deprecated.  Set the conf to contain the location for localized archives.  Used  by internal DistributedCache code. Parameters:conf - The conf to modify to contain the localized cachesstr - a comma separated list of local archives setLocalFiles @Deprecated public static void setLocalFiles(Configuration conf,                             String str) Deprecated.  Set the conf to contain the location for localized files.  Used  by internal DistributedCache code. Parameters:conf - The conf to modify to contain the localized cachesstr - a comma separated list of local files Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DoubleValueSum (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DoubleValueSum (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class DoubleValueSum java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum All Implemented Interfaces: ValueAggregator<String> Direct Known Subclasses: DoubleValueSum @InterfaceAudience.Public @InterfaceStability.Stable public class DoubleValueSum extends Object implements ValueAggregator<String> This class implements a value aggregator that sums up a sequence of double  values. Constructor Summary Constructors  Constructor and Description DoubleValueSum() The default constructor Method Summary Methods  Modifier and Type Method and Description void addNextValue(double val) add a value to the aggregator void addNextValue(Object val) add a value to the aggregator ArrayList<String> getCombinerOutput()  String getReport()  double getSum()  void reset() reset the aggregator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail DoubleValueSum public DoubleValueSum() The default constructor Method Detail addNextValue public void addNextValue(Object val) add a value to the aggregator Specified by: addNextValue in interface ValueAggregator<String> Parameters:val - an object whose string representation represents a double value. addNextValue public void addNextValue(double val) add a value to the aggregator Parameters:val - a double value. getReport public String getReport() Specified by: getReport in interface ValueAggregator<String> Returns:the string representation of the aggregated value getSum public double getSum() Returns:the aggregated value reset public void reset() reset the aggregator Specified by: reset in interface ValueAggregator<String> getCombinerOutput public ArrayList<String> getCombinerOutput() Specified by: getCombinerOutput in interface ValueAggregator<String> Returns:return an array of one element. The element is a string          representation of the aggregated value. The return value is          expected to be used by the a combiner. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DoubleWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DoubleWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class DoubleWritable java.lang.Object org.apache.hadoop.io.DoubleWritable All Implemented Interfaces: Comparable<DoubleWritable>, Writable, WritableComparable<DoubleWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class DoubleWritable extends Object implements WritableComparable<DoubleWritable> Writable for Double values. Constructor Summary Constructors  Constructor and Description DoubleWritable()  DoubleWritable(double value)  Method Summary Methods  Modifier and Type Method and Description int compareTo(DoubleWritable o)  boolean equals(Object o) Returns true iff o is a DoubleWritable with the same value. double get()  int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(double value)  String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail DoubleWritable public DoubleWritable() DoubleWritable public DoubleWritable(double value) Method Detail readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException set public void set(double value) get public double get() equals public boolean equals(Object o) Returns true iff o is a DoubleWritable with the same value. Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(DoubleWritable o) Specified by: compareTo in interface Comparable<DoubleWritable> toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  DynamicBloomFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="DynamicBloomFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util.bloom Class DynamicBloomFilter java.lang.Object org.apache.hadoop.util.bloom.Filter org.apache.hadoop.util.bloom.DynamicBloomFilter All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class DynamicBloomFilter extends org.apache.hadoop.util.bloom.Filter Implements a dynamic Bloom filter, as defined in the INFOCOM 2006 paper.    A dynamic Bloom filter (DBF) makes use of a s * m bit matrix but  each of the s rows is a standard Bloom filter. The creation   process of a DBF is iterative. At the start, the DBF is a 1 * m  bit matrix, i.e., it is composed of a single standard Bloom filter.  It assumes that nr elements are recorded in the   initial bit vector, where nr <= n (n is  the cardinality of the set A to record in the filter).      As the size of A grows during the execution of the application,  several keys must be inserted in the DBF.  When inserting a key into the DBF,  one must first get an active Bloom filter in the matrix.  A Bloom filter is  active when the number of recorded keys, nr, is   strictly less than the current cardinality of A, n.  If an active Bloom filter is found, the key is inserted and   nr is incremented by one. On the other hand, if there  is no active Bloom filter, a new one is created (i.e., a new row is added to  the matrix) according to the current size of A and the element  is added in this new Bloom filter and the nr value of  this new Bloom filter is set to one.  A given key is said to belong to the  DBF if the k positions are set to one in one of the matrix rows.    Originally created by  European Commission One-Lab Project 034819. See Also:The general behavior of a filter,  A Bloom filter,  Theory and Network Applications of Dynamic Bloom Filters Field Summary Fields inherited from class org.apache.hadoop.util.bloom.Filter hash, hashType, nbHash, vectorSize Constructor Summary Constructors  Constructor and Description DynamicBloomFilter() Zero-args constructor for the serialization. DynamicBloomFilter(int vectorSize,                                     int nbHash,                                     int hashType,                                     int nr) Constructor. Method Summary Methods  Modifier and Type Method and Description void add(org.apache.hadoop.util.bloom.Key key) Adds a key to this filter. void and(org.apache.hadoop.util.bloom.Filter filter) Peforms a logical AND between this filter and a specified filter. boolean membershipTest(org.apache.hadoop.util.bloom.Key key) Determines wether a specified key belongs to this filter. void not() Performs a logical NOT on this filter. void or(org.apache.hadoop.util.bloom.Filter filter) Peforms a logical OR between this filter and a specified filter. void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. void xor(org.apache.hadoop.util.bloom.Filter filter) Peforms a logical XOR between this filter and a specified filter. Methods inherited from class org.apache.hadoop.util.bloom.Filter add, add, add Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail DynamicBloomFilter public DynamicBloomFilter() Zero-args constructor for the serialization. DynamicBloomFilter public DynamicBloomFilter(int vectorSize,                   int nbHash,                   int hashType,                   int nr) Constructor.    Builds an empty Dynamic Bloom filter. Parameters:vectorSize - The number of bits in the vector.nbHash - The number of hash function to consider.hashType - type of the hashing function (see  Hash).nr - The threshold for the maximum number of keys to record in a  dynamic Bloom filter row. Method Detail add public void add(org.apache.hadoop.util.bloom.Key key) Description copied from class: org.apache.hadoop.util.bloom.Filter Adds a key to this filter. Specified by: add in class org.apache.hadoop.util.bloom.Filter Parameters:key - The key to add. and public void and(org.apache.hadoop.util.bloom.Filter filter) Description copied from class: org.apache.hadoop.util.bloom.Filter Peforms a logical AND between this filter and a specified filter.    Invariant: The result is assigned to this filter. Specified by: and in class org.apache.hadoop.util.bloom.Filter Parameters:filter - The filter to AND with. membershipTest public boolean membershipTest(org.apache.hadoop.util.bloom.Key key) Description copied from class: org.apache.hadoop.util.bloom.Filter Determines wether a specified key belongs to this filter. Specified by: membershipTest in class org.apache.hadoop.util.bloom.Filter Parameters:key - The key to test. Returns:boolean True if the specified key belongs to this filter.                      False otherwise. not public void not() Description copied from class: org.apache.hadoop.util.bloom.Filter Performs a logical NOT on this filter.    The result is assigned to this filter. Specified by: not in class org.apache.hadoop.util.bloom.Filter or public void or(org.apache.hadoop.util.bloom.Filter filter) Description copied from class: org.apache.hadoop.util.bloom.Filter Peforms a logical OR between this filter and a specified filter.    Invariant: The result is assigned to this filter. Specified by: or in class org.apache.hadoop.util.bloom.Filter Parameters:filter - The filter to OR with. xor public void xor(org.apache.hadoop.util.bloom.Filter filter) Description copied from class: org.apache.hadoop.util.bloom.Filter Peforms a logical XOR between this filter and a specified filter.    Invariant: The result is assigned to this filter. Specified by: xor in class org.apache.hadoop.util.bloom.Filter Parameters:filter - The filter to XOR with. toString public String toString() Overrides: toString in class Object write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Overrides: write in class org.apache.hadoop.util.bloom.Filter Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Overrides: readFields in class org.apache.hadoop.util.bloom.Filter Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ElasticByteBufferPool (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ElasticByteBufferPool (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class ElasticByteBufferPool java.lang.Object org.apache.hadoop.io.ElasticByteBufferPool All Implemented Interfaces: ByteBufferPool @InterfaceAudience.Public @InterfaceStability.Stable public final class ElasticByteBufferPool extends Object implements ByteBufferPool This is a simple ByteBufferPool which just creates ByteBuffers as needed.  It also caches ByteBuffers after they're released.  It will always return  the smallest cached buffer with at least the capacity you request.  We don't try to do anything clever here like try to limit the maximum cache  size. Constructor Summary Constructors  Constructor and Description ElasticByteBufferPool()  Method Summary Methods  Modifier and Type Method and Description ByteBuffer getBuffer(boolean direct,                   int length) Get a new direct ByteBuffer. void putBuffer(ByteBuffer buffer) Release a buffer back to the pool. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ElasticByteBufferPool public ElasticByteBufferPool() Method Detail getBuffer public ByteBuffer getBuffer(boolean direct,                    int length) Description copied from interface: ByteBufferPool Get a new direct ByteBuffer.  The pool can provide this from  removing a buffer from its internal cache, or by allocating a   new buffer. Specified by: getBuffer in interface ByteBufferPool Parameters:direct - Whether the buffer should be direct.length - The minimum length the buffer will have. Returns:A new ByteBuffer.  This ByteBuffer must be direct.                    Its capacity can be less than what was requested, but                    must be at least 1 byte. putBuffer public void putBuffer(ByteBuffer buffer) Description copied from interface: ByteBufferPool Release a buffer back to the pool.  The pool may choose to put this buffer into its cache. Specified by: putBuffer in interface ByteBufferPool Parameters:buffer - a direct bytebuffer Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Endpoint (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Endpoint (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.types Class Endpoint java.lang.Object org.apache.hadoop.registry.client.types.Endpoint All Implemented Interfaces: Cloneable @InterfaceAudience.Public @InterfaceStability.Evolving public final class Endpoint extends Object implements Cloneable Description of a single service/component endpoint.  It is designed to be marshalled as JSON.    Every endpoint can have more than one address entry, such as  a list of URLs to a replicated service, or a (hostname, port)  pair. Each of these address entries is represented as a string list,  as that is the only reliably marshallable form of a tuple JSON can represent. Field Summary Fields  Modifier and Type Field and Description List<Map<String,String>> addresses a list of address tuples —tuples whose format depends on the address type String addressType Type of address. String api API implemented at the end of the binding String protocolType Protocol type. Constructor Summary Constructors  Constructor and Description Endpoint() Create an empty instance. Endpoint(Endpoint that) Create an endpoint from another endpoint. Endpoint(String api,                 String addressType,                 String protocolType) Build an endpoint with an empty address list Endpoint(String api,                 String addressType,                 String protocolType,                 List<Map<String,String>> addrs) Build an endpoint with a list of addresses Endpoint(String api,                 String addressType,                 String protocolType,                 Map<String,String>... addrs) Build an endpoint with a list of addresses Endpoint(String api,                 String addressType,                 String protocolType,                 Map<String,String> addr) Build an endpoint with a single address entry. Endpoint(String api,                 String protocolType,                 URI... uris) Build an endpoint from a list of URIs; each URI  is ASCII-encoded and added to the list of addresses. Method Summary Methods  Modifier and Type Method and Description Object clone() Shallow clone: the lists of addresses are shared String toString()  void validate() Validate the record by checking for null fields and other invalid  conditions Methods inherited from class java.lang.Object equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail api public String api API implemented at the end of the binding addressType public String addressType Type of address. The standard types are defined in  AddressTypes protocolType public String protocolType Protocol type. Some standard types are defined in  ProtocolTypes addresses public List<Map<String,String>> addresses a list of address tuples —tuples whose format depends on the address type Constructor Detail Endpoint public Endpoint() Create an empty instance. Endpoint public Endpoint(Endpoint that) Create an endpoint from another endpoint.  This is a deep clone with a new list of addresses. Parameters:that - the endpoint to copy from Endpoint public Endpoint(String api,         String addressType,         String protocolType,         List<Map<String,String>> addrs) Build an endpoint with a list of addresses Parameters:api - API nameaddressType - address typeprotocolType - protocol typeaddrs - addresses Endpoint public Endpoint(String api,         String addressType,         String protocolType) Build an endpoint with an empty address list Parameters:api - API nameaddressType - address typeprotocolType - protocol type Endpoint public Endpoint(String api,         String addressType,         String protocolType,         Map<String,String> addr) Build an endpoint with a single address entry.    This constructor is superfluous given the varags constructor is equivalent  for a single element argument. However, type-erasure in java generics  causes javac to warn about unchecked generic array creation. This  constructor, which represents the common "one address" case, does  not generate compile-time warnings. Parameters:api - API nameaddressType - address typeprotocolType - protocol typeaddr - address. May be null —in which case it is not added Endpoint public Endpoint(String api,         String addressType,         String protocolType,         Map<String,String>... addrs) Build an endpoint with a list of addresses Parameters:api - API nameaddressType - address typeprotocolType - protocol typeaddrs - addresses. Null elements will be skipped Endpoint public Endpoint(String api,         String protocolType,         URI... uris) Build an endpoint from a list of URIs; each URI  is ASCII-encoded and added to the list of addresses. Parameters:api - API nameprotocolType - protocol typeuris - URIs to convert to a list of tup;les Method Detail toString public String toString() Overrides: toString in class Object validate public void validate() Validate the record by checking for null fields and other invalid  conditions Throws: NullPointerException - if a field is null when it  MUST be set. RuntimeException - on invalid entries clone public Object clone()              throws CloneNotSupportedException Shallow clone: the lists of addresses are shared Overrides: clone in class Object Returns:a cloned instance Throws: CloneNotSupportedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  EnumSetWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="EnumSetWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class EnumSetWritable<E extends Enum<E>> java.lang.Object java.util.AbstractCollection<E> org.apache.hadoop.io.EnumSetWritable<E> All Implemented Interfaces: Iterable<E>, Collection<E>, Configurable, Writable @InterfaceAudience.Public @InterfaceStability.Stable public class EnumSetWritable<E extends Enum<E>> extends AbstractCollection<E> implements Writable, Configurable A Writable wrapper for EnumSet. Constructor Summary Constructors  Constructor and Description EnumSetWritable(EnumSet<E> value) Construct a new EnumSetWritable. EnumSetWritable(EnumSet<E> value,                               Class<E> elementType) Construct a new EnumSetWritable. Method Summary Methods  Modifier and Type Method and Description boolean add(E e)  boolean equals(Object o) Returns true if o is an EnumSetWritable with the same value,  or both are null. EnumSet<E> get() Return the value of this EnumSetWritable. Configuration getConf() Return the configuration used by this object. Class<E> getElementType() Returns the class of all the elements of the underlying EnumSetWriable. int hashCode()  Iterator<E> iterator()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(EnumSet<E> value,       Class<E> elementType) reset the EnumSetWritable with specified  value and elementType. void setConf(Configuration conf) Set the configuration to be used by this object. int size()  String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.util.AbstractCollection addAll, clear, contains, containsAll, isEmpty, remove, removeAll, retainAll, toArray, toArray Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail EnumSetWritable public EnumSetWritable(EnumSet<E> value,                Class<E> elementType) Construct a new EnumSetWritable. If the value argument is null or  its size is zero, the elementType argument must not be null. If  the argument value's size is bigger than zero, the argument  elementType is not be used. Parameters:value - elementType -  EnumSetWritable public EnumSetWritable(EnumSet<E> value) Construct a new EnumSetWritable. Argument value should not be null  or empty. Parameters:value -  Method Detail iterator public Iterator<E> iterator() Specified by: iterator in interface Iterable<E extends Enum<E>> Specified by: iterator in interface Collection<E extends Enum<E>> Specified by: iterator in class AbstractCollection<E extends Enum<E>> size public int size() Specified by: size in interface Collection<E extends Enum<E>> Specified by: size in class AbstractCollection<E extends Enum<E>> add public boolean add(E e) Specified by: add in interface Collection<E extends Enum<E>> Overrides: add in class AbstractCollection<E extends Enum<E>> set public void set(EnumSet<E> value,        Class<E> elementType) reset the EnumSetWritable with specified  value and elementType. If the value argument  is null or its size is zero, the elementType argument must not be  null. If the argument value's size is bigger than zero, the  argument elementType is not be used. Parameters:value - elementType -  get public EnumSet<E> get() Return the value of this EnumSetWritable. readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object o) Returns true if o is an EnumSetWritable with the same value,  or both are null. Specified by: equals in interface Collection<E extends Enum<E>> Overrides: equals in class Object getElementType public Class<E> getElementType() Returns the class of all the elements of the underlying EnumSetWriable. It  may return null. Returns:the element class hashCode public int hashCode() Specified by: hashCode in interface Collection<E extends Enum<E>> Overrides: hashCode in class Object toString public String toString() Overrides: toString in class AbstractCollection<E extends Enum<E>> getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Event (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Event (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.event Interface Event<TYPE extends Enum<TYPE>> All Known Implementing Classes: AbstractEvent @InterfaceAudience.Public @InterfaceStability.Evolving public interface Event<TYPE extends Enum<TYPE>> Interface defining events api. Method Summary Methods  Modifier and Type Method and Description long getTimestamp()  TYPE getType()  String toString()  Method Detail getType TYPE getType() getTimestamp long getTimestamp() toString String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  EventCounter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="EventCounter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.log.metrics Class EventCounter java.lang.Object org.apache.log4j.AppenderSkeleton org.apache.hadoop.log.metrics.EventCounter All Implemented Interfaces: org.apache.log4j.Appender, org.apache.log4j.spi.OptionHandler @InterfaceAudience.Public @InterfaceStability.Stable public class EventCounter extends org.apache.log4j.AppenderSkeleton A log4J Appender that simply counts logging events in three levels:  fatal, error and warn. The class name is used in log4j.properties Field Summary Fields inherited from class org.apache.log4j.AppenderSkeleton closed, errorHandler, headFilter, layout, name, tailFilter, threshold Constructor Summary Constructors  Constructor and Description EventCounter()  Method Summary Methods  Modifier and Type Method and Description void append(org.apache.log4j.spi.LoggingEvent event)  void close()  boolean requiresLayout()  Methods inherited from class org.apache.log4j.AppenderSkeleton activateOptions, addFilter, clearFilters, doAppend, finalize, getErrorHandler, getFilter, getFirstFilter, getLayout, getName, getThreshold, isAsSevereAsThreshold, setErrorHandler, setLayout, setName, setThreshold Methods inherited from class java.lang.Object clone, equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail EventCounter public EventCounter() Method Detail append public void append(org.apache.log4j.spi.LoggingEvent event) Specified by: append in class org.apache.log4j.AppenderSkeleton close public void close() requiresLayout public boolean requiresLayout() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  EventHandler (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="EventHandler (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.event Interface EventHandler<T extends Event> Type Parameters:T - parameterized event of type T @InterfaceAudience.Public @InterfaceStability.Evolving public interface EventHandler<T extends Event> Interface for handling events of type T Method Summary Methods  Modifier and Type Method and Description void handle(T event)  Method Detail handle void handle(T event) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FSDataInputStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FSDataInputStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FSDataInputStream java.lang.Object java.io.InputStream java.io.FilterInputStream java.io.DataInputStream org.apache.hadoop.fs.FSDataInputStream All Implemented Interfaces: Closeable, DataInput, AutoCloseable, org.apache.hadoop.fs.ByteBufferReadable, CanSetDropBehind, CanSetReadahead, org.apache.hadoop.fs.CanUnbuffer, org.apache.hadoop.fs.HasEnhancedByteBufferAccess, org.apache.hadoop.fs.HasFileDescriptor, PositionedReadable, Seekable @InterfaceAudience.Public @InterfaceStability.Stable public class FSDataInputStream extends DataInputStream implements Seekable, PositionedReadable, org.apache.hadoop.fs.ByteBufferReadable, org.apache.hadoop.fs.HasFileDescriptor, CanSetDropBehind, CanSetReadahead, org.apache.hadoop.fs.HasEnhancedByteBufferAccess, org.apache.hadoop.fs.CanUnbuffer Utility that wraps a FSInputStream in a DataInputStream  and buffers input through a BufferedInputStream. Field Summary Fields inherited from class java.io.FilterInputStream in Constructor Summary Constructors  Constructor and Description FSDataInputStream(InputStream in)  Method Summary Methods  Modifier and Type Method and Description FileDescriptor getFileDescriptor()  long getPos() Get the current position in the input stream. int read(ByteBuffer buf) Reads up to buf.remaining() bytes into buf. ByteBuffer read(ByteBufferPool bufferPool,         int maxLength)  ByteBuffer read(ByteBufferPool bufferPool,         int maxLength,         EnumSet<ReadOption> opts) Get a ByteBuffer containing file data. int read(long position,         byte[] buffer,         int offset,         int length) Read bytes from the given position in the stream to the given buffer. void readFully(long position,                   byte[] buffer) See readFully(long, byte[], int, int). void readFully(long position,                   byte[] buffer,                   int offset,                   int length) Read bytes from the given position in the stream to the given buffer. void releaseBuffer(ByteBuffer buffer) Release a ByteBuffer which was created by the enhanced ByteBuffer read  function. void seek(long desired) Seek to the given offset. boolean seekToNewSource(long targetPos) Seek to the given position on an alternate copy of the data. void setDropBehind(Boolean dropBehind) Configure whether the stream should drop the cache. void setReadahead(Long readahead) Set the readahead on this stream. void unbuffer() Reduce the buffering. Methods inherited from class java.io.DataInputStream read, read, readBoolean, readByte, readChar, readDouble, readFloat, readFully, readFully, readInt, readLine, readLong, readShort, readUnsignedByte, readUnsignedShort, readUTF, readUTF, skipBytes Methods inherited from class java.io.FilterInputStream available, close, mark, markSupported, read, reset, skip Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail FSDataInputStream public FSDataInputStream(InputStream in) Method Detail seek public void seek(long desired)           throws IOException Seek to the given offset. Specified by: seek in interface Seekable Parameters:desired - offset to seek to Throws: IOException getPos public long getPos()             throws IOException Get the current position in the input stream. Specified by: getPos in interface Seekable Returns:current position in the input stream Throws: IOException read public int read(long position,        byte[] buffer,        int offset,        int length)          throws IOException Read bytes from the given position in the stream to the given buffer. Specified by: read in interface PositionedReadable Parameters:position - position in the input stream to seekbuffer - buffer into which data is readoffset - offset into the buffer in which data is writtenlength - maximum number of bytes to read Returns:total number of bytes read into the buffer, or -1          if there is no more data because the end of the stream has been          reached Throws: IOException readFully public void readFully(long position,              byte[] buffer,              int offset,              int length)                throws IOException Read bytes from the given position in the stream to the given buffer.  Continues to read until length bytes have been read. Specified by: readFully in interface PositionedReadable Parameters:position - position in the input stream to seekbuffer - buffer into which data is readoffset - offset into the buffer in which data is writtenlength - the number of bytes to read Throws: EOFException - If the end of stream is reached while reading.                       If an exception is thrown an undetermined number                       of bytes in the buffer may have been written. IOException readFully public void readFully(long position,              byte[] buffer)                throws IOException See readFully(long, byte[], int, int). Specified by: readFully in interface PositionedReadable Throws: IOException seekToNewSource public boolean seekToNewSource(long targetPos)                         throws IOException Seek to the given position on an alternate copy of the data. Specified by: seekToNewSource in interface Seekable Parameters:targetPos - position to seek to Returns:true if a new source is found, false otherwise Throws: IOException read public int read(ByteBuffer buf)          throws IOException Description copied from interface: org.apache.hadoop.fs.ByteBufferReadable Reads up to buf.remaining() bytes into buf. Callers should use  buf.limit(..) to control the size of the desired read.    After a successful call, buf.position() will be advanced by the number   of bytes read and buf.limit() should be unchanged.    In the case of an exception, the values of buf.position() and buf.limit()  are undefined, and callers should be prepared to recover from this  eventuality.    Many implementations will throw UnsupportedOperationException, so  callers that are not confident in support for this method from the  underlying filesystem should be prepared to handle that exception.    Implementations should treat 0-length requests as legitimate, and must not  signal an error upon their receipt. Specified by: read in interface org.apache.hadoop.fs.ByteBufferReadable Parameters:buf - the ByteBuffer to receive the results of the read operation. Returns:the number of bytes read, possibly zero, or -1 if           reach end-of-stream Throws: IOException - if there is some error performing the read getFileDescriptor public FileDescriptor getFileDescriptor()                                  throws IOException Specified by: getFileDescriptor in interface org.apache.hadoop.fs.HasFileDescriptor Returns:the FileDescriptor Throws: IOException setReadahead public void setReadahead(Long readahead)                   throws IOException,                          UnsupportedOperationException Description copied from interface: CanSetReadahead Set the readahead on this stream. Specified by: setReadahead in interface CanSetReadahead Parameters:readahead - The readahead to use.  null means to use the default. Throws: IOException - If there was an error changing the dropBehind                       setting.          UnsupportedOperationException  If this stream doesn't support                                         setting readahead. UnsupportedOperationException setDropBehind public void setDropBehind(Boolean dropBehind)                    throws IOException,                           UnsupportedOperationException Description copied from interface: CanSetDropBehind Configure whether the stream should drop the cache. Specified by: setDropBehind in interface CanSetDropBehind Parameters:dropBehind - Whether to drop the cache.  null means to use the                       default value. Throws: IOException - If there was an error changing the dropBehind                       setting.          UnsupportedOperationException  If this stream doesn't support                                         setting the drop-behind. UnsupportedOperationException read public ByteBuffer read(ByteBufferPool bufferPool,               int maxLength,               EnumSet<ReadOption> opts)                 throws IOException,                        UnsupportedOperationException Description copied from interface: org.apache.hadoop.fs.HasEnhancedByteBufferAccess Get a ByteBuffer containing file data.  This ByteBuffer may come from the stream itself, via a call like mmap,  or it may come from the ByteBufferFactory which is passed in as an  argument. Specified by: read in interface org.apache.hadoop.fs.HasEnhancedByteBufferAccess Parameters:bufferPool - If this is non-null, it will be used to create a fallback             ByteBuffer when the stream itself cannot create one.maxLength - The maximum length of buffer to return.  We may return a buffer             which is shorter than this.opts - Options to use when reading. Returns:We will always return an empty buffer if maxLength was 0,             whether or not we are at EOF.             If maxLength > 0, we will return null if the stream has             reached EOF.             Otherwise, we will return a ByteBuffer containing at least one              byte.  You must free this ByteBuffer when you are done with it              by calling releaseBuffer on it.  The buffer will continue to be             readable until it is released in this manner.  However, the             input stream's close method may warn about unclosed buffers. Throws: IOException UnsupportedOperationException read public final ByteBuffer read(ByteBufferPool bufferPool,               int maxLength)                       throws IOException,                              UnsupportedOperationException Throws: IOException UnsupportedOperationException releaseBuffer public void releaseBuffer(ByteBuffer buffer) Description copied from interface: org.apache.hadoop.fs.HasEnhancedByteBufferAccess Release a ByteBuffer which was created by the enhanced ByteBuffer read  function. You must not continue using the ByteBuffer after calling this   function. Specified by: releaseBuffer in interface org.apache.hadoop.fs.HasEnhancedByteBufferAccess Parameters:buffer - The ByteBuffer to release. unbuffer public void unbuffer() Description copied from interface: org.apache.hadoop.fs.CanUnbuffer Reduce the buffering.  This will also free sockets and file descriptors  held by the stream, if possible. Specified by: unbuffer in interface org.apache.hadoop.fs.CanUnbuffer Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FSDataOutputStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FSDataOutputStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FSDataOutputStream java.lang.Object java.io.OutputStream java.io.FilterOutputStream java.io.DataOutputStream org.apache.hadoop.fs.FSDataOutputStream All Implemented Interfaces: Closeable, DataOutput, Flushable, AutoCloseable, CanSetDropBehind, Syncable @InterfaceAudience.Public @InterfaceStability.Stable public class FSDataOutputStream extends DataOutputStream implements Syncable, CanSetDropBehind Utility that wraps a OutputStream in a DataOutputStream. Field Summary Fields inherited from class java.io.DataOutputStream written Fields inherited from class java.io.FilterOutputStream out Constructor Summary Constructors  Constructor and Description FSDataOutputStream(OutputStream out) Deprecated.  FSDataOutputStream(OutputStream out,                                     org.apache.hadoop.fs.FileSystem.Statistics stats)  FSDataOutputStream(OutputStream out,                                     org.apache.hadoop.fs.FileSystem.Statistics stats,                                     long startPosition)  Method Summary Methods  Modifier and Type Method and Description void close() Close the underlying output stream. long getPos() Get the current position in the output stream. void hflush() Flush out the data in client's user buffer. void hsync() Similar to posix fsync, flush out the data in client's user buffer   all the way to the disk device (but the disk may have it in its cache). void setDropBehind(Boolean dropBehind) Configure whether the stream should drop the cache. void sync() Deprecated.  Methods inherited from class java.io.DataOutputStream flush, size, write, write, writeBoolean, writeByte, writeBytes, writeChar, writeChars, writeDouble, writeFloat, writeInt, writeLong, writeShort, writeUTF Methods inherited from class java.io.FilterOutputStream write Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface java.io.DataOutput write Constructor Detail FSDataOutputStream @Deprecated public FSDataOutputStream(OutputStream out)                    throws IOException Deprecated.  Throws: IOException FSDataOutputStream public FSDataOutputStream(OutputStream out,                   org.apache.hadoop.fs.FileSystem.Statistics stats)                    throws IOException Throws: IOException FSDataOutputStream public FSDataOutputStream(OutputStream out,                   org.apache.hadoop.fs.FileSystem.Statistics stats,                   long startPosition)                    throws IOException Throws: IOException Method Detail getPos public long getPos()             throws IOException Get the current position in the output stream. Returns:the current position in the output stream Throws: IOException close public void close()            throws IOException Close the underlying output stream. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Overrides: close in class FilterOutputStream Throws: IOException sync @Deprecated public void sync()           throws IOException Deprecated.  Specified by: sync in interface Syncable Throws: IOExceptionSee Also:Syncable.hflush() hflush public void hflush()             throws IOException Description copied from interface: Syncable Flush out the data in client's user buffer. After the return of  this call, new readers will see the data. Specified by: hflush in interface Syncable Throws: IOException - if any error occurs hsync public void hsync()            throws IOException Description copied from interface: Syncable Similar to posix fsync, flush out the data in client's user buffer   all the way to the disk device (but the disk may have it in its cache). Specified by: hsync in interface Syncable Throws: IOException - if error occurs setDropBehind public void setDropBehind(Boolean dropBehind)                    throws IOException Description copied from interface: CanSetDropBehind Configure whether the stream should drop the cache. Specified by: setDropBehind in interface CanSetDropBehind Parameters:dropBehind - Whether to drop the cache.  null means to use the                       default value. Throws: IOException - If there was an error changing the dropBehind                       setting.          UnsupportedOperationException  If this stream doesn't support                                         setting the drop-behind. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FSError (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FSError (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FSError java.lang.Object java.lang.Throwable java.lang.Error org.apache.hadoop.fs.FSError All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class FSError extends Error Thrown for unexpected filesystem errors, presumed to reflect disk errors  in the native filesystem. See Also:Serialized Form Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FTPException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FTPException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.ftp Class FTPException java.lang.Object java.lang.Throwable java.lang.Exception java.lang.RuntimeException org.apache.hadoop.fs.ftp.FTPException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class FTPException extends RuntimeException A class to wrap a Throwable into a Runtime Exception. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description FTPException(String message)  FTPException(String message,                         Throwable t)  FTPException(Throwable t)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail FTPException public FTPException(String message) FTPException public FTPException(Throwable t) FTPException public FTPException(String message,             Throwable t) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FTPFileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FTPFileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.ftp Class FTPFileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem org.apache.hadoop.fs.ftp.FTPFileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class FTPFileSystem extends FileSystem  A FileSystem backed by an FTP client provided by Apache Commons Net.   Field Summary Fields  Modifier and Type Field and Description static int DEFAULT_BLOCK_SIZE  static int DEFAULT_BUFFER_SIZE  static String E_SAME_DIRECTORY_ONLY  static String FS_FTP_HOST  static String FS_FTP_HOST_PORT  static String FS_FTP_PASSWORD_PREFIX  static String FS_FTP_USER_PREFIX  static org.apache.commons.logging.Log LOG  Fields inherited from class org.apache.hadoop.fs.FileSystem DEFAULT_FS, FS_DEFAULT_NAME_KEY, SHUTDOWN_HOOK_PRIORITY, statistics Constructor Summary Constructors  Constructor and Description FTPFileSystem()  Method Summary Methods  Modifier and Type Method and Description FSDataOutputStream append(Path f,             int bufferSize,             Progressable progress) This optional operation is not yet supported. FSDataOutputStream create(Path file,             FsPermission permission,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) A stream obtained via this call must be closed before using other APIs of  this class or else the invocation will block. boolean delete(Path file,             boolean recursive) Delete a file. protected int getDefaultPort() Get the default port for this FTPFileSystem. FileStatus getFileStatus(Path file) Return a file status object that represents the path. Path getHomeDirectory() Return the current user's home directory in this filesystem. String getScheme() Return the protocol scheme for the FileSystem. URI getUri() Returns a URI whose scheme and authority identify this FileSystem. Path getWorkingDirectory() Get the current working directory for the given file system void initialize(URI uri,                     Configuration conf) Called after a new FileSystem instance is constructed. FileStatus[] listStatus(Path file) List the statuses of the files/directories in the given path if the path is  a directory. boolean mkdirs(Path file,             FsPermission permission) Make the given file and all non-existent parents into  directories. FSDataInputStream open(Path file,         int bufferSize) Opens an FSDataInputStream at the indicated Path. boolean rename(Path src,             Path dst) Renames Path src to Path dst. void setWorkingDirectory(Path newDir) Set the current working directory for the given file system. Methods inherited from class org.apache.hadoop.fs.FileSystem append, append, areSymlinksEnabled, cancelDeleteOnExit, canonicalizeUri, checkPath, clearStatistics, close, closeAll, closeAllForUGI, completeLocalOutput, concat, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyToLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, create, create, createNewFile, createNonRecursive, createNonRecursive, createNonRecursive, createSnapshot, createSnapshot, createSymlink, delete, deleteOnExit, deleteSnapshot, enableSymlinks, exists, fixRelativePart, get, get, get, getAclStatus, getAllStatistics, getBlockSize, getCanonicalUri, getContentSummary, getDefaultBlockSize, getDefaultBlockSize, getDefaultReplication, getDefaultReplication, getDefaultUri, getFileBlockLocations, getFileBlockLocations, getFileChecksum, getFileChecksum, getFileLinkStatus, getFileSystemClass, getFSofPath, getInitialWorkingDirectory, getLength, getLinkTarget, getLocal, getName, getNamed, getReplication, getServerDefaults, getServerDefaults, getStatistics, getStatistics, getStatus, getStatus, getUsed, getXAttr, getXAttrs, getXAttrs, globStatus, globStatus, isDirectory, isFile, listCorruptFileBlocks, listFiles, listLocatedStatus, listLocatedStatus, listStatus, listStatus, listStatus, listStatusIterator, listXAttrs, makeQualified, mkdirs, mkdirs, modifyAclEntries, moveFromLocalFile, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveCreate, primitiveMkdir, primitiveMkdir, printStatistics, processDeleteOnExit, removeAcl, removeAclEntries, removeDefaultAcl, removeXAttr, rename, renameSnapshot, resolveLink, resolvePath, setAcl, setDefaultUri, setDefaultUri, setOwner, setPermission, setReplication, setTimes, setVerifyChecksum, setWriteChecksum, setXAttr, setXAttr, startLocalOutput, supportsSymlinks, truncate Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LOG public static final org.apache.commons.logging.Log LOG DEFAULT_BUFFER_SIZE public static final int DEFAULT_BUFFER_SIZE See Also:Constant Field Values DEFAULT_BLOCK_SIZE public static final int DEFAULT_BLOCK_SIZE See Also:Constant Field Values FS_FTP_USER_PREFIX public static final String FS_FTP_USER_PREFIX See Also:Constant Field Values FS_FTP_HOST public static final String FS_FTP_HOST See Also:Constant Field Values FS_FTP_HOST_PORT public static final String FS_FTP_HOST_PORT See Also:Constant Field Values FS_FTP_PASSWORD_PREFIX public static final String FS_FTP_PASSWORD_PREFIX See Also:Constant Field Values E_SAME_DIRECTORY_ONLY public static final String E_SAME_DIRECTORY_ONLY See Also:Constant Field Values Constructor Detail FTPFileSystem public FTPFileSystem() Method Detail getScheme public String getScheme() Return the protocol scheme for the FileSystem.   Overrides: getScheme in class FileSystem Returns:ftp getDefaultPort protected int getDefaultPort() Get the default port for this FTPFileSystem. Overrides: getDefaultPort in class FileSystem Returns:the default port initialize public void initialize(URI uri,               Configuration conf)                 throws IOException Description copied from class: FileSystem Called after a new FileSystem instance is constructed. Overrides: initialize in class FileSystem Parameters:uri - a uri whose authority section names the host, port, etc.    for this FileSystemconf - the configuration Throws: IOException open public FSDataInputStream open(Path file,                      int bufferSize)                        throws IOException Description copied from class: FileSystem Opens an FSDataInputStream at the indicated Path. Specified by: open in class FileSystem Parameters:file - the file name to openbufferSize - the size of the buffer to be used. Throws: IOException create public FSDataOutputStream create(Path file,                         FsPermission permission,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException A stream obtained via this call must be closed before using other APIs of  this class or else the invocation will block. Specified by: create in class FileSystem Parameters:file - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) append public FSDataOutputStream append(Path f,                         int bufferSize,                         Progressable progress)                           throws IOException This optional operation is not yet supported. Specified by: append in class FileSystem Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used.progress - for reporting progress if it is not null. Throws: IOException delete public boolean delete(Path file,              boolean recursive)                throws IOException Description copied from class: FileSystem Delete a file. Specified by: delete in class FileSystem Parameters:file - the path to delete.recursive - if path is a directory and set to   true, the directory is deleted else throws an exception. In  case of a file the recursive can be set to either true or false. Returns:true if delete is successful else false. Throws: IOException getUri public URI getUri() Description copied from class: FileSystem Returns a URI whose scheme and authority identify this FileSystem. Specified by: getUri in class FileSystem listStatus public FileStatus[] listStatus(Path file)                         throws IOException Description copied from class: FileSystem List the statuses of the files/directories in the given path if the path is  a directory. Specified by: listStatus in class FileSystem Parameters:file - given path Returns:the statuses of the files/directories in the given patch Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException getFileStatus public FileStatus getFileStatus(Path file)                          throws IOException Description copied from class: FileSystem Return a file status object that represents the path. Specified by: getFileStatus in class FileSystem Parameters:file - The path we want information from Returns:a FileStatus object Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException mkdirs public boolean mkdirs(Path file,              FsPermission permission)                throws IOException Description copied from class: FileSystem Make the given file and all non-existent parents into  directories. Has the semantics of Unix 'mkdir -p'.  Existence of the directory hierarchy is not an error. Specified by: mkdirs in class FileSystem Parameters:file - path to createpermission - to apply to f Throws: IOException rename public boolean rename(Path src,              Path dst)                throws IOException Description copied from class: FileSystem Renames Path src to Path dst.  Can take place on local fs  or remote DFS. Specified by: rename in class FileSystem Parameters:src - path to be renameddst - new path after rename Returns:true if rename is successful Throws: IOException - on failure getWorkingDirectory public Path getWorkingDirectory() Description copied from class: FileSystem Get the current working directory for the given file system Specified by: getWorkingDirectory in class FileSystem Returns:the directory pathname getHomeDirectory public Path getHomeDirectory() Description copied from class: FileSystem Return the current user's home directory in this filesystem.  The default implementation returns "/user/$USER/". Overrides: getHomeDirectory in class FileSystem setWorkingDirectory public void setWorkingDirectory(Path newDir) Description copied from class: FileSystem Set the current working directory for the given file system. All relative  paths will be resolved relative to it. Specified by: setWorkingDirectory in class FileSystem Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FailoverFailedException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FailoverFailedException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha Class FailoverFailedException java.lang.Object java.lang.Throwable java.lang.Exception org.apache.hadoop.ha.FailoverFailedException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class FailoverFailedException extends Exception Exception thrown to indicate service failover has failed. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description FailoverFailedException(String message)  FailoverFailedException(String message,                                               Throwable cause)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail FailoverFailedException public FailoverFailedException(String message) FailoverFailedException public FailoverFailedException(String message,                        Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FenceMethod (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FenceMethod (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha Interface FenceMethod @InterfaceAudience.Public @InterfaceStability.Unstable public interface FenceMethod A fencing method is a method by which one node can forcibly prevent  another node from making continued progress. This might be implemented  by killing a process on the other node, by denying the other node's  access to shared storage, or by accessing a PDU to cut the other node's  power.    Since these methods are often vendor- or device-specific, operators  may implement this interface in order to achieve fencing.    Fencing is configured by the operator as an ordered list of methods to  attempt. Each method will be tried in turn, and the next in the list  will only be attempted if the previous one fails. See NodeFencer  for more information.    If an implementation also implements Configurable then its  setConf method will be called upon instantiation. Method Summary Methods  Modifier and Type Method and Description void checkArgs(String args) Verify that the given fencing method's arguments are valid. boolean tryFence(HAServiceTarget target,                 String args) Attempt to fence the target node. Method Detail checkArgs void checkArgs(String args)                throws BadFencingConfigurationException Verify that the given fencing method's arguments are valid. Parameters:args - the arguments provided in the configuration. This may         be null if the operator did not configure any arguments. Throws: BadFencingConfigurationException - if the arguments are invalid tryFence boolean tryFence(HAServiceTarget target,                String args)                  throws BadFencingConfigurationException Attempt to fence the target node. Parameters:serviceAddr - the address (host:ipcport) of the service to fenceargs - the configured arguments, which were checked at startup by              checkArgs(String) Returns:true if fencing was successful, false if unsuccessful or               indeterminate Throws: BadFencingConfigurationException - if the configuration was          determined to be invalid only at runtime Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FieldSelectionHelper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FieldSelectionHelper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.fieldsel Class FieldSelectionHelper java.lang.Object org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper @InterfaceAudience.Public @InterfaceStability.Stable public class FieldSelectionHelper extends Object This class implements a mapper/reducer class that can be used to perform  field selections in a manner similar to unix cut. The input data is treated  as fields separated by a user specified separator (the default value is  "\t"). The user can specify a list of fields that form the map output keys,  and a list of fields that form the map output values. If the inputformat is  TextInputFormat, the mapper will ignore the key to the map function. and the  fields are from the value only. Otherwise, the fields are the union of those  from the key and those from the value.    The field separator is under attribute "mapreduce.fieldsel.data.field.separator"    The map output field list spec is under attribute   "mapreduce.fieldsel.map.output.key.value.fields.spec".  The value is expected to be like "keyFieldsSpec:valueFieldsSpec"  key/valueFieldsSpec are comma (,) separated field spec: fieldSpec,fieldSpec,fieldSpec ...  Each field spec can be a simple number (e.g. 5) specifying a specific field, or a range  (like 2-5) to specify a range of fields, or an open range (like 3-) specifying all   the fields starting from field 3. The open range field spec applies value fields only.  They have no effect on the key fields.    Here is an example: "4,3,0,1:6,5,1-3,7-". It specifies to use fields 4,3,0 and 1 for keys,  and use fields 6,5,1,2,3,7 and above for values.    The reduce output field list spec is under attribute   "mapreduce.fieldsel.reduce.output.key.value.fields.spec".    The reducer extracts output key/value pairs in a similar manner, except that  the key is never ignored. Field Summary Fields  Modifier and Type Field and Description static String DATA_FIELD_SEPERATOR  static Text emptyText  static String MAP_OUTPUT_KEY_VALUE_SPEC  static String REDUCE_OUTPUT_KEY_VALUE_SPEC  Constructor Summary Constructors  Constructor and Description FieldSelectionHelper()  FieldSelectionHelper(Text key,                                         Text val)  Method Summary Methods  Modifier and Type Method and Description void extractOutputKeyValue(String key,                                           String val,                                           String fieldSep,                                           List<Integer> keyFieldList,                                           List<Integer> valFieldList,                                           int allValueFieldsFrom,                                           boolean ignoreKey,                                           boolean isMap)  Text getKey()  Text getValue()  static int parseOutputKeyValueSpec(String keyValueSpec,                                               List<Integer> keyFieldList,                                               List<Integer> valueFieldList)  static String specToString(String fieldSeparator,                         String keyValueSpec,                         int allValueFieldsFrom,                         List<Integer> keyFieldList,                         List<Integer> valueFieldList)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail emptyText public static Text emptyText DATA_FIELD_SEPERATOR public static final String DATA_FIELD_SEPERATOR See Also:Constant Field Values MAP_OUTPUT_KEY_VALUE_SPEC public static final String MAP_OUTPUT_KEY_VALUE_SPEC See Also:Constant Field Values REDUCE_OUTPUT_KEY_VALUE_SPEC public static final String REDUCE_OUTPUT_KEY_VALUE_SPEC See Also:Constant Field Values Constructor Detail FieldSelectionHelper public FieldSelectionHelper() FieldSelectionHelper public FieldSelectionHelper(Text key,                     Text val) Method Detail parseOutputKeyValueSpec public static int parseOutputKeyValueSpec(String keyValueSpec,                           List<Integer> keyFieldList,                           List<Integer> valueFieldList) specToString public static String specToString(String fieldSeparator,                   String keyValueSpec,                   int allValueFieldsFrom,                   List<Integer> keyFieldList,                   List<Integer> valueFieldList) getKey public Text getKey() getValue public Text getValue() extractOutputKeyValue public void extractOutputKeyValue(String key,                          String val,                          String fieldSep,                          List<Integer> keyFieldList,                          List<Integer> valFieldList,                          int allValueFieldsFrom,                          boolean ignoreKey,                          boolean isMap) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FieldSelectionMapReduce (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FieldSelectionMapReduce (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred.lib Class FieldSelectionMapReduce<K,V> java.lang.Object org.apache.hadoop.mapred.lib.FieldSelectionMapReduce<K,V> All Implemented Interfaces: Closeable, AutoCloseable, JobConfigurable, Mapper<K,V,Text,Text>, Reducer<Text,Text,Text,Text> @InterfaceAudience.Public @InterfaceStability.Stable public class FieldSelectionMapReduce<K,V> extends Object implements Mapper<K,V,Text,Text>, Reducer<Text,Text,Text,Text> This class implements a mapper/reducer class that can be used to perform  field selections in a manner similar to unix cut. The input data is treated  as fields separated by a user specified separator (the default value is  "\t"). The user can specify a list of fields that form the map output keys,  and a list of fields that form the map output values. If the inputformat is  TextInputFormat, the mapper will ignore the key to the map function. and the  fields are from the value only. Otherwise, the fields are the union of those  from the key and those from the value.    The field separator is under attribute "mapreduce.fieldsel.data.field.separator"    The map output field list spec is under attribute   "mapreduce.fieldsel.map.output.key.value.fields.spec".  The value is expected to be like "keyFieldsSpec:valueFieldsSpec"  key/valueFieldsSpec are comma (,) separated field spec: fieldSpec,fieldSpec,fieldSpec ...  Each field spec can be a simple number (e.g. 5) specifying a specific field, or a range  (like 2-5) to specify a range of fields, or an open range (like 3-) specifying all   the fields starting from field 3. The open range field spec applies value fields only.  They have no effect on the key fields.    Here is an example: "4,3,0,1:6,5,1-3,7-". It specifies to use fields 4,3,0 and 1 for keys,  and use fields 6,5,1,2,3,7 and above for values.    The reduce output field list spec is under attribute   "mapreduce.fieldsel.reduce.output.key.value.fields.spec".    The reducer extracts output key/value pairs in a similar manner, except that  the key is never ignored. Field Summary Fields  Modifier and Type Field and Description static org.apache.commons.logging.Log LOG  Constructor Summary Constructors  Constructor and Description FieldSelectionMapReduce()  Method Summary Methods  Modifier and Type Method and Description void close()  void configure(JobConf job) Initializes a new instance from a JobConf. void map(K key,       V val,       OutputCollector<Text,Text> output,       Reporter reporter) The identify function. void reduce(Text key,             Iterator<Text> values,             OutputCollector<Text,Text> output,             Reporter reporter) Reduces values for a given key. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LOG public static final org.apache.commons.logging.Log LOG Constructor Detail FieldSelectionMapReduce public FieldSelectionMapReduce() Method Detail map public void map(K key,        V val,        OutputCollector<Text,Text> output,        Reporter reporter)          throws IOException The identify function. Input key/value pair is written directly to output. Specified by: map in interface Mapper<K,V,Text,Text> Parameters:key - the input key.val - the input value.output - collects mapped keys and values.reporter - facility to report progress. Throws: IOException configure public void configure(JobConf job) Description copied from interface: JobConfigurable Initializes a new instance from a JobConf. Specified by: configure in interface JobConfigurable Parameters:job - the configuration close public void close()            throws IOException Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Throws: IOException reduce public void reduce(Text key,           Iterator<Text> values,           OutputCollector<Text,Text> output,           Reporter reporter)             throws IOException Description copied from interface: Reducer Reduces values for a given key.      The framework calls this method for each   <key, (list of values)> pair in the grouped inputs.  Output values must be of the same type as input values.  Input keys must   not be altered. The framework will reuse the key and value objects  that are passed into the reduce, therefore the application should clone  the objects they want to keep a copy of. In many cases, all values are   combined into zero or one value.        Output pairs are collected with calls to    OutputCollector.collect(Object,Object).  Applications can use the Reporter provided to report progress   or just indicate that they are alive. In scenarios where the application   takes a significant amount of time to process individual key/value   pairs, this is crucial since the framework might assume that the task has   timed-out and kill that task. The other way of avoiding this is to set     mapreduce.task.timeout to a high-enough value (or even zero for no   time-outs). Specified by: reduce in interface Reducer<Text,Text,Text,Text> Parameters:key - the key.values - the list of values to reduce.output - to collect keys and combined values.reporter - facility to report progress. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FieldSelectionMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FieldSelectionMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.fieldsel Class FieldSelectionMapper<K,V> java.lang.Object org.apache.hadoop.mapreduce.Mapper<K,V,Text,Text> org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionMapper<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class FieldSelectionMapper<K,V> extends Mapper<K,V,Text,Text> This class implements a mapper class that can be used to perform  field selections in a manner similar to unix cut. The input data is treated  as fields separated by a user specified separator (the default value is  "\t"). The user can specify a list of fields that form the map output keys,  and a list of fields that form the map output values. If the inputformat is  TextInputFormat, the mapper will ignore the key to the map function. and the  fields are from the value only. Otherwise, the fields are the union of those  from the key and those from the value.    The field separator is under attribute "mapreduce.fieldsel.data.field.separator"    The map output field list spec is under attribute   "mapreduce.fieldsel.map.output.key.value.fields.spec".   The value is expected to be like  "keyFieldsSpec:valueFieldsSpec" key/valueFieldsSpec are comma (,) separated  field spec: fieldSpec,fieldSpec,fieldSpec ... Each field spec can be a   simple number (e.g. 5) specifying a specific field, or a range (like 2-5)  to specify a range of fields, or an open range (like 3-) specifying all   the fields starting from field 3. The open range field spec applies value  fields only. They have no effect on the key fields.    Here is an example: "4,3,0,1:6,5,1-3,7-". It specifies to use fields  4,3,0 and 1 for keys, and use fields 6,5,1,2,3,7 and above for values. Field Summary Fields  Modifier and Type Field and Description static org.apache.commons.logging.Log LOG  Constructor Summary Constructors  Constructor and Description FieldSelectionMapper()  Method Summary Methods  Modifier and Type Method and Description void map(K key,       V val,       org.apache.hadoop.mapreduce.Mapper.Context context) The identify function. void setup(org.apache.hadoop.mapreduce.Mapper.Context context) Called once at the beginning of the task. Methods inherited from class org.apache.hadoop.mapreduce.Mapper cleanup, run Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LOG public static final org.apache.commons.logging.Log LOG Constructor Detail FieldSelectionMapper public FieldSelectionMapper() Method Detail setup public void setup(org.apache.hadoop.mapreduce.Mapper.Context context)            throws IOException,                   InterruptedException Description copied from class: Mapper Called once at the beginning of the task. Overrides: setup in class Mapper<K,V,Text,Text> Throws: IOException InterruptedException map public void map(K key,        V val,        org.apache.hadoop.mapreduce.Mapper.Context context)          throws IOException,                 InterruptedException The identify function. Input key/value pair is written directly to output. Overrides: map in class Mapper<K,V,Text,Text> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FieldSelectionReducer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FieldSelectionReducer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.fieldsel Class FieldSelectionReducer<K,V> java.lang.Object org.apache.hadoop.mapreduce.Reducer<Text,Text,Text,Text> org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionReducer<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class FieldSelectionReducer<K,V> extends Reducer<Text,Text,Text,Text> This class implements a reducer class that can be used to perform field  selections in a manner similar to unix cut.     The input data is treated as fields separated by a user specified  separator (the default value is "\t"). The user can specify a list of  fields that form the reduce output keys, and a list of fields that form  the reduce output values. The fields are the union of those from the key  and those from the value.    The field separator is under attribute "mapreduce.fieldsel.data.field.separator"    The reduce output field list spec is under attribute   "mapreduce.fieldsel.reduce.output.key.value.fields.spec".   The value is expected to be like  "keyFieldsSpec:valueFieldsSpec" key/valueFieldsSpec are comma (,)   separated field spec: fieldSpec,fieldSpec,fieldSpec ... Each field spec  can be a simple number (e.g. 5) specifying a specific field, or a range  (like 2-5) to specify a range of fields, or an open range (like 3-)   specifying all the fields starting from field 3. The open range field  spec applies value fields only. They have no effect on the key fields.    Here is an example: "4,3,0,1:6,5,1-3,7-". It specifies to use fields  4,3,0 and 1 for keys, and use fields 6,5,1,2,3,7 and above for values. Field Summary Fields  Modifier and Type Field and Description static org.apache.commons.logging.Log LOG  Constructor Summary Constructors  Constructor and Description FieldSelectionReducer()  Method Summary Methods  Modifier and Type Method and Description void reduce(Text key,             Iterable<Text> values,             org.apache.hadoop.mapreduce.Reducer.Context context) This method is called once for each key. void setup(org.apache.hadoop.mapreduce.Reducer.Context context) Called once at the start of the task. Methods inherited from class org.apache.hadoop.mapreduce.Reducer cleanup, run Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LOG public static final org.apache.commons.logging.Log LOG Constructor Detail FieldSelectionReducer public FieldSelectionReducer() Method Detail setup public void setup(org.apache.hadoop.mapreduce.Reducer.Context context)            throws IOException,                   InterruptedException Description copied from class: Reducer Called once at the start of the task. Overrides: setup in class Reducer<Text,Text,Text,Text> Throws: IOException InterruptedException reduce public void reduce(Text key,           Iterable<Text> values,           org.apache.hadoop.mapreduce.Reducer.Context context)             throws IOException,                    InterruptedException Description copied from class: Reducer This method is called once for each key. Most applications will define  their reduce class by overriding this method. The default implementation  is an identity function. Overrides: reduce in class Reducer<Text,Text,Text,Text> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FieldTypeInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FieldTypeInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.meta Class FieldTypeInfo java.lang.Object org.apache.hadoop.record.meta.FieldTypeInfo Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class FieldTypeInfo extends Object Represents a type information for a field, which is made up of its   ID (name) and its type (a TypeID object). Method Summary Methods  Modifier and Type Method and Description boolean equals(FieldTypeInfo ti) Deprecated.    boolean equals(Object o) Deprecated.  Two FieldTypeInfos are equal if ach of their fields matches String getFieldID() Deprecated.  get the field's id (name) TypeID getTypeID() Deprecated.  get the field's TypeID object int hashCode() Deprecated.  We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Method Detail getTypeID public TypeID getTypeID() Deprecated.  get the field's TypeID object getFieldID public String getFieldID() Deprecated.  get the field's id (name) equals public boolean equals(Object o) Deprecated.  Two FieldTypeInfos are equal if ach of their fields matches Overrides: equals in class Object hashCode public int hashCode() Deprecated.  We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Overrides: hashCode in class Object equals public boolean equals(FieldTypeInfo ti) Deprecated.  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileAlreadyExistsException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileAlreadyExistsException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class FileAlreadyExistsException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.mapred.FileAlreadyExistsException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class FileAlreadyExistsException extends IOException Used when target file already exists for any operation and   is not configured to be overwritten. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description FileAlreadyExistsException()  FileAlreadyExistsException(String msg)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail FileAlreadyExistsException public FileAlreadyExistsException() FileAlreadyExistsException public FileAlreadyExistsException(String msg) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileChecksum (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileChecksum (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FileChecksum java.lang.Object org.apache.hadoop.fs.FileChecksum All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public abstract class FileChecksum extends Object implements Writable An abstract class representing file checksums for files. Constructor Summary Constructors  Constructor and Description FileChecksum()  Method Summary Methods  Modifier and Type Method and Description boolean equals(Object other) Return true if both the algorithms and the values are the same. abstract String getAlgorithmName() The checksum algorithm name abstract byte[] getBytes() The value of the checksum in bytes org.apache.hadoop.fs.Options.ChecksumOpt getChecksumOpt()  abstract int getLength() The length of the checksum in bytes int hashCode()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.io.Writable readFields, write Constructor Detail FileChecksum public FileChecksum() Method Detail getAlgorithmName public abstract String getAlgorithmName() The checksum algorithm name getLength public abstract int getLength() The length of the checksum in bytes getBytes public abstract byte[] getBytes() The value of the checksum in bytes getChecksumOpt public org.apache.hadoop.fs.Options.ChecksumOpt getChecksumOpt() equals public boolean equals(Object other) Return true if both the algorithms and the values are the same. Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FileContext java.lang.Object org.apache.hadoop.fs.FileContext @InterfaceAudience.Public @InterfaceStability.Evolving public class FileContext extends Object The FileContext class provides an interface to the application writer for  using the Hadoop file system.  It provides a set of methods for the usual operation: create, open,   list, etc        *** Path Names ***       The Hadoop file system supports a URI name space and URI names.  It offers a forest of file systems that can be referenced using fully  qualified URIs.  Two common Hadoop file systems implementations are     the local file system: file:///path   the hdfs file system hdfs://nnAddress:nnPort/path      While URI names are very flexible, it requires knowing the name or address  of the server. For convenience one often wants to access the default system  in one's environment without knowing its name/address. This has an  additional benefit that it allows one to change one's default fs   (e.g. admin moves application from cluster1 to cluster2).      To facilitate this, Hadoop supports a notion of a default file system.  The user can set his default file system, although this is  typically set up for you in your environment via your default config.  A default file system implies a default scheme and authority; slash-relative  names (such as /for/bar) are resolved relative to that default FS.  Similarly a user can also have working-directory-relative names (i.e. names  not starting with a slash). While the working directory is generally in the  same default FS, the wd can be in a different FS.     Hence Hadoop path names can be one of:       fully qualified URI: scheme://authority/path    slash relative names: /path relative to the default file system    wd-relative names: path  relative to the working dir         Relative paths with scheme (scheme:foo/bar) are illegal.         ****The Role of the FileContext and configuration defaults****      The FileContext provides file namespace context for resolving file names;   it also contains the umask for permissions, In that sense it is like the   per-process file-related state in Unix system.   These two properties        default file system i.e your slash)    umask      in general, are obtained from the default configuration file   in your environment,  (@see Configuration).      No other configuration parameters are obtained from the default config as    far as the file context layer is concerned. All file system instances   (i.e. deployments of file systems) have default properties; we call these   server side (SS) defaults. Operation like create allow one to select many    properties: either pass them in as explicit parameters or use   the SS properties.      The file system related SS defaults are       the home directory (default is "/user/userName")    the initial wd (only for local fs)    replication factor    block size    buffer size    encryptDataTransfer     checksum option. (checksumType and  bytesPerChecksum)        *** Usage Model for the FileContext class ***     Example 1: use the default config read from the $HADOOP_CONFIG/core.xml.    Unspecified values come from core-defaults.xml in the release jar.         myFContext = FileContext.getFileContext(); // uses the default config                                                 // which has your default FS      myFContext.create(path, ...);     myFContext.setWorkingDir(path)     myFContext.open (path, ...);         Example 2: Get a FileContext with a specific URI as the default FS         myFContext = FileContext.getFileContext(URI)    myFContext.create(path, ...);    ...     Example 3: FileContext with local file system as the default        myFContext = FileContext.getLocalFSFileContext()    myFContext.create(path, ...);    ...      Example 4: Use a specific config, ignoring $HADOOP_CONFIG   Generally you should not need use a config unless you are doing          configX = someConfigSomeOnePassedToYou.     myFContext = getFileContext(configX); // configX is not changed,                                               // is passed down      myFContext.create(path, ...);    ...    Field Summary Fields  Modifier and Type Field and Description static FsPermission DEFAULT_PERM Default permission for directory and symlink  In previous versions, this default permission was also used to  create files, so files created end up with ugo+x permission. static FsPermission DIR_DEFAULT_PERM Default permission for directory static FsPermission FILE_DEFAULT_PERM Default permission for file static org.apache.commons.logging.Log LOG  static int SHUTDOWN_HOOK_PRIORITY Priority of the FileContext shutdown hook. Method Summary Methods  Modifier and Type Method and Description static void clearStatistics() Clears all the statistics stored in AbstractFileSystem, for all the file  systems. FSDataOutputStream create(Path f,             EnumSet<CreateFlag> createFlag,             org.apache.hadoop.fs.Options.CreateOpts... opts) Create or overwrite file on indicated path and returns an output stream for  writing into the file. void createSymlink(Path target,                           Path link,                           boolean createParent) Creates a symbolic link to an existing file. boolean delete(Path f,             boolean recursive) Delete a file. boolean deleteOnExit(Path f) Mark a path to be deleted on JVM shutdown. AclStatus getAclStatus(Path path) Gets the ACLs of files and directories. static Map<URI,org.apache.hadoop.fs.FileSystem.Statistics> getAllStatistics()  FileChecksum getFileChecksum(Path f) Get the checksum of a file. static FileContext getFileContext() Create a FileContext using the default config read from the  $HADOOP_CONFIG/core.xml, Unspecified key-values for config are defaulted  from core-defaults.xml in the release jar. protected static FileContext getFileContext(AbstractFileSystem defaultFS) Create a FileContext for specified file system using the default config. static FileContext getFileContext(AbstractFileSystem defFS,                             Configuration aConf) Create a FileContext with specified FS as default using the specified  config. static FileContext getFileContext(Configuration aConf) Create a FileContext using the passed config. static FileContext getFileContext(URI defaultFsUri) Create a FileContext for specified URI using the default config. static FileContext getFileContext(URI defaultFsUri,                             Configuration aConf) Create a FileContext for specified default URI using the specified config. FileStatus getFileLinkStatus(Path f) Return a file status object that represents the path. FileStatus getFileStatus(Path f) Return a file status object that represents the path. protected AbstractFileSystem getFSofPath(Path absOrFqPath) Get the file system of supplied path. FsStatus getFsStatus(Path f) Returns a status object describing the use and capacity of the  file system denoted by the Parh argument p. Path getHomeDirectory() Return the current user's home directory in this file system. Path getLinkTarget(Path f) Returns the target of the given symbolic link as it was specified  when the link was created. static FileContext getLocalFSFileContext()  static FileContext getLocalFSFileContext(Configuration aConf)  static org.apache.hadoop.fs.FileSystem.Statistics getStatistics(URI uri) Get the statistics for a particular file system org.apache.hadoop.security.UserGroupInformation getUgi() Gets the ugi in the file-context FsPermission getUMask()  Path getWorkingDirectory() Gets the working directory for wd-relative names (such a "foo/bar"). byte[] getXAttr(Path path,                 String name) Get an xattr for a file or directory. Map<String,byte[]> getXAttrs(Path path) Get all of the xattrs for a file or directory. Map<String,byte[]> getXAttrs(Path path,                   List<String> names) Get all of the xattrs for a file or directory. org.apache.hadoop.fs.RemoteIterator<Path> listCorruptFileBlocks(Path path)  org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f) List the statuses of the files/directories in the given path if the path is  a directory. org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatus(Path f) List the statuses of the files/directories in the given path if the path is  a directory. List<String> listXAttrs(Path path) Get all of the xattr names for a file or directory. Path makeQualified(Path path) Make the path fully qualified if it is isn't. void mkdir(Path dir,           FsPermission permission,           boolean createParent) Make(create) a directory and all the non-existent parents. void modifyAclEntries(Path path,                                 List<AclEntry> aclSpec) Modifies ACL entries of files and directories. FSDataInputStream open(Path f) Opens an FSDataInputStream at the indicated Path using  default buffersize. FSDataInputStream open(Path f,         int bufferSize) Opens an FSDataInputStream at the indicated Path. static void printStatistics() Prints the statistics to standard output. void removeAcl(Path path) Removes all but the base ACL entries of files and directories. void removeAclEntries(Path path,                                 List<AclEntry> aclSpec) Removes ACL entries from files and directories. void removeDefaultAcl(Path path) Removes all default ACL entries from files and directories. void removeXAttr(Path path,                       String name) Remove an xattr of a file or directory. void rename(Path src,             Path dst,             org.apache.hadoop.fs.Options.Rename... options) Renames Path src to Path dst     protected Path resolve(Path f) Resolves all symbolic links in the specified path. protected Path resolveIntermediate(Path f) Resolves all symbolic links in the specified path leading up   to, but not including the final path component. Path resolvePath(Path f) Resolve the path following any symlinks or mount points void setAcl(Path path,             List<AclEntry> aclSpec) Fully replaces ACL of files and directories, discarding all existing  entries. void setOwner(Path f,                 String username,                 String groupname) Set owner of a path (i.e. void setPermission(Path f,                           FsPermission permission) Set permission of a path. boolean setReplication(Path f,                             short replication) Set replication for an existing file. void setTimes(Path f,                 long mtime,                 long atime) Set access time of a file. void setUMask(FsPermission newUmask) Set umask to the supplied parameter. void setVerifyChecksum(boolean verifyChecksum,                                   Path f) Set the verify checksum flag for the  file system denoted by the path. void setWorkingDirectory(Path newWDir) Set the working directory for wd-relative names (such a "foo/bar"). void setXAttr(Path path,                 String name,                 byte[] value) Set an xattr of a file or directory. void setXAttr(Path path,                 String name,                 byte[] value,                 EnumSet<XAttrSetFlag> flag) Set an xattr of a file or directory. boolean truncate(Path f,                 long newLength) Truncate the file in the indicated path to the indicated size. org.apache.hadoop.fs.FileContext.Util util()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LOG public static final org.apache.commons.logging.Log LOG DEFAULT_PERM public static final FsPermission DEFAULT_PERM Default permission for directory and symlink  In previous versions, this default permission was also used to  create files, so files created end up with ugo+x permission.  See HADOOP-9155 for detail.   Two new constants are added to solve this, please use   DIR_DEFAULT_PERM for directory, and use  FILE_DEFAULT_PERM for file.  This constant is kept for compatibility. DIR_DEFAULT_PERM public static final FsPermission DIR_DEFAULT_PERM Default permission for directory FILE_DEFAULT_PERM public static final FsPermission FILE_DEFAULT_PERM Default permission for file SHUTDOWN_HOOK_PRIORITY public static final int SHUTDOWN_HOOK_PRIORITY Priority of the FileContext shutdown hook. See Also:Constant Field Values Method Detail getFSofPath protected AbstractFileSystem getFSofPath(Path absOrFqPath)                                   throws UnsupportedFileSystemException,                                          IOException Get the file system of supplied path. Parameters:absOrFqPath - - absolute or fully qualified path Returns:the file system of the path Throws: UnsupportedFileSystemException - If the file system for            absOrFqPath is not supported. IOExcepton - If the file system for absOrFqPath could          not be instantiated. IOException getFileContext public static FileContext getFileContext(AbstractFileSystem defFS,                          Configuration aConf) Create a FileContext with specified FS as default using the specified  config. Parameters:defFS - aConf -  Returns:new FileContext with specifed FS as default. getFileContext protected static FileContext getFileContext(AbstractFileSystem defaultFS) Create a FileContext for specified file system using the default config. Parameters:defaultFS -  Returns:a FileContext with the specified AbstractFileSystem                  as the default FS. getFileContext public static FileContext getFileContext()                                   throws UnsupportedFileSystemException Create a FileContext using the default config read from the  $HADOOP_CONFIG/core.xml, Unspecified key-values for config are defaulted  from core-defaults.xml in the release jar. Throws: UnsupportedFileSystemException - If the file system from the default            configuration is not supported getLocalFSFileContext public static FileContext getLocalFSFileContext()                                          throws UnsupportedFileSystemException Returns:a FileContext for the local file system using the default config. Throws: UnsupportedFileSystemException - If the file system for            FsConstants.LOCAL_FS_URI is not supported. getFileContext public static FileContext getFileContext(URI defaultFsUri)                                   throws UnsupportedFileSystemException Create a FileContext for specified URI using the default config. Parameters:defaultFsUri -  Returns:a FileContext with the specified URI as the default FS. Throws: UnsupportedFileSystemException - If the file system for            defaultFsUri is not supported getFileContext public static FileContext getFileContext(URI defaultFsUri,                          Configuration aConf)                                   throws UnsupportedFileSystemException Create a FileContext for specified default URI using the specified config. Parameters:defaultFsUri - aConf -  Returns:new FileContext for specified uri Throws: UnsupportedFileSystemException - If the file system with specified is            not supported RuntimeException - If the file system specified is supported but          could not be instantiated, or if login fails. getFileContext public static FileContext getFileContext(Configuration aConf)                                   throws UnsupportedFileSystemException Create a FileContext using the passed config. Generally it is better to use  getFileContext(URI, Configuration) instead of this one. Parameters:aConf -  Returns:new FileContext Throws: UnsupportedFileSystemException - If file system in the config            is not supported getLocalFSFileContext public static FileContext getLocalFSFileContext(Configuration aConf)                                          throws UnsupportedFileSystemException Parameters:aConf - - from which the FileContext is configured Returns:a FileContext for the local file system using the specified config. Throws: UnsupportedFileSystemException - If default file system in the config            is not supported setWorkingDirectory public void setWorkingDirectory(Path newWDir)                          throws IOException Set the working directory for wd-relative names (such a "foo/bar"). Working  directory feature is provided by simply prefixing relative names with the  working dir. Note this is different from Unix where the wd is actually set  to the inode. Hence setWorkingDir does not follow symlinks etc. This works  better in a distributed environment that has multiple independent roots.  getWorkingDirectory() should return what setWorkingDir() set. Parameters:newWDir - new working directory Throws: IOException -             NewWdir can be one of:                        relative path: "foo/bar";            absolute without scheme: "/foo/bar"            fully qualified with scheme: "xx://auth/foo/bar"                          Illegal WDs:                        relative with scheme: "xx:foo/bar"            non existent directory             getWorkingDirectory public Path getWorkingDirectory() Gets the working directory for wd-relative names (such a "foo/bar"). getUgi public org.apache.hadoop.security.UserGroupInformation getUgi() Gets the ugi in the file-context Returns:UserGroupInformation getHomeDirectory public Path getHomeDirectory() Return the current user's home directory in this file system.  The default implementation returns "/user/$USER/". Returns:the home directory getUMask public FsPermission getUMask() Returns:the umask of this FileContext setUMask public void setUMask(FsPermission newUmask) Set umask to the supplied parameter. Parameters:newUmask - the new umask resolvePath public Path resolvePath(Path f)                  throws FileNotFoundException,                         org.apache.hadoop.fs.UnresolvedLinkException,                         org.apache.hadoop.security.AccessControlException,                         IOException Resolve the path following any symlinks or mount points Parameters:f - to be resolved Returns:fully qualified resolved path Throws: FileNotFoundException - If f does not exist org.apache.hadoop.security.AccessControlException - if access denied IOException - If an IO Error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws            undeclared exception to RPC server    RuntimeExceptions: InvalidPathException - If path f is not valid org.apache.hadoop.fs.UnresolvedLinkException makeQualified public Path makeQualified(Path path) Make the path fully qualified if it is isn't.   A Fully-qualified path has scheme and authority specified and an absolute  path.  Use the default file system and working dir in this FileContext to qualify. Parameters:path -  Returns:qualified path create public FSDataOutputStream create(Path f,                         EnumSet<CreateFlag> createFlag,                         org.apache.hadoop.fs.Options.CreateOpts... opts)                           throws org.apache.hadoop.security.AccessControlException,                                  FileAlreadyExistsException,                                  FileNotFoundException,                                  ParentNotDirectoryException,                                  UnsupportedFileSystemException,                                  IOException Create or overwrite file on indicated path and returns an output stream for  writing into the file. Parameters:f - the file name to opencreateFlag - gives the semantics of create; see CreateFlagopts - file creation options; see Options.CreateOpts.                      Progress - to report progress on the operation - default null           Permission - umask is applied against permisssion: default is           FsPermissions:getDefault()             CreateParent - create missing parent path; default is to not           to create parents           The defaults for the following are SS defaults of the file           server implementing the target path. Not all parameters make sense           for all kinds of file system - eg. localFS ignores Blocksize,           replication, checksum                      BufferSize - buffersize used in FSDataOutputStream           Blocksize - block size for file blocks           ReplicationFactor - replication for blocks           ChecksumParam - Checksum parameters. server default is used           if not specified.                       Returns:FSDataOutputStream for created file Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileAlreadyExistsException - If file f already exists FileNotFoundException - If parent of f does not exist            and createParent is false ParentNotDirectoryException - If parent of f is not a            directory. UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws            undeclared exception to RPC server    RuntimeExceptions: InvalidPathException - If path f is not valid mkdir public void mkdir(Path dir,          FsPermission permission,          boolean createParent)            throws org.apache.hadoop.security.AccessControlException,                   FileAlreadyExistsException,                   FileNotFoundException,                   ParentNotDirectoryException,                   UnsupportedFileSystemException,                   IOException Make(create) a directory and all the non-existent parents. Parameters:dir - - the dir to makepermission - - permissions is set permission&~umaskcreateParent - - if true then missing parent dirs are created if false           then parent must exist Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileAlreadyExistsException - If directory dir already            exists FileNotFoundException - If parent of dir does not exist            and createParent is false ParentNotDirectoryException - If parent of dir is not a            directory UnsupportedFileSystemException - If file system for dir          is not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server    RuntimeExceptions: InvalidPathException - If path dir is not valid delete public boolean delete(Path f,              boolean recursive)                throws org.apache.hadoop.security.AccessControlException,                       FileNotFoundException,                       UnsupportedFileSystemException,                       IOException Delete a file. Parameters:f - the path to delete.recursive - if path is a directory and set to   true, the directory is deleted else throws an exception. In  case of a file the recursive can be set to either true or false. Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server    RuntimeExceptions: InvalidPathException - If path f is invalid open public FSDataInputStream open(Path f)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               UnsupportedFileSystemException,                               IOException Opens an FSDataInputStream at the indicated Path using  default buffersize. Parameters:f - the file name to open Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If file f does not exist UnsupportedFileSystemException - If file system for f          is not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server open public FSDataInputStream open(Path f,                      int bufferSize)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               UnsupportedFileSystemException,                               IOException Opens an FSDataInputStream at the indicated Path. Parameters:f - the file name to openbufferSize - the size of the buffer to be used. Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If file f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server truncate public boolean truncate(Path f,                long newLength)                  throws org.apache.hadoop.security.AccessControlException,                         FileNotFoundException,                         UnsupportedFileSystemException,                         IOException Truncate the file in the indicated path to the indicated size.    Fails if path is a directory.  Fails if path does not exist.  Fails if path is not closed.  Fails if new size is greater than current size.   Parameters:f - The path to the file to be truncatednewLength - The size the file is to be truncated to Returns:true if the file has been truncated to the desired  newLength and is immediately available to be reused for  write operations such as append, or  false if a background process of adjusting the length of  the last block has been started, and clients should wait for it to  complete before proceeding with further file updates. Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If file f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred  Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws            undeclared exception to RPC server setReplication public boolean setReplication(Path f,                      short replication)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               IOException Set replication for an existing file. Parameters:f - file namereplication - new replication Returns:true if successful Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If file f does not exist IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server rename public void rename(Path src,           Path dst,           org.apache.hadoop.fs.Options.Rename... options)             throws org.apache.hadoop.security.AccessControlException,                    FileAlreadyExistsException,                    FileNotFoundException,                    ParentNotDirectoryException,                    UnsupportedFileSystemException,                    IOException Renames Path src to Path dst    Fails if src is a file and dst is a directory.  Fails if src is a directory and dst is a file.  Fails if the parent of dst does not exist or is a file.      If OVERWRITE option is not passed as an argument, rename fails if the dst  already exists.    If OVERWRITE option is passed as an argument, rename overwrites the dst if  it is a file or an empty directory. Rename fails if dst is a non-empty  directory.    Note that atomicity of rename is dependent on the file system  implementation. Please refer to the file system documentation for details   Parameters:src - path to be renameddst - new path after rename Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileAlreadyExistsException - If dst already exists and            options has Options.Rename.OVERWRITE             option false. FileNotFoundException - If src does not exist ParentNotDirectoryException - If parent of dst is not a            directory UnsupportedFileSystemException - If file system for src            and dst is not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws            undeclared exception to RPC server setPermission public void setPermission(Path f,                  FsPermission permission)                    throws org.apache.hadoop.security.AccessControlException,                           FileNotFoundException,                           UnsupportedFileSystemException,                           IOException Set permission of a path. Parameters:f - permission - - the new absolute permission (umask is not applied) Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f          is not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server setOwner public void setOwner(Path f,             String username,             String groupname)               throws org.apache.hadoop.security.AccessControlException,                      UnsupportedFileSystemException,                      FileNotFoundException,                      IOException Set owner of a path (i.e. a file or a directory). The parameters username  and groupname cannot both be null. Parameters:f - The pathusername - If it is null, the original username remains unchanged.groupname - If it is null, the original groupname remains unchanged. Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server    RuntimeExceptions: HadoopIllegalArgumentException - If username or            groupname is invalid. setTimes public void setTimes(Path f,             long mtime,             long atime)               throws org.apache.hadoop.security.AccessControlException,                      FileNotFoundException,                      UnsupportedFileSystemException,                      IOException Set access time of a file. Parameters:f - The pathmtime - Set the modification time of this file.         The number of milliseconds since epoch (Jan 1, 1970).          A value of -1 means that this call should not set modification time.atime - Set the access time of this file.         The number of milliseconds since Jan 1, 1970.          A value of -1 means that this call should not set access time. Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server getFileChecksum public FileChecksum getFileChecksum(Path f)                              throws org.apache.hadoop.security.AccessControlException,                                     FileNotFoundException,                                     IOException Get the checksum of a file. Parameters:f - file path Returns:The file checksum.  The default return value is null,   which indicates that no checksum algorithm is implemented   in the corresponding FileSystem. Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server setVerifyChecksum public void setVerifyChecksum(boolean verifyChecksum,                      Path f)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               UnsupportedFileSystemException,                               IOException Set the verify checksum flag for the  file system denoted by the path.  This is only applicable if the   corresponding FileSystem supports checksum. By default doesn't do anything. Parameters:verifyChecksum - f - set the verifyChecksum for the Filesystem containing this path Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server getFileStatus public FileStatus getFileStatus(Path f)                          throws org.apache.hadoop.security.AccessControlException,                                 FileNotFoundException,                                 UnsupportedFileSystemException,                                 IOException Return a file status object that represents the path. Parameters:f - The path we want information from Returns:a FileStatus object Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server getFileLinkStatus public FileStatus getFileLinkStatus(Path f)                              throws org.apache.hadoop.security.AccessControlException,                                     FileNotFoundException,                                     UnsupportedFileSystemException,                                     IOException Return a file status object that represents the path. If the path   refers to a symlink then the FileStatus of the symlink is returned.  The behavior is equivalent to #getFileStatus() if the underlying  file system does not support symbolic links. Parameters:f - The path we want information from. Returns:A FileStatus object Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred getLinkTarget public Path getLinkTarget(Path f)                    throws org.apache.hadoop.security.AccessControlException,                           FileNotFoundException,                           UnsupportedFileSystemException,                           IOException Returns the target of the given symbolic link as it was specified  when the link was created.  Links in the path leading up to the  final path component are resolved transparently. Parameters:f - the path to return the target of Returns:The un-interpreted target of the symbolic link. Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If path f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If the given path does not refer to a symlink            or an I/O error occurred getFsStatus public FsStatus getFsStatus(Path f)                      throws org.apache.hadoop.security.AccessControlException,                             FileNotFoundException,                             UnsupportedFileSystemException,                             IOException Returns a status object describing the use and capacity of the  file system denoted by the Parh argument p.  If the file system has multiple partitions, the  use and capacity of the partition pointed to by the specified  path is reflected. Parameters:f - Path for which status should be obtained. null means the  root partition of the default file system. Returns:a FsStatus object Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server createSymlink public void createSymlink(Path target,                  Path link,                  boolean createParent)                    throws org.apache.hadoop.security.AccessControlException,                           FileAlreadyExistsException,                           FileNotFoundException,                           ParentNotDirectoryException,                           UnsupportedFileSystemException,                           IOException Creates a symbolic link to an existing file. An exception is thrown if   the symlink exits, the user does not have permission to create symlink,  or the underlying file system does not support symlinks.    Symlink permissions are ignored, access to a symlink is determined by  the permissions of the symlink target.    Symlinks in paths leading up to the final path component are resolved   transparently. If the final path component refers to a symlink some   functions operate on the symlink itself, these are:  - delete(f) and deleteOnExit(f) - Deletes the symlink.  - rename(src, dst) - If src refers to a symlink, the symlink is     renamed. If dst refers to a symlink, the symlink is over-written.  - getLinkTarget(f) - Returns the target of the symlink.   - getFileLinkStatus(f) - Returns a FileStatus object describing    the symlink.  Some functions, create() and mkdir(), expect the final path component  does not exist. If they are given a path that refers to a symlink that   does exist they behave as if the path referred to an existing file or   directory. All other functions fully resolve, ie follow, the symlink.   These are: open, setReplication, setOwner, setTimes, setWorkingDirectory,  setPermission, getFileChecksum, setVerifyChecksum, getFileBlockLocations,  getFsStatus, getFileStatus, exists, and listStatus.    Symlink targets are stored as given to createSymlink, assuming the   underlying file system is capable of storing a fully qualified URI.  Dangling symlinks are permitted. FileContext supports four types of   symlink targets, and resolves them as follows    Given a path referring to a symlink of form:           fs://host/A/B/link         In this path X is the scheme and authority that identify the file system,  and Y is the path leading up to the final path component "link". If Y is  a symlink  itself then let Y' be the target of Y and X' be the scheme and  authority of Y'. Symlink targets may:    1. Fully qualified URIs    fs://hostX/A/B/file  Resolved according to the target file system.    2. Partially qualified URIs (eg scheme but no host)    fs:///A/B/file  Resolved according to the target file system. Eg resolving                  a symlink to hdfs:///A results in an exception because                  HDFS URIs must be fully qualified, while a symlink to                   file:///A will not since Hadoop's local file systems                   require partially qualified URIs.    3. Relative paths    path  Resolves to [Y'][path]. Eg if Y resolves to hdfs://host/A and path         is "../B/file" then [Y'][path] is hdfs://host/B/file    4. Absolute paths    path  Resolves to [X'][path]. Eg if Y resolves hdfs://host/A/B and path        is "/file" then [X][path] is hdfs://host/file   Parameters:target - the target of the symbolic linklink - the path to be created that points to targetcreateParent - if true then missing parent dirs are created if                       false then parent must exist Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileAlreadyExistsException - If file linkcode> already exists FileNotFoundException - If target does not exist ParentNotDirectoryException - If parent of link is not a            directory. UnsupportedFileSystemException - If file system for             target or link is not supported IOException - If an I/O error occurred listStatus public org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatus(Path f)                                                            throws org.apache.hadoop.security.AccessControlException,                                                                   FileNotFoundException,                                                                   UnsupportedFileSystemException,                                                                   IOException List the statuses of the files/directories in the given path if the path is  a directory. Parameters:f - is the path Returns:an iterator that traverses statuses of the files/directories           in the given path Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server listCorruptFileBlocks public org.apache.hadoop.fs.RemoteIterator<Path> listCorruptFileBlocks(Path path)                                                                 throws IOException Returns:an iterator over the corrupt files under the given path  (may contain duplicates if a file has more than one corrupt block) Throws: IOException listLocatedStatus public org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f)                                                                          throws org.apache.hadoop.security.AccessControlException,                                                                                 FileNotFoundException,                                                                                 UnsupportedFileSystemException,                                                                                 IOException List the statuses of the files/directories in the given path if the path is  a directory.   Return the file's status and block locations If the path is a file.    If a returned status is a file, it contains the file's block locations. Parameters:f - is the path Returns:an iterator that traverses statuses of the files/directories           in the given path  If any IO exception (for example the input directory gets deleted while  listing is being executed), next() or hasNext() of the returned iterator  may throw a RuntimeException with the io exception as the cause. Throws: org.apache.hadoop.security.AccessControlException - If access is denied FileNotFoundException - If f does not exist UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server deleteOnExit public boolean deleteOnExit(Path f)                      throws org.apache.hadoop.security.AccessControlException,                             IOException Mark a path to be deleted on JVM shutdown. Parameters:f - the existing path to delete. Returns:true if deleteOnExit is successful, otherwise false. Throws: org.apache.hadoop.security.AccessControlException - If access is denied UnsupportedFileSystemException - If file system for f is            not supported IOException - If an I/O error occurred    Exceptions applicable to file systems accessed over RPC: org.apache.hadoop.ipc.RpcClientException - If an exception occurred in the RPC client org.apache.hadoop.ipc.RpcServerException - If an exception occurred in the RPC server org.apache.hadoop.ipc.UnexpectedServerException - If server implementation throws             undeclared exception to RPC server util public org.apache.hadoop.fs.FileContext.Util util() resolve protected Path resolve(Path f)                 throws FileNotFoundException,                        org.apache.hadoop.fs.UnresolvedLinkException,                        org.apache.hadoop.security.AccessControlException,                        IOException Resolves all symbolic links in the specified path.  Returns the new path object. Throws: FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException org.apache.hadoop.security.AccessControlException IOException resolveIntermediate protected Path resolveIntermediate(Path f)                             throws IOException Resolves all symbolic links in the specified path leading up   to, but not including the final path component. Parameters:f - path to resolve Returns:the new path object. Throws: IOException getStatistics public static org.apache.hadoop.fs.FileSystem.Statistics getStatistics(URI uri) Get the statistics for a particular file system Parameters:uri - the uri to lookup the statistics. Only scheme and authority part           of the uri are used as the key to store and lookup. Returns:a statistics object clearStatistics public static void clearStatistics() Clears all the statistics stored in AbstractFileSystem, for all the file  systems. printStatistics public static void printStatistics() Prints the statistics to standard output. File System is identified by the  scheme and authority. getAllStatistics public static Map<URI,org.apache.hadoop.fs.FileSystem.Statistics> getAllStatistics() Returns:Map of uri and statistics for each filesystem instantiated. The uri          consists of scheme and authority for the filesystem. modifyAclEntries public void modifyAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Modifies ACL entries of files and directories.  This method can add new ACL  entries or modify the permissions on existing ACL entries.  All existing  ACL entries that are not specified in this call are retained without  changes.  (Modifications are merged into the current ACL.) Parameters:path - Path to modifyaclSpec - List describing modifications Throws: IOException - if an ACL could not be modified removeAclEntries public void removeAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Removes ACL entries from files and directories.  Other ACL entries are  retained. Parameters:path - Path to modifyaclSpec - List describing entries to remove Throws: IOException - if an ACL could not be modified removeDefaultAcl public void removeDefaultAcl(Path path)                       throws IOException Removes all default ACL entries from files and directories. Parameters:path - Path to modify Throws: IOException - if an ACL could not be modified removeAcl public void removeAcl(Path path)                throws IOException Removes all but the base ACL entries of files and directories.  The entries  for user, group, and others are retained for compatibility with permission  bits. Parameters:path - Path to modify Throws: IOException - if an ACL could not be removed setAcl public void setAcl(Path path,           List<AclEntry> aclSpec)             throws IOException Fully replaces ACL of files and directories, discarding all existing  entries. Parameters:path - Path to modifyaclSpec - List describing modifications, must include entries    for user, group, and others for compatibility with permission bits. Throws: IOException - if an ACL could not be modified getAclStatus public AclStatus getAclStatus(Path path)                        throws IOException Gets the ACLs of files and directories. Parameters:path - Path to get Returns:RemoteIterator which returns each AclStatus Throws: IOException - if an ACL could not be read setXAttr public void setXAttr(Path path,             String name,             byte[] value)               throws IOException Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to modifyname - xattr name.value - xattr value. Throws: IOException setXAttr public void setXAttr(Path path,             String name,             byte[] value,             EnumSet<XAttrSetFlag> flag)               throws IOException Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to modifyname - xattr name.value - xattr value.flag - xattr set flag Throws: IOException getXAttr public byte[] getXAttr(Path path,               String name)                 throws IOException Get an xattr for a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributename - xattr name. Returns:byte[] xattr value. Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path)                              throws IOException Get all of the xattrs for a file or directory.  Only those xattrs for which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributes Returns:Map describing the XAttrs of the file or directory Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path,                            List<String> names)                              throws IOException Get all of the xattrs for a file or directory.  Only those xattrs for which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributesnames - XAttr names. Returns:Map describing the XAttrs of the file or directory Throws: IOException removeXAttr public void removeXAttr(Path path,                String name)                  throws IOException Remove an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to remove extended attributename - xattr name Throws: IOException listXAttrs public List<String> listXAttrs(Path path)                         throws IOException Get all of the xattr names for a file or directory.  Only those xattr names which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributes Returns:List of the XAttr names of the file or directory Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class FileInputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K,V> Direct Known Subclasses: CombineFileInputFormat, FixedLengthInputFormat, KeyValueTextInputFormat, NLineInputFormat, SequenceFileInputFormat, TextInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public abstract class FileInputFormat<K,V> extends InputFormat<K,V> A base class for file-based InputFormats.    FileInputFormat is the base class for all file-based   InputFormats. This provides a generic implementation of  getSplits(JobContext).  Subclasses of FileInputFormat can also override the   isSplitable(JobContext, Path) method to ensure input-files are  not split-up and are processed as a whole by Mappers. Field Summary Fields  Modifier and Type Field and Description static int DEFAULT_LIST_STATUS_NUM_THREADS  static String INPUT_DIR  static String INPUT_DIR_RECURSIVE  static String LIST_STATUS_NUM_THREADS  static String NUM_INPUT_FILES  static String PATHFILTER_CLASS  static String SPLIT_MAXSIZE  static String SPLIT_MINSIZE  Constructor Summary Constructors  Constructor and Description FileInputFormat()  Method Summary Methods  Modifier and Type Method and Description static void addInputPath(Job job,                         Path path) Add a Path to the list of inputs for the map-reduce job. protected void addInputPathRecursively(List<FileStatus> result,                                               FileSystem fs,                                               Path path,                                               PathFilter inputFilter) Add files in the input path recursively into the results. static void addInputPaths(Job job,                           String commaSeparatedPaths) Add the given comma separated paths to the list of inputs for   the map-reduce job. protected long computeSplitSize(long blockSize,                                 long minSize,                                 long maxSize)  protected int getBlockIndex(BlockLocation[] blkLocations,                           long offset)  protected long getFormatMinSplitSize() Get the lower bound on split size imposed by the format. static boolean getInputDirRecursive(JobContext job)  static PathFilter getInputPathFilter(JobContext context) Get a PathFilter instance of the filter set for the input paths. static Path[] getInputPaths(JobContext context) Get the list of input Paths for the map-reduce job. static long getMaxSplitSize(JobContext context) Get the maximum split size. static long getMinSplitSize(JobContext job) Get the minimum split size List<InputSplit> getSplits(JobContext job) Generate the list of files and make them into FileSplits. protected boolean isSplitable(JobContext context,                       Path filename) Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be. protected List<FileStatus> listStatus(JobContext job) List input directories. protected FileSplit makeSplit(Path file,                   long start,                   long length,                   String[] hosts) A factory that makes the split for this class. protected FileSplit makeSplit(Path file,                   long start,                   long length,                   String[] hosts,                   String[] inMemoryHosts) A factory that makes the split for this class. static void setInputDirRecursive(Job job,                                         boolean inputDirRecursive)  static void setInputPathFilter(Job job,                                     Class<? extends PathFilter> filter) Set a PathFilter to be applied to the input paths for the map-reduce job. static void setInputPaths(Job job,                           Path... inputPaths) Set the array of Paths as the list of inputs  for the map-reduce job. static void setInputPaths(Job job,                           String commaSeparatedPaths) Sets the given comma separated paths as the list of inputs   for the map-reduce job. static void setMaxInputSplitSize(Job job,                                         long size) Set the maximum split size static void setMinInputSplitSize(Job job,                                         long size) Set the minimum input split size Methods inherited from class org.apache.hadoop.mapreduce.InputFormat createRecordReader Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail INPUT_DIR public static final String INPUT_DIR See Also:Constant Field Values SPLIT_MAXSIZE public static final String SPLIT_MAXSIZE See Also:Constant Field Values SPLIT_MINSIZE public static final String SPLIT_MINSIZE See Also:Constant Field Values PATHFILTER_CLASS public static final String PATHFILTER_CLASS See Also:Constant Field Values NUM_INPUT_FILES public static final String NUM_INPUT_FILES See Also:Constant Field Values INPUT_DIR_RECURSIVE public static final String INPUT_DIR_RECURSIVE See Also:Constant Field Values LIST_STATUS_NUM_THREADS public static final String LIST_STATUS_NUM_THREADS See Also:Constant Field Values DEFAULT_LIST_STATUS_NUM_THREADS public static final int DEFAULT_LIST_STATUS_NUM_THREADS See Also:Constant Field Values Constructor Detail FileInputFormat public FileInputFormat() Method Detail setInputDirRecursive public static void setInputDirRecursive(Job job,                         boolean inputDirRecursive) Parameters:job - the job to modifyinputDirRecursive -  getInputDirRecursive public static boolean getInputDirRecursive(JobContext job) Parameters:job - the job to look at. Returns:should the files to be read recursively? getFormatMinSplitSize protected long getFormatMinSplitSize() Get the lower bound on split size imposed by the format. Returns:the number of bytes of the minimal split for this format isSplitable protected boolean isSplitable(JobContext context,                   Path filename) Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be.    FileInputFormat implementations can override this and return  false to ensure that individual input files are never split-up  so that Mappers process entire files. Parameters:context - the job contextfilename - the file name to check Returns:is this file splitable? setInputPathFilter public static void setInputPathFilter(Job job,                       Class<? extends PathFilter> filter) Set a PathFilter to be applied to the input paths for the map-reduce job. Parameters:job - the job to modifyfilter - the PathFilter class use for filtering the input paths. setMinInputSplitSize public static void setMinInputSplitSize(Job job,                         long size) Set the minimum input split size Parameters:job - the job to modifysize - the minimum size getMinSplitSize public static long getMinSplitSize(JobContext job) Get the minimum split size Parameters:job - the job Returns:the minimum number of bytes that can be in a split setMaxInputSplitSize public static void setMaxInputSplitSize(Job job,                         long size) Set the maximum split size Parameters:job - the job to modifysize - the maximum split size getMaxSplitSize public static long getMaxSplitSize(JobContext context) Get the maximum split size. Parameters:context - the job to look at. Returns:the maximum number of bytes a split can include getInputPathFilter public static PathFilter getInputPathFilter(JobContext context) Get a PathFilter instance of the filter set for the input paths. Returns:the PathFilter instance set for the job, NULL if none has been set. listStatus protected List<FileStatus> listStatus(JobContext job)                                throws IOException List input directories.  Subclasses may override to, e.g., select only files matching a regular  expression. Parameters:job - the job to list input paths for Returns:array of FileStatus objects Throws: IOException - if zero items. addInputPathRecursively protected void addInputPathRecursively(List<FileStatus> result,                            FileSystem fs,                            Path path,                            PathFilter inputFilter)                                 throws IOException Add files in the input path recursively into the results. Parameters:result - The List to store all files.fs - The FileSystem.path - The input path.inputFilter - The input filter that can be used to filter files/dirs. Throws: IOException makeSplit protected FileSplit makeSplit(Path file,                   long start,                   long length,                   String[] hosts) A factory that makes the split for this class. It can be overridden  by sub-classes to make sub-types makeSplit protected FileSplit makeSplit(Path file,                   long start,                   long length,                   String[] hosts,                   String[] inMemoryHosts) A factory that makes the split for this class. It can be overridden  by sub-classes to make sub-types getSplits public List<InputSplit> getSplits(JobContext job)                            throws IOException Generate the list of files and make them into FileSplits. Specified by: getSplits in class InputFormat<K,V> Parameters:job - the job context Returns:an array of InputSplits for the job. Throws: IOException computeSplitSize protected long computeSplitSize(long blockSize,                     long minSize,                     long maxSize) getBlockIndex protected int getBlockIndex(BlockLocation[] blkLocations,                 long offset) setInputPaths public static void setInputPaths(Job job,                  String commaSeparatedPaths)                           throws IOException Sets the given comma separated paths as the list of inputs   for the map-reduce job. Parameters:job - the jobcommaSeparatedPaths - Comma separated paths to be set as          the list of inputs for the map-reduce job. Throws: IOException addInputPaths public static void addInputPaths(Job job,                  String commaSeparatedPaths)                           throws IOException Add the given comma separated paths to the list of inputs for   the map-reduce job. Parameters:job - The job to modifycommaSeparatedPaths - Comma separated paths to be added to         the list of inputs for the map-reduce job. Throws: IOException setInputPaths public static void setInputPaths(Job job,                  Path... inputPaths)                           throws IOException Set the array of Paths as the list of inputs  for the map-reduce job. Parameters:job - The job to modifyinputPaths - the Paths of the input directories/files   for the map-reduce job. Throws: IOException addInputPath public static void addInputPath(Job job,                 Path path)                          throws IOException Add a Path to the list of inputs for the map-reduce job. Parameters:job - The Job to modifypath - Path to be added to the list of inputs for              the map-reduce job. Throws: IOException getInputPaths public static Path[] getInputPaths(JobContext context) Get the list of input Paths for the map-reduce job. Parameters:context - The job Returns:the list of input Paths for the map-reduce job. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileInputFormatCounter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileInputFormatCounter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.mapreduce.lib.input Enum FileInputFormatCounter java.lang.Object java.lang.Enum<FileInputFormatCounter> org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter All Implemented Interfaces: Serializable, Comparable<FileInputFormatCounter> @InterfaceAudience.Public @InterfaceStability.Evolving public enum FileInputFormatCounter extends Enum<FileInputFormatCounter> Enum Constant Summary Enum Constants  Enum Constant and Description BYTES_READ  Method Summary Methods  Modifier and Type Method and Description static FileInputFormatCounter valueOf(String name) Returns the enum constant of this type with the specified name. static FileInputFormatCounter[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail BYTES_READ public static final FileInputFormatCounter BYTES_READ Method Detail values public static FileInputFormatCounter[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (FileInputFormatCounter c : FileInputFormatCounter.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static FileInputFormatCounter valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileOutputCommitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileOutputCommitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class FileOutputCommitter java.lang.Object org.apache.hadoop.mapreduce.OutputCommitter org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter Direct Known Subclasses: PartialFileOutputCommitter @InterfaceAudience.Public @InterfaceStability.Stable public class FileOutputCommitter extends OutputCommitter An OutputCommitter that commits files specified   in job output directory i.e. ${mapreduce.output.fileoutputformat.outputdir}. Field Summary Fields  Modifier and Type Field and Description static String FILEOUTPUTCOMMITTER_ALGORITHM_VERSION  static int FILEOUTPUTCOMMITTER_ALGORITHM_VERSION_DEFAULT  static String PENDING_DIR_NAME Name of directory where pending data is placed. static String SUCCEEDED_FILE_NAME  static String SUCCESSFUL_JOB_OUTPUT_DIR_MARKER  protected static String TEMP_DIR_NAME Deprecated.  Constructor Summary Constructors  Constructor and Description FileOutputCommitter(Path outputPath,                                       JobContext context) Create a file output committer FileOutputCommitter(Path outputPath,                                       TaskAttemptContext context) Create a file output committer Method Summary Methods  Modifier and Type Method and Description void abortJob(JobContext context,                 org.apache.hadoop.mapreduce.JobStatus.State state) Delete the temporary directory, including all of the work directories. void abortTask(TaskAttemptContext context) Delete the work directory void cleanupJob(JobContext context) Deprecated.  void commitJob(JobContext context) The job has completed so move all committed tasks to the final output dir. void commitTask(TaskAttemptContext context) Move the files from the work directory to the job output directory protected Path getCommittedTaskPath(int appAttemptId,                                         TaskAttemptContext context) Compute the path where the output of a committed task is stored until the  entire job is committed for a specific application attempt. Path getCommittedTaskPath(TaskAttemptContext context) Compute the path where the output of a committed task is stored until  the entire job is committed. static Path getCommittedTaskPath(TaskAttemptContext context,                                         Path out)  protected Path getJobAttemptPath(int appAttemptId) Compute the path where the output of a given job attempt will be placed. Path getJobAttemptPath(JobContext context) Compute the path where the output of a given job attempt will be placed. static Path getJobAttemptPath(JobContext context,                                   Path out) Compute the path where the output of a given job attempt will be placed. Path getTaskAttemptPath(TaskAttemptContext context) Compute the path where the output of a task attempt is stored until  that task is committed. static Path getTaskAttemptPath(TaskAttemptContext context,                                     Path out) Compute the path where the output of a task attempt is stored until  that task is committed. Path getWorkPath() Get the directory that the task should write results into. boolean isRecoverySupported() Deprecated.  boolean needsTaskCommit(TaskAttemptContext context) Did this task write any files in the work directory? void recoverTask(TaskAttemptContext context) Recover the task output. void setupJob(JobContext context) Create the temporary directory that is the root of all of the task   work directories. void setupTask(TaskAttemptContext context) No task setup required. Methods inherited from class org.apache.hadoop.mapreduce.OutputCommitter isRecoverySupported Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail PENDING_DIR_NAME public static final String PENDING_DIR_NAME Name of directory where pending data is placed.  Data that has not been  committed yet. See Also:Constant Field Values TEMP_DIR_NAME @Deprecated protected static final String TEMP_DIR_NAME Deprecated.  Temporary directory name   The static variable to be compatible with M/R 1.x See Also:Constant Field Values SUCCEEDED_FILE_NAME public static final String SUCCEEDED_FILE_NAME See Also:Constant Field Values SUCCESSFUL_JOB_OUTPUT_DIR_MARKER public static final String SUCCESSFUL_JOB_OUTPUT_DIR_MARKER See Also:Constant Field Values FILEOUTPUTCOMMITTER_ALGORITHM_VERSION public static final String FILEOUTPUTCOMMITTER_ALGORITHM_VERSION See Also:Constant Field Values FILEOUTPUTCOMMITTER_ALGORITHM_VERSION_DEFAULT public static final int FILEOUTPUTCOMMITTER_ALGORITHM_VERSION_DEFAULT See Also:Constant Field Values Constructor Detail FileOutputCommitter public FileOutputCommitter(Path outputPath,                    TaskAttemptContext context)                     throws IOException Create a file output committer Parameters:outputPath - the job's output path, or null if you want the output  committer to act as a noop.context - the task's context Throws: IOException FileOutputCommitter @InterfaceAudience.Private public FileOutputCommitter(Path outputPath,                                              JobContext context)                     throws IOException Create a file output committer Parameters:outputPath - the job's output path, or null if you want the output  committer to act as a noop.context - the task's context Throws: IOException Method Detail getJobAttemptPath public Path getJobAttemptPath(JobContext context) Compute the path where the output of a given job attempt will be placed. Parameters:context - the context of the job.  This is used to get the  application attempt id. Returns:the path to store job attempt data. getJobAttemptPath public static Path getJobAttemptPath(JobContext context,                      Path out) Compute the path where the output of a given job attempt will be placed. Parameters:context - the context of the job.  This is used to get the  application attempt id.out - the output path to place these in. Returns:the path to store job attempt data. getJobAttemptPath protected Path getJobAttemptPath(int appAttemptId) Compute the path where the output of a given job attempt will be placed. Parameters:appAttemptId - the ID of the application attempt for this job. Returns:the path to store job attempt data. getTaskAttemptPath public Path getTaskAttemptPath(TaskAttemptContext context) Compute the path where the output of a task attempt is stored until  that task is committed. Parameters:context - the context of the task attempt. Returns:the path where a task attempt should be stored. getTaskAttemptPath public static Path getTaskAttemptPath(TaskAttemptContext context,                       Path out) Compute the path where the output of a task attempt is stored until  that task is committed. Parameters:context - the context of the task attempt.out - The output path to put things in. Returns:the path where a task attempt should be stored. getCommittedTaskPath public Path getCommittedTaskPath(TaskAttemptContext context) Compute the path where the output of a committed task is stored until  the entire job is committed. Parameters:context - the context of the task attempt Returns:the path where the output of a committed task is stored until  the entire job is committed. getCommittedTaskPath public static Path getCommittedTaskPath(TaskAttemptContext context,                         Path out) getCommittedTaskPath protected Path getCommittedTaskPath(int appAttemptId,                         TaskAttemptContext context) Compute the path where the output of a committed task is stored until the  entire job is committed for a specific application attempt. Parameters:appAttemptId - the id of the application attempt to usecontext - the context of any task. Returns:the path where the output of a committed task is stored. getWorkPath public Path getWorkPath()                  throws IOException Get the directory that the task should write results into. Returns:the work directory Throws: IOException setupJob public void setupJob(JobContext context)               throws IOException Create the temporary directory that is the root of all of the task   work directories. Specified by: setupJob in class OutputCommitter Parameters:context - the job's context Throws: IOException - if temporary output could not be created commitJob public void commitJob(JobContext context)                throws IOException The job has completed so move all committed tasks to the final output dir.  Delete the temporary directory, including all of the work directories.  Create a _SUCCESS file to make it as successful. Overrides: commitJob in class OutputCommitter Parameters:context - the job's context Throws: IOException cleanupJob @Deprecated public void cleanupJob(JobContext context)                 throws IOException Deprecated.  Description copied from class: OutputCommitter For cleaning up the job's output after job completion.  This is called  from the application master process for the entire job. This may be called  multiple times. Overrides: cleanupJob in class OutputCommitter Parameters:context - Context of the job whose output is being written. Throws: IOException abortJob public void abortJob(JobContext context,             org.apache.hadoop.mapreduce.JobStatus.State state)               throws IOException Delete the temporary directory, including all of the work directories. Overrides: abortJob in class OutputCommitter Parameters:context - the job's contextstate - final runstate of the job Throws: IOException setupTask public void setupTask(TaskAttemptContext context)                throws IOException No task setup required. Specified by: setupTask in class OutputCommitter Parameters:context - Context of the task whose output is being written. Throws: IOException commitTask public void commitTask(TaskAttemptContext context)                 throws IOException Move the files from the work directory to the job output directory Specified by: commitTask in class OutputCommitter Parameters:context - the task context Throws: IOException - if commit is not successful. abortTask public void abortTask(TaskAttemptContext context)                throws IOException Delete the work directory Specified by: abortTask in class OutputCommitter Throws: IOException needsTaskCommit public boolean needsTaskCommit(TaskAttemptContext context)                         throws IOException Did this task write any files in the work directory? Specified by: needsTaskCommit in class OutputCommitter Parameters:context - the task's context Returns:true/false Throws: IOException isRecoverySupported @Deprecated public boolean isRecoverySupported() Deprecated.  Description copied from class: OutputCommitter Is task output recovery supported for restarting jobs?    If task output recovery is supported, job restart can be done more  efficiently. Overrides: isRecoverySupported in class OutputCommitter Returns:true if task output recovery is supported,          false otherwiseSee Also:OutputCommitter.recoverTask(TaskAttemptContext) recoverTask public void recoverTask(TaskAttemptContext context)                  throws IOException Description copied from class: OutputCommitter Recover the task output.     The retry-count for the job will be passed via the   MRJobConfig.APPLICATION_ATTEMPT_ID key in    JobContext.getConfiguration() for the   OutputCommitter.  This is called from the application master  process, but it is called individually for each task.    If an exception is thrown the task will be attempted again.     This may be called multiple times for the same task.  But from different  application attempts. Overrides: recoverTask in class OutputCommitter Parameters:context - Context of the task whose output is being recovered Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class FileOutputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat<K,V> Direct Known Subclasses: MapFileOutputFormat, SequenceFileOutputFormat, TextOutputFormat @InterfaceAudience.Public @InterfaceStability.Stable public abstract class FileOutputFormat<K,V> extends OutputFormat<K,V> A base class for OutputFormats that read from FileSystems. Field Summary Fields  Modifier and Type Field and Description protected static String BASE_OUTPUT_NAME  static String COMPRESS  static String COMPRESS_CODEC  static String COMPRESS_TYPE  static String OUTDIR  protected static String PART  Constructor Summary Constructors  Constructor and Description FileOutputFormat()  Method Summary Methods  Modifier and Type Method and Description void checkOutputSpecs(JobContext job) Check for validity of the output-specification for the job. static boolean getCompressOutput(JobContext job) Is the job output compressed? Path getDefaultWorkFile(TaskAttemptContext context,                                     String extension) Get the default path and filename for the output format. OutputCommitter getOutputCommitter(TaskAttemptContext context) Get the output committer for this output format. static Class<? extends CompressionCodec> getOutputCompressorClass(JobContext job,                                                 Class<? extends CompressionCodec> defaultValue) Get the CompressionCodec for compressing the job outputs. protected static String getOutputName(JobContext job) Get the base output name for the output file. static Path getOutputPath(JobContext job) Get the Path to the output directory for the map-reduce job. static Path getPathForWorkFile(TaskInputOutputContext<?,?,?,?> context,                                     String name,                                     String extension) Helper function to generate a Path for a file that is unique for  the task within the job output directory. abstract RecordWriter<K,V> getRecordWriter(TaskAttemptContext job) Get the RecordWriter for the given task. static String getUniqueFile(TaskAttemptContext context,                           String name,                           String extension) Generate a unique filename, based on the task id, name, and extension static Path getWorkOutputPath(TaskInputOutputContext<?,?,?,?> context) Get the Path to the task's temporary output directory    for the map-reduce job     Tasks' Side-Effect Files static void setCompressOutput(Job job,                                   boolean compress) Set whether the output of the job is compressed. static void setOutputCompressorClass(Job job,                                                 Class<? extends CompressionCodec> codecClass) Set the CompressionCodec to be used to compress job outputs. protected static void setOutputName(JobContext job,                           String name) Set the base output name for output file to be created. static void setOutputPath(Job job,                           Path outputDir) Set the Path of the output directory for the map-reduce job. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail BASE_OUTPUT_NAME protected static final String BASE_OUTPUT_NAME See Also:Constant Field Values PART protected static final String PART See Also:Constant Field Values COMPRESS public static final String COMPRESS See Also:Constant Field Values COMPRESS_CODEC public static final String COMPRESS_CODEC See Also:Constant Field Values COMPRESS_TYPE public static final String COMPRESS_TYPE See Also:Constant Field Values OUTDIR public static final String OUTDIR See Also:Constant Field Values Constructor Detail FileOutputFormat public FileOutputFormat() Method Detail setCompressOutput public static void setCompressOutput(Job job,                      boolean compress) Set whether the output of the job is compressed. Parameters:job - the job to modifycompress - should the output of the job be compressed? getCompressOutput public static boolean getCompressOutput(JobContext job) Is the job output compressed? Parameters:job - the Job to look in Returns:true if the job output should be compressed,          false otherwise setOutputCompressorClass public static void setOutputCompressorClass(Job job,                             Class<? extends CompressionCodec> codecClass) Set the CompressionCodec to be used to compress job outputs. Parameters:job - the job to modifycodecClass - the CompressionCodec to be used to                    compress the job outputs getOutputCompressorClass public static Class<? extends CompressionCodec> getOutputCompressorClass(JobContext job,                                                          Class<? extends CompressionCodec> defaultValue) Get the CompressionCodec for compressing the job outputs. Parameters:job - the Job to look indefaultValue - the CompressionCodec to return if not set Returns:the CompressionCodec to be used to compress the           job outputs Throws: IllegalArgumentException - if the class was specified, but not found getRecordWriter public abstract RecordWriter<K,V> getRecordWriter(TaskAttemptContext job)                                            throws IOException,                                                   InterruptedException Description copied from class: OutputFormat Get the RecordWriter for the given task. Specified by: getRecordWriter in class OutputFormat<K,V> Parameters:job - the information about the current task. Returns:a RecordWriter to write the output for the job. Throws: IOException InterruptedException checkOutputSpecs public void checkOutputSpecs(JobContext job)                       throws FileAlreadyExistsException,                              IOException Description copied from class: OutputFormat Check for validity of the output-specification for the job.     This is to validate the output specification for the job when it is  a job is submitted.  Typically checks that it does not already exist,  throwing an exception when it already exists, so that output is not  overwritten. Specified by: checkOutputSpecs in class OutputFormat<K,V> Parameters:job - information about the job Throws: IOException - when output should not be attempted FileAlreadyExistsException setOutputPath public static void setOutputPath(Job job,                  Path outputDir) Set the Path of the output directory for the map-reduce job. Parameters:job - The job to modifyoutputDir - the Path of the output directory for   the map-reduce job. getOutputPath public static Path getOutputPath(JobContext job) Get the Path to the output directory for the map-reduce job. Returns:the Path to the output directory for the map-reduce job.See Also:getWorkOutputPath(TaskInputOutputContext) getWorkOutputPath public static Path getWorkOutputPath(TaskInputOutputContext<?,?,?,?> context)                               throws IOException,                                      InterruptedException Get the Path to the task's temporary output directory    for the map-reduce job     Tasks' Side-Effect Files    Some applications need to create/write-to side-files, which differ from  the actual job-outputs.    In such cases there could be issues with 2 instances of the same TIP   (running simultaneously e.g. speculative tasks) trying to open/write-to the  same file (path) on HDFS. Hence the application-writer will have to pick   unique names per task-attempt (e.g. using the attemptid, say   attempt_200709221812_0001_m_000000_0), not just per TIP.     To get around this the Map-Reduce framework helps the application-writer   out by maintaining a special   ${mapreduce.output.fileoutputformat.outputdir}/_temporary/_${taskid}   sub-directory for each task-attempt on HDFS where the output of the   task-attempt goes. On successful completion of the task-attempt the files   in the ${mapreduce.output.fileoutputformat.outputdir}/_temporary/_${taskid} (only)   are promoted to ${mapreduce.output.fileoutputformat.outputdir}. Of course, the   framework discards the sub-directory of unsuccessful task-attempts. This   is completely transparent to the application.    The application-writer can take advantage of this by creating any   side-files required in a work directory during execution   of his task i.e. via   getWorkOutputPath(TaskInputOutputContext), and  the framework will move them out similarly - thus she doesn't have to pick   unique paths per task-attempt.    The entire discussion holds true for maps of jobs with   reducer=NONE (i.e. 0 reduces) since output of the map, in that case,   goes directly to HDFS. Returns:the Path to the task's temporary output directory   for the map-reduce job. Throws: IOException InterruptedException getPathForWorkFile public static Path getPathForWorkFile(TaskInputOutputContext<?,?,?,?> context,                       String name,                       String extension)                                throws IOException,                                       InterruptedException Helper function to generate a Path for a file that is unique for  the task within the job output directory.  The path can be used to create custom files from within the map and  reduce tasks. The path name will be unique for each task. The path parent  will be the job output directory.ls  This method uses the getUniqueFile(org.apache.hadoop.mapreduce.TaskAttemptContext, java.lang.String, java.lang.String) method to make the file name  unique for the task. Parameters:context - the context for the task.name - the name for the file.extension - the extension for the file Returns:a unique path accross all tasks of the job. Throws: IOException InterruptedException getUniqueFile public static String getUniqueFile(TaskAttemptContext context,                    String name,                    String extension) Generate a unique filename, based on the task id, name, and extension Parameters:context - the task that is calling thisname - the base filenameextension - the filename extension Returns:a string like $name-[mrsct]-$id$extension getDefaultWorkFile public Path getDefaultWorkFile(TaskAttemptContext context,                       String extension)                         throws IOException Get the default path and filename for the output format. Parameters:context - the task contextextension - an extension to add to the filename Returns:a full path $output/_temporary/$taskid/part-[mr]-$id Throws: IOException getOutputName protected static String getOutputName(JobContext job) Get the base output name for the output file. setOutputName protected static void setOutputName(JobContext job,                  String name) Set the base output name for output file to be created. getOutputCommitter public OutputCommitter getOutputCommitter(TaskAttemptContext context)                                    throws IOException Description copied from class: OutputFormat Get the output committer for this output format. This is responsible  for ensuring the output is committed correctly. Specified by: getOutputCommitter in class OutputFormat<K,V> Parameters:context - the task context Returns:an output committer Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileOutputFormatCounter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileOutputFormatCounter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.mapreduce.lib.output Enum FileOutputFormatCounter java.lang.Object java.lang.Enum<FileOutputFormatCounter> org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter All Implemented Interfaces: Serializable, Comparable<FileOutputFormatCounter> @InterfaceAudience.Public @InterfaceStability.Evolving public enum FileOutputFormatCounter extends Enum<FileOutputFormatCounter> Enum Constant Summary Enum Constants  Enum Constant and Description BYTES_WRITTEN  Method Summary Methods  Modifier and Type Method and Description static FileOutputFormatCounter valueOf(String name) Returns the enum constant of this type with the specified name. static FileOutputFormatCounter[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail BYTES_WRITTEN public static final FileOutputFormatCounter BYTES_WRITTEN Method Detail values public static FileOutputFormatCounter[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (FileOutputFormatCounter c : FileOutputFormatCounter.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static FileOutputFormatCounter valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileSink (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileSink (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.sink Class FileSink java.lang.Object org.apache.hadoop.metrics2.sink.FileSink All Implemented Interfaces: Closeable, AutoCloseable, MetricsPlugin, MetricsSink @InterfaceAudience.Public @InterfaceStability.Evolving public class FileSink extends Object implements MetricsSink, Closeable A metrics sink that writes to a file Constructor Summary Constructors  Constructor and Description FileSink()  Method Summary Methods  Modifier and Type Method and Description void close()  void flush() Flush any buffered metrics void init(org.apache.commons.configuration.SubsetConfiguration conf) Initialize the plugin void putMetrics(MetricsRecord record) Put a metrics record in the sink Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail FileSink public FileSink() Method Detail init public void init(org.apache.commons.configuration.SubsetConfiguration conf) Description copied from interface: MetricsPlugin Initialize the plugin Specified by: init in interface MetricsPlugin Parameters:conf - the configuration object for the plugin putMetrics public void putMetrics(MetricsRecord record) Description copied from interface: MetricsSink Put a metrics record in the sink Specified by: putMetrics in interface MetricsSink Parameters:record - the record to put flush public void flush() Description copied from interface: MetricsSink Flush any buffered metrics Specified by: flush in interface MetricsSink close public void close()            throws IOException Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileSplit (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileSplit (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class FileSplit java.lang.Object org.apache.hadoop.mapreduce.InputSplit org.apache.hadoop.mapreduce.lib.input.FileSplit All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class FileSplit extends InputSplit implements Writable A section of an input file.  Returned by InputFormat.getSplits(JobContext) and passed to  InputFormat.createRecordReader(InputSplit,TaskAttemptContext). Constructor Summary Constructors  Constructor and Description FileSplit()  FileSplit(Path file,                   long start,                   long length,                   String[] hosts) Constructs a split with host information FileSplit(Path file,                   long start,                   long length,                   String[] hosts,                   String[] inMemoryHosts) Constructs a split with host and cached-blocks information Method Summary Methods  Modifier and Type Method and Description long getLength() The number of bytes in the file to process. SplitLocationInfo[] getLocationInfo() Gets info about which nodes the input split is stored on and how it is  stored at each location. String[] getLocations() Get the list of nodes by name where the data for the split would be local. Path getPath() The file containing this split's data. long getStart() The position of the first byte in the file to process. void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail FileSplit public FileSplit() FileSplit public FileSplit(Path file,          long start,          long length,          String[] hosts) Constructs a split with host information Parameters:file - the file namestart - the position of the first byte in the file to processlength - the number of bytes in the file to processhosts - the list of hosts containing the block, possibly null FileSplit public FileSplit(Path file,          long start,          long length,          String[] hosts,          String[] inMemoryHosts) Constructs a split with host and cached-blocks information Parameters:file - the file namestart - the position of the first byte in the file to processlength - the number of bytes in the file to processhosts - the list of hosts containing the blockinMemoryHosts - the list of hosts containing the block in memory Method Detail getPath public Path getPath() The file containing this split's data. getStart public long getStart() The position of the first byte in the file to process. getLength public long getLength() The number of bytes in the file to process. Specified by: getLength in class InputSplit Returns:the number of bytes in the split toString public String toString() Overrides: toString in class Object write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException getLocations public String[] getLocations()                       throws IOException Description copied from class: InputSplit Get the list of nodes by name where the data for the split would be local.  The locations do not need to be serialized. Specified by: getLocations in class InputSplit Returns:a new array of the node nodes. Throws: IOException getLocationInfo @InterfaceStability.Evolving public SplitLocationInfo[] getLocationInfo()                                     throws IOException Description copied from class: InputSplit Gets info about which nodes the input split is stored on and how it is  stored at each location. Overrides: getLocationInfo in class InputSplit Returns:list of SplitLocationInfos describing how the split     data is stored at each location. A null value indicates that all the     locations have the data stored on disk. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FileStatus java.lang.Object org.apache.hadoop.fs.FileStatus All Implemented Interfaces: Comparable, Writable Direct Known Subclasses: LocatedFileStatus @InterfaceAudience.Public @InterfaceStability.Stable public class FileStatus extends Object implements Writable, Comparable Interface that represents the client side information for a file. Constructor Summary Constructors  Constructor and Description FileStatus()  FileStatus(FileStatus other) Copy constructor. FileStatus(long length,                     boolean isdir,                     int block_replication,                     long blocksize,                     long modification_time,                     long access_time,                     FsPermission permission,                     String owner,                     String group,                     Path path) Constructor for file systems on which symbolic links are not supported FileStatus(long length,                     boolean isdir,                     int block_replication,                     long blocksize,                     long modification_time,                     long access_time,                     FsPermission permission,                     String owner,                     String group,                     Path symlink,                     Path path)  FileStatus(long length,                     boolean isdir,                     int block_replication,                     long blocksize,                     long modification_time,                     Path path)  Method Summary Methods  Modifier and Type Method and Description int compareTo(Object o) Compare this object to another object boolean equals(Object o) Compare if this object is equal to another object long getAccessTime() Get the access time of the file. long getBlockSize() Get the block size of the file. String getGroup() Get the group associated with the file. long getLen() Get the length of this file, in bytes. long getModificationTime() Get the modification time of the file. String getOwner() Get the owner of the file. Path getPath()  FsPermission getPermission() Get FsPermission associated with the file. short getReplication() Get the replication factor of a file. Path getSymlink()  int hashCode() Returns a hash code value for the object, which is defined as  the hash code of the path name. boolean isDir() Deprecated.  Use isFile(),    isDirectory(), and isSymlink()   instead. boolean isDirectory() Is this a directory? boolean isEncrypted() Tell whether the underlying file or directory is encrypted or not. boolean isFile() Is this a file? boolean isSymlink() Is this a symbolic link? void readFields(DataInput in) Deserialize the fields of this object from in. protected void setGroup(String group) Sets group. protected void setOwner(String owner) Sets owner. void setPath(Path p)  protected void setPermission(FsPermission permission) Sets permission. void setSymlink(Path p)  String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail FileStatus public FileStatus() FileStatus public FileStatus(long length,           boolean isdir,           int block_replication,           long blocksize,           long modification_time,           Path path) FileStatus public FileStatus(long length,           boolean isdir,           int block_replication,           long blocksize,           long modification_time,           long access_time,           FsPermission permission,           String owner,           String group,           Path path) Constructor for file systems on which symbolic links are not supported FileStatus public FileStatus(long length,           boolean isdir,           int block_replication,           long blocksize,           long modification_time,           long access_time,           FsPermission permission,           String owner,           String group,           Path symlink,           Path path) FileStatus public FileStatus(FileStatus other)            throws IOException Copy constructor. Parameters:other - FileStatus to copy Throws: IOException Method Detail getLen public long getLen() Get the length of this file, in bytes. Returns:the length of this file, in bytes. isFile public boolean isFile() Is this a file? Returns:true if this is a file isDirectory public boolean isDirectory() Is this a directory? Returns:true if this is a directory isDir @Deprecated public boolean isDir() Deprecated. Use isFile(),    isDirectory(), and isSymlink()   instead. Old interface, instead use the explicit isFile(),   isDirectory(), and isSymlink() Returns:true if this is a directory. isSymlink public boolean isSymlink() Is this a symbolic link? Returns:true if this is a symbolic link getBlockSize public long getBlockSize() Get the block size of the file. Returns:the number of bytes getReplication public short getReplication() Get the replication factor of a file. Returns:the replication factor of a file. getModificationTime public long getModificationTime() Get the modification time of the file. Returns:the modification time of file in milliseconds since January 1, 1970 UTC. getAccessTime public long getAccessTime() Get the access time of the file. Returns:the access time of file in milliseconds since January 1, 1970 UTC. getPermission public FsPermission getPermission() Get FsPermission associated with the file. Returns:permssion. If a filesystem does not have a notion of permissions          or if permissions could not be determined, then default           permissions equivalent of "rwxrwxrwx" is returned. isEncrypted public boolean isEncrypted() Tell whether the underlying file or directory is encrypted or not. Returns:true if the underlying file is encrypted. getOwner public String getOwner() Get the owner of the file. Returns:owner of the file. The string could be empty if there is no          notion of owner of a file in a filesystem or if it could not           be determined (rare). getGroup public String getGroup() Get the group associated with the file. Returns:group for the file. The string could be empty if there is no          notion of group of a file in a filesystem or if it could not           be determined (rare). getPath public Path getPath() setPath public void setPath(Path p) setPermission protected void setPermission(FsPermission permission) Sets permission. Parameters:permission - if permission is null, default value is set setOwner protected void setOwner(String owner) Sets owner. Parameters:owner - if it is null, default value is set setGroup protected void setGroup(String group) Sets group. Parameters:group - if it is null, default value is set getSymlink public Path getSymlink()                 throws IOException Returns:The contents of the symbolic link. Throws: IOException setSymlink public void setSymlink(Path p) write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException compareTo public int compareTo(Object o) Compare this object to another object Specified by: compareTo in interface Comparable Parameters:o - the object to be compared. Returns:a negative integer, zero, or a positive integer as this object    is less than, equal to, or greater than the specified object. Throws: ClassCastException - if the specified object's is not of           type FileStatus equals public boolean equals(Object o) Compare if this object is equal to another object Overrides: equals in class Object Parameters:o - the object to be compared. Returns:true if two file status has the same path name; false if not. hashCode public int hashCode() Returns a hash code value for the object, which is defined as  the hash code of the path name. Overrides: hashCode in class Object Returns:a hash code value for the path name. toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable Direct Known Subclasses: FilterFileSystem, FTPFileSystem, NativeAzureFileSystem, NativeS3FileSystem, RawLocalFileSystem, S3FileSystem, ViewFileSystem @InterfaceAudience.Public @InterfaceStability.Stable public abstract class FileSystem extends Configured implements Closeable An abstract base class for a fairly generic filesystem.  It  may be implemented as a distributed filesystem, or as a "local"  one that reflects the locally-connected disk.  The local version  exists for small Hadoop instances and for testing.    All user code that may potentially use the Hadoop Distributed  File System should be written to use a FileSystem object.  The  Hadoop DFS is a multi-machine system that appears as a single  disk.  It's useful because of its fault tolerance and potentially  very large capacity.      The local implementation is LocalFileSystem and distributed  implementation is DistributedFileSystem. Field Summary Fields  Modifier and Type Field and Description static String DEFAULT_FS  static String FS_DEFAULT_NAME_KEY  static org.apache.commons.logging.Log LOG  static int SHUTDOWN_HOOK_PRIORITY Priority of the FileSystem shutdown hook. protected org.apache.hadoop.fs.FileSystem.Statistics statistics The statistics for this file system. Constructor Summary Constructors  Modifier Constructor and Description protected  FileSystem()  Method Summary Methods  Modifier and Type Method and Description FSDataOutputStream append(Path f) Append to an existing file (optional operation). FSDataOutputStream append(Path f,             int bufferSize) Append to an existing file (optional operation). abstract FSDataOutputStream append(Path f,             int bufferSize,             Progressable progress) Append to an existing file (optional operation). static boolean areSymlinksEnabled()  boolean cancelDeleteOnExit(Path f) Cancel the deletion of the path when the FileSystem is closed protected URI canonicalizeUri(URI uri) Canonicalize the given URI. protected void checkPath(Path path) Check that a Path belongs to this FileSystem. static void clearStatistics() Reset all statistics for all file systems void close() No more filesystem operations are needed. static void closeAll() Close all cached filesystems. static void closeAllForUGI(org.apache.hadoop.security.UserGroupInformation ugi) Close all cached filesystems for a given UGI. void completeLocalOutput(Path fsOutputFile,                                       Path tmpLocalFile) Called when we're all done writing to the target. void concat(Path trg,             Path[] psrcs) Concat existing files together. void copyFromLocalFile(boolean delSrc,                                   boolean overwrite,                                   Path[] srcs,                                   Path dst) The src files are on the local disk. void copyFromLocalFile(boolean delSrc,                                   boolean overwrite,                                   Path src,                                   Path dst) The src file is on the local disk. void copyFromLocalFile(boolean delSrc,                                   Path src,                                   Path dst) The src file is on the local disk. void copyFromLocalFile(Path src,                                   Path dst) The src file is on the local disk. void copyToLocalFile(boolean delSrc,                               Path src,                               Path dst) The src file is under FS, and the dst is on the local disk. void copyToLocalFile(boolean delSrc,                               Path src,                               Path dst,                               boolean useRawLocalFileSystem) The src file is under FS, and the dst is on the local disk. void copyToLocalFile(Path src,                               Path dst) The src file is under FS, and the dst is on the local disk. static FSDataOutputStream create(FileSystem fs,             Path file,             FsPermission permission) create a file with the provided permission  The permission of the file is set to be the provided permission as in  setPermission, not permission&~umask    It is implemented using two RPCs. FSDataOutputStream create(Path f) Create an FSDataOutputStream at the indicated Path. FSDataOutputStream create(Path f,             boolean overwrite) Create an FSDataOutputStream at the indicated Path. FSDataOutputStream create(Path f,             boolean overwrite,             int bufferSize) Create an FSDataOutputStream at the indicated Path. FSDataOutputStream create(Path f,             boolean overwrite,             int bufferSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream create(Path f,             boolean overwrite,             int bufferSize,             short replication,             long blockSize) Create an FSDataOutputStream at the indicated Path. FSDataOutputStream create(Path f,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. abstract FSDataOutputStream create(Path f,             FsPermission permission,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream create(Path f,             FsPermission permission,             EnumSet<CreateFlag> flags,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream create(Path f,             FsPermission permission,             EnumSet<CreateFlag> flags,             int bufferSize,             short replication,             long blockSize,             Progressable progress,             org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt) Create an FSDataOutputStream at the indicated Path with a custom  checksum option FSDataOutputStream create(Path f,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream create(Path f,             short replication) Create an FSDataOutputStream at the indicated Path. FSDataOutputStream create(Path f,             short replication,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. boolean createNewFile(Path f) Creates the given Path as a brand-new zero-length file. FSDataOutputStream createNonRecursive(Path f,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Deprecated.  API only for 0.20-append FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Deprecated.  API only for 0.20-append FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     EnumSet<CreateFlag> flags,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Deprecated.  API only for 0.20-append Path createSnapshot(Path path) Create a snapshot with a default name. Path createSnapshot(Path path,                             String snapshotName) Create a snapshot void createSymlink(Path target,                           Path link,                           boolean createParent) See FileContext.createSymlink(Path, Path, boolean) boolean delete(Path f) Deprecated.  Use delete(Path, boolean) instead. abstract boolean delete(Path f,             boolean recursive) Delete a file. boolean deleteOnExit(Path f) Mark a path to be deleted when FileSystem is closed. void deleteSnapshot(Path path,                             String snapshotName) Delete a snapshot of a directory static void enableSymlinks()  boolean exists(Path f) Check if exists. protected Path fixRelativePart(Path p) See FileContext.fixRelativePart(org.apache.hadoop.fs.Path) static FileSystem get(Configuration conf) Returns the configured filesystem implementation. static FileSystem get(URI uri,       Configuration conf) Returns the FileSystem for this URI's scheme and authority. static FileSystem get(URI uri,       Configuration conf,       String user) Get a filesystem instance based on the uri, the passed  configuration and the user AclStatus getAclStatus(Path path) Gets the ACL of a file or directory. static List<org.apache.hadoop.fs.FileSystem.Statistics> getAllStatistics() Return the FileSystem classes that have Statistics long getBlockSize(Path f) Deprecated.  Use getFileStatus() instead protected URI getCanonicalUri() Return a canonicalized form of this FileSystem's URI. ContentSummary getContentSummary(Path f) Return the ContentSummary of a given Path. long getDefaultBlockSize() Deprecated.  use getDefaultBlockSize(Path) instead long getDefaultBlockSize(Path f) Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. protected int getDefaultPort() Get the default port for this file system. short getDefaultReplication() Deprecated.  use getDefaultReplication(Path) instead short getDefaultReplication(Path path) Get the default replication for a path. static URI getDefaultUri(Configuration conf) Get the default filesystem URI from a configuration. BlockLocation[] getFileBlockLocations(FileStatus file,                                           long start,                                           long len) Return an array containing hostnames, offset and size of   portions of the given file. BlockLocation[] getFileBlockLocations(Path p,                                           long start,                                           long len) Return an array containing hostnames, offset and size of   portions of the given file. FileChecksum getFileChecksum(Path f) Get the checksum of a file. FileChecksum getFileChecksum(Path f,                               long length) Get the checksum of a file, from the beginning of the file till the  specific length. FileStatus getFileLinkStatus(Path f) See FileContext.getFileLinkStatus(Path) abstract FileStatus getFileStatus(Path f) Return a file status object that represents the path. static Class<? extends FileSystem> getFileSystemClass(String scheme,                                     Configuration conf)  protected static FileSystem getFSofPath(Path absOrFqPath,                       Configuration conf)  Path getHomeDirectory() Return the current user's home directory in this filesystem. protected Path getInitialWorkingDirectory() Note: with the new FilesContext class, getWorkingDirectory()  will be removed. long getLength(Path f) Deprecated.  Use getFileStatus() instead Path getLinkTarget(Path f) See FileContext.getLinkTarget(Path) static LocalFileSystem getLocal(Configuration conf) Get the local file system. String getName() Deprecated.  call #getUri() instead. static FileSystem getNamed(String name,                 Configuration conf) Deprecated.  call #get(URI,Configuration) instead. short getReplication(Path src) Deprecated.  Use getFileStatus() instead String getScheme() Return the protocol scheme for the FileSystem. FsServerDefaults getServerDefaults() Deprecated.  use getServerDefaults(Path) instead FsServerDefaults getServerDefaults(Path p) Return a set of server default configuration values static Map<String,org.apache.hadoop.fs.FileSystem.Statistics> getStatistics() Deprecated.  use getAllStatistics() instead static org.apache.hadoop.fs.FileSystem.Statistics getStatistics(String scheme,                           Class<? extends FileSystem> cls) Get the statistics for a particular file system FsStatus getStatus() Returns a status object describing the use and capacity of the  file system. FsStatus getStatus(Path p) Returns a status object describing the use and capacity of the  file system. abstract URI getUri() Returns a URI whose scheme and authority identify this FileSystem. long getUsed() Return the total size of all files in the filesystem. abstract Path getWorkingDirectory() Get the current working directory for the given file system byte[] getXAttr(Path path,                 String name) Get an xattr name and value for a file or directory. Map<String,byte[]> getXAttrs(Path path) Get all of the xattr name/value pairs for a file or directory. Map<String,byte[]> getXAttrs(Path path,                   List<String> names) Get all of the xattrs name/value pairs for a file or directory. FileStatus[] globStatus(Path pathPattern) Return all the files that match filePattern and are not checksum  files. FileStatus[] globStatus(Path pathPattern,                     PathFilter filter) Return an array of FileStatus objects whose path names match pathPattern  and is accepted by the user-supplied path filter. void initialize(URI name,                     Configuration conf) Called after a new FileSystem instance is constructed. boolean isDirectory(Path f) True iff the named path is a directory. boolean isFile(Path f) True iff the named path is a regular file. org.apache.hadoop.fs.RemoteIterator<Path> listCorruptFileBlocks(Path path)  org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listFiles(Path f,                   boolean recursive) List the statuses and block locations of the files in the given path. org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f) List the statuses of the files/directories in the given path if the path is  a directory. protected org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f,                                   PathFilter filter) Listing a directory  The returned results include its block location if it is a file  The results are filtered by the given path filter abstract FileStatus[] listStatus(Path f) List the statuses of the files/directories in the given path if the path is  a directory. FileStatus[] listStatus(Path[] files) Filter files/directories in the given list of paths using default  path filter. FileStatus[] listStatus(Path[] files,                     PathFilter filter) Filter files/directories in the given list of paths using user-supplied  path filter. FileStatus[] listStatus(Path f,                     PathFilter filter) Filter files/directories in the given path using the user-supplied path  filter. org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatusIterator(Path p) Returns a remote iterator so that followup calls are made on demand  while consuming the entries. List<String> listXAttrs(Path path) Get all of the xattr names for a file or directory. Path makeQualified(Path path) Make sure that a path specifies a FileSystem. static boolean mkdirs(FileSystem fs,             Path dir,             FsPermission permission) create a directory with the provided permission  The permission of the directory is set to be the provided permission as in  setPermission, not permission&~umask boolean mkdirs(Path f) Call mkdirs(Path, FsPermission) with default permission. abstract boolean mkdirs(Path f,             FsPermission permission) Make the given file and all non-existent parents into  directories. void modifyAclEntries(Path path,                                 List<AclEntry> aclSpec) Modifies ACL entries of files and directories. void moveFromLocalFile(Path[] srcs,                                   Path dst) The src files is on the local disk. void moveFromLocalFile(Path src,                                   Path dst) The src file is on the local disk. void moveToLocalFile(Path src,                               Path dst) The src file is under FS, and the dst is on the local disk. static FileSystem newInstance(Configuration conf) Returns a unique configured filesystem implementation. static FileSystem newInstance(URI uri,                       Configuration conf) Returns the FileSystem for this URI's scheme and authority. static FileSystem newInstance(URI uri,                       Configuration conf,                       String user) Returns the FileSystem for this URI's scheme and authority and the   passed user. static LocalFileSystem newInstanceLocal(Configuration conf) Get a unique local file system object FSDataInputStream open(Path f) Opens an FSDataInputStream at the indicated Path. abstract FSDataInputStream open(Path f,         int bufferSize) Opens an FSDataInputStream at the indicated Path. protected FSDataOutputStream primitiveCreate(Path f,                               FsPermission absolutePermission,                               EnumSet<CreateFlag> flag,                               int bufferSize,                               short replication,                               long blockSize,                               Progressable progress,                               org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt) Deprecated.  protected boolean primitiveMkdir(Path f,                             FsPermission absolutePermission) Deprecated.  protected void primitiveMkdir(Path f,                             FsPermission absolutePermission,                             boolean createParent) Deprecated.  static void printStatistics() Print all statistics for all file systems protected void processDeleteOnExit() Delete all files that were marked as delete-on-exit. void removeAcl(Path path) Removes all but the base ACL entries of files and directories. void removeAclEntries(Path path,                                 List<AclEntry> aclSpec) Removes ACL entries from files and directories. void removeDefaultAcl(Path path) Removes all default ACL entries from files and directories. void removeXAttr(Path path,                       String name) Remove an xattr of a file or directory. abstract boolean rename(Path src,             Path dst) Renames Path src to Path dst. protected void rename(Path src,             Path dst,             org.apache.hadoop.fs.Options.Rename... options) Deprecated.  void renameSnapshot(Path path,                             String snapshotOldName,                             String snapshotNewName) Rename a snapshot protected Path resolveLink(Path f) See AbstractFileSystem.getLinkTarget(Path) Path resolvePath(Path p) Return the fully-qualified path of path f resolving the path  through any symlinks or mount point void setAcl(Path path,             List<AclEntry> aclSpec) Fully replaces ACL of files and directories, discarding all existing  entries. static void setDefaultUri(Configuration conf,                           String uri) Set the default filesystem URI in a configuration. static void setDefaultUri(Configuration conf,                           URI uri) Set the default filesystem URI in a configuration. void setOwner(Path p,                 String username,                 String groupname) Set owner of a path (i.e. void setPermission(Path p,                           FsPermission permission) Set permission of a path. boolean setReplication(Path src,                             short replication) Set replication for an existing file. void setTimes(Path p,                 long mtime,                 long atime) Set access time of a file void setVerifyChecksum(boolean verifyChecksum) Set the verify checksum flag. abstract void setWorkingDirectory(Path new_dir) Set the current working directory for the given file system. void setWriteChecksum(boolean writeChecksum) Set the write checksum flag. void setXAttr(Path path,                 String name,                 byte[] value) Set an xattr of a file or directory. void setXAttr(Path path,                 String name,                 byte[] value,                 EnumSet<XAttrSetFlag> flag) Set an xattr of a file or directory. Path startLocalOutput(Path fsOutputFile,                                 Path tmpLocalFile) Returns a local File that the user can write output to. boolean supportsSymlinks() See AbstractFileSystem.supportsSymlinks() boolean truncate(Path f,                 long newLength) Truncate the file in the indicated path to the indicated size. Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail FS_DEFAULT_NAME_KEY public static final String FS_DEFAULT_NAME_KEY See Also:Constant Field Values DEFAULT_FS public static final String DEFAULT_FS See Also:Constant Field Values LOG public static final org.apache.commons.logging.Log LOG SHUTDOWN_HOOK_PRIORITY public static final int SHUTDOWN_HOOK_PRIORITY Priority of the FileSystem shutdown hook. See Also:Constant Field Values statistics protected org.apache.hadoop.fs.FileSystem.Statistics statistics The statistics for this file system. Constructor Detail FileSystem protected FileSystem() Method Detail get public static FileSystem get(URI uri,              Configuration conf,              String user)                       throws IOException,                              InterruptedException Get a filesystem instance based on the uri, the passed  configuration and the user Parameters:uri - of the filesystemconf - the configuration to useuser - to perform the get as Returns:the filesystem instance Throws: IOException InterruptedException get public static FileSystem get(Configuration conf)                       throws IOException Returns the configured filesystem implementation. Parameters:conf - the configuration to use Throws: IOException getDefaultUri public static URI getDefaultUri(Configuration conf) Get the default filesystem URI from a configuration. Parameters:conf - the configuration to use Returns:the uri of the default filesystem setDefaultUri public static void setDefaultUri(Configuration conf,                  URI uri) Set the default filesystem URI in a configuration. Parameters:conf - the configuration to alteruri - the new default filesystem uri setDefaultUri public static void setDefaultUri(Configuration conf,                  String uri) Set the default filesystem URI in a configuration. Parameters:conf - the configuration to alteruri - the new default filesystem uri initialize public void initialize(URI name,               Configuration conf)                 throws IOException Called after a new FileSystem instance is constructed. Parameters:name - a uri whose authority section names the host, port, etc.    for this FileSystemconf - the configuration Throws: IOException getScheme public String getScheme() Return the protocol scheme for the FileSystem.    This implementation throws an UnsupportedOperationException. Returns:the protocol scheme for the FileSystem. getUri public abstract URI getUri() Returns a URI whose scheme and authority identify this FileSystem. getCanonicalUri protected URI getCanonicalUri() Return a canonicalized form of this FileSystem's URI.    The default implementation simply calls canonicalizeUri(URI)  on the filesystem's own URI, so subclasses typically only need to  implement that method. See Also:canonicalizeUri(URI) canonicalizeUri protected URI canonicalizeUri(URI uri) Canonicalize the given URI.    This is filesystem-dependent, but may for example consist of  canonicalizing the hostname using DNS and adding the default  port if not specified.    The default implementation simply fills in the default port if  not specified and if the filesystem has a default port. Returns:URISee Also:NetUtils.getCanonicalUri(URI, int) getDefaultPort protected int getDefaultPort() Get the default port for this file system. Returns:the default port or 0 if there isn't one getFSofPath protected static FileSystem getFSofPath(Path absOrFqPath,                      Configuration conf)                                  throws UnsupportedFileSystemException,                                         IOException Throws: UnsupportedFileSystemException IOException getName @Deprecated public String getName() Deprecated. call #getUri() instead. getNamed @Deprecated public static FileSystem getNamed(String name,                              Configuration conf)                            throws IOException Deprecated. call #get(URI,Configuration) instead. Throws: IOException getLocal public static LocalFileSystem getLocal(Configuration conf)                                 throws IOException Get the local file system. Parameters:conf - the configuration to configure the file system with Returns:a LocalFileSystem Throws: IOException get public static FileSystem get(URI uri,              Configuration conf)                       throws IOException Returns the FileSystem for this URI's scheme and authority.  The scheme  of the URI determines a configuration property name,  fs.scheme.class whose value names the FileSystem class.  The entire URI is passed to the FileSystem instance's initialize method. Throws: IOException newInstance public static FileSystem newInstance(URI uri,                      Configuration conf,                      String user)                               throws IOException,                                      InterruptedException Returns the FileSystem for this URI's scheme and authority and the   passed user. Internally invokes newInstance(URI, Configuration) Parameters:uri - of the filesystemconf - the configuration to useuser - to perform the get as Returns:filesystem instance Throws: IOException InterruptedException newInstance public static FileSystem newInstance(URI uri,                      Configuration conf)                               throws IOException Returns the FileSystem for this URI's scheme and authority.  The scheme  of the URI determines a configuration property name,  fs.scheme.class whose value names the FileSystem class.  The entire URI is passed to the FileSystem instance's initialize method.  This always returns a new FileSystem object. Throws: IOException newInstance public static FileSystem newInstance(Configuration conf)                               throws IOException Returns a unique configured filesystem implementation.  This always returns a new FileSystem object. Parameters:conf - the configuration to use Throws: IOException newInstanceLocal public static LocalFileSystem newInstanceLocal(Configuration conf)                                         throws IOException Get a unique local file system object Parameters:conf - the configuration to configure the file system with Returns:a LocalFileSystem  This always returns a new FileSystem object. Throws: IOException closeAll public static void closeAll()                      throws IOException Close all cached filesystems. Be sure those filesystems are not  used anymore. Throws: IOException closeAllForUGI public static void closeAllForUGI(org.apache.hadoop.security.UserGroupInformation ugi)                            throws IOException Close all cached filesystems for a given UGI. Be sure those filesystems   are not used anymore. Parameters:ugi - user group info to close Throws: IOException makeQualified public Path makeQualified(Path path) Make sure that a path specifies a FileSystem. Parameters:path - to use create public static FSDataOutputStream create(FileSystem fs,                         Path file,                         FsPermission permission)                                  throws IOException create a file with the provided permission  The permission of the file is set to be the provided permission as in  setPermission, not permission&~umask    It is implemented using two RPCs. It is understood that it is inefficient,  but the implementation is thread-safe. The other option is to change the  value of umask in configuration to be 0, but it is not thread-safe. Parameters:fs - file system handlefile - the name of the file to be createdpermission - the permission of the file Returns:an output stream Throws: IOException mkdirs public static boolean mkdirs(FileSystem fs,              Path dir,              FsPermission permission)                       throws IOException create a directory with the provided permission  The permission of the directory is set to be the provided permission as in  setPermission, not permission&~umask Parameters:fs - file system handledir - the name of the directory to be createdpermission - the permission of the directory Returns:true if the directory creation succeeds; false otherwise Throws: IOExceptionSee Also:create(FileSystem, Path, FsPermission) checkPath protected void checkPath(Path path) Check that a Path belongs to this FileSystem. Parameters:path - to check getFileBlockLocations public BlockLocation[] getFileBlockLocations(FileStatus file,                                     long start,                                     long len)                                       throws IOException Return an array containing hostnames, offset and size of   portions of the given file.  For a nonexistent   file or regions, null will be returned.  This call is most helpful with DFS, where it returns   hostnames of machines that contain the given file.  The FileSystem will simply return an elt containing 'localhost'. Parameters:file - FilesStatus to get data fromstart - offset into the given filelen - length for which to get locations for Throws: IOException getFileBlockLocations public BlockLocation[] getFileBlockLocations(Path p,                                     long start,                                     long len)                                       throws IOException Return an array containing hostnames, offset and size of   portions of the given file.  For a nonexistent   file or regions, null will be returned.  This call is most helpful with DFS, where it returns   hostnames of machines that contain the given file.  The FileSystem will simply return an elt containing 'localhost'. Parameters:p - path is used to identify an FS since an FS could have           another FS that it could be delegating the call tostart - offset into the given filelen - length for which to get locations for Throws: IOException getServerDefaults @Deprecated public FsServerDefaults getServerDefaults()                                    throws IOException Deprecated. use getServerDefaults(Path) instead Return a set of server default configuration values Returns:server default configuration values Throws: IOException getServerDefaults public FsServerDefaults getServerDefaults(Path p)                                    throws IOException Return a set of server default configuration values Parameters:p - path is used to identify an FS since an FS could have           another FS that it could be delegating the call to Returns:server default configuration values Throws: IOException resolvePath public Path resolvePath(Path p)                  throws IOException Return the fully-qualified path of path f resolving the path  through any symlinks or mount point Parameters:p - path to be resolved Returns:fully qualified path Throws: FileNotFoundException IOException open public abstract FSDataInputStream open(Path f,                      int bufferSize)                                 throws IOException Opens an FSDataInputStream at the indicated Path. Parameters:f - the file name to openbufferSize - the size of the buffer to be used. Throws: IOException open public FSDataInputStream open(Path f)                        throws IOException Opens an FSDataInputStream at the indicated Path. Parameters:f - the file to open Throws: IOException create public FSDataOutputStream create(Path f)                           throws IOException Create an FSDataOutputStream at the indicated Path.  Files are overwritten by default. Parameters:f - the file to create Throws: IOException create public FSDataOutputStream create(Path f,                         boolean overwrite)                           throws IOException Create an FSDataOutputStream at the indicated Path. Parameters:f - the file to createoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an exception will be thrown. Throws: IOException create public FSDataOutputStream create(Path f,                         Progressable progress)                           throws IOException Create an FSDataOutputStream at the indicated Path with write-progress  reporting.  Files are overwritten by default. Parameters:f - the file to createprogress - to report progress Throws: IOException create public FSDataOutputStream create(Path f,                         short replication)                           throws IOException Create an FSDataOutputStream at the indicated Path.  Files are overwritten by default. Parameters:f - the file to createreplication - the replication factor Throws: IOException create public FSDataOutputStream create(Path f,                         short replication,                         Progressable progress)                           throws IOException Create an FSDataOutputStream at the indicated Path with write-progress  reporting.  Files are overwritten by default. Parameters:f - the file to createreplication - the replication factorprogress - to report progress Throws: IOException create public FSDataOutputStream create(Path f,                         boolean overwrite,                         int bufferSize)                           throws IOException Create an FSDataOutputStream at the indicated Path. Parameters:f - the file name to createoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used. Throws: IOException create public FSDataOutputStream create(Path f,                         boolean overwrite,                         int bufferSize,                         Progressable progress)                           throws IOException Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Parameters:f - the path of the file to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used. Throws: IOException create public FSDataOutputStream create(Path f,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize)                           throws IOException Create an FSDataOutputStream at the indicated Path. Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOException create public FSDataOutputStream create(Path f,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOException create public abstract FSDataOutputStream create(Path f,                         FsPermission permission,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                                    throws IOException Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Parameters:f - the file name to openpermission - overwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file.blockSize - progress -  Throws: IOExceptionSee Also:setPermission(Path, FsPermission) create public FSDataOutputStream create(Path f,                         FsPermission permission,                         EnumSet<CreateFlag> flags,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Parameters:f - the file name to openpermission - flags - CreateFlags to use for this stream.bufferSize - the size of the buffer to be used.replication - required block replication for the file.blockSize - progress -  Throws: IOExceptionSee Also:setPermission(Path, FsPermission) create public FSDataOutputStream create(Path f,                         FsPermission permission,                         EnumSet<CreateFlag> flags,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress,                         org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt)                           throws IOException Create an FSDataOutputStream at the indicated Path with a custom  checksum option Parameters:f - the file name to openpermission - flags - CreateFlags to use for this stream.bufferSize - the size of the buffer to be used.replication - required block replication for the file.blockSize - progress - checksumOpt - checksum parameter. If null, the values         found in conf will be used. Throws: IOExceptionSee Also:setPermission(Path, FsPermission) primitiveCreate @Deprecated protected FSDataOutputStream primitiveCreate(Path f,                                             FsPermission absolutePermission,                                             EnumSet<CreateFlag> flag,                                             int bufferSize,                                             short replication,                                             long blockSize,                                             Progressable progress,                                             org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt)                                       throws IOException Deprecated.  Throws: IOException primitiveMkdir @Deprecated protected boolean primitiveMkdir(Path f,                                 FsPermission absolutePermission)                           throws IOException Deprecated.  This version of the mkdirs method assumes that the permission is absolute.  It has been added to support the FileContext that processes the permission  with umask before calling this method.  This a temporary method added to support the transition from FileSystem  to FileContext for user applications. Throws: IOException primitiveMkdir @Deprecated protected void primitiveMkdir(Path f,                              FsPermission absolutePermission,                              boolean createParent)                        throws IOException Deprecated.  This version of the mkdirs method assumes that the permission is absolute.  It has been added to support the FileContext that processes the permission  with umask before calling this method.  This a temporary method added to support the transition from FileSystem  to FileContext for user applications. Throws: IOException createNonRecursive @Deprecated public FSDataOutputStream createNonRecursive(Path f,                                                boolean overwrite,                                                int bufferSize,                                                short replication,                                                long blockSize,                                                Progressable progress)                                       throws IOException Deprecated. API only for 0.20-append Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,  the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file.blockSize - progress -  Throws: IOExceptionSee Also:setPermission(Path, FsPermission) createNonRecursive @Deprecated public FSDataOutputStream createNonRecursive(Path f,                                                FsPermission permission,                                                boolean overwrite,                                                int bufferSize,                                                short replication,                                                long blockSize,                                                Progressable progress)                                       throws IOException Deprecated. API only for 0.20-append Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Parameters:f - the file name to openpermission - overwrite - if a file with this name already exists, then if true,  the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file.blockSize - progress -  Throws: IOExceptionSee Also:setPermission(Path, FsPermission) createNonRecursive @Deprecated public FSDataOutputStream createNonRecursive(Path f,                                                FsPermission permission,                                                EnumSet<CreateFlag> flags,                                                int bufferSize,                                                short replication,                                                long blockSize,                                                Progressable progress)                                       throws IOException Deprecated. API only for 0.20-append Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Parameters:f - the file name to openpermission - flags - CreateFlags to use for this stream.bufferSize - the size of the buffer to be used.replication - required block replication for the file.blockSize - progress -  Throws: IOExceptionSee Also:setPermission(Path, FsPermission) createNewFile public boolean createNewFile(Path f)                       throws IOException Creates the given Path as a brand-new zero-length file.  If  create fails, or if it already existed, return false. Parameters:f - path to use for create Throws: IOException append public FSDataOutputStream append(Path f)                           throws IOException Append to an existing file (optional operation).  Same as append(f, getConf().getInt("io.file.buffer.size", 4096), null) Parameters:f - the existing file to be appended. Throws: IOException append public FSDataOutputStream append(Path f,                         int bufferSize)                           throws IOException Append to an existing file (optional operation).  Same as append(f, bufferSize, null). Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used. Throws: IOException append public abstract FSDataOutputStream append(Path f,                         int bufferSize,                         Progressable progress)                                    throws IOException Append to an existing file (optional operation). Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used.progress - for reporting progress if it is not null. Throws: IOException concat public void concat(Path trg,           Path[] psrcs)             throws IOException Concat existing files together. Parameters:trg - the path to the target destination.psrcs - the paths to the sources to use for the concatenation. Throws: IOException getReplication @Deprecated public short getReplication(Path src)                      throws IOException Deprecated. Use getFileStatus() instead Get replication. Parameters:src - file name Returns:file replication Throws: IOException setReplication public boolean setReplication(Path src,                      short replication)                        throws IOException Set replication for an existing file. Parameters:src - file namereplication - new replication Returns:true if successful;          false if file does not exist or is a directory Throws: IOException rename public abstract boolean rename(Path src,              Path dst)                         throws IOException Renames Path src to Path dst.  Can take place on local fs  or remote DFS. Parameters:src - path to be renameddst - new path after rename Returns:true if rename is successful Throws: IOException - on failure rename @Deprecated protected void rename(Path src,                      Path dst,                      org.apache.hadoop.fs.Options.Rename... options)                throws IOException Deprecated.  Renames Path src to Path dst    Fails if src is a file and dst is a directory.  Fails if src is a directory and dst is a file.  Fails if the parent of dst does not exist or is a file.      If OVERWRITE option is not passed as an argument, rename fails  if the dst already exists.    If OVERWRITE option is passed as an argument, rename overwrites  the dst if it is a file or an empty directory. Rename fails if dst is  a non-empty directory.    Note that atomicity of rename is dependent on the file system  implementation. Please refer to the file system documentation for  details. This default implementation is non atomic.    This method is deprecated since it is a temporary method added to   support the transition from FileSystem to FileContext for user   applications. Parameters:src - path to be renameddst - new path after rename Throws: IOException - on failure truncate public boolean truncate(Path f,                long newLength)                  throws IOException Truncate the file in the indicated path to the indicated size.    Fails if path is a directory.  Fails if path does not exist.  Fails if path is not closed.  Fails if new size is greater than current size.   Parameters:f - The path to the file to be truncatednewLength - The size the file is to be truncated to Returns:true if the file has been truncated to the desired  newLength and is immediately available to be reused for  write operations such as append, or  false if a background process of adjusting the length of  the last block has been started, and clients should wait for it to  complete before proceeding with further file updates. Throws: IOException delete @Deprecated public boolean delete(Path f)                throws IOException Deprecated. Use delete(Path, boolean) instead. Delete a file Throws: IOException delete public abstract boolean delete(Path f,              boolean recursive)                         throws IOException Delete a file. Parameters:f - the path to delete.recursive - if path is a directory and set to   true, the directory is deleted else throws an exception. In  case of a file the recursive can be set to either true or false. Returns:true if delete is successful else false. Throws: IOException deleteOnExit public boolean deleteOnExit(Path f)                      throws IOException Mark a path to be deleted when FileSystem is closed.  When the JVM shuts down,  all FileSystem objects will be closed automatically.  Then,  the marked path will be deleted as a result of closing the FileSystem.  The path has to exist in the file system. Parameters:f - the path to delete. Returns:true if deleteOnExit is successful, otherwise false. Throws: IOException cancelDeleteOnExit public boolean cancelDeleteOnExit(Path f) Cancel the deletion of the path when the FileSystem is closed Parameters:f - the path to cancel deletion processDeleteOnExit protected void processDeleteOnExit() Delete all files that were marked as delete-on-exit. This recursively  deletes all files in the specified paths. exists public boolean exists(Path f)                throws IOException Check if exists. Parameters:f - source file Throws: IOException isDirectory public boolean isDirectory(Path f)                     throws IOException True iff the named path is a directory.  Note: Avoid using this method. Instead reuse the FileStatus   returned by getFileStatus() or listStatus() methods. Parameters:f - path to check Throws: IOException isFile public boolean isFile(Path f)                throws IOException True iff the named path is a regular file.  Note: Avoid using this method. Instead reuse the FileStatus   returned by getFileStatus() or listStatus() methods. Parameters:f - path to check Throws: IOException getLength @Deprecated public long getLength(Path f)                throws IOException Deprecated. Use getFileStatus() instead Throws: IOException getContentSummary public ContentSummary getContentSummary(Path f)                                  throws IOException Return the ContentSummary of a given Path. Parameters:f - path to use Throws: IOException listStatus public abstract FileStatus[] listStatus(Path f)                                  throws FileNotFoundException,                                         IOException List the statuses of the files/directories in the given path if the path is  a directory. Parameters:f - given path Returns:the statuses of the files/directories in the given patch Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException listCorruptFileBlocks public org.apache.hadoop.fs.RemoteIterator<Path> listCorruptFileBlocks(Path path)                                                                 throws IOException Returns:an iterator over the corrupt files under the given path  (may contain duplicates if a file has more than one corrupt block) Throws: IOException listStatus public FileStatus[] listStatus(Path f,                       PathFilter filter)                         throws FileNotFoundException,                                IOException Filter files/directories in the given path using the user-supplied path  filter. Parameters:f - a path namefilter - the user-supplied path filter Returns:an array of FileStatus objects for the files under the given path          after applying the filter Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException listStatus public FileStatus[] listStatus(Path[] files)                         throws FileNotFoundException,                                IOException Filter files/directories in the given list of paths using default  path filter. Parameters:files - a list of paths Returns:a list of statuses for the files under the given paths after          applying the filter default Path filter Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException listStatus public FileStatus[] listStatus(Path[] files,                       PathFilter filter)                         throws FileNotFoundException,                                IOException Filter files/directories in the given list of paths using user-supplied  path filter. Parameters:files - a list of pathsfilter - the user-supplied path filter Returns:a list of statuses for the files under the given paths after          applying the filter Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException globStatus public FileStatus[] globStatus(Path pathPattern)                         throws IOException Return all the files that match filePattern and are not checksum  files. Results are sorted by their names.      A filename pattern is composed of regular characters and  special pattern matching characters, which are:                     ?       Matches any single character.            *       Matches zero or more characters.            [abc]       Matches a single character from character set      {a,b,c}.            [a-b]       Matches a single character from the character range      {a...b}.  Note that character a must be      lexicographically less than or equal to character b.            [^a]       Matches a single character that is not from character set or range      {a}.  Note that the ^ character must occur      immediately to the right of the opening bracket.            \c       Removes (escapes) any special meaning of character c.            {ab,cd}       Matches a string from the string set {ab, cd}                  {ab,c{de,fh}}       Matches a string from the string set {ab, cde, cfh}          Parameters:pathPattern - a regular expression specifying a pth pattern Returns:an array of paths that match the path pattern Throws: IOException globStatus public FileStatus[] globStatus(Path pathPattern,                       PathFilter filter)                         throws IOException Return an array of FileStatus objects whose path names match pathPattern  and is accepted by the user-supplied path filter. Results are sorted by  their path names.  Return null if pathPattern has no glob and the path does not exist.  Return an empty array if pathPattern has a glob and no path matches it. Parameters:pathPattern - a regular expression specifying the path patternfilter - a user-supplied path filter Returns:an array of FileStatus objects Throws: IOException - if any I/O error occurs when fetching file status listLocatedStatus public org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f)                                                                          throws FileNotFoundException,                                                                                 IOException List the statuses of the files/directories in the given path if the path is  a directory.   Return the file's status and block locations If the path is a file.    If a returned status is a file, it contains the file's block locations. Parameters:f - is the path Returns:an iterator that traverses statuses of the files/directories           in the given path Throws: FileNotFoundException - If f does not exist IOException - If an I/O error occurred listLocatedStatus protected org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f,                                                                        PathFilter filter)                                                                             throws FileNotFoundException,                                                                                    IOException Listing a directory  The returned results include its block location if it is a file  The results are filtered by the given path filter Parameters:f - a pathfilter - a path filter Returns:an iterator that traverses statuses of the files/directories           in the given path Throws: FileNotFoundException - if f does not exist IOException - if any I/O error occurred listStatusIterator public org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatusIterator(Path p)                                                                    throws FileNotFoundException,                                                                           IOException Returns a remote iterator so that followup calls are made on demand  while consuming the entries. Each file system implementation should  override this method and provide a more efficient implementation, if  possible. Parameters:p - target path Returns:remote iterator Throws: FileNotFoundException IOException listFiles public org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listFiles(Path f,                                                                boolean recursive)                                                                  throws FileNotFoundException,                                                                         IOException List the statuses and block locations of the files in the given path.    If the path is a directory,     if recursive is false, returns files in the directory;    if recursive is true, return files in the subtree rooted at the path.  If the path is a file, return the file's status and block locations. Parameters:f - is the pathrecursive - if the subdirectories need to be traversed recursively Returns:an iterator that traverses statuses of the files Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException getHomeDirectory public Path getHomeDirectory() Return the current user's home directory in this filesystem.  The default implementation returns "/user/$USER/". setWorkingDirectory public abstract void setWorkingDirectory(Path new_dir) Set the current working directory for the given file system. All relative  paths will be resolved relative to it. Parameters:new_dir -  getWorkingDirectory public abstract Path getWorkingDirectory() Get the current working directory for the given file system Returns:the directory pathname getInitialWorkingDirectory protected Path getInitialWorkingDirectory() Note: with the new FilesContext class, getWorkingDirectory()  will be removed.   The working directory is implemented in FilesContext.    Some file systems like LocalFileSystem have an initial workingDir  that we use as the starting workingDir. For other file systems  like HDFS there is no built in notion of an initial workingDir. Returns:if there is built in notion of workingDir then it  is returned; else a null is returned. mkdirs public boolean mkdirs(Path f)                throws IOException Call mkdirs(Path, FsPermission) with default permission. Throws: IOException mkdirs public abstract boolean mkdirs(Path f,              FsPermission permission)                         throws IOException Make the given file and all non-existent parents into  directories. Has the semantics of Unix 'mkdir -p'.  Existence of the directory hierarchy is not an error. Parameters:f - path to createpermission - to apply to f Throws: IOException copyFromLocalFile public void copyFromLocalFile(Path src,                      Path dst)                        throws IOException The src file is on the local disk.  Add it to FS at  the given dst name and the source is kept intact afterwards Parameters:src - pathdst - path Throws: IOException moveFromLocalFile public void moveFromLocalFile(Path[] srcs,                      Path dst)                        throws IOException The src files is on the local disk.  Add it to FS at  the given dst name, removing the source afterwards. Parameters:srcs - pathdst - path Throws: IOException moveFromLocalFile public void moveFromLocalFile(Path src,                      Path dst)                        throws IOException The src file is on the local disk.  Add it to FS at  the given dst name, removing the source afterwards. Parameters:src - pathdst - path Throws: IOException copyFromLocalFile public void copyFromLocalFile(boolean delSrc,                      Path src,                      Path dst)                        throws IOException The src file is on the local disk.  Add it to FS at  the given dst name.  delSrc indicates if the source should be removed Parameters:delSrc - whether to delete the srcsrc - pathdst - path Throws: IOException copyFromLocalFile public void copyFromLocalFile(boolean delSrc,                      boolean overwrite,                      Path[] srcs,                      Path dst)                        throws IOException The src files are on the local disk.  Add it to FS at  the given dst name.  delSrc indicates if the source should be removed Parameters:delSrc - whether to delete the srcoverwrite - whether to overwrite an existing filesrcs - array of paths which are sourcedst - path Throws: IOException copyFromLocalFile public void copyFromLocalFile(boolean delSrc,                      boolean overwrite,                      Path src,                      Path dst)                        throws IOException The src file is on the local disk.  Add it to FS at  the given dst name.  delSrc indicates if the source should be removed Parameters:delSrc - whether to delete the srcoverwrite - whether to overwrite an existing filesrc - pathdst - path Throws: IOException copyToLocalFile public void copyToLocalFile(Path src,                    Path dst)                      throws IOException The src file is under FS, and the dst is on the local disk.  Copy it from FS control to the local dst name. Parameters:src - pathdst - path Throws: IOException moveToLocalFile public void moveToLocalFile(Path src,                    Path dst)                      throws IOException The src file is under FS, and the dst is on the local disk.  Copy it from FS control to the local dst name.  Remove the source afterwards Parameters:src - pathdst - path Throws: IOException copyToLocalFile public void copyToLocalFile(boolean delSrc,                    Path src,                    Path dst)                      throws IOException The src file is under FS, and the dst is on the local disk.  Copy it from FS control to the local dst name.  delSrc indicates if the src will be removed or not. Parameters:delSrc - whether to delete the srcsrc - pathdst - path Throws: IOException copyToLocalFile public void copyToLocalFile(boolean delSrc,                    Path src,                    Path dst,                    boolean useRawLocalFileSystem)                      throws IOException The src file is under FS, and the dst is on the local disk. Copy it from FS  control to the local dst name. delSrc indicates if the src will be removed  or not. useRawLocalFileSystem indicates whether to use RawLocalFileSystem  as local file system or not. RawLocalFileSystem is non crc file system.So,  It will not create any crc files at local. Parameters:delSrc - whether to delete the srcsrc - pathdst - pathuseRawLocalFileSystem - whether to use RawLocalFileSystem as local file system or not. Throws: IOException - - if any IO error startLocalOutput public Path startLocalOutput(Path fsOutputFile,                     Path tmpLocalFile)                       throws IOException Returns a local File that the user can write output to.  The caller  provides both the eventual FS target name and the local working  file.  If the FS is local, we write directly into the target.  If  the FS is remote, we write into the tmp local area. Parameters:fsOutputFile - path of output filetmpLocalFile - path of local tmp file Throws: IOException completeLocalOutput public void completeLocalOutput(Path fsOutputFile,                        Path tmpLocalFile)                          throws IOException Called when we're all done writing to the target.  A local FS will  do nothing, because we've written to exactly the right place.  A remote  FS will copy the contents of tmpLocalFile to the correct target at  fsOutputFile. Parameters:fsOutputFile - path of output filetmpLocalFile - path to local tmp file Throws: IOException close public void close()            throws IOException No more filesystem operations are needed.  Will  release any held locks. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Throws: IOException getUsed public long getUsed()              throws IOException Return the total size of all files in the filesystem. Throws: IOException getBlockSize @Deprecated public long getBlockSize(Path f)                   throws IOException Deprecated. Use getFileStatus() instead Throws: IOException getDefaultBlockSize @Deprecated public long getDefaultBlockSize() Deprecated. use getDefaultBlockSize(Path) instead Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. getDefaultBlockSize public long getDefaultBlockSize(Path f) Return the number of bytes that large input files should be optimally  be split into to minimize i/o time.  The given path will be used to  locate the actual filesystem.  The full path does not have to exist. Parameters:f - path of file Returns:the default block size for the path's filesystem getDefaultReplication @Deprecated public short getDefaultReplication() Deprecated. use getDefaultReplication(Path) instead Get the default replication. getDefaultReplication public short getDefaultReplication(Path path) Get the default replication for a path.   The given path will be used to  locate the actual filesystem.  The full path does not have to exist. Parameters:path - of the file Returns:default replication for the path's filesystem getFileStatus public abstract FileStatus getFileStatus(Path f)                                   throws IOException Return a file status object that represents the path. Parameters:f - The path we want information from Returns:a FileStatus object Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException fixRelativePart protected Path fixRelativePart(Path p) See FileContext.fixRelativePart(org.apache.hadoop.fs.Path) createSymlink public void createSymlink(Path target,                  Path link,                  boolean createParent)                    throws org.apache.hadoop.security.AccessControlException,                           FileAlreadyExistsException,                           FileNotFoundException,                           ParentNotDirectoryException,                           UnsupportedFileSystemException,                           IOException See FileContext.createSymlink(Path, Path, boolean) Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException ParentNotDirectoryException UnsupportedFileSystemException IOException getFileLinkStatus public FileStatus getFileLinkStatus(Path f)                              throws org.apache.hadoop.security.AccessControlException,                                     FileNotFoundException,                                     UnsupportedFileSystemException,                                     IOException See FileContext.getFileLinkStatus(Path) Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException UnsupportedFileSystemException IOException supportsSymlinks public boolean supportsSymlinks() See AbstractFileSystem.supportsSymlinks() getLinkTarget public Path getLinkTarget(Path f)                    throws IOException See FileContext.getLinkTarget(Path) Throws: IOException resolveLink protected Path resolveLink(Path f)                     throws IOException See AbstractFileSystem.getLinkTarget(Path) Throws: IOException getFileChecksum public FileChecksum getFileChecksum(Path f)                              throws IOException Get the checksum of a file. Parameters:f - The file path Returns:The file checksum.  The default return value is null,   which indicates that no checksum algorithm is implemented   in the corresponding FileSystem. Throws: IOException getFileChecksum public FileChecksum getFileChecksum(Path f,                            long length)                              throws IOException Get the checksum of a file, from the beginning of the file till the  specific length. Parameters:f - The file pathlength - The length of the file range for checksum calculation Returns:The file checksum. Throws: IOException setVerifyChecksum public void setVerifyChecksum(boolean verifyChecksum) Set the verify checksum flag. This is only applicable if the   corresponding FileSystem supports checksum. By default doesn't do anything. Parameters:verifyChecksum -  setWriteChecksum public void setWriteChecksum(boolean writeChecksum) Set the write checksum flag. This is only applicable if the   corresponding FileSystem supports checksum. By default doesn't do anything. Parameters:writeChecksum -  getStatus public FsStatus getStatus()                    throws IOException Returns a status object describing the use and capacity of the  file system. If the file system has multiple partitions, the  use and capacity of the root partition is reflected. Returns:a FsStatus object Throws: IOException - see specific implementation getStatus public FsStatus getStatus(Path p)                    throws IOException Returns a status object describing the use and capacity of the  file system. If the file system has multiple partitions, the  use and capacity of the partition pointed to by the specified  path is reflected. Parameters:p - Path for which status should be obtained. null means  the default partition. Returns:a FsStatus object Throws: IOException - see specific implementation setPermission public void setPermission(Path p,                  FsPermission permission)                    throws IOException Set permission of a path. Parameters:p - permission -  Throws: IOException setOwner public void setOwner(Path p,             String username,             String groupname)               throws IOException Set owner of a path (i.e. a file or a directory).  The parameters username and groupname cannot both be null. Parameters:p - The pathusername - If it is null, the original username remains unchanged.groupname - If it is null, the original groupname remains unchanged. Throws: IOException setTimes public void setTimes(Path p,             long mtime,             long atime)               throws IOException Set access time of a file Parameters:p - The pathmtime - Set the modification time of this file.               The number of milliseconds since Jan 1, 1970.                A value of -1 means that this call should not set modification time.atime - Set the access time of this file.               The number of milliseconds since Jan 1, 1970.                A value of -1 means that this call should not set access time. Throws: IOException createSnapshot public final Path createSnapshot(Path path)                           throws IOException Create a snapshot with a default name. Parameters:path - The directory where snapshots will be taken. Returns:the snapshot path. Throws: IOException createSnapshot public Path createSnapshot(Path path,                   String snapshotName)                     throws IOException Create a snapshot Parameters:path - The directory where snapshots will be taken.snapshotName - The name of the snapshot Returns:the snapshot path. Throws: IOException renameSnapshot public void renameSnapshot(Path path,                   String snapshotOldName,                   String snapshotNewName)                     throws IOException Rename a snapshot Parameters:path - The directory path where the snapshot was takensnapshotOldName - Old name of the snapshotsnapshotNewName - New name of the snapshot Throws: IOException deleteSnapshot public void deleteSnapshot(Path path,                   String snapshotName)                     throws IOException Delete a snapshot of a directory Parameters:path - The directory that the to-be-deleted snapshot belongs tosnapshotName - The name of the snapshot Throws: IOException modifyAclEntries public void modifyAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Modifies ACL entries of files and directories.  This method can add new ACL  entries or modify the permissions on existing ACL entries.  All existing  ACL entries that are not specified in this call are retained without  changes.  (Modifications are merged into the current ACL.) Parameters:path - Path to modifyaclSpec - List describing modifications Throws: IOException - if an ACL could not be modified removeAclEntries public void removeAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Removes ACL entries from files and directories.  Other ACL entries are  retained. Parameters:path - Path to modifyaclSpec - List describing entries to remove Throws: IOException - if an ACL could not be modified removeDefaultAcl public void removeDefaultAcl(Path path)                       throws IOException Removes all default ACL entries from files and directories. Parameters:path - Path to modify Throws: IOException - if an ACL could not be modified removeAcl public void removeAcl(Path path)                throws IOException Removes all but the base ACL entries of files and directories.  The entries  for user, group, and others are retained for compatibility with permission  bits. Parameters:path - Path to modify Throws: IOException - if an ACL could not be removed setAcl public void setAcl(Path path,           List<AclEntry> aclSpec)             throws IOException Fully replaces ACL of files and directories, discarding all existing  entries. Parameters:path - Path to modifyaclSpec - List describing modifications, must include entries    for user, group, and others for compatibility with permission bits. Throws: IOException - if an ACL could not be modified getAclStatus public AclStatus getAclStatus(Path path)                        throws IOException Gets the ACL of a file or directory. Parameters:path - Path to get Returns:AclStatus describing the ACL of the file or directory Throws: IOException - if an ACL could not be read setXAttr public void setXAttr(Path path,             String name,             byte[] value)               throws IOException Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to modifyname - xattr name.value - xattr value. Throws: IOException setXAttr public void setXAttr(Path path,             String name,             byte[] value,             EnumSet<XAttrSetFlag> flag)               throws IOException Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to modifyname - xattr name.value - xattr value.flag - xattr set flag Throws: IOException getXAttr public byte[] getXAttr(Path path,               String name)                 throws IOException Get an xattr name and value for a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributename - xattr name. Returns:byte[] xattr value. Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path)                              throws IOException Get all of the xattr name/value pairs for a file or directory.  Only those xattrs which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributes Returns:Map describing the XAttrs of the file or directory Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path,                            List<String> names)                              throws IOException Get all of the xattrs name/value pairs for a file or directory.  Only those xattrs which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributesnames - XAttr names. Returns:Map describing the XAttrs of the file or directory Throws: IOException listXAttrs public List<String> listXAttrs(Path path)                         throws IOException Get all of the xattr names for a file or directory.  Only those xattr names which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to get extended attributes Returns:List of the XAttr names of the file or directory Throws: IOException removeXAttr public void removeXAttr(Path path,                String name)                  throws IOException Remove an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Parameters:path - Path to remove extended attributename - xattr name Throws: IOException getFileSystemClass public static Class<? extends FileSystem> getFileSystemClass(String scheme,                                              Configuration conf)                                                       throws IOException Throws: IOException getStatistics @Deprecated public static Map<String,org.apache.hadoop.fs.FileSystem.Statistics> getStatistics() Deprecated. use getAllStatistics() instead Get the Map of Statistics object indexed by URI Scheme. Returns:a Map having a key as URI scheme and value as Statistics object getAllStatistics public static List<org.apache.hadoop.fs.FileSystem.Statistics> getAllStatistics() Return the FileSystem classes that have Statistics getStatistics public static org.apache.hadoop.fs.FileSystem.Statistics getStatistics(String scheme,                                                        Class<? extends FileSystem> cls) Get the statistics for a particular file system Parameters:cls - the class to lookup Returns:a statistics object clearStatistics public static void clearStatistics() Reset all statistics for all file systems printStatistics public static void printStatistics()                             throws IOException Print all statistics for all file systems Throws: IOException areSymlinksEnabled public static boolean areSymlinksEnabled() enableSymlinks public static void enableSymlinks() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FileUtil (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FileUtil (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FileUtil java.lang.Object org.apache.hadoop.fs.FileUtil @InterfaceAudience.Public @InterfaceStability.Evolving public class FileUtil extends Object A collection of file-processing util methods Field Summary Fields  Modifier and Type Field and Description static int SYMLINK_NO_PRIVILEGE  Constructor Summary Constructors  Constructor and Description FileUtil()  Method Summary Methods  Modifier and Type Method and Description static boolean canExecute(File f) Platform independent implementation for File.canExecute() static boolean canRead(File f) Platform independent implementation for File.canRead() static boolean canWrite(File f) Platform independent implementation for File.canWrite() static int chmod(String filename,           String perm) Change the permissions on a filename. static int chmod(String filename,           String perm,           boolean recursive) Change the permissions on a file / directory, recursively, if  needed. static boolean copy(File src,         FileSystem dstFS,         Path dst,         boolean deleteSource,         Configuration conf) Copy local files to a FileSystem. static boolean copy(FileSystem srcFS,         FileStatus srcStatus,         FileSystem dstFS,         Path dst,         boolean deleteSource,         boolean overwrite,         Configuration conf) Copy files between FileSystems. static boolean copy(FileSystem srcFS,         Path[] srcs,         FileSystem dstFS,         Path dst,         boolean deleteSource,         boolean overwrite,         Configuration conf)  static boolean copy(FileSystem srcFS,         Path src,         File dst,         boolean deleteSource,         Configuration conf) Copy FileSystem files to local files. static boolean copy(FileSystem srcFS,         Path src,         FileSystem dstFS,         Path dst,         boolean deleteSource,         boolean overwrite,         Configuration conf) Copy files between FileSystems. static boolean copy(FileSystem srcFS,         Path src,         FileSystem dstFS,         Path dst,         boolean deleteSource,         Configuration conf) Copy files between FileSystems. static boolean copyMerge(FileSystem srcFS,                   Path srcDir,                   FileSystem dstFS,                   Path dstFile,                   boolean deleteSource,                   Configuration conf,                   String addString) Copy all files in a directory to one output file (merge). static String[] createJarWithClassPath(String inputClassPath,                                             Path pwd,                                             Map<String,String> callerEnv)  static String[] createJarWithClassPath(String inputClassPath,                                             Path pwd,                                             Path targetDir,                                             Map<String,String> callerEnv) Create a jar file at the given path, containing a manifest with a classpath  that references all specified entries. static File createLocalTempFile(File basefile,                                       String prefix,                                       boolean isDeleteOnExit) Create a tmp file for a base file. static boolean fullyDelete(File dir) Delete a directory and all its contents. static boolean fullyDelete(File dir,                       boolean tryGrantPermissions) Delete a directory and all its contents. static void fullyDelete(FileSystem fs,                       Path dir) Deprecated.  Use FileSystem.delete(Path, boolean) static boolean fullyDeleteContents(File dir) Delete the contents of a directory, not the directory itself. static boolean fullyDeleteContents(File dir,                                       boolean tryGrantPermissions) Delete the contents of a directory, not the directory itself. static long getDU(File dir) Takes an input dir and returns the du on that local directory. static String[] list(File dir) A wrapper for File.list(). static File[] listFiles(File dir) A wrapper for File.listFiles(). static String makeShellPath(File file) Convert a os-native filename to a path that works for the shell. static String makeShellPath(File file,                           boolean makeCanonicalPath) Convert a os-native filename to a path that works for the shell. static String makeShellPath(String filename) Convert a os-native filename to a path that works for the shell. static String readLink(File f) Returns the target of the given symlink. static void replaceFile(File src,                       File target) Move the src file to the name specified by target. static boolean setExecutable(File f,                           boolean executable) Platform independent implementation for File.setExecutable(boolean)  File#setExecutable does not work as expected on Windows. static void setOwner(File file,                 String username,                 String groupname) Set the ownership on a file / directory. static void setPermission(File f,                           FsPermission permission) Set permissions to the required value. static boolean setReadable(File f,                       boolean readable) Platform independent implementation for File.setReadable(boolean)  File#setReadable does not work as expected on Windows. static boolean setWritable(File f,                       boolean writable) Platform independent implementation for File.setWritable(boolean)  File#setWritable does not work as expected on Windows. static Path[] stat2Paths(FileStatus[] stats) convert an array of FileStatus to an array of Path static Path[] stat2Paths(FileStatus[] stats,                     Path path) convert an array of FileStatus to an array of Path. static int symLink(String target,               String linkname) Create a soft link between a src and destination  only on a local disk. static void unTar(File inFile,           File untarDir) Given a Tar File as input it will untar the file in a the untar directory  passed as the second parameter    This utility will untar ".tar" files and ".tar.gz","tgz" files. static void unZip(File inFile,           File unzipDir) Given a File input it will unzip the file in a the unzip directory  passed as the second parameter Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail SYMLINK_NO_PRIVILEGE public static final int SYMLINK_NO_PRIVILEGE See Also:Constant Field Values Constructor Detail FileUtil public FileUtil() Method Detail stat2Paths public static Path[] stat2Paths(FileStatus[] stats) convert an array of FileStatus to an array of Path Parameters:stats - an array of FileStatus objects Returns:an array of paths corresponding to the input stat2Paths public static Path[] stat2Paths(FileStatus[] stats,                 Path path) convert an array of FileStatus to an array of Path.  If stats if null, return path Parameters:stats - an array of FileStatus objectspath - default path to return in stats is null Returns:an array of paths corresponding to the input fullyDelete public static boolean fullyDelete(File dir) Delete a directory and all its contents.  If  we return false, the directory may be partially-deleted.  (1) If dir is symlink to a file, the symlink is deleted. The file pointed      to by the symlink is not deleted.  (2) If dir is symlink to a directory, symlink is deleted. The directory      pointed to by symlink is not deleted.  (3) If dir is a normal file, it is deleted.  (4) If dir is a normal directory, then dir and all its contents recursively      are deleted. fullyDelete public static boolean fullyDelete(File dir,                   boolean tryGrantPermissions) Delete a directory and all its contents.  If  we return false, the directory may be partially-deleted.  (1) If dir is symlink to a file, the symlink is deleted. The file pointed      to by the symlink is not deleted.  (2) If dir is symlink to a directory, symlink is deleted. The directory      pointed to by symlink is not deleted.  (3) If dir is a normal file, it is deleted.  (4) If dir is a normal directory, then dir and all its contents recursively      are deleted. Parameters:dir - the file or directory to be deletedtryGrantPermissions - true if permissions should be modified to delete a file. Returns:true on success false on failure. readLink public static String readLink(File f) Returns the target of the given symlink. Returns the empty string if  the given path does not refer to a symlink or there is an error  accessing the symlink. Parameters:f - File representing the symbolic link. Returns:The target of the symbolic link, empty string on error or if not          a symlink. fullyDeleteContents public static boolean fullyDeleteContents(File dir) Delete the contents of a directory, not the directory itself.  If  we return false, the directory may be partially-deleted.  If dir is a symlink to a directory, all the contents of the actual  directory pointed to by dir will be deleted. fullyDeleteContents public static boolean fullyDeleteContents(File dir,                           boolean tryGrantPermissions) Delete the contents of a directory, not the directory itself.  If  we return false, the directory may be partially-deleted.  If dir is a symlink to a directory, all the contents of the actual  directory pointed to by dir will be deleted. Parameters:tryGrantPermissions - if 'true', try grant +rwx permissions to this   and all the underlying directories before trying to delete their contents. fullyDelete @Deprecated public static void fullyDelete(FileSystem fs,                           Path dir)                         throws IOException Deprecated. Use FileSystem.delete(Path, boolean) Recursively delete a directory. Parameters:fs - FileSystem on which the path is presentdir - directory to recursively delete Throws: IOException copy public static boolean copy(FileSystem srcFS,            Path src,            FileSystem dstFS,            Path dst,            boolean deleteSource,            Configuration conf)                     throws IOException Copy files between FileSystems. Throws: IOException copy public static boolean copy(FileSystem srcFS,            Path[] srcs,            FileSystem dstFS,            Path dst,            boolean deleteSource,            boolean overwrite,            Configuration conf)                     throws IOException Throws: IOException copy public static boolean copy(FileSystem srcFS,            Path src,            FileSystem dstFS,            Path dst,            boolean deleteSource,            boolean overwrite,            Configuration conf)                     throws IOException Copy files between FileSystems. Throws: IOException copy public static boolean copy(FileSystem srcFS,            FileStatus srcStatus,            FileSystem dstFS,            Path dst,            boolean deleteSource,            boolean overwrite,            Configuration conf)                     throws IOException Copy files between FileSystems. Throws: IOException copyMerge public static boolean copyMerge(FileSystem srcFS,                 Path srcDir,                 FileSystem dstFS,                 Path dstFile,                 boolean deleteSource,                 Configuration conf,                 String addString)                          throws IOException Copy all files in a directory to one output file (merge). Throws: IOException copy public static boolean copy(File src,            FileSystem dstFS,            Path dst,            boolean deleteSource,            Configuration conf)                     throws IOException Copy local files to a FileSystem. Throws: IOException copy public static boolean copy(FileSystem srcFS,            Path src,            File dst,            boolean deleteSource,            Configuration conf)                     throws IOException Copy FileSystem files to local files. Throws: IOException makeShellPath public static String makeShellPath(String filename)                             throws IOException Convert a os-native filename to a path that works for the shell. Parameters:filename - The filename to convert Returns:The unix pathname Throws: IOException - on windows, there can be problems with the subprocess makeShellPath public static String makeShellPath(File file)                             throws IOException Convert a os-native filename to a path that works for the shell. Parameters:file - The filename to convert Returns:The unix pathname Throws: IOException - on windows, there can be problems with the subprocess makeShellPath public static String makeShellPath(File file,                    boolean makeCanonicalPath)                             throws IOException Convert a os-native filename to a path that works for the shell. Parameters:file - The filename to convertmakeCanonicalPath - Whether to make canonical path for the file passed Returns:The unix pathname Throws: IOException - on windows, there can be problems with the subprocess getDU public static long getDU(File dir) Takes an input dir and returns the du on that local directory. Very basic  implementation. Parameters:dir - The input dir to get the disk space of this local dir Returns:The total disk space of the input local directory unZip public static void unZip(File inFile,          File unzipDir)                   throws IOException Given a File input it will unzip the file in a the unzip directory  passed as the second parameter Parameters:inFile - The zip file as inputunzipDir - The unzip directory where to unzip the zip file. Throws: IOException unTar public static void unTar(File inFile,          File untarDir)                   throws IOException Given a Tar File as input it will untar the file in a the untar directory  passed as the second parameter    This utility will untar ".tar" files and ".tar.gz","tgz" files. Parameters:inFile - The tar file as input.untarDir - The untar directory where to untar the tar file. Throws: IOException symLink public static int symLink(String target,           String linkname)                    throws IOException Create a soft link between a src and destination  only on a local disk. HDFS does not support this.  On Windows, when symlink creation fails due to security  setting, we will log a warning. The return code in this  case is 2. Parameters:target - the target for symlinklinkname - the symlink Returns:0 on success Throws: IOException chmod public static int chmod(String filename,         String perm)                  throws IOException,                         InterruptedException Change the permissions on a filename. Parameters:filename - the name of the file to changeperm - the permission string Returns:the exit code from the command Throws: IOException InterruptedException chmod public static int chmod(String filename,         String perm,         boolean recursive)                  throws IOException Change the permissions on a file / directory, recursively, if  needed. Parameters:filename - name of the file whose permissions are to changeperm - permission stringrecursive - true, if permissions should be changed recursively Returns:the exit code from the command. Throws: IOException setOwner public static void setOwner(File file,             String username,             String groupname)                      throws IOException Set the ownership on a file / directory. User name and group name  cannot both be null. Parameters:file - the file to changeusername - the new user owner namegroupname - the new group owner name Throws: IOException setReadable public static boolean setReadable(File f,                   boolean readable) Platform independent implementation for File.setReadable(boolean)  File#setReadable does not work as expected on Windows. Parameters:f - input filereadable -  Returns:true on success, false otherwise setWritable public static boolean setWritable(File f,                   boolean writable) Platform independent implementation for File.setWritable(boolean)  File#setWritable does not work as expected on Windows. Parameters:f - input filewritable -  Returns:true on success, false otherwise setExecutable public static boolean setExecutable(File f,                     boolean executable) Platform independent implementation for File.setExecutable(boolean)  File#setExecutable does not work as expected on Windows.  Note: revoking execute permission on folders does not have the same  behavior on Windows as on Unix platforms. Creating, deleting or renaming  a file within that folder will still succeed on Windows. Parameters:f - input fileexecutable -  Returns:true on success, false otherwise canRead public static boolean canRead(File f) Platform independent implementation for File.canRead() Parameters:f - input file Returns:On Unix, same as File.canRead()          On Windows, true if process has read access on the path canWrite public static boolean canWrite(File f) Platform independent implementation for File.canWrite() Parameters:f - input file Returns:On Unix, same as File.canWrite()          On Windows, true if process has write access on the path canExecute public static boolean canExecute(File f) Platform independent implementation for File.canExecute() Parameters:f - input file Returns:On Unix, same as File.canExecute()          On Windows, true if process has execute access on the path setPermission public static void setPermission(File f,                  FsPermission permission)                           throws IOException Set permissions to the required value. Uses the java primitives instead  of forking if group == other. Parameters:f - the file to changepermission - the new permissions Throws: IOException createLocalTempFile public static final File createLocalTempFile(File basefile,                        String prefix,                        boolean isDeleteOnExit)                                       throws IOException Create a tmp file for a base file. Parameters:basefile - the base file of the tmpprefix - file name prefix of tmpisDeleteOnExit - if true, the tmp will be deleted when the VM exits Returns:a newly created tmp file Throws: IOException - If a tmp file cannot createdSee Also:File.createTempFile(String, String, File),  File.deleteOnExit() replaceFile public static void replaceFile(File src,                File target)                         throws IOException Move the src file to the name specified by target. Parameters:src - the source filetarget - the target file Throws: IOException - If this operation fails listFiles public static File[] listFiles(File dir)                         throws IOException A wrapper for File.listFiles(). This java.io API returns null   when a dir is not a directory or for any I/O error. Instead of having  null check everywhere File#listFiles() is used, we will add utility API  to get around this problem. For the majority of cases where we prefer   an IOException to be thrown. Parameters:dir - directory for which listing should be performed Returns:list of files or empty list Throws: IOException - for invalid directory or for a bad disk. list public static String[] list(File dir)                      throws IOException A wrapper for File.list(). This java.io API returns null   when a dir is not a directory or for any I/O error. Instead of having  null check everywhere File#list() is used, we will add utility API  to get around this problem. For the majority of cases where we prefer   an IOException to be thrown. Parameters:dir - directory for which listing should be performed Returns:list of file names or empty string list Throws: IOException - for invalid directory or for a bad disk. createJarWithClassPath public static String[] createJarWithClassPath(String inputClassPath,                               Path pwd,                               Map<String,String> callerEnv)                                        throws IOException Throws: IOException createJarWithClassPath public static String[] createJarWithClassPath(String inputClassPath,                               Path pwd,                               Path targetDir,                               Map<String,String> callerEnv)                                        throws IOException Create a jar file at the given path, containing a manifest with a classpath  that references all specified entries.    Some platforms may have an upper limit on command line length.  For example,  the maximum command line length on Windows is 8191 characters, but the  length of the classpath may exceed this.  To work around this limitation,  use this method to create a small intermediate jar with a manifest that  contains the full classpath.  It returns the absolute path to the new jar,  which the caller may set as the classpath for a new process.    Environment variable evaluation is not supported within a jar manifest, so  this method expands environment variables before inserting classpath entries  to the manifest.  The method parses environment variables according to  platform-specific syntax (%VAR% on Windows, or $VAR otherwise).  On Windows,  environment variables are case-insensitive.  For example, %VAR% and %var%  evaluate to the same value.    Specifying the classpath in a jar manifest does not support wildcards, so  this method expands wildcards internally.  Any classpath entry that ends  with * is translated to all files at that path with extension .jar or .JAR. Parameters:inputClassPath - String input classpath to bundle into the jar manifestpwd - Path to working directory to save jartargetDir - path to where the jar execution will have its working dircallerEnv - Map caller's environment variables to use    for expansion Returns:String[] with absolute path to new jar in position 0 and    unexpanded wild card entry path in position 1 Throws: IOException - if there is an I/O error while writing the jar file Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FilterFileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FilterFileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FilterFileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem org.apache.hadoop.fs.FilterFileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable Direct Known Subclasses: ChecksumFileSystem @InterfaceAudience.Public @InterfaceStability.Stable public class FilterFileSystem extends FileSystem A FilterFileSystem contains  some other file system, which it uses as  its  basic file system, possibly transforming  the data along the way or providing  additional  functionality. The class FilterFileSystem  itself simply overrides all  methods of  FileSystem with versions that  pass all requests to the contained  file  system. Subclasses of FilterFileSystem  may further override some of  these methods  and may also provide additional methods  and fields. Field Summary Fields  Modifier and Type Field and Description protected FileSystem fs  protected String swapScheme  Fields inherited from class org.apache.hadoop.fs.FileSystem DEFAULT_FS, FS_DEFAULT_NAME_KEY, LOG, SHUTDOWN_HOOK_PRIORITY, statistics Constructor Summary Constructors  Constructor and Description FilterFileSystem()  FilterFileSystem(FileSystem fs)  Method Summary Methods  Modifier and Type Method and Description void access(Path path,             FsAction mode) Checks if the user can access a path. FSDataOutputStream append(Path f,             int bufferSize,             Progressable progress) Append to an existing file (optional operation). protected URI canonicalizeUri(URI uri) Canonicalize the given URI. protected void checkPath(Path path) Check that a Path belongs to this FileSystem. void close() No more filesystem operations are needed. void completeLocalOutput(Path fsOutputFile,                                       Path tmpLocalFile) Called when we're all done writing to the target. void concat(Path f,             Path[] psrcs) Concat existing files together. void copyFromLocalFile(boolean delSrc,                                   boolean overwrite,                                   Path[] srcs,                                   Path dst) The src files are on the local disk. void copyFromLocalFile(boolean delSrc,                                   boolean overwrite,                                   Path src,                                   Path dst) The src file is on the local disk. void copyFromLocalFile(boolean delSrc,                                   Path src,                                   Path dst) The src file is on the local disk. void copyToLocalFile(boolean delSrc,                               Path src,                               Path dst) The src file is under FS, and the dst is on the local disk. FSDataOutputStream create(Path f,             FsPermission permission,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream create(Path f,             FsPermission permission,             EnumSet<CreateFlag> flags,             int bufferSize,             short replication,             long blockSize,             Progressable progress,             org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt) Create an FSDataOutputStream at the indicated Path with a custom  checksum option FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     EnumSet<CreateFlag> flags,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Deprecated.  Path createSnapshot(Path path,                             String snapshotName) Create a snapshot void createSymlink(Path target,                           Path link,                           boolean createParent) See FileContext.createSymlink(Path, Path, boolean) boolean delete(Path f,             boolean recursive) Delete a file void deleteSnapshot(Path path,                             String snapshotName) Delete a snapshot of a directory AclStatus getAclStatus(Path path) Gets the ACL of a file or directory. protected URI getCanonicalUri() Return a canonicalized form of this FileSystem's URI. FileSystem[] getChildFileSystems() Get all the immediate child FileSystems embedded in this FileSystem. Configuration getConf() Return the configuration used by this object. long getDefaultBlockSize() Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. long getDefaultBlockSize(Path f) Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. short getDefaultReplication() Get the default replication. short getDefaultReplication(Path f) Get the default replication for a path. BlockLocation[] getFileBlockLocations(FileStatus file,                                           long start,                                           long len) Return an array containing hostnames, offset and size of   portions of the given file. FileChecksum getFileChecksum(Path f) Get the checksum of a file. FileChecksum getFileChecksum(Path f,                               long length) Get the checksum of a file, from the beginning of the file till the  specific length. FileStatus getFileLinkStatus(Path f) See FileContext.getFileLinkStatus(Path) FileStatus getFileStatus(Path f) Get file status. Path getHomeDirectory() Return the current user's home directory in this filesystem. protected Path getInitialWorkingDirectory() Note: with the new FilesContext class, getWorkingDirectory()  will be removed. Path getLinkTarget(Path f) See FileContext.getLinkTarget(Path) FileSystem getRawFileSystem() Get the raw file system FsServerDefaults getServerDefaults() Return a set of server default configuration values FsServerDefaults getServerDefaults(Path f) Return a set of server default configuration values FsStatus getStatus(Path p) Returns a status object describing the use and capacity of the  file system. URI getUri() Returns a URI whose scheme and authority identify this FileSystem. long getUsed() Return the total size of all files in the filesystem. Path getWorkingDirectory() Get the current working directory for the given file system byte[] getXAttr(Path path,                 String name) Get an xattr name and value for a file or directory. Map<String,byte[]> getXAttrs(Path path) Get all of the xattr name/value pairs for a file or directory. Map<String,byte[]> getXAttrs(Path path,                   List<String> names) Get all of the xattrs name/value pairs for a file or directory. void initialize(URI name,                     Configuration conf) Called after a new FileSystem instance is constructed. org.apache.hadoop.fs.RemoteIterator<Path> listCorruptFileBlocks(Path path)  org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f) List files and its block locations in a directory. FileStatus[] listStatus(Path f) List files in a directory. org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatusIterator(Path f) Return a remote iterator for listing in a directory List<String> listXAttrs(Path path) Get all of the xattr names for a file or directory. Path makeQualified(Path path) Make sure that a path specifies a FileSystem. boolean mkdirs(Path f,             FsPermission permission) Make the given file and all non-existent parents into  directories. void modifyAclEntries(Path path,                                 List<AclEntry> aclSpec) Modifies ACL entries of files and directories. FSDataInputStream open(Path f,         int bufferSize) Opens an FSDataInputStream at the indicated Path. protected FSDataOutputStream primitiveCreate(Path f,                               FsPermission absolutePermission,                               EnumSet<CreateFlag> flag,                               int bufferSize,                               short replication,                               long blockSize,                               Progressable progress,                               org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt)  protected boolean primitiveMkdir(Path f,                             FsPermission abdolutePermission) This version of the mkdirs method assumes that the permission is absolute. void removeAcl(Path path) Removes all but the base ACL entries of files and directories. void removeAclEntries(Path path,                                 List<AclEntry> aclSpec) Removes ACL entries from files and directories. void removeDefaultAcl(Path path) Removes all default ACL entries from files and directories. void removeXAttr(Path path,                       String name) Remove an xattr of a file or directory. boolean rename(Path src,             Path dst) Renames Path src to Path dst. void renameSnapshot(Path path,                             String snapshotOldName,                             String snapshotNewName) Rename a snapshot protected Path resolveLink(Path f) See AbstractFileSystem.getLinkTarget(Path) Path resolvePath(Path p) Return the fully-qualified path of path f resolving the path  through any symlinks or mount point void setAcl(Path path,             List<AclEntry> aclSpec) Fully replaces ACL of files and directories, discarding all existing  entries. void setOwner(Path p,                 String username,                 String groupname) Set owner of a path (i.e. void setPermission(Path p,                           FsPermission permission) Set permission of a path. boolean setReplication(Path src,                             short replication) Set replication for an existing file. void setTimes(Path p,                 long mtime,                 long atime) Set access time of a file void setVerifyChecksum(boolean verifyChecksum) Set the verify checksum flag. void setWorkingDirectory(Path newDir) Set the current working directory for the given file system. void setWriteChecksum(boolean writeChecksum) Set the write checksum flag. void setXAttr(Path path,                 String name,                 byte[] value) Set an xattr of a file or directory. void setXAttr(Path path,                 String name,                 byte[] value,                 EnumSet<XAttrSetFlag> flag) Set an xattr of a file or directory. Path startLocalOutput(Path fsOutputFile,                                 Path tmpLocalFile) Returns a local File that the user can write output to. boolean supportsSymlinks() See AbstractFileSystem.supportsSymlinks() boolean truncate(Path f,                 long newLength) Truncate the file in the indicated path to the indicated size. Methods inherited from class org.apache.hadoop.fs.FileSystem append, append, areSymlinksEnabled, cancelDeleteOnExit, clearStatistics, closeAll, closeAllForUGI, copyFromLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, create, createNewFile, createNonRecursive, createNonRecursive, createSnapshot, delete, deleteOnExit, enableSymlinks, exists, fixRelativePart, get, get, get, getAllStatistics, getBlockSize, getContentSummary, getDefaultPort, getDefaultUri, getFileBlockLocations, getFileSystemClass, getFSofPath, getLength, getLocal, getName, getNamed, getReplication, getScheme, getStatistics, getStatistics, getStatus, globStatus, globStatus, isDirectory, isFile, listFiles, listLocatedStatus, listStatus, listStatus, listStatus, mkdirs, mkdirs, moveFromLocalFile, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveMkdir, printStatistics, processDeleteOnExit, rename, setDefaultUri, setDefaultUri Methods inherited from class org.apache.hadoop.conf.Configured setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail fs protected FileSystem fs swapScheme protected String swapScheme Constructor Detail FilterFileSystem public FilterFileSystem() FilterFileSystem public FilterFileSystem(FileSystem fs) Method Detail getRawFileSystem public FileSystem getRawFileSystem() Get the raw file system Returns:FileSystem being filtered initialize public void initialize(URI name,               Configuration conf)                 throws IOException Called after a new FileSystem instance is constructed. Overrides: initialize in class FileSystem Parameters:name - a uri whose authority section names the host, port, etc.    for this FileSystemconf - the configuration Throws: IOException getUri public URI getUri() Returns a URI whose scheme and authority identify this FileSystem. Specified by: getUri in class FileSystem getCanonicalUri protected URI getCanonicalUri() Description copied from class: FileSystem Return a canonicalized form of this FileSystem's URI.    The default implementation simply calls FileSystem.canonicalizeUri(URI)  on the filesystem's own URI, so subclasses typically only need to  implement that method. Overrides: getCanonicalUri in class FileSystem See Also:FileSystem.canonicalizeUri(URI) canonicalizeUri protected URI canonicalizeUri(URI uri) Description copied from class: FileSystem Canonicalize the given URI.    This is filesystem-dependent, but may for example consist of  canonicalizing the hostname using DNS and adding the default  port if not specified.    The default implementation simply fills in the default port if  not specified and if the filesystem has a default port. Overrides: canonicalizeUri in class FileSystem Returns:URISee Also:NetUtils.getCanonicalUri(URI, int) makeQualified public Path makeQualified(Path path) Make sure that a path specifies a FileSystem. Overrides: makeQualified in class FileSystem Parameters:path - to use checkPath protected void checkPath(Path path) Check that a Path belongs to this FileSystem. Overrides: checkPath in class FileSystem Parameters:path - to check getFileBlockLocations public BlockLocation[] getFileBlockLocations(FileStatus file,                                     long start,                                     long len)                                       throws IOException Description copied from class: FileSystem Return an array containing hostnames, offset and size of   portions of the given file.  For a nonexistent   file or regions, null will be returned.  This call is most helpful with DFS, where it returns   hostnames of machines that contain the given file.  The FileSystem will simply return an elt containing 'localhost'. Overrides: getFileBlockLocations in class FileSystem Parameters:file - FilesStatus to get data fromstart - offset into the given filelen - length for which to get locations for Throws: IOException resolvePath public Path resolvePath(Path p)                  throws IOException Description copied from class: FileSystem Return the fully-qualified path of path f resolving the path  through any symlinks or mount point Overrides: resolvePath in class FileSystem Parameters:p - path to be resolved Returns:fully qualified path Throws: FileNotFoundException IOException open public FSDataInputStream open(Path f,                      int bufferSize)                        throws IOException Opens an FSDataInputStream at the indicated Path. Specified by: open in class FileSystem Parameters:f - the file name to openbufferSize - the size of the buffer to be used. Throws: IOException append public FSDataOutputStream append(Path f,                         int bufferSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Append to an existing file (optional operation). Specified by: append in class FileSystem Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used.progress - for reporting progress if it is not null. Throws: IOException concat public void concat(Path f,           Path[] psrcs)             throws IOException Description copied from class: FileSystem Concat existing files together. Overrides: concat in class FileSystem Parameters:f - the path to the target destination.psrcs - the paths to the sources to use for the concatenation. Throws: IOException create public FSDataOutputStream create(Path f,                         FsPermission permission,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Specified by: create in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) create public FSDataOutputStream create(Path f,                         FsPermission permission,                         EnumSet<CreateFlag> flags,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress,                         org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt)                           throws IOException Description copied from class: FileSystem Create an FSDataOutputStream at the indicated Path with a custom  checksum option Overrides: create in class FileSystem Parameters:f - the file name to openflags - CreateFlags to use for this stream.bufferSize - the size of the buffer to be used.replication - required block replication for the file.checksumOpt - checksum parameter. If null, the values         found in conf will be used. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) createNonRecursive @Deprecated public FSDataOutputStream createNonRecursive(Path f,                                                FsPermission permission,                                                EnumSet<CreateFlag> flags,                                                int bufferSize,                                                short replication,                                                long blockSize,                                                Progressable progress)                                       throws IOException Deprecated.  Description copied from class: FileSystem Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Overrides: createNonRecursive in class FileSystem Parameters:f - the file name to openflags - CreateFlags to use for this stream.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) setReplication public boolean setReplication(Path src,                      short replication)                        throws IOException Set replication for an existing file. Overrides: setReplication in class FileSystem Parameters:src - file namereplication - new replication Returns:true if successful;          false if file does not exist or is a directory Throws: IOException rename public boolean rename(Path src,              Path dst)                throws IOException Renames Path src to Path dst.  Can take place on local fs  or remote DFS. Specified by: rename in class FileSystem Parameters:src - path to be renameddst - new path after rename Returns:true if rename is successful Throws: IOException - on failure truncate public boolean truncate(Path f,                long newLength)                  throws IOException Description copied from class: FileSystem Truncate the file in the indicated path to the indicated size.    Fails if path is a directory.  Fails if path does not exist.  Fails if path is not closed.  Fails if new size is greater than current size.   Overrides: truncate in class FileSystem Parameters:f - The path to the file to be truncatednewLength - The size the file is to be truncated to Returns:true if the file has been truncated to the desired  newLength and is immediately available to be reused for  write operations such as append, or  false if a background process of adjusting the length of  the last block has been started, and clients should wait for it to  complete before proceeding with further file updates. Throws: IOException delete public boolean delete(Path f,              boolean recursive)                throws IOException Delete a file Specified by: delete in class FileSystem Parameters:f - the path to delete.recursive - if path is a directory and set to   true, the directory is deleted else throws an exception. In  case of a file the recursive can be set to either true or false. Returns:true if delete is successful else false. Throws: IOException listStatus public FileStatus[] listStatus(Path f)                         throws IOException List files in a directory. Specified by: listStatus in class FileSystem Parameters:f - given path Returns:the statuses of the files/directories in the given patch Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException listCorruptFileBlocks public org.apache.hadoop.fs.RemoteIterator<Path> listCorruptFileBlocks(Path path)                                                                 throws IOException Overrides: listCorruptFileBlocks in class FileSystem Returns:an iterator over the corrupt files under the given path  (may contain duplicates if a file has more than one corrupt block) Throws: IOException listLocatedStatus public org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f)                                                                          throws IOException List files and its block locations in a directory. Overrides: listLocatedStatus in class FileSystem Parameters:f - is the path Returns:an iterator that traverses statuses of the files/directories           in the given path Throws: FileNotFoundException - If f does not exist IOException - If an I/O error occurred listStatusIterator public org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatusIterator(Path f)                                                                    throws IOException Return a remote iterator for listing in a directory Overrides: listStatusIterator in class FileSystem Parameters:f - target path Returns:remote iterator Throws: IOException getHomeDirectory public Path getHomeDirectory() Description copied from class: FileSystem Return the current user's home directory in this filesystem.  The default implementation returns "/user/$USER/". Overrides: getHomeDirectory in class FileSystem setWorkingDirectory public void setWorkingDirectory(Path newDir) Set the current working directory for the given file system. All relative  paths will be resolved relative to it. Specified by: setWorkingDirectory in class FileSystem Parameters:newDir -  getWorkingDirectory public Path getWorkingDirectory() Get the current working directory for the given file system Specified by: getWorkingDirectory in class FileSystem Returns:the directory pathname getInitialWorkingDirectory protected Path getInitialWorkingDirectory() Description copied from class: FileSystem Note: with the new FilesContext class, getWorkingDirectory()  will be removed.   The working directory is implemented in FilesContext.    Some file systems like LocalFileSystem have an initial workingDir  that we use as the starting workingDir. For other file systems  like HDFS there is no built in notion of an initial workingDir. Overrides: getInitialWorkingDirectory in class FileSystem Returns:if there is built in notion of workingDir then it  is returned; else a null is returned. getStatus public FsStatus getStatus(Path p)                    throws IOException Description copied from class: FileSystem Returns a status object describing the use and capacity of the  file system. If the file system has multiple partitions, the  use and capacity of the partition pointed to by the specified  path is reflected. Overrides: getStatus in class FileSystem Parameters:p - Path for which status should be obtained. null means  the default partition. Returns:a FsStatus object Throws: IOException - see specific implementation mkdirs public boolean mkdirs(Path f,              FsPermission permission)                throws IOException Description copied from class: FileSystem Make the given file and all non-existent parents into  directories. Has the semantics of Unix 'mkdir -p'.  Existence of the directory hierarchy is not an error. Specified by: mkdirs in class FileSystem Parameters:f - path to createpermission - to apply to f Throws: IOException copyFromLocalFile public void copyFromLocalFile(boolean delSrc,                      Path src,                      Path dst)                        throws IOException The src file is on the local disk.  Add it to FS at  the given dst name.  delSrc indicates if the source should be removed Overrides: copyFromLocalFile in class FileSystem Parameters:delSrc - whether to delete the srcsrc - pathdst - path Throws: IOException copyFromLocalFile public void copyFromLocalFile(boolean delSrc,                      boolean overwrite,                      Path[] srcs,                      Path dst)                        throws IOException The src files are on the local disk.  Add it to FS at  the given dst name.  delSrc indicates if the source should be removed Overrides: copyFromLocalFile in class FileSystem Parameters:delSrc - whether to delete the srcoverwrite - whether to overwrite an existing filesrcs - array of paths which are sourcedst - path Throws: IOException copyFromLocalFile public void copyFromLocalFile(boolean delSrc,                      boolean overwrite,                      Path src,                      Path dst)                        throws IOException The src file is on the local disk.  Add it to FS at  the given dst name.  delSrc indicates if the source should be removed Overrides: copyFromLocalFile in class FileSystem Parameters:delSrc - whether to delete the srcoverwrite - whether to overwrite an existing filesrc - pathdst - path Throws: IOException copyToLocalFile public void copyToLocalFile(boolean delSrc,                    Path src,                    Path dst)                      throws IOException The src file is under FS, and the dst is on the local disk.  Copy it from FS control to the local dst name.  delSrc indicates if the src will be removed or not. Overrides: copyToLocalFile in class FileSystem Parameters:delSrc - whether to delete the srcsrc - pathdst - path Throws: IOException startLocalOutput public Path startLocalOutput(Path fsOutputFile,                     Path tmpLocalFile)                       throws IOException Returns a local File that the user can write output to.  The caller  provides both the eventual FS target name and the local working  file.  If the FS is local, we write directly into the target.  If  the FS is remote, we write into the tmp local area. Overrides: startLocalOutput in class FileSystem Parameters:fsOutputFile - path of output filetmpLocalFile - path of local tmp file Throws: IOException completeLocalOutput public void completeLocalOutput(Path fsOutputFile,                        Path tmpLocalFile)                          throws IOException Called when we're all done writing to the target.  A local FS will  do nothing, because we've written to exactly the right place.  A remote  FS will copy the contents of tmpLocalFile to the correct target at  fsOutputFile. Overrides: completeLocalOutput in class FileSystem Parameters:fsOutputFile - path of output filetmpLocalFile - path to local tmp file Throws: IOException getUsed public long getUsed()              throws IOException Return the total size of all files in the filesystem. Overrides: getUsed in class FileSystem Throws: IOException getDefaultBlockSize public long getDefaultBlockSize() Description copied from class: FileSystem Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. Overrides: getDefaultBlockSize in class FileSystem getDefaultReplication public short getDefaultReplication() Description copied from class: FileSystem Get the default replication. Overrides: getDefaultReplication in class FileSystem getServerDefaults public FsServerDefaults getServerDefaults()                                    throws IOException Description copied from class: FileSystem Return a set of server default configuration values Overrides: getServerDefaults in class FileSystem Returns:server default configuration values Throws: IOException getDefaultBlockSize public long getDefaultBlockSize(Path f) Description copied from class: FileSystem Return the number of bytes that large input files should be optimally  be split into to minimize i/o time.  The given path will be used to  locate the actual filesystem.  The full path does not have to exist. Overrides: getDefaultBlockSize in class FileSystem Parameters:f - path of file Returns:the default block size for the path's filesystem getDefaultReplication public short getDefaultReplication(Path f) Description copied from class: FileSystem Get the default replication for a path.   The given path will be used to  locate the actual filesystem.  The full path does not have to exist. Overrides: getDefaultReplication in class FileSystem Parameters:f - of the file Returns:default replication for the path's filesystem getServerDefaults public FsServerDefaults getServerDefaults(Path f)                                    throws IOException Description copied from class: FileSystem Return a set of server default configuration values Overrides: getServerDefaults in class FileSystem Parameters:f - path is used to identify an FS since an FS could have           another FS that it could be delegating the call to Returns:server default configuration values Throws: IOException getFileStatus public FileStatus getFileStatus(Path f)                          throws IOException Get file status. Specified by: getFileStatus in class FileSystem Parameters:f - The path we want information from Returns:a FileStatus object Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException access public void access(Path path,           FsAction mode)             throws org.apache.hadoop.security.AccessControlException,                    FileNotFoundException,                    IOException Description copied from class: FileSystem Checks if the user can access a path.  The mode specifies which access  checks to perform.  If the requested permissions are granted, then the  method returns normally.  If access is denied, then the method throws an  AccessControlException.    The default implementation of this method calls FileSystem.getFileStatus(Path)  and checks the returned permissions against the requested permissions.  Note that the getFileStatus call will be subject to authorization checks.  Typically, this requires search (execute) permissions on each directory in  the path's prefix, but this is implementation-defined.  Any file system  that provides a richer authorization model (such as ACLs) may override the  default implementation so that it checks against that model instead.    In general, applications should avoid using this method, due to the risk of  time-of-check/time-of-use race conditions.  The permissions on a file may  change immediately after the access call returns.  Most applications should  prefer running specific file system actions as the desired user represented  by a UserGroupInformation. Parameters:path - Path to checkmode - type of access to check Throws: org.apache.hadoop.security.AccessControlException - if access is denied FileNotFoundException - if the path does not exist IOException - see specific implementation createSymlink public void createSymlink(Path target,                  Path link,                  boolean createParent)                    throws org.apache.hadoop.security.AccessControlException,                           FileAlreadyExistsException,                           FileNotFoundException,                           ParentNotDirectoryException,                           UnsupportedFileSystemException,                           IOException Description copied from class: FileSystem See FileContext.createSymlink(Path, Path, boolean) Overrides: createSymlink in class FileSystem Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException ParentNotDirectoryException UnsupportedFileSystemException IOException getFileLinkStatus public FileStatus getFileLinkStatus(Path f)                              throws org.apache.hadoop.security.AccessControlException,                                     FileNotFoundException,                                     UnsupportedFileSystemException,                                     IOException Description copied from class: FileSystem See FileContext.getFileLinkStatus(Path) Overrides: getFileLinkStatus in class FileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException UnsupportedFileSystemException IOException supportsSymlinks public boolean supportsSymlinks() Description copied from class: FileSystem See AbstractFileSystem.supportsSymlinks() Overrides: supportsSymlinks in class FileSystem getLinkTarget public Path getLinkTarget(Path f)                    throws IOException Description copied from class: FileSystem See FileContext.getLinkTarget(Path) Overrides: getLinkTarget in class FileSystem Throws: IOException resolveLink protected Path resolveLink(Path f)                     throws IOException Description copied from class: FileSystem See AbstractFileSystem.getLinkTarget(Path) Overrides: resolveLink in class FileSystem Throws: IOException getFileChecksum public FileChecksum getFileChecksum(Path f)                              throws IOException Description copied from class: FileSystem Get the checksum of a file. Overrides: getFileChecksum in class FileSystem Parameters:f - The file path Returns:The file checksum.  The default return value is null,   which indicates that no checksum algorithm is implemented   in the corresponding FileSystem. Throws: IOException getFileChecksum public FileChecksum getFileChecksum(Path f,                            long length)                              throws IOException Description copied from class: FileSystem Get the checksum of a file, from the beginning of the file till the  specific length. Overrides: getFileChecksum in class FileSystem Parameters:f - The file pathlength - The length of the file range for checksum calculation Returns:The file checksum. Throws: IOException setVerifyChecksum public void setVerifyChecksum(boolean verifyChecksum) Description copied from class: FileSystem Set the verify checksum flag. This is only applicable if the   corresponding FileSystem supports checksum. By default doesn't do anything. Overrides: setVerifyChecksum in class FileSystem setWriteChecksum public void setWriteChecksum(boolean writeChecksum) Description copied from class: FileSystem Set the write checksum flag. This is only applicable if the   corresponding FileSystem supports checksum. By default doesn't do anything. Overrides: setWriteChecksum in class FileSystem getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable Overrides: getConf in class Configured close public void close()            throws IOException Description copied from class: FileSystem No more filesystem operations are needed.  Will  release any held locks. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Overrides: close in class FileSystem Throws: IOException setOwner public void setOwner(Path p,             String username,             String groupname)               throws IOException Description copied from class: FileSystem Set owner of a path (i.e. a file or a directory).  The parameters username and groupname cannot both be null. Overrides: setOwner in class FileSystem Parameters:p - The pathusername - If it is null, the original username remains unchanged.groupname - If it is null, the original groupname remains unchanged. Throws: IOException setTimes public void setTimes(Path p,             long mtime,             long atime)               throws IOException Description copied from class: FileSystem Set access time of a file Overrides: setTimes in class FileSystem Parameters:p - The pathmtime - Set the modification time of this file.               The number of milliseconds since Jan 1, 1970.                A value of -1 means that this call should not set modification time.atime - Set the access time of this file.               The number of milliseconds since Jan 1, 1970.                A value of -1 means that this call should not set access time. Throws: IOException setPermission public void setPermission(Path p,                  FsPermission permission)                    throws IOException Description copied from class: FileSystem Set permission of a path. Overrides: setPermission in class FileSystem Throws: IOException primitiveCreate protected FSDataOutputStream primitiveCreate(Path f,                                  FsPermission absolutePermission,                                  EnumSet<CreateFlag> flag,                                  int bufferSize,                                  short replication,                                  long blockSize,                                  Progressable progress,                                  org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt)                                       throws IOException Overrides: primitiveCreate in class FileSystem Throws: IOException primitiveMkdir protected boolean primitiveMkdir(Path f,                      FsPermission abdolutePermission)                           throws IOException Description copied from class: FileSystem This version of the mkdirs method assumes that the permission is absolute.  It has been added to support the FileContext that processes the permission  with umask before calling this method.  This a temporary method added to support the transition from FileSystem  to FileContext for user applications. Overrides: primitiveMkdir in class FileSystem Throws: IOException getChildFileSystems public FileSystem[] getChildFileSystems() Description copied from class: FileSystem Get all the immediate child FileSystems embedded in this FileSystem.  It does not recurse and get grand children.  If a FileSystem  has multiple child FileSystems, then it should return a unique list  of those FileSystems.  Default is to return null to signify no children. Returns:FileSystems used by this FileSystem createSnapshot public Path createSnapshot(Path path,                   String snapshotName)                     throws IOException Description copied from class: FileSystem Create a snapshot Overrides: createSnapshot in class FileSystem Parameters:path - The directory where snapshots will be taken.snapshotName - The name of the snapshot Returns:the snapshot path. Throws: IOException renameSnapshot public void renameSnapshot(Path path,                   String snapshotOldName,                   String snapshotNewName)                     throws IOException Description copied from class: FileSystem Rename a snapshot Overrides: renameSnapshot in class FileSystem Parameters:path - The directory path where the snapshot was takensnapshotOldName - Old name of the snapshotsnapshotNewName - New name of the snapshot Throws: IOException deleteSnapshot public void deleteSnapshot(Path path,                   String snapshotName)                     throws IOException Description copied from class: FileSystem Delete a snapshot of a directory Overrides: deleteSnapshot in class FileSystem Parameters:path - The directory that the to-be-deleted snapshot belongs tosnapshotName - The name of the snapshot Throws: IOException modifyAclEntries public void modifyAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Description copied from class: FileSystem Modifies ACL entries of files and directories.  This method can add new ACL  entries or modify the permissions on existing ACL entries.  All existing  ACL entries that are not specified in this call are retained without  changes.  (Modifications are merged into the current ACL.) Overrides: modifyAclEntries in class FileSystem Parameters:path - Path to modifyaclSpec - List describing modifications Throws: IOException - if an ACL could not be modified removeAclEntries public void removeAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Description copied from class: FileSystem Removes ACL entries from files and directories.  Other ACL entries are  retained. Overrides: removeAclEntries in class FileSystem Parameters:path - Path to modifyaclSpec - List describing entries to remove Throws: IOException - if an ACL could not be modified removeDefaultAcl public void removeDefaultAcl(Path path)                       throws IOException Description copied from class: FileSystem Removes all default ACL entries from files and directories. Overrides: removeDefaultAcl in class FileSystem Parameters:path - Path to modify Throws: IOException - if an ACL could not be modified removeAcl public void removeAcl(Path path)                throws IOException Description copied from class: FileSystem Removes all but the base ACL entries of files and directories.  The entries  for user, group, and others are retained for compatibility with permission  bits. Overrides: removeAcl in class FileSystem Parameters:path - Path to modify Throws: IOException - if an ACL could not be removed setAcl public void setAcl(Path path,           List<AclEntry> aclSpec)             throws IOException Description copied from class: FileSystem Fully replaces ACL of files and directories, discarding all existing  entries. Overrides: setAcl in class FileSystem Parameters:path - Path to modifyaclSpec - List describing modifications, must include entries    for user, group, and others for compatibility with permission bits. Throws: IOException - if an ACL could not be modified getAclStatus public AclStatus getAclStatus(Path path)                        throws IOException Description copied from class: FileSystem Gets the ACL of a file or directory. Overrides: getAclStatus in class FileSystem Parameters:path - Path to get Returns:AclStatus describing the ACL of the file or directory Throws: IOException - if an ACL could not be read setXAttr public void setXAttr(Path path,             String name,             byte[] value)               throws IOException Description copied from class: FileSystem Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: setXAttr in class FileSystem Parameters:path - Path to modifyname - xattr name.value - xattr value. Throws: IOException setXAttr public void setXAttr(Path path,             String name,             byte[] value,             EnumSet<XAttrSetFlag> flag)               throws IOException Description copied from class: FileSystem Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: setXAttr in class FileSystem Parameters:path - Path to modifyname - xattr name.value - xattr value.flag - xattr set flag Throws: IOException getXAttr public byte[] getXAttr(Path path,               String name)                 throws IOException Description copied from class: FileSystem Get an xattr name and value for a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: getXAttr in class FileSystem Parameters:path - Path to get extended attributename - xattr name. Returns:byte[] xattr value. Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path)                              throws IOException Description copied from class: FileSystem Get all of the xattr name/value pairs for a file or directory.  Only those xattrs which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Overrides: getXAttrs in class FileSystem Parameters:path - Path to get extended attributes Returns:Map describing the XAttrs of the file or directory Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path,                            List<String> names)                              throws IOException Description copied from class: FileSystem Get all of the xattrs name/value pairs for a file or directory.  Only those xattrs which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Overrides: getXAttrs in class FileSystem Parameters:path - Path to get extended attributesnames - XAttr names. Returns:Map describing the XAttrs of the file or directory Throws: IOException listXAttrs public List<String> listXAttrs(Path path)                         throws IOException Description copied from class: FileSystem Get all of the xattr names for a file or directory.  Only those xattr names which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Overrides: listXAttrs in class FileSystem Parameters:path - Path to get extended attributes Returns:List of the XAttr names of the file or directory Throws: IOException removeXAttr public void removeXAttr(Path path,                String name)                  throws IOException Description copied from class: FileSystem Remove an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: removeXAttr in class FileSystem Parameters:path - Path to remove extended attributename - xattr name Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FilterOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FilterOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class FilterOutputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat<K,V> Direct Known Subclasses: LazyOutputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class FilterOutputFormat<K,V> extends OutputFormat<K,V> FilterOutputFormat is a convenience class that wraps OutputFormat. Field Summary Fields  Modifier and Type Field and Description protected OutputFormat<K,V> baseOut  Constructor Summary Constructors  Constructor and Description FilterOutputFormat()  FilterOutputFormat(OutputFormat<K,V> baseOut) Create a FilterOutputFormat based on the underlying output format. Method Summary Methods  Modifier and Type Method and Description void checkOutputSpecs(JobContext context) Check for validity of the output-specification for the job. OutputCommitter getOutputCommitter(TaskAttemptContext context) Get the output committer for this output format. RecordWriter<K,V> getRecordWriter(TaskAttemptContext context) Get the RecordWriter for the given task. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail baseOut protected OutputFormat<K,V> baseOut Constructor Detail FilterOutputFormat public FilterOutputFormat() FilterOutputFormat public FilterOutputFormat(OutputFormat<K,V> baseOut) Create a FilterOutputFormat based on the underlying output format. Parameters:baseOut - the underlying OutputFormat Method Detail getRecordWriter public RecordWriter<K,V> getRecordWriter(TaskAttemptContext context)                                   throws IOException,                                          InterruptedException Description copied from class: OutputFormat Get the RecordWriter for the given task. Specified by: getRecordWriter in class OutputFormat<K,V> Parameters:context - the information about the current task. Returns:a RecordWriter to write the output for the job. Throws: IOException InterruptedException checkOutputSpecs public void checkOutputSpecs(JobContext context)                       throws IOException,                              InterruptedException Description copied from class: OutputFormat Check for validity of the output-specification for the job.     This is to validate the output specification for the job when it is  a job is submitted.  Typically checks that it does not already exist,  throwing an exception when it already exists, so that output is not  overwritten. Specified by: checkOutputSpecs in class OutputFormat<K,V> Parameters:context - information about the job Throws: IOException - when output should not be attempted InterruptedException getOutputCommitter public OutputCommitter getOutputCommitter(TaskAttemptContext context)                                    throws IOException,                                           InterruptedException Description copied from class: OutputFormat Get the output committer for this output format. This is responsible  for ensuring the output is committed correctly. Specified by: getOutputCommitter in class OutputFormat<K,V> Parameters:context - the task context Returns:an output committer Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FinalApplicationStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FinalApplicationStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum FinalApplicationStatus java.lang.Object java.lang.Enum<FinalApplicationStatus> org.apache.hadoop.yarn.api.records.FinalApplicationStatus All Implemented Interfaces: Serializable, Comparable<FinalApplicationStatus> @InterfaceAudience.Public @InterfaceStability.Stable public enum FinalApplicationStatus extends Enum<FinalApplicationStatus> Enumeration of various final states of an Application. Enum Constant Summary Enum Constants  Enum Constant and Description FAILED Application which failed. KILLED Application which was terminated by a user or admin. SUCCEEDED Application which finished successfully. UNDEFINED Undefined state when either the application has not yet finished Method Summary Methods  Modifier and Type Method and Description static FinalApplicationStatus valueOf(String name) Returns the enum constant of this type with the specified name. static FinalApplicationStatus[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail UNDEFINED public static final FinalApplicationStatus UNDEFINED Undefined state when either the application has not yet finished SUCCEEDED public static final FinalApplicationStatus SUCCEEDED Application which finished successfully. FAILED public static final FinalApplicationStatus FAILED Application which failed. KILLED public static final FinalApplicationStatus KILLED Application which was terminated by a user or admin. Method Detail values public static FinalApplicationStatus[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (FinalApplicationStatus c : FinalApplicationStatus.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static FinalApplicationStatus valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FinishApplicationMasterRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FinishApplicationMasterRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class FinishApplicationMasterRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class FinishApplicationMasterRequest extends Object The finalization request sent by the ApplicationMaster to  inform the ResourceManager about its completion.    The final request includes details such:      Final state of the ApplicationMaster          Diagnostic information in case of failure of the      ApplicationMaster        Tracking URL   See Also:ApplicationMasterProtocol.finishApplicationMaster(FinishApplicationMasterRequest) Constructor Summary Constructors  Constructor and Description FinishApplicationMasterRequest()  Method Summary Methods  Modifier and Type Method and Description abstract String getDiagnostics() Get diagnostic information on application failure. abstract FinalApplicationStatus getFinalApplicationStatus() Get final state of the ApplicationMaster. abstract String getTrackingUrl() Get the tracking URL for the ApplicationMaster. static FinishApplicationMasterRequest newInstance(FinalApplicationStatus finalAppStatus,                       String diagnostics,                       String url)  abstract void setDiagnostics(String diagnostics) Set diagnostic information on application failure. abstract void setFinalApplicationStatus(FinalApplicationStatus finalState) Set the final state of the ApplicationMaster abstract void setTrackingUrl(String url) Set the final tracking URLfor the ApplicationMaster. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail FinishApplicationMasterRequest public FinishApplicationMasterRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static FinishApplicationMasterRequest newInstance(FinalApplicationStatus finalAppStatus,                                                                                             String diagnostics,                                                                                             String url) getFinalApplicationStatus @InterfaceAudience.Public @InterfaceStability.Stable public abstract FinalApplicationStatus getFinalApplicationStatus() Get final state of the ApplicationMaster. Returns:final state of the ApplicationMaster setFinalApplicationStatus @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setFinalApplicationStatus(FinalApplicationStatus finalState) Set the final state of the ApplicationMaster Parameters:finalState - final state of the ApplicationMaster getDiagnostics @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getDiagnostics() Get diagnostic information on application failure. Returns:diagnostic information on application failure setDiagnostics @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setDiagnostics(String diagnostics) Set diagnostic information on application failure. Parameters:diagnostics - diagnostic information on application failure getTrackingUrl @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getTrackingUrl() Get the tracking URL for the ApplicationMaster.  This url if contains scheme then that will be used by resource manager  web application proxy otherwise it will default to http. Returns:tracking URLfor the ApplicationMaster setTrackingUrl @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setTrackingUrl(String url) Set the final tracking URLfor the ApplicationMaster.  This is the web-URL to which ResourceManager or web-application proxy will  redirect client/users once the application is finished and the  ApplicationMaster is gone.    If the passed url has a scheme then that will be used by the  ResourceManager and web-application proxy, otherwise the scheme will  default to http.      Empty, null, "N/A" strings are all valid besides a real URL. In case an url  isn't explicitly passed, it defaults to "N/A" on the ResourceManager.   Parameters:url - tracking URLfor the ApplicationMaster Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FinishApplicationMasterResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FinishApplicationMasterResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class FinishApplicationMasterResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class FinishApplicationMasterResponse extends Object The response sent by the ResourceManager to a  ApplicationMaster on it's completion.    The response, includes:    A flag which indicates that the application has successfully unregistered  with the RM and the application can safely stop.      Note: The flag indicates whether the application has successfully  unregistered and is safe to stop. The application may stop after the flag is  true. If the application stops before the flag is true then the RM may retry  the application. See Also:ApplicationMasterProtocol.finishApplicationMaster(FinishApplicationMasterRequest) Constructor Summary Constructors  Constructor and Description FinishApplicationMasterResponse()  Method Summary Methods  Modifier and Type Method and Description abstract boolean getIsUnregistered() Get the flag which indicates that the application has successfully  unregistered with the RM and the application can safely stop. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail FinishApplicationMasterResponse public FinishApplicationMasterResponse() Method Detail getIsUnregistered @InterfaceAudience.Public @InterfaceStability.Stable public abstract boolean getIsUnregistered() Get the flag which indicates that the application has successfully  unregistered with the RM and the application can safely stop. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FixedLengthInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FixedLengthInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class FixedLengthInputFormat java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<LongWritable,BytesWritable> org.apache.hadoop.mapreduce.lib.input.FixedLengthInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class FixedLengthInputFormat extends FileInputFormat<LongWritable,BytesWritable> FixedLengthInputFormat is an input format used to read input files  which contain fixed length records.  The content of a record need not be  text.  It can be arbitrary binary data.  Users must configure the record  length property by calling:  FixedLengthInputFormat.setRecordLength(conf, recordLength); or  conf.setInt(FixedLengthInputFormat.FIXED_RECORD_LENGTH, recordLength);   See Also:FixedLengthRecordReader Field Summary Fields  Modifier and Type Field and Description static String FIXED_RECORD_LENGTH  Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description FixedLengthInputFormat()  Method Summary Methods  Modifier and Type Method and Description RecordReader<LongWritable,BytesWritable> createRecordReader(InputSplit split,                                     TaskAttemptContext context) Create a record reader for a given split. static int getRecordLength(Configuration conf) Get record length value protected boolean isSplitable(JobContext context,                       Path file) Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be. static void setRecordLength(Configuration conf,                               int recordLength) Set the length of each record Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getFormatMinSplitSize, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, getSplits, listStatus, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail FIXED_RECORD_LENGTH public static final String FIXED_RECORD_LENGTH See Also:Constant Field Values Constructor Detail FixedLengthInputFormat public FixedLengthInputFormat() Method Detail setRecordLength public static void setRecordLength(Configuration conf,                    int recordLength) Set the length of each record Parameters:conf - configurationrecordLength - the length of a record getRecordLength public static int getRecordLength(Configuration conf) Get record length value Parameters:conf - configuration Returns:the record length, zero means none was set createRecordReader public RecordReader<LongWritable,BytesWritable> createRecordReader(InputSplit split,                                                           TaskAttemptContext context)                                                             throws IOException,                                                                    InterruptedException Description copied from class: InputFormat Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Specified by: createRecordReader in class InputFormat<LongWritable,BytesWritable> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException InterruptedException isSplitable protected boolean isSplitable(JobContext context,                   Path file) Description copied from class: FileInputFormat Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be.    FileInputFormat implementations can override this and return  false to ensure that individual input files are never split-up  so that Mappers process entire files. Overrides: isSplitable in class FileInputFormat<LongWritable,BytesWritable> Parameters:context - the job contextfile - the file name to check Returns:is this file splitable? Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FloatSplitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FloatSplitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class FloatSplitter java.lang.Object org.apache.hadoop.mapreduce.lib.db.FloatSplitter All Implemented Interfaces: DBSplitter @InterfaceAudience.Public @InterfaceStability.Evolving public class FloatSplitter extends Object implements DBSplitter Implement DBSplitter over floating-point values. Constructor Summary Constructors  Constructor and Description FloatSplitter()  Method Summary Methods  Modifier and Type Method and Description List<InputSplit> split(Configuration conf,           ResultSet results,           String colName) Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail FloatSplitter public FloatSplitter() Method Detail split public List<InputSplit> split(Configuration conf,                      ResultSet results,                      String colName)                        throws SQLException Description copied from interface: DBSplitter Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Specified by: split in interface DBSplitter Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FloatWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FloatWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class FloatWritable java.lang.Object org.apache.hadoop.io.FloatWritable All Implemented Interfaces: Comparable<FloatWritable>, Writable, WritableComparable<FloatWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class FloatWritable extends Object implements WritableComparable<FloatWritable> A WritableComparable for floats. Constructor Summary Constructors  Constructor and Description FloatWritable()  FloatWritable(float value)  Method Summary Methods  Modifier and Type Method and Description int compareTo(FloatWritable o) Compares two FloatWritables. boolean equals(Object o) Returns true iff o is a FloatWritable with the same value. float get() Return the value of this FloatWritable. int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(float value) Set the value of this FloatWritable. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail FloatWritable public FloatWritable() FloatWritable public FloatWritable(float value) Method Detail set public void set(float value) Set the value of this FloatWritable. get public float get() Return the value of this FloatWritable. readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object o) Returns true iff o is a FloatWritable with the same value. Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(FloatWritable o) Compares two FloatWritables. Specified by: compareTo in interface Comparable<FloatWritable> toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FsAction (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FsAction (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.fs.permission Enum FsAction java.lang.Object java.lang.Enum<FsAction> org.apache.hadoop.fs.permission.FsAction All Implemented Interfaces: Serializable, Comparable<FsAction> @InterfaceAudience.Public @InterfaceStability.Stable public enum FsAction extends Enum<FsAction> File system actions, e.g. read, write, etc. Enum Constant Summary Enum Constants  Enum Constant and Description ALL  EXECUTE  NONE  READ  READ_EXECUTE  READ_WRITE  WRITE  WRITE_EXECUTE  Field Summary Fields  Modifier and Type Field and Description String SYMBOL Symbolic representation Method Summary Methods  Modifier and Type Method and Description FsAction and(FsAction that) AND operation. static FsAction getFsAction(String permission) Get the FsAction enum for String representation of permissions boolean implies(FsAction that) Return true if this action implies that action. FsAction not() NOT operation. FsAction or(FsAction that) OR operation. static FsAction valueOf(String name) Returns the enum constant of this type with the specified name. static FsAction[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail NONE public static final FsAction NONE EXECUTE public static final FsAction EXECUTE WRITE public static final FsAction WRITE WRITE_EXECUTE public static final FsAction WRITE_EXECUTE READ public static final FsAction READ READ_EXECUTE public static final FsAction READ_EXECUTE READ_WRITE public static final FsAction READ_WRITE ALL public static final FsAction ALL Field Detail SYMBOL public final String SYMBOL Symbolic representation Method Detail values public static FsAction[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (FsAction c : FsAction.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static FsAction valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null implies public boolean implies(FsAction that) Return true if this action implies that action. Parameters:that -  and public FsAction and(FsAction that) AND operation. or public FsAction or(FsAction that) OR operation. not public FsAction not() NOT operation. getFsAction public static FsAction getFsAction(String permission) Get the FsAction enum for String representation of permissions Parameters:permission - 3-character string representation of permission. ex: rwx Returns:Returns FsAction enum if the corresponding FsAction exists for permission.          Otherwise returns null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FsConstants (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FsConstants (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Interface FsConstants @InterfaceAudience.Public @InterfaceStability.Stable public interface FsConstants FileSystem related constants. Field Summary Fields  Modifier and Type Field and Description static String FTP_SCHEME  static URI LOCAL_FS_URI  static int MAX_PATH_LINKS  static String VIEWFS_SCHEME  static URI VIEWFS_URI ViewFs: viewFs file system (ie the mount file system on client side) Field Detail LOCAL_FS_URI static final URI LOCAL_FS_URI FTP_SCHEME static final String FTP_SCHEME See Also:Constant Field Values MAX_PATH_LINKS static final int MAX_PATH_LINKS See Also:Constant Field Values VIEWFS_URI static final URI VIEWFS_URI ViewFs: viewFs file system (ie the mount file system on client side) VIEWFS_SCHEME static final String VIEWFS_SCHEME See Also:Constant Field Values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FsPermission (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FsPermission (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.permission Class FsPermission java.lang.Object org.apache.hadoop.fs.permission.FsPermission All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class FsPermission extends Object implements Writable A class for file/directory permissions. Field Summary Fields  Modifier and Type Field and Description static int DEFAULT_UMASK  static String DEPRECATED_UMASK_LABEL umask property label deprecated key and code in getUMask method   to accommodate it may be removed in version .23 static int MAX_PERMISSION_LENGTH Maximum acceptable length of a permission string to parse static String UMASK_LABEL  Constructor Summary Constructors  Constructor and Description FsPermission(FsAction u,                         FsAction g,                         FsAction o) Construct by the given FsAction. FsPermission(FsAction u,                         FsAction g,                         FsAction o,                         boolean sb)  FsPermission(FsPermission other) Copy constructor FsPermission(short mode) Construct by the given mode. FsPermission(String mode) Construct by given mode, either in octal or symbolic format. Method Summary Methods  Modifier and Type Method and Description FsPermission applyUMask(FsPermission umask) Apply a umask to this permission and return a new one. static FsPermission createImmutable(short permission) Create an immutable FsPermission object. boolean equals(Object obj)  void fromShort(short n)  boolean getAclBit() Returns true if there is also an ACL (access control list). static FsPermission getCachePoolDefault() Get the default permission for cache pools. static FsPermission getDefault() Get the default permission for directory and symlink. static FsPermission getDirDefault() Get the default permission for directory. boolean getEncryptedBit() Returns true if the file is encrypted or directory is in an encryption zone static FsPermission getFileDefault() Get the default permission for file. FsAction getGroupAction() Return group FsAction. FsAction getOtherAction() Return other FsAction. boolean getStickyBit()  static FsPermission getUMask(Configuration conf) Get the user file creation mask (umask)    UMASK_LABEL config param has umask value that is either symbolic   or octal. FsAction getUserAction() Return user FsAction. int hashCode()  static FsPermission read(DataInput in) Create and initialize a FsPermission from DataInput. void readFields(DataInput in) Deserialize the fields of this object from in. static void setUMask(Configuration conf,                 FsPermission umask) Set the user file creation mask (umask) short toExtendedShort() Encodes the object to a short. short toShort() Encode the object to a short. String toString()  static FsPermission valueOf(String unixSymbolicPermission) Create a FsPermission from a Unix symbolic permission string void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail MAX_PERMISSION_LENGTH public static final int MAX_PERMISSION_LENGTH Maximum acceptable length of a permission string to parse See Also:Constant Field Values DEPRECATED_UMASK_LABEL public static final String DEPRECATED_UMASK_LABEL umask property label deprecated key and code in getUMask method   to accommodate it may be removed in version .23 See Also:Constant Field Values UMASK_LABEL public static final String UMASK_LABEL See Also:Constant Field Values DEFAULT_UMASK public static final int DEFAULT_UMASK See Also:Constant Field Values Constructor Detail FsPermission public FsPermission(FsAction u,             FsAction g,             FsAction o) Construct by the given FsAction. Parameters:u - user actiong - group actiono - other action FsPermission public FsPermission(FsAction u,             FsAction g,             FsAction o,             boolean sb) FsPermission public FsPermission(short mode) Construct by the given mode. Parameters:mode - See Also:toShort() FsPermission public FsPermission(FsPermission other) Copy constructor Parameters:other - other permission FsPermission public FsPermission(String mode) Construct by given mode, either in octal or symbolic format. Parameters:mode - mode as a string, either in octal or symbolic format Throws: IllegalArgumentException - if mode is invalid Method Detail createImmutable public static FsPermission createImmutable(short permission) Create an immutable FsPermission object. getUserAction public FsAction getUserAction() Return user FsAction. getGroupAction public FsAction getGroupAction() Return group FsAction. getOtherAction public FsAction getOtherAction() Return other FsAction. fromShort public void fromShort(short n) write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException read public static FsPermission read(DataInput in)                          throws IOException Create and initialize a FsPermission from DataInput. Throws: IOException toShort public short toShort() Encode the object to a short. toExtendedShort public short toExtendedShort() Encodes the object to a short.  Unlike toShort(), this method may  return values outside the fixed range 00000 - 01777 if extended features  are encoded into this permission, such as the ACL bit. Returns:short extended short representation of this permission equals public boolean equals(Object obj) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object toString public String toString() Overrides: toString in class Object applyUMask public FsPermission applyUMask(FsPermission umask) Apply a umask to this permission and return a new one.  The umask is used by create, mkdir, and other Hadoop filesystem operations.  The mode argument for these operations is modified by removing the bits  which are set in the umask.  Thus, the umask limits the permissions which  newly created files and directories get. Parameters:umask - The umask to use Returns:The effective permission getUMask public static FsPermission getUMask(Configuration conf) Get the user file creation mask (umask)    UMASK_LABEL config param has umask value that is either symbolic   or octal.    Symbolic umask is applied relative to file mode creation mask;   the permission op characters '+' clears the corresponding bit in the mask,   '-' sets bits in the mask.    Octal umask, the specified bits are set in the file mode creation mask.    DEPRECATED_UMASK_LABEL config param has umask value set to decimal. getStickyBit public boolean getStickyBit() getAclBit public boolean getAclBit() Returns true if there is also an ACL (access control list). Returns:boolean true if there is also an ACL (access control list). getEncryptedBit public boolean getEncryptedBit() Returns true if the file is encrypted or directory is in an encryption zone setUMask public static void setUMask(Configuration conf,             FsPermission umask) Set the user file creation mask (umask) getDefault public static FsPermission getDefault() Get the default permission for directory and symlink.  In previous versions, this default permission was also used to  create files, so files created end up with ugo+x permission.  See HADOOP-9155 for detail.   Two new methods are added to solve this, please use   getDirDefault() for directory, and use  getFileDefault() for file.  This method is kept for compatibility. getDirDefault public static FsPermission getDirDefault() Get the default permission for directory. getFileDefault public static FsPermission getFileDefault() Get the default permission for file. getCachePoolDefault public static FsPermission getCachePoolDefault() Get the default permission for cache pools. valueOf public static FsPermission valueOf(String unixSymbolicPermission) Create a FsPermission from a Unix symbolic permission string Parameters:unixSymbolicPermission - e.g. "-rw-rw-rw-" Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FsServerDefaults (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FsServerDefaults (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FsServerDefaults java.lang.Object org.apache.hadoop.fs.FsServerDefaults All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class FsServerDefaults extends Object implements Writable Provides server default configuration values to clients. Constructor Summary Constructors  Constructor and Description FsServerDefaults()  FsServerDefaults(long blockSize,                                 int bytesPerChecksum,                                 int writePacketSize,                                 short replication,                                 int fileBufferSize,                                 boolean encryptDataTransfer,                                 long trashInterval,                                 org.apache.hadoop.util.DataChecksum.Type checksumType)  Method Summary Methods  Modifier and Type Method and Description long getBlockSize()  int getBytesPerChecksum()  org.apache.hadoop.util.DataChecksum.Type getChecksumType()  boolean getEncryptDataTransfer()  int getFileBufferSize()  short getReplication()  long getTrashInterval()  int getWritePacketSize()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail FsServerDefaults public FsServerDefaults() FsServerDefaults public FsServerDefaults(long blockSize,                 int bytesPerChecksum,                 int writePacketSize,                 short replication,                 int fileBufferSize,                 boolean encryptDataTransfer,                 long trashInterval,                 org.apache.hadoop.util.DataChecksum.Type checksumType) Method Detail getBlockSize public long getBlockSize() getBytesPerChecksum public int getBytesPerChecksum() getWritePacketSize public int getWritePacketSize() getReplication public short getReplication() getFileBufferSize public int getFileBufferSize() getEncryptDataTransfer public boolean getEncryptDataTransfer() getTrashInterval public long getTrashInterval() getChecksumType public org.apache.hadoop.util.DataChecksum.Type getChecksumType() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  FsStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="FsStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class FsStatus java.lang.Object org.apache.hadoop.fs.FsStatus All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class FsStatus extends Object implements Writable This class is used to represent the capacity, free and used space on a  FileSystem. Constructor Summary Constructors  Constructor and Description FsStatus(long capacity,                 long used,                 long remaining) Construct a FsStatus object, using the specified statistics Method Summary Methods  Modifier and Type Method and Description long getCapacity() Return the capacity in bytes of the file system long getRemaining() Return the number of remaining bytes on the file system long getUsed() Return the number of bytes used on the file system void readFields(DataInput in) Deserialize the fields of this object from in. void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail FsStatus public FsStatus(long capacity,         long used,         long remaining) Construct a FsStatus object, using the specified statistics Method Detail getCapacity public long getCapacity() Return the capacity in bytes of the file system getUsed public long getUsed() Return the number of bytes used on the file system getRemaining public long getRemaining() Return the number of remaining bytes on the file system write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GangliaContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GangliaContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.ganglia Class GangliaContext java.lang.Object org.apache.hadoop.metrics.spi.AbstractMetricsContext org.apache.hadoop.metrics.ganglia.GangliaContext All Implemented Interfaces: org.apache.hadoop.metrics.MetricsContext @InterfaceAudience.Public @InterfaceStability.Evolving public class GangliaContext extends AbstractMetricsContext Context for sending metrics to Ganglia. Field Summary Fields  Modifier and Type Field and Description protected byte[] buffer  protected DatagramSocket datagramSocket  protected List<? extends SocketAddress> metricsServers  protected int offset  Fields inherited from interface org.apache.hadoop.metrics.MetricsContext DEFAULT_PERIOD Constructor Summary Constructors  Constructor and Description GangliaContext() Creates a new instance of GangliaContext Method Summary Methods  Modifier and Type Method and Description void close() method to close the datagram socket protected void emitMetric(String name,                     String type,                     String value)  protected int getDmax(String metricName)  protected int getSlope(String metricName)  protected int getTmax(String metricName)  protected String getUnits(String metricName)  protected void xdr_int(int i) Puts an integer into the buffer as 4 bytes, big-endian. protected void xdr_string(String s) Puts a string into the buffer by first writing the size of the string  as an int, followed by the bytes of the string, padded if necessary to  a multiple of 4. Methods inherited from class org.apache.hadoop.metrics.spi.AbstractMetricsContext createRecord, flush, getAllRecords, getAttribute, getAttributeTable, getContextFactory, getContextName, getPeriod, isMonitoring, newRecord, parseAndSetPeriod, registerUpdater, remove, setPeriod, startMonitoring, stopMonitoring, unregisterUpdater, update Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail buffer protected byte[] buffer offset protected int offset metricsServers protected List<? extends SocketAddress> metricsServers datagramSocket protected DatagramSocket datagramSocket Constructor Detail GangliaContext @InterfaceAudience.Private public GangliaContext() Creates a new instance of GangliaContext Method Detail close public void close() method to close the datagram socket Specified by: close in interface org.apache.hadoop.metrics.MetricsContext Overrides: close in class AbstractMetricsContext emitMetric protected void emitMetric(String name,               String type,               String value)                    throws IOException Throws: IOException getUnits protected String getUnits(String metricName) getSlope protected int getSlope(String metricName) getTmax protected int getTmax(String metricName) getDmax protected int getDmax(String metricName) xdr_string protected void xdr_string(String s) Puts a string into the buffer by first writing the size of the string  as an int, followed by the bytes of the string, padded if necessary to  a multiple of 4. xdr_int protected void xdr_int(int i) Puts an integer into the buffer as 4 bytes, big-endian. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GenericWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GenericWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class GenericWritable java.lang.Object org.apache.hadoop.io.GenericWritable All Implemented Interfaces: Configurable, Writable @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GenericWritable extends Object implements Writable, Configurable A wrapper for Writable instances.    When two sequence files, which have same Key type but different Value  types, are mapped out to reduce, multiple Value types is not allowed.  In this case, this class can help you wrap instances with different types.        Compared with ObjectWritable, this class is much more effective,  because ObjectWritable will append the class declaration as a String   into the output file in every Key-Value pair.        Generic Writable implements Configurable interface, so that it will be   configured by the framework. The configuration is passed to the wrapped objects  implementing Configurable interface before deserialization.       how to use it:   1. Write your own class, such as GenericObject, which extends GenericWritable.   2. Implements the abstract method getTypes(), defines      the classes which will be wrapped in GenericObject in application.     Attention: this classes defined in getTypes() method, must     implement Writable interface.      The code looks like this:    public class GenericObject extends GenericWritable {      private static Class[] CLASSES = {                ClassType1.class,                 ClassType2.class,                ClassType3.class,                };    protected Class[] getTypes() {        return CLASSES;    }  }   Since:   Nov 8, 2006 Constructor Summary Constructors  Constructor and Description GenericWritable()  Method Summary Methods  Modifier and Type Method and Description Writable get() Return the wrapped instance. Configuration getConf() Return the configuration used by this object. protected abstract Class<? extends Writable>[] getTypes() Return all classes that may be wrapped. void readFields(DataInput in) Deserialize the fields of this object from in. void set(Writable obj) Set the instance that is wrapped. void setConf(Configuration conf) Set the configuration to be used by this object. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail GenericWritable public GenericWritable() Method Detail set public void set(Writable obj) Set the instance that is wrapped. Parameters:obj -  get public Writable get() Return the wrapped instance. toString public String toString() Overrides: toString in class Object readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException getTypes protected abstract Class<? extends Writable>[] getTypes() Return all classes that may be wrapped.  Subclasses should implement this  to return a constant array of classes. getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetApplicationAttemptReportRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetApplicationAttemptReportRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetApplicationAttemptReportRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class GetApplicationAttemptReportRequest extends Object  The request sent by a client to the ResourceManager to get an  ApplicationAttemptReport for an application attempt.        The request should include the ApplicationAttemptId of the  application attempt.   See Also:ApplicationAttemptReport,  ApplicationBaseProtocol.getApplicationAttemptReport(GetApplicationAttemptReportRequest) Constructor Summary Constructors  Constructor and Description GetApplicationAttemptReportRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationAttemptId getApplicationAttemptId() Get the ApplicationAttemptId of an application attempt. static GetApplicationAttemptReportRequest newInstance(ApplicationAttemptId applicationAttemptId)  abstract void setApplicationAttemptId(ApplicationAttemptId applicationAttemptId) Set the ApplicationAttemptId of an application attempt Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetApplicationAttemptReportRequest public GetApplicationAttemptReportRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static GetApplicationAttemptReportRequest newInstance(ApplicationAttemptId applicationAttemptId) getApplicationAttemptId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ApplicationAttemptId getApplicationAttemptId() Get the ApplicationAttemptId of an application attempt. Returns:ApplicationAttemptId of an application attempt setApplicationAttemptId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setApplicationAttemptId(ApplicationAttemptId applicationAttemptId) Set the ApplicationAttemptId of an application attempt Parameters:applicationAttemptId - ApplicationAttemptId of an application attempt Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetApplicationAttemptReportResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetApplicationAttemptReportResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetApplicationAttemptReportResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class GetApplicationAttemptReportResponse extends Object  The response sent by the ResourceManager to a client requesting  an application attempt report.        The response includes an ApplicationAttemptReport which has the  details about the particular application attempt   See Also:ApplicationAttemptReport,  ApplicationBaseProtocol.getApplicationAttemptReport(GetApplicationAttemptReportRequest) Constructor Summary Constructors  Constructor and Description GetApplicationAttemptReportResponse()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationAttemptReport getApplicationAttemptReport() Get the ApplicationAttemptReport for the application attempt. static GetApplicationAttemptReportResponse newInstance(ApplicationAttemptReport ApplicationAttemptReport)  abstract void setApplicationAttemptReport(ApplicationAttemptReport applicationAttemptReport) Get the ApplicationAttemptReport for the application attempt. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetApplicationAttemptReportResponse public GetApplicationAttemptReportResponse() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static GetApplicationAttemptReportResponse newInstance(ApplicationAttemptReport ApplicationAttemptReport) getApplicationAttemptReport @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ApplicationAttemptReport getApplicationAttemptReport() Get the ApplicationAttemptReport for the application attempt. Returns:ApplicationAttemptReport for the application attempt setApplicationAttemptReport @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setApplicationAttemptReport(ApplicationAttemptReport applicationAttemptReport) Get the ApplicationAttemptReport for the application attempt. Parameters:applicationAttemptReport - ApplicationAttemptReport for the application attempt Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetApplicationAttemptsRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetApplicationAttemptsRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetApplicationAttemptsRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class GetApplicationAttemptsRequest extends Object  The request from clients to get a list of application attempt reports of an  application from the ResourceManager.   See Also:ApplicationBaseProtocol.getApplicationAttempts(GetApplicationAttemptsRequest) Constructor Summary Constructors  Constructor and Description GetApplicationAttemptsRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationId getApplicationId() Get the ApplicationId of an application static GetApplicationAttemptsRequest newInstance(ApplicationId applicationId)  abstract void setApplicationId(ApplicationId applicationId) Set the ApplicationId of an application Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetApplicationAttemptsRequest public GetApplicationAttemptsRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static GetApplicationAttemptsRequest newInstance(ApplicationId applicationId) getApplicationId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ApplicationId getApplicationId() Get the ApplicationId of an application Returns:ApplicationId of an application setApplicationId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setApplicationId(ApplicationId applicationId) Set the ApplicationId of an application Parameters:applicationId - ApplicationId of an application Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetApplicationAttemptsResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetApplicationAttemptsResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetApplicationAttemptsResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class GetApplicationAttemptsResponse extends Object  The response sent by the ResourceManager to a client requesting  a list of ApplicationAttemptReport for application attempts.        The ApplicationAttemptReport for each application includes the  details of an application attempt.   See Also:ApplicationAttemptReport,  ApplicationBaseProtocol.getApplicationAttempts(GetApplicationAttemptsRequest) Constructor Summary Constructors  Constructor and Description GetApplicationAttemptsResponse()  Method Summary Methods  Modifier and Type Method and Description abstract List<ApplicationAttemptReport> getApplicationAttemptList() Get a list of ApplicationReport of an application. static GetApplicationAttemptsResponse newInstance(List<ApplicationAttemptReport> applicationAttempts)  abstract void setApplicationAttemptList(List<ApplicationAttemptReport> applicationAttempts) Get a list of ApplicationReport of an application. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetApplicationAttemptsResponse public GetApplicationAttemptsResponse() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static GetApplicationAttemptsResponse newInstance(List<ApplicationAttemptReport> applicationAttempts) getApplicationAttemptList @InterfaceAudience.Public @InterfaceStability.Unstable public abstract List<ApplicationAttemptReport> getApplicationAttemptList() Get a list of ApplicationReport of an application. Returns:a list of ApplicationReport of an application setApplicationAttemptList @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setApplicationAttemptList(List<ApplicationAttemptReport> applicationAttempts) Get a list of ApplicationReport of an application. Parameters:applicationAttempts - a list of ApplicationReport of an application Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetApplicationReportRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetApplicationReportRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetApplicationReportRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetApplicationReportRequest extends Object The request sent by a client to the ResourceManager to   get an ApplicationReport for an application.    The request should include the ApplicationId of the   application. See Also:ApplicationBaseProtocol.getApplicationReport(GetApplicationReportRequest),  ApplicationReport Constructor Summary Constructors  Constructor and Description GetApplicationReportRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationId getApplicationId() Get the ApplicationId of the application. static GetApplicationReportRequest newInstance(ApplicationId applicationId)  abstract void setApplicationId(ApplicationId applicationId) Set the ApplicationId of the application Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetApplicationReportRequest public GetApplicationReportRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetApplicationReportRequest newInstance(ApplicationId applicationId) getApplicationId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationId getApplicationId() Get the ApplicationId of the application. Returns:ApplicationId of the application setApplicationId @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setApplicationId(ApplicationId applicationId) Set the ApplicationId of the application Parameters:applicationId - ApplicationId of the application Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetApplicationReportResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetApplicationReportResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetApplicationReportResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetApplicationReportResponse extends Object The response sent by the ResourceManager to a client  requesting an application report.    The response includes an ApplicationReport which has details such   as user, queue, name, host on which the ApplicationMaster is   running, RPC port, tracking URL, diagnostics, start time etc. See Also:ApplicationBaseProtocol.getApplicationReport(GetApplicationReportRequest) Constructor Summary Constructors  Constructor and Description GetApplicationReportResponse()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationReport getApplicationReport() Get the ApplicationReport for the application. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetApplicationReportResponse public GetApplicationReportResponse() Method Detail getApplicationReport @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationReport getApplicationReport() Get the ApplicationReport for the application. Returns:ApplicationReport for the application Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetApplicationsRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetApplicationsRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetApplicationsRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetApplicationsRequest extends Object The request from clients to get a report of Applications  in the cluster from the ResourceManager. See Also:ApplicationBaseProtocol.getApplications(GetApplicationsRequest) Constructor Summary Constructors  Constructor and Description GetApplicationsRequest()  Method Summary Methods  Modifier and Type Method and Description abstract EnumSet<YarnApplicationState> getApplicationStates() Get the application states to filter applications on abstract Set<String> getApplicationTypes() Get the application types to filter applications on static GetApplicationsRequest newInstance()  static GetApplicationsRequest newInstance(ApplicationsRequestScope scope)  The request from clients to get a report of Applications matching the  giving application types in the cluster from the  ResourceManager. static GetApplicationsRequest newInstance(ApplicationsRequestScope scope,                       Set<String> users,                       Set<String> queues,                       Set<String> applicationTypes,                       Set<String> applicationTags,                       EnumSet<YarnApplicationState> applicationStates,                       org.apache.commons.lang.math.LongRange startRange,                       org.apache.commons.lang.math.LongRange finishRange,                       Long limit)  The request from clients to get a report of Applications matching the  giving application types in the cluster from the  ResourceManager. static GetApplicationsRequest newInstance(EnumSet<YarnApplicationState> applicationStates)  The request from clients to get a report of Applications matching the  giving application states in the cluster from the  ResourceManager. static GetApplicationsRequest newInstance(Set<String> applicationTypes)  The request from clients to get a report of Applications matching the  giving application types in the cluster from the  ResourceManager. static GetApplicationsRequest newInstance(Set<String> applicationTypes,                       EnumSet<YarnApplicationState> applicationStates)  The request from clients to get a report of Applications matching the  giving and application types and application types in the cluster from the  ResourceManager. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetApplicationsRequest public GetApplicationsRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetApplicationsRequest newInstance() newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetApplicationsRequest newInstance(ApplicationsRequestScope scope,                                                                                     Set<String> users,                                                                                     Set<String> queues,                                                                                     Set<String> applicationTypes,                                                                                     Set<String> applicationTags,                                                                                     EnumSet<YarnApplicationState> applicationStates,                                                                                     org.apache.commons.lang.math.LongRange startRange,                                                                                     org.apache.commons.lang.math.LongRange finishRange,                                                                                     Long limit)  The request from clients to get a report of Applications matching the  giving application types in the cluster from the  ResourceManager.   Parameters:scope - ApplicationsRequestScope to filter byusers - list of users to filter byqueues - list of scheduler queues to filter byapplicationTypes - types of applicationsapplicationTags - application tags to filter byapplicationStates - application states to filter bystartRange - range of application start times to filter byfinishRange - range of application finish times to filter bylimit - number of applications to limit to Returns:GetApplicationsRequest to be used with  ApplicationBaseProtocol.getApplications(GetApplicationsRequest)See Also:Setting any of the parameters to null, would just disable that  filter newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetApplicationsRequest newInstance(ApplicationsRequestScope scope)  The request from clients to get a report of Applications matching the  giving application types in the cluster from the  ResourceManager.   Parameters:scope - ApplicationsRequestScope to filter bySee Also:ApplicationBaseProtocol.getApplications(GetApplicationsRequest) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetApplicationsRequest newInstance(Set<String> applicationTypes)  The request from clients to get a report of Applications matching the  giving application types in the cluster from the  ResourceManager.   See Also:ApplicationBaseProtocol.getApplications(GetApplicationsRequest) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetApplicationsRequest newInstance(EnumSet<YarnApplicationState> applicationStates)  The request from clients to get a report of Applications matching the  giving application states in the cluster from the  ResourceManager.   See Also:ApplicationBaseProtocol.getApplications(GetApplicationsRequest) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetApplicationsRequest newInstance(Set<String> applicationTypes,                                                                                     EnumSet<YarnApplicationState> applicationStates)  The request from clients to get a report of Applications matching the  giving and application types and application types in the cluster from the  ResourceManager.   See Also:ApplicationBaseProtocol.getApplications(GetApplicationsRequest) getApplicationTypes @InterfaceAudience.Public @InterfaceStability.Stable public abstract Set<String> getApplicationTypes() Get the application types to filter applications on Returns:Set of Application Types to filter on getApplicationStates @InterfaceAudience.Public @InterfaceStability.Stable public abstract EnumSet<YarnApplicationState> getApplicationStates() Get the application states to filter applications on Returns:Set of Application states to filter on Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetApplicationsResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetApplicationsResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetApplicationsResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetApplicationsResponse extends Object The response sent by the ResourceManager to a client  requesting an ApplicationReport for applications.  The ApplicationReport for each application includes details  such as user, queue, name, host on which the ApplicationMaster  is running, RPC port, tracking URL, diagnostics, start time etc. See Also:ApplicationReport,  ApplicationBaseProtocol.getApplications(GetApplicationsRequest) Constructor Summary Constructors  Constructor and Description GetApplicationsResponse()  Method Summary Methods  Modifier and Type Method and Description abstract List<ApplicationReport> getApplicationList() Get ApplicationReport for applications. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetApplicationsResponse public GetApplicationsResponse() Method Detail getApplicationList @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ApplicationReport> getApplicationList() Get ApplicationReport for applications. Returns:ApplicationReport for applications Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetClusterMetricsRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetClusterMetricsRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetClusterMetricsRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetClusterMetricsRequest extends Object The request sent by clients to get cluster metrics from the   ResourceManager.    Currently, this is empty. See Also:ApplicationClientProtocol.getClusterMetrics(GetClusterMetricsRequest) Constructor Summary Constructors  Constructor and Description GetClusterMetricsRequest()  Method Summary Methods  Modifier and Type Method and Description static GetClusterMetricsRequest newInstance()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetClusterMetricsRequest public GetClusterMetricsRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetClusterMetricsRequest newInstance() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetClusterMetricsResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetClusterMetricsResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetClusterMetricsResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetClusterMetricsResponse extends Object The response sent by the ResourceManager to a client  requesting cluster metrics. See Also:YarnClusterMetrics,  ApplicationClientProtocol.getClusterMetrics(GetClusterMetricsRequest) Constructor Summary Constructors  Constructor and Description GetClusterMetricsResponse()  Method Summary Methods  Modifier and Type Method and Description abstract YarnClusterMetrics getClusterMetrics() Get the YarnClusterMetrics for the cluster. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetClusterMetricsResponse public GetClusterMetricsResponse() Method Detail getClusterMetrics @InterfaceAudience.Public @InterfaceStability.Stable public abstract YarnClusterMetrics getClusterMetrics() Get the YarnClusterMetrics for the cluster. Returns:YarnClusterMetrics for the cluster Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetClusterNodeLabelsRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetClusterNodeLabelsRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetClusterNodeLabelsRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class GetClusterNodeLabelsRequest extends Object Constructor Summary Constructors  Constructor and Description GetClusterNodeLabelsRequest()  Method Summary Methods  Modifier and Type Method and Description static GetClusterNodeLabelsRequest newInstance()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetClusterNodeLabelsRequest public GetClusterNodeLabelsRequest() Method Detail newInstance public static GetClusterNodeLabelsRequest newInstance() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetClusterNodeLabelsResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetClusterNodeLabelsResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetClusterNodeLabelsResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class GetClusterNodeLabelsResponse extends Object Constructor Summary Constructors  Constructor and Description GetClusterNodeLabelsResponse()  Method Summary Methods  Modifier and Type Method and Description abstract Set<String> getNodeLabels()  static GetClusterNodeLabelsResponse newInstance(Set<String> labels)  abstract void setNodeLabels(Set<String> labels)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetClusterNodeLabelsResponse public GetClusterNodeLabelsResponse() Method Detail newInstance public static GetClusterNodeLabelsResponse newInstance(Set<String> labels) setNodeLabels @InterfaceAudience.Public @InterfaceStability.Evolving public abstract void setNodeLabels(Set<String> labels) getNodeLabels @InterfaceAudience.Public @InterfaceStability.Evolving public abstract Set<String> getNodeLabels() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetClusterNodesRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetClusterNodesRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetClusterNodesRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetClusterNodesRequest extends Object The request from clients to get a report of all nodes  in the cluster from the ResourceManager.  The request will ask for all nodes in the given NodeStates. See Also:ApplicationClientProtocol.getClusterNodes(GetClusterNodesRequest) Constructor Summary Constructors  Constructor and Description GetClusterNodesRequest()  Method Summary Methods  Modifier and Type Method and Description abstract EnumSet<NodeState> getNodeStates() The state to filter the cluster nodes with. static GetClusterNodesRequest newInstance()  static GetClusterNodesRequest newInstance(EnumSet<NodeState> states)  abstract void setNodeStates(EnumSet<NodeState> states) The state to filter the cluster nodes with. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetClusterNodesRequest public GetClusterNodesRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetClusterNodesRequest newInstance(EnumSet<NodeState> states) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetClusterNodesRequest newInstance() getNodeStates public abstract EnumSet<NodeState> getNodeStates() The state to filter the cluster nodes with. setNodeStates public abstract void setNodeStates(EnumSet<NodeState> states) The state to filter the cluster nodes with. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetClusterNodesResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetClusterNodesResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetClusterNodesResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetClusterNodesResponse extends Object The response sent by the ResourceManager to a client  requesting a NodeReport for all nodes.    The NodeReport contains per-node information such as   available resources, number of containers, tracking url, rack name, health  status etc. See Also:NodeReport,  ApplicationClientProtocol.getClusterNodes(GetClusterNodesRequest) Constructor Summary Constructors  Constructor and Description GetClusterNodesResponse()  Method Summary Methods  Modifier and Type Method and Description abstract List<NodeReport> getNodeReports() Get NodeReport for all nodes in the cluster. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetClusterNodesResponse public GetClusterNodesResponse() Method Detail getNodeReports @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<NodeReport> getNodeReports() Get NodeReport for all nodes in the cluster. Returns:NodeReport for all nodes in the cluster Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetContainerReportRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetContainerReportRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetContainerReportRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class GetContainerReportRequest extends Object  The request sent by a client to the ResourceManager to get an  ContainerReport for a container.   Constructor Summary Constructors  Constructor and Description GetContainerReportRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ContainerId getContainerId() Get the ContainerId of the Container. static GetContainerReportRequest newInstance(ContainerId containerId)  abstract void setContainerId(ContainerId containerId) Set the ContainerId of the container Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetContainerReportRequest public GetContainerReportRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static GetContainerReportRequest newInstance(ContainerId containerId) getContainerId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ContainerId getContainerId() Get the ContainerId of the Container. Returns:ContainerId of the Container setContainerId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setContainerId(ContainerId containerId) Set the ContainerId of the container Parameters:containerId - ContainerId of the container Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetContainerReportResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetContainerReportResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetContainerReportResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class GetContainerReportResponse extends Object  The response sent by the ResourceManager to a client requesting  a container report.        The response includes a ContainerReport which has details of a  container.   Constructor Summary Constructors  Constructor and Description GetContainerReportResponse()  Method Summary Methods  Modifier and Type Method and Description abstract ContainerReport getContainerReport() Get the ContainerReport for the container. static GetContainerReportResponse newInstance(ContainerReport containerReport)  abstract void setContainerReport(ContainerReport containerReport)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetContainerReportResponse public GetContainerReportResponse() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static GetContainerReportResponse newInstance(ContainerReport containerReport) getContainerReport @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ContainerReport getContainerReport() Get the ContainerReport for the container. Returns:ContainerReport for the container setContainerReport @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setContainerReport(ContainerReport containerReport) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetContainerStatusesRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetContainerStatusesRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetContainerStatusesRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetContainerStatusesRequest extends Object The request sent by the ApplicationMaster to the  NodeManager to get ContainerStatus of requested  containers. See Also:ContainerManagementProtocol.getContainerStatuses(GetContainerStatusesRequest) Constructor Summary Constructors  Constructor and Description GetContainerStatusesRequest()  Method Summary Methods  Modifier and Type Method and Description abstract List<ContainerId> getContainerIds() Get the list of ContainerIds of containers for which to obtain  the ContainerStatus. static GetContainerStatusesRequest newInstance(List<ContainerId> containerIds)  abstract void setContainerIds(List<ContainerId> containerIds) Set a list of ContainerIds of containers for which to obtain  the ContainerStatus Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetContainerStatusesRequest public GetContainerStatusesRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetContainerStatusesRequest newInstance(List<ContainerId> containerIds) getContainerIds @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ContainerId> getContainerIds() Get the list of ContainerIds of containers for which to obtain  the ContainerStatus. Returns:the list of ContainerIds of containers for which to          obtain the ContainerStatus. setContainerIds @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setContainerIds(List<ContainerId> containerIds) Set a list of ContainerIds of containers for which to obtain  the ContainerStatus Parameters:containerIds - a list of ContainerIds of containers for which to           obtain the ContainerStatus Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetContainerStatusesResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetContainerStatusesResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetContainerStatusesResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetContainerStatusesResponse extends Object The response sent by the NodeManager to the  ApplicationMaster when asked to obtain the  ContainerStatus of requested containers. See Also:ContainerManagementProtocol.getContainerStatuses(GetContainerStatusesRequest) Constructor Summary Constructors  Constructor and Description GetContainerStatusesResponse()  Method Summary Methods  Modifier and Type Method and Description abstract List<ContainerStatus> getContainerStatuses() Get the ContainerStatuses of the requested containers. abstract Map<ContainerId,org.apache.hadoop.yarn.api.records.SerializedException> getFailedRequests() Get the containerId-to-exception map in which the exception indicates error  from per container for failed requests Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetContainerStatusesResponse public GetContainerStatusesResponse() Method Detail getContainerStatuses @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ContainerStatus> getContainerStatuses() Get the ContainerStatuses of the requested containers. Returns:ContainerStatuses of the requested containers. getFailedRequests @InterfaceAudience.Public @InterfaceStability.Stable public abstract Map<ContainerId,org.apache.hadoop.yarn.api.records.SerializedException> getFailedRequests() Get the containerId-to-exception map in which the exception indicates error  from per container for failed requests Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetContainersRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetContainersRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetContainersRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class GetContainersRequest extends Object  The request from clients to get a list of container reports, which belong to  an application attempt from the ResourceManager.   See Also:ApplicationBaseProtocol.getContainers(GetContainersRequest) Constructor Summary Constructors  Constructor and Description GetContainersRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationAttemptId getApplicationAttemptId() Get the ApplicationAttemptId of an application attempt. static GetContainersRequest newInstance(ApplicationAttemptId applicationAttemptId)  abstract void setApplicationAttemptId(ApplicationAttemptId applicationAttemptId) Set the ApplicationAttemptId of an application attempt Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetContainersRequest public GetContainersRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static GetContainersRequest newInstance(ApplicationAttemptId applicationAttemptId) getApplicationAttemptId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ApplicationAttemptId getApplicationAttemptId() Get the ApplicationAttemptId of an application attempt. Returns:ApplicationAttemptId of an application attempt setApplicationAttemptId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setApplicationAttemptId(ApplicationAttemptId applicationAttemptId) Set the ApplicationAttemptId of an application attempt Parameters:applicationAttemptId - ApplicationAttemptId of an application attempt Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetContainersResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetContainersResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetContainersResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class GetContainersResponse extends Object  The response sent by the ResourceManager to a client requesting  a list of ContainerReport for containers.        The ContainerReport for each container includes the container  details.   See Also:ContainerReport,  ApplicationBaseProtocol.getContainers(GetContainersRequest) Constructor Summary Constructors  Constructor and Description GetContainersResponse()  Method Summary Methods  Modifier and Type Method and Description abstract List<ContainerReport> getContainerList() Get a list of ContainerReport for all the containers of an  application attempt. static GetContainersResponse newInstance(List<ContainerReport> containers)  abstract void setContainerList(List<ContainerReport> containers) Set a list of ContainerReport for all the containers of an  application attempt. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetContainersResponse public GetContainersResponse() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static GetContainersResponse newInstance(List<ContainerReport> containers) getContainerList @InterfaceAudience.Public @InterfaceStability.Unstable public abstract List<ContainerReport> getContainerList() Get a list of ContainerReport for all the containers of an  application attempt. Returns:a list of ContainerReport for all the containers of an          application attempt setContainerList @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setContainerList(List<ContainerReport> containers) Set a list of ContainerReport for all the containers of an  application attempt. Parameters:containers - a list of ContainerReport for all the containers of           an application attempt Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetDelegationTokenRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetDelegationTokenRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetDelegationTokenRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetDelegationTokenRequest extends Object The request issued by the client to get a delegation token from  the ResourceManager.  for more information. Constructor Summary Constructors  Constructor and Description GetDelegationTokenRequest()  Method Summary Methods  Modifier and Type Method and Description abstract String getRenewer()  static GetDelegationTokenRequest newInstance(String renewer)  abstract void setRenewer(String renewer)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetDelegationTokenRequest public GetDelegationTokenRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetDelegationTokenRequest newInstance(String renewer) getRenewer @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getRenewer() setRenewer @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setRenewer(String renewer) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetDelegationTokenResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetDelegationTokenResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetDelegationTokenResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetDelegationTokenResponse extends Object Response to a GetDelegationTokenRequest request   from the client. The response contains the token that   can be used by the containers to talk to  ClientRMService. Constructor Summary Constructors  Constructor and Description GetDelegationTokenResponse()  Method Summary Methods  Modifier and Type Method and Description abstract Token getRMDelegationToken() The Delegation tokens have a identifier which maps to  AbstractDelegationTokenIdentifier. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetDelegationTokenResponse public GetDelegationTokenResponse() Method Detail getRMDelegationToken @InterfaceAudience.Public @InterfaceStability.Stable public abstract Token getRMDelegationToken() The Delegation tokens have a identifier which maps to  AbstractDelegationTokenIdentifier. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetNewApplicationRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetNewApplicationRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetNewApplicationRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetNewApplicationRequest extends Object The request sent by clients to get a new ApplicationId for  submitting an application.    Currently, this is empty. See Also:ApplicationClientProtocol.getNewApplication(GetNewApplicationRequest) Constructor Summary Constructors  Constructor and Description GetNewApplicationRequest()  Method Summary Methods  Modifier and Type Method and Description static GetNewApplicationRequest newInstance()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetNewApplicationRequest public GetNewApplicationRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetNewApplicationRequest newInstance() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetNewApplicationResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetNewApplicationResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetNewApplicationResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetNewApplicationResponse extends Object The response sent by the ResourceManager to the client for   a request to get a new ApplicationId for submitting applications.    Clients can submit an application with the returned  ApplicationId. See Also:ApplicationClientProtocol.getNewApplication(GetNewApplicationRequest) Constructor Summary Constructors  Constructor and Description GetNewApplicationResponse()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationId getApplicationId() Get the new ApplicationId allocated by the   ResourceManager. abstract Resource getMaximumResourceCapability() Get the maximum capability for any Resource allocated by the   ResourceManager in the cluster. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetNewApplicationResponse public GetNewApplicationResponse() Method Detail getApplicationId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationId getApplicationId() Get the new ApplicationId allocated by the   ResourceManager. Returns:new ApplicationId allocated by the            ResourceManager getMaximumResourceCapability @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getMaximumResourceCapability() Get the maximum capability for any Resource allocated by the   ResourceManager in the cluster. Returns:maximum capability of allocated resources in the cluster Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetQueueInfoRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetQueueInfoRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetQueueInfoRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetQueueInfoRequest extends Object The request sent by clients to get queue information  from the ResourceManager. See Also:ApplicationClientProtocol.getQueueInfo(GetQueueInfoRequest) Constructor Summary Constructors  Constructor and Description GetQueueInfoRequest()  Method Summary Methods  Modifier and Type Method and Description abstract boolean getIncludeApplications() Is information about active applications required? abstract boolean getIncludeChildQueues() Is information about child queues required? abstract String getQueueName() Get the queue name for which to get queue information. abstract boolean getRecursive() Is information on the entire child queue hierarchy required? static GetQueueInfoRequest newInstance(String queueName,                       boolean includeApplications,                       boolean includeChildQueues,                       boolean recursive)  abstract void setIncludeApplications(boolean includeApplications) Should we get fetch information about active applications? abstract void setIncludeChildQueues(boolean includeChildQueues) Should we fetch information about child queues? abstract void setQueueName(String queueName) Set the queue name for which to get queue information abstract void setRecursive(boolean recursive) Should we fetch information on the entire child queue hierarchy? Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetQueueInfoRequest public GetQueueInfoRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetQueueInfoRequest newInstance(String queueName,                                                                                  boolean includeApplications,                                                                                  boolean includeChildQueues,                                                                                  boolean recursive) getQueueName @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getQueueName() Get the queue name for which to get queue information. Returns:queue name for which to get queue information setQueueName @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setQueueName(String queueName) Set the queue name for which to get queue information Parameters:queueName - queue name for which to get queue information getIncludeApplications @InterfaceAudience.Public @InterfaceStability.Stable public abstract boolean getIncludeApplications() Is information about active applications required? Returns:true if applications' information is to be included,          else false setIncludeApplications @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setIncludeApplications(boolean includeApplications) Should we get fetch information about active applications? Parameters:includeApplications - fetch information about active                              applications? getIncludeChildQueues @InterfaceAudience.Public @InterfaceStability.Stable public abstract boolean getIncludeChildQueues() Is information about child queues required? Returns:true if information about child queues is required,          else false setIncludeChildQueues @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setIncludeChildQueues(boolean includeChildQueues) Should we fetch information about child queues? Parameters:includeChildQueues - fetch information about child queues? getRecursive @InterfaceAudience.Public @InterfaceStability.Stable public abstract boolean getRecursive() Is information on the entire child queue hierarchy required? Returns:true if information about entire hierarchy is           required, false otherwise setRecursive @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setRecursive(boolean recursive) Should we fetch information on the entire child queue hierarchy? Parameters:recursive - fetch information on the entire child queue                    hierarchy? Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetQueueInfoResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetQueueInfoResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetQueueInfoResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetQueueInfoResponse extends Object The response sent by the ResourceManager to a client  requesting information about queues in the system.    The response includes a QueueInfo which has details such as  queue name, used/total capacities, running applications, child queues etc. See Also:QueueInfo,  ApplicationClientProtocol.getQueueInfo(GetQueueInfoRequest) Constructor Summary Constructors  Constructor and Description GetQueueInfoResponse()  Method Summary Methods  Modifier and Type Method and Description abstract QueueInfo getQueueInfo() Get the QueueInfo for the specified queue. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetQueueInfoResponse public GetQueueInfoResponse() Method Detail getQueueInfo @InterfaceAudience.Public @InterfaceStability.Stable public abstract QueueInfo getQueueInfo() Get the QueueInfo for the specified queue. Returns:QueueInfo for the specified queue Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetQueueUserAclsInfoRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetQueueUserAclsInfoRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetQueueUserAclsInfoRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetQueueUserAclsInfoRequest extends Object The request sent by clients to the ResourceManager to   get queue acls for the current user.  Currently, this is empty. See Also:ApplicationClientProtocol.getQueueUserAcls(GetQueueUserAclsInfoRequest) Constructor Summary Constructors  Constructor and Description GetQueueUserAclsInfoRequest()  Method Summary Methods  Modifier and Type Method and Description static GetQueueUserAclsInfoRequest newInstance()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetQueueUserAclsInfoRequest public GetQueueUserAclsInfoRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static GetQueueUserAclsInfoRequest newInstance() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GetQueueUserAclsInfoResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GetQueueUserAclsInfoResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class GetQueueUserAclsInfoResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class GetQueueUserAclsInfoResponse extends Object The response sent by the ResourceManager to clients  seeking queue acls for the user.  The response contains a list of QueueUserACLInfo which  provides information about QueueACL per queue. See Also:QueueACL,  QueueUserACLInfo,  ApplicationClientProtocol.getQueueUserAcls(GetQueueUserAclsInfoRequest) Constructor Summary Constructors  Constructor and Description GetQueueUserAclsInfoResponse()  Method Summary Methods  Modifier and Type Method and Description abstract List<QueueUserACLInfo> getUserAclsInfoList() Get the QueueUserACLInfo per queue for the user. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GetQueueUserAclsInfoResponse public GetQueueUserAclsInfoResponse() Method Detail getUserAclsInfoList @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<QueueUserACLInfo> getUserAclsInfoList() Get the QueueUserACLInfo per queue for the user. Returns:QueueUserACLInfo per queue for the user Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GlobFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GlobFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.filter Class GlobFilter java.lang.Object org.apache.hadoop.metrics2.MetricsFilter org.apache.hadoop.metrics2.filter.AbstractPatternFilter org.apache.hadoop.metrics2.filter.GlobFilter All Implemented Interfaces: MetricsPlugin @InterfaceAudience.Public @InterfaceStability.Evolving public class GlobFilter extends org.apache.hadoop.metrics2.filter.AbstractPatternFilter A glob pattern filter for metrics.  The class name is used in metrics config files Field Summary Fields inherited from class org.apache.hadoop.metrics2.filter.AbstractPatternFilter EXCLUDE_KEY, EXCLUDE_TAGS_KEY, INCLUDE_KEY, INCLUDE_TAGS_KEY Constructor Summary Constructors  Constructor and Description GlobFilter()  Method Summary Methods  Modifier and Type Method and Description protected Pattern compile(String s) Compile a string pattern in to a pattern object Methods inherited from class org.apache.hadoop.metrics2.filter.AbstractPatternFilter accepts, accepts, accepts, init Methods inherited from class org.apache.hadoop.metrics2.MetricsFilter accepts Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GlobFilter public GlobFilter() Method Detail compile protected Pattern compile(String s) Description copied from class: org.apache.hadoop.metrics2.filter.AbstractPatternFilter Compile a string pattern in to a pattern object Specified by: compile in class org.apache.hadoop.metrics2.filter.AbstractPatternFilter Parameters:s - the string pattern to compile Returns:the compiled pattern object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GraphiteSink (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GraphiteSink (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.sink Class GraphiteSink java.lang.Object org.apache.hadoop.metrics2.sink.GraphiteSink All Implemented Interfaces: Closeable, AutoCloseable, MetricsPlugin, MetricsSink @InterfaceAudience.Public @InterfaceStability.Evolving public class GraphiteSink extends Object implements MetricsSink, Closeable A metrics sink that writes to a Graphite server Constructor Summary Constructors  Constructor and Description GraphiteSink()  Method Summary Methods  Modifier and Type Method and Description void close()  void flush() Flush any buffered metrics void init(org.apache.commons.configuration.SubsetConfiguration conf) Initialize the plugin void putMetrics(MetricsRecord record) Put a metrics record in the sink Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GraphiteSink public GraphiteSink() Method Detail init public void init(org.apache.commons.configuration.SubsetConfiguration conf) Description copied from interface: MetricsPlugin Initialize the plugin Specified by: init in interface MetricsPlugin Parameters:conf - the configuration object for the plugin putMetrics public void putMetrics(MetricsRecord record) Description copied from interface: MetricsSink Put a metrics record in the sink Specified by: putMetrics in interface MetricsSink Parameters:record - the record to put flush public void flush() Description copied from interface: MetricsSink Flush any buffered metrics Specified by: flush in interface MetricsSink close public void close()            throws IOException Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GroupMappingServiceProvider (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GroupMappingServiceProvider (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.security Interface GroupMappingServiceProvider @InterfaceAudience.Public @InterfaceStability.Evolving public interface GroupMappingServiceProvider An interface for the implementation of a user-to-groups mapping service  used by Groups. Field Summary Fields  Modifier and Type Field and Description static String GROUP_MAPPING_CONFIG_PREFIX  Method Summary Methods  Modifier and Type Method and Description void cacheGroupsAdd(List<String> groups) Caches the group user information void cacheGroupsRefresh() Refresh the cache of groups and user mapping List<String> getGroups(String user) Get all various group memberships of a given user. Field Detail GROUP_MAPPING_CONFIG_PREFIX static final String GROUP_MAPPING_CONFIG_PREFIX See Also:Constant Field Values Method Detail getGroups List<String> getGroups(String user)                        throws IOException Get all various group memberships of a given user.  Returns EMPTY list in case of non-existing user Parameters:user - User's name Returns:group memberships of user Throws: IOException cacheGroupsRefresh void cacheGroupsRefresh()                         throws IOException Refresh the cache of groups and user mapping Throws: IOException cacheGroupsAdd void cacheGroupsAdd(List<String> groups)                     throws IOException Caches the group user information Parameters:groups - list of groups to add to cache Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  GzipCodec (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="GzipCodec (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class GzipCodec java.lang.Object org.apache.hadoop.io.compress.DefaultCodec org.apache.hadoop.io.compress.GzipCodec All Implemented Interfaces: Configurable, CompressionCodec, DirectDecompressionCodec @InterfaceAudience.Public @InterfaceStability.Evolving public class GzipCodec extends DefaultCodec This class creates gzip compressors/decompressors. Constructor Summary Constructors  Constructor and Description GzipCodec()  Method Summary Methods  Modifier and Type Method and Description Compressor createCompressor() Create a new Compressor for use by this CompressionCodec. Decompressor createDecompressor() Create a new Decompressor for use by this CompressionCodec. DirectDecompressor createDirectDecompressor() Create a new DirectDecompressor for use by this DirectDecompressionCodec. CompressionInputStream createInputStream(InputStream in) Create a CompressionInputStream that will read from the given  input stream. CompressionInputStream createInputStream(InputStream in,                                   Decompressor decompressor) Create a CompressionInputStream that will read from the given   InputStream with the given Decompressor. CompressionOutputStream createOutputStream(OutputStream out) Create a CompressionOutputStream that will write to the given   OutputStream. CompressionOutputStream createOutputStream(OutputStream out,                                     Compressor compressor) Create a CompressionOutputStream that will write to the given   OutputStream with the given Compressor. Class<? extends Compressor> getCompressorType() Get the type of Compressor needed by this CompressionCodec. Class<? extends Decompressor> getDecompressorType() Get the type of Decompressor needed by this CompressionCodec. String getDefaultExtension() Get the default filename extension for this kind of compression. Methods inherited from class org.apache.hadoop.io.compress.DefaultCodec getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail GzipCodec public GzipCodec() Method Detail createOutputStream public CompressionOutputStream createOutputStream(OutputStream out)                                            throws IOException Description copied from interface: CompressionCodec Create a CompressionOutputStream that will write to the given   OutputStream. Specified by: createOutputStream in interface CompressionCodec Overrides: createOutputStream in class DefaultCodec Parameters:out - the location for the final output stream Returns:a stream the user can write uncompressed data to have it compressed Throws: IOException createOutputStream public CompressionOutputStream createOutputStream(OutputStream out,                                          Compressor compressor)                                            throws IOException Description copied from interface: CompressionCodec Create a CompressionOutputStream that will write to the given   OutputStream with the given Compressor. Specified by: createOutputStream in interface CompressionCodec Overrides: createOutputStream in class DefaultCodec Parameters:out - the location for the final output streamcompressor - compressor to use Returns:a stream the user can write uncompressed data to have it compressed Throws: IOException createCompressor public Compressor createCompressor() Description copied from interface: CompressionCodec Create a new Compressor for use by this CompressionCodec. Specified by: createCompressor in interface CompressionCodec Overrides: createCompressor in class DefaultCodec Returns:a new compressor for use by this codec getCompressorType public Class<? extends Compressor> getCompressorType() Description copied from interface: CompressionCodec Get the type of Compressor needed by this CompressionCodec. Specified by: getCompressorType in interface CompressionCodec Overrides: getCompressorType in class DefaultCodec Returns:the type of compressor needed by this codec. createInputStream public CompressionInputStream createInputStream(InputStream in)                                          throws IOException Description copied from interface: CompressionCodec Create a CompressionInputStream that will read from the given  input stream. Specified by: createInputStream in interface CompressionCodec Overrides: createInputStream in class DefaultCodec Parameters:in - the stream to read compressed bytes from Returns:a stream to read uncompressed bytes from Throws: IOException createInputStream public CompressionInputStream createInputStream(InputStream in,                                        Decompressor decompressor)                                          throws IOException Description copied from interface: CompressionCodec Create a CompressionInputStream that will read from the given   InputStream with the given Decompressor. Specified by: createInputStream in interface CompressionCodec Overrides: createInputStream in class DefaultCodec Parameters:in - the stream to read compressed bytes fromdecompressor - decompressor to use Returns:a stream to read uncompressed bytes from Throws: IOException createDecompressor public Decompressor createDecompressor() Description copied from interface: CompressionCodec Create a new Decompressor for use by this CompressionCodec. Specified by: createDecompressor in interface CompressionCodec Overrides: createDecompressor in class DefaultCodec Returns:a new decompressor for use by this codec getDecompressorType public Class<? extends Decompressor> getDecompressorType() Description copied from interface: CompressionCodec Get the type of Decompressor needed by this CompressionCodec. Specified by: getDecompressorType in interface CompressionCodec Overrides: getDecompressorType in class DefaultCodec Returns:the type of decompressor needed by this codec. createDirectDecompressor public DirectDecompressor createDirectDecompressor() Description copied from class: DefaultCodec Create a new DirectDecompressor for use by this DirectDecompressionCodec. Specified by: createDirectDecompressor in interface DirectDecompressionCodec Overrides: createDirectDecompressor in class DefaultCodec Returns:a new direct decompressor for use by this codec getDefaultExtension public String getDefaultExtension() Description copied from interface: CompressionCodec Get the default filename extension for this kind of compression. Specified by: getDefaultExtension in interface CompressionCodec Overrides: getDefaultExtension in class DefaultCodec Returns:the extension including the '.' Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HAServiceProtocol (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HAServiceProtocol (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha Interface HAServiceProtocol @InterfaceAudience.Public @InterfaceStability.Evolving public interface HAServiceProtocol Protocol interface that provides High Availability related primitives to  monitor and fail-over the service.    This interface could be used by HA frameworks to manage the service. Field Summary Fields  Modifier and Type Field and Description static long versionID Initial version of the protocol Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.ha.HAServiceStatus getServiceStatus() Return the current status of the service. void monitorHealth() Monitor the health of service. void transitionToActive(org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo) Request service to transition to active state. void transitionToStandby(org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo) Request service to transition to standby state. Field Detail versionID static final long versionID Initial version of the protocol See Also:Constant Field Values Method Detail monitorHealth void monitorHealth()                    throws HealthCheckFailedException,                           org.apache.hadoop.security.AccessControlException,                           IOException Monitor the health of service. This periodically called by the HA  frameworks to monitor the health of the service.    Service is expected to perform checks to ensure it is functional.  If the service is not healthy due to failure or partial failure,  it is expected to throw HealthCheckFailedException.  The definition of service not healthy is left to the service.    Note that when health check of an Active service fails,  failover to standby may be done. Throws: HealthCheckFailedException - if the health check of a service fails. org.apache.hadoop.security.AccessControlException - if access is denied. IOException - if other errors happen transitionToActive void transitionToActive(org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo)                         throws ServiceFailedException,                                org.apache.hadoop.security.AccessControlException,                                IOException Request service to transition to active state. No operation, if the  service is already in active state. Throws: ServiceFailedException - if transition from standby to active fails. org.apache.hadoop.security.AccessControlException - if access is denied. IOException - if other errors happen transitionToStandby void transitionToStandby(org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo)                          throws ServiceFailedException,                                 org.apache.hadoop.security.AccessControlException,                                 IOException Request service to transition to standby state. No operation, if the  service is already in standby state. Throws: ServiceFailedException - if transition from active to standby fails. org.apache.hadoop.security.AccessControlException - if access is denied. IOException - if other errors happen getServiceStatus org.apache.hadoop.ha.HAServiceStatus getServiceStatus()                                                       throws org.apache.hadoop.security.AccessControlException,                                                              IOException Return the current status of the service. The status indicates  the current state (e.g ACTIVE/STANDBY) as well as  some additional information. HAServiceStatus Throws: org.apache.hadoop.security.AccessControlException - if access is denied. IOException - if other errors happen Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HAServiceProtocolHelper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HAServiceProtocolHelper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha Class HAServiceProtocolHelper java.lang.Object org.apache.hadoop.ha.HAServiceProtocolHelper @InterfaceAudience.Public @InterfaceStability.Evolving public class HAServiceProtocolHelper extends Object Helper for making HAServiceProtocol RPC calls. This helper  unwraps the RemoteException to specific exceptions. Constructor Summary Constructors  Constructor and Description HAServiceProtocolHelper()  Method Summary Methods  Modifier and Type Method and Description static void monitorHealth(HAServiceProtocol svc,                           org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo)  static void transitionToActive(HAServiceProtocol svc,                                     org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo)  static void transitionToStandby(HAServiceProtocol svc,                                       org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail HAServiceProtocolHelper public HAServiceProtocolHelper() Method Detail monitorHealth public static void monitorHealth(HAServiceProtocol svc,                  org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo)                           throws IOException Throws: IOException transitionToActive public static void transitionToActive(HAServiceProtocol svc,                       org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo)                                throws IOException Throws: IOException transitionToStandby public static void transitionToStandby(HAServiceProtocol svc,                        org.apache.hadoop.ha.HAServiceProtocol.StateChangeRequestInfo reqInfo)                                 throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HAServiceProtocolPB (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HAServiceProtocolPB (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha.protocolPB Interface HAServiceProtocolPB All Superinterfaces: org.apache.hadoop.ha.proto.HAServiceProtocolProtos.HAServiceProtocolService.BlockingInterface, org.apache.hadoop.ipc.VersionedProtocol @InterfaceAudience.Public @InterfaceStability.Evolving public interface HAServiceProtocolPB extends org.apache.hadoop.ha.proto.HAServiceProtocolProtos.HAServiceProtocolService.BlockingInterface, org.apache.hadoop.ipc.VersionedProtocol Method Summary Methods inherited from interface org.apache.hadoop.ha.proto.HAServiceProtocolProtos.HAServiceProtocolService.BlockingInterface getServiceStatus, monitorHealth, transitionToActive, transitionToStandby Methods inherited from interface org.apache.hadoop.ipc.VersionedProtocol getProtocolSignature, getProtocolVersion Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HAServiceTarget (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HAServiceTarget (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha Class HAServiceTarget java.lang.Object org.apache.hadoop.ha.HAServiceTarget @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class HAServiceTarget extends Object Represents a target of the client side HA administration commands. Constructor Summary Constructors  Constructor and Description HAServiceTarget()  Method Summary Methods  Modifier and Type Method and Description protected void addFencingParameters(Map<String,String> ret) Hook to allow subclasses to add any parameters they would like to  expose to fencing implementations/scripts. abstract void checkFencingConfigured()  abstract InetSocketAddress getAddress()  abstract org.apache.hadoop.ha.NodeFencer getFencer()  Map<String,String> getFencingParameters()  HAServiceProtocol getProxy(Configuration conf,                 int timeoutMs)  abstract InetSocketAddress getZKFCAddress()  org.apache.hadoop.ha.ZKFCProtocol getZKFCProxy(Configuration conf,                         int timeoutMs)  boolean isAutoFailoverEnabled()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail HAServiceTarget public HAServiceTarget() Method Detail getAddress public abstract InetSocketAddress getAddress() Returns:the IPC address of the target node. getZKFCAddress public abstract InetSocketAddress getZKFCAddress() Returns:the IPC address of the ZKFC on the target node getFencer public abstract org.apache.hadoop.ha.NodeFencer getFencer() Returns:a Fencer implementation configured for this target node checkFencingConfigured public abstract void checkFencingConfigured()                                      throws BadFencingConfigurationException Throws: BadFencingConfigurationException - if the fencing configuration  appears to be invalid. This is divorced from the above  getFencer() method so that the configuration can be checked  during the pre-flight phase of failover. getProxy public HAServiceProtocol getProxy(Configuration conf,                          int timeoutMs)                            throws IOException Returns:a proxy to connect to the target HA Service. Throws: IOException getZKFCProxy public org.apache.hadoop.ha.ZKFCProtocol getZKFCProxy(Configuration conf,                                              int timeoutMs)                                                throws IOException Returns:a proxy to the ZKFC which is associated with this HA service. Throws: IOException getFencingParameters public final Map<String,String> getFencingParameters() addFencingParameters protected void addFencingParameters(Map<String,String> ret) Hook to allow subclasses to add any parameters they would like to  expose to fencing implementations/scripts. Fencing methods are free  to use this map as they see fit -- notably, the shell script  implementation takes each entry, prepends 'target_', substitutes  '_' for '.', and adds it to the environment of the script.  Subclass implementations should be sure to delegate to the superclass  implementation as well as adding their own keys. Parameters:ret - map which can be mutated to pass parameters to the fencer isAutoFailoverEnabled public boolean isAutoFailoverEnabled() Returns:true if auto failover should be considered enabled Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HadoopIllegalArgumentException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HadoopIllegalArgumentException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop Class HadoopIllegalArgumentException java.lang.Object java.lang.Throwable java.lang.Exception java.lang.RuntimeException java.lang.IllegalArgumentException org.apache.hadoop.HadoopIllegalArgumentException All Implemented Interfaces: Serializable Direct Known Subclasses: InvalidPathException @InterfaceAudience.Public @InterfaceStability.Stable public class HadoopIllegalArgumentException extends IllegalArgumentException Indicates that a method has been passed illegal or invalid argument. This  exception is thrown instead of IllegalArgumentException to differentiate the  exception thrown in Hadoop implementation from the one thrown in JDK. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description HadoopIllegalArgumentException(String message) Constructs exception with the specified detail message. Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail HadoopIllegalArgumentException public HadoopIllegalArgumentException(String message) Constructs exception with the specified detail message. Parameters:message - detailed message. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HashFunction (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HashFunction (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util.bloom Class HashFunction java.lang.Object org.apache.hadoop.util.bloom.HashFunction @InterfaceAudience.Public @InterfaceStability.Stable public final class HashFunction extends Object Implements a hash object that returns a certain number of hashed values. See Also:The general behavior of a key being stored in a filter,  The general behavior of a filter Constructor Summary Constructors  Constructor and Description HashFunction(int maxValue,                         int nbHash,                         int hashType) Constructor. Method Summary Methods  Modifier and Type Method and Description void clear() Clears this hash function. int[] hash(org.apache.hadoop.util.bloom.Key k) Hashes a specified key into several integers. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail HashFunction public HashFunction(int maxValue,             int nbHash,             int hashType) Constructor.    Builds a hash function that must obey to a given maximum number of returned values and a highest value. Parameters:maxValue - The maximum highest returned value.nbHash - The number of resulting hashed values.hashType - type of the hashing function (see Hash). Method Detail clear public void clear() Clears this hash function. A NOOP hash public int[] hash(org.apache.hadoop.util.bloom.Key k) Hashes a specified key into several integers. Parameters:k - The specified key. Returns:The array of hashed values. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HashPartitioner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HashPartitioner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.partition Class HashPartitioner<K,V> java.lang.Object org.apache.hadoop.mapreduce.Partitioner<K,V> org.apache.hadoop.mapreduce.lib.partition.HashPartitioner<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class HashPartitioner<K,V> extends Partitioner<K,V> Partition keys by their Object.hashCode(). Constructor Summary Constructors  Constructor and Description HashPartitioner()  Method Summary Methods  Modifier and Type Method and Description int getPartition(K key,                         V value,                         int numReduceTasks) Use Object.hashCode() to partition. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail HashPartitioner public HashPartitioner() Method Detail getPartition public int getPartition(K key,                V value,                int numReduceTasks) Use Object.hashCode() to partition. Specified by: getPartition in class Partitioner<K,V> Parameters:key - the key to be partioned.value - the entry value.numReduceTasks - the total number of partitions. Returns:the partition number for the key. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HdfsVolumeId (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HdfsVolumeId (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class HdfsVolumeId java.lang.Object org.apache.hadoop.fs.HdfsVolumeId All Implemented Interfaces: Comparable<VolumeId>, VolumeId @InterfaceStability.Unstable @InterfaceAudience.Public public class HdfsVolumeId extends Object implements VolumeId HDFS-specific volume identifier which implements VolumeId. Can be  used to differentiate between the data directories on a single datanode. This  identifier is only unique on a per-datanode basis. Constructor Summary Constructors  Constructor and Description HdfsVolumeId(byte[] id)  Method Summary Methods  Modifier and Type Method and Description int compareTo(VolumeId arg0)  boolean equals(Object obj)  int hashCode()  String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail HdfsVolumeId public HdfsVolumeId(byte[] id) Method Detail compareTo public int compareTo(VolumeId arg0) Specified by: compareTo in interface Comparable<VolumeId> Specified by: compareTo in interface VolumeId hashCode public int hashCode() Specified by: hashCode in interface VolumeId Overrides: hashCode in class Object equals public boolean equals(Object obj) Specified by: equals in interface VolumeId Overrides: equals in class Object toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HealthCheckFailedException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HealthCheckFailedException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha Class HealthCheckFailedException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.ha.HealthCheckFailedException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class HealthCheckFailedException extends IOException Exception thrown to indicate that health check of a service failed. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description HealthCheckFailedException(String message)  HealthCheckFailedException(String message,                                                     Throwable cause)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail HealthCheckFailedException public HealthCheckFailedException(String message) HealthCheckFailedException public HealthCheckFailedException(String message,                           Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HistoryFileManager (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HistoryFileManager (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.v2.hs Class HistoryFileManager java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Unstable public class HistoryFileManager extends AbstractService This class provides a way to interact with history files in a thread safe  manor. Field Summary Fields  Modifier and Type Field and Description protected org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.JobListCache jobListCache  protected ThreadPoolExecutor moveToDoneExecutor  Constructor Summary Constructors  Constructor and Description HistoryFileManager()  Method Summary Methods  Modifier and Type Method and Description protected org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.JobListCache createJobListCache()  protected boolean deleteDir(FileStatus serialDir)  protected List<FileStatus> findTimestampedDirectories() Finds all history directories with a timestamp component by scanning the  filesystem. Collection<org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.HistoryFileInfo> getAllFileInfo()  org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.HistoryFileInfo getFileInfo(org.apache.hadoop.mapreduce.v2.api.records.JobId jobId)  protected static List<FileStatus> scanDirectory(Path path,                           FileContext fc,                           PathFilter pathFilter)  protected List<FileStatus> scanDirectoryForHistoryFiles(Path path,                                                         FileContext fc)  protected void serviceInit(Configuration conf) All initialization code needed by a service. void serviceStop() Actions called during the transition to the STOPPED state. protected void setMaxHistoryAge(long newValue)  Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceStart, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail jobListCache protected org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.JobListCache jobListCache moveToDoneExecutor protected ThreadPoolExecutor moveToDoneExecutor Constructor Detail HistoryFileManager public HistoryFileManager() Method Detail serviceInit protected void serviceInit(Configuration conf)                     throws Exception Description copied from class: AbstractService All initialization code needed by a service.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.init(Configuration) prevents re-entrancy.  The base implementation checks to see if the subclass has created  a new configuration instance, and if so, updates the base class value Overrides: serviceInit in class AbstractService Parameters:conf - configuration Throws: Exception - on a failure -these will be caught,  possibly wrapped, and wil; trigger a service stop serviceStop public void serviceStop()                  throws Exception Description copied from class: AbstractService Actions called during the transition to the STOPPED state.  This method will only ever be called once during the lifecycle of  a specific service instance.  Implementations do not need to be synchronized as the logic  in AbstractService.stop() prevents re-entrancy.  Implementations MUST write this to be robust against failures, including  checks for null references -and for the first failure to not stop other  attempts to shut down parts of the service. Overrides: serviceStop in class AbstractService Throws: Exception - if needed -these will be caught and logged. createJobListCache protected org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.JobListCache createJobListCache() scanDirectory protected static List<FileStatus> scanDirectory(Path path,                              FileContext fc,                              PathFilter pathFilter)                                          throws IOException Throws: IOException scanDirectoryForHistoryFiles protected List<FileStatus> scanDirectoryForHistoryFiles(Path path,                                             FileContext fc)                                                  throws IOException Throws: IOException findTimestampedDirectories protected List<FileStatus> findTimestampedDirectories()                                                throws IOException Finds all history directories with a timestamp component by scanning the  filesystem. Used when the JobHistory server is started. Returns:list of history directories Throws: IOException getAllFileInfo public Collection<org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.HistoryFileInfo> getAllFileInfo()                                                                                                 throws IOException Throws: IOException getFileInfo public org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.HistoryFileInfo getFileInfo(org.apache.hadoop.mapreduce.v2.api.records.JobId jobId)                                                                                  throws IOException Throws: IOException deleteDir protected boolean deleteDir(FileStatus serialDir)                      throws org.apache.hadoop.security.AccessControlException,                             FileNotFoundException,                             UnsupportedFileSystemException,                             IOException Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException UnsupportedFileSystemException IOException setMaxHistoryAge protected void setMaxHistoryAge(long newValue) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  HistoryStorage (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="HistoryStorage (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.v2.hs Interface HistoryStorage @InterfaceAudience.Public @InterfaceStability.Unstable public interface HistoryStorage Provides an API to query jobs that have finished.    For those implementing this API be aware that there is no feedback when  files are removed from HDFS.  You may rely on HistoryFileManager to help  you know when that has happened if you have not made a complete backup of  the data stored on HDFS. Method Summary Methods  Modifier and Type Method and Description Map<org.apache.hadoop.mapreduce.v2.api.records.JobId,org.apache.hadoop.mapreduce.v2.app.job.Job> getAllPartialJobs() Get all of the cached jobs. org.apache.hadoop.mapreduce.v2.app.job.Job getFullJob(org.apache.hadoop.mapreduce.v2.api.records.JobId jobId) Get a fully parsed job. org.apache.hadoop.mapreduce.v2.hs.webapp.dao.JobsInfo getPartialJobs(Long offset,                             Long count,                             String user,                             String queue,                             Long sBegin,                             Long sEnd,                             Long fBegin,                             Long fEnd,                             org.apache.hadoop.mapreduce.v2.api.records.JobState jobState) Look for a set of partial jobs. void setHistoryFileManager(HistoryFileManager hsManager) Give the Storage a reference to a class that can be used to interact with  history files. Method Detail setHistoryFileManager void setHistoryFileManager(HistoryFileManager hsManager) Give the Storage a reference to a class that can be used to interact with  history files. Parameters:hsManager - the class that is used to interact with history files. getPartialJobs org.apache.hadoop.mapreduce.v2.hs.webapp.dao.JobsInfo getPartialJobs(Long offset,                                                                    Long count,                                                                    String user,                                                                    String queue,                                                                    Long sBegin,                                                                    Long sEnd,                                                                    Long fBegin,                                                                    Long fEnd,                                                                    org.apache.hadoop.mapreduce.v2.api.records.JobState jobState) Look for a set of partial jobs. Parameters:offset - the offset into the list of jobs.count - the maximum number of jobs to return.user - only return jobs for the given user.queue - only return jobs for in the given queue.sBegin - only return Jobs that started on or after the given time.sEnd - only return Jobs that started on or before the given time.fBegin - only return Jobs that ended on or after the given time.fEnd - only return Jobs that ended on or before the given time.jobState - only return Jobs that are in the given job state. Returns:The list of filtered jobs. getAllPartialJobs Map<org.apache.hadoop.mapreduce.v2.api.records.JobId,org.apache.hadoop.mapreduce.v2.app.job.Job> getAllPartialJobs() Get all of the cached jobs.  This only returns partial jobs and is here for  legacy reasons. Returns:all of the cached jobs getFullJob org.apache.hadoop.mapreduce.v2.app.job.Job getFullJob(org.apache.hadoop.mapreduce.v2.api.records.JobId jobId) Get a fully parsed job. Parameters:jobId - the id of the job Returns:the job, or null if it is not found. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ID (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ID (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class ID java.lang.Object org.apache.hadoop.mapreduce.ID All Implemented Interfaces: Comparable<ID>, Writable, WritableComparable<ID> Direct Known Subclasses: ID @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ID extends Object implements WritableComparable<ID> A general identifier, which internally stores the id  as an integer. This is the super class of JobID,   TaskID and TaskAttemptID. See Also:JobID,  TaskID,  TaskAttemptID Field Summary Fields  Modifier and Type Field and Description protected int id  protected static char SEPARATOR  Constructor Summary Constructors  Modifier Constructor and Description protected  ID()    ID(int id) constructs an ID object from the given int Method Summary Methods  Modifier and Type Method and Description int compareTo(ID that) Compare IDs by associated numbers boolean equals(Object o)  int getId() returns the int which represents the identifier int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail SEPARATOR protected static final char SEPARATOR See Also:Constant Field Values id protected int id Constructor Detail ID public ID(int id) constructs an ID object from the given int ID protected ID() Method Detail getId public int getId() returns the int which represents the identifier toString public String toString() Overrides: toString in class Object hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object o) Overrides: equals in class Object compareTo public int compareTo(ID that) Compare IDs by associated numbers Specified by: compareTo in interface Comparable<ID> readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  IOUtils (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="IOUtils (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class IOUtils java.lang.Object org.apache.hadoop.io.IOUtils @InterfaceAudience.Public @InterfaceStability.Evolving public class IOUtils extends Object An utility class for I/O related functionality. Constructor Summary Constructors  Constructor and Description IOUtils()  Method Summary Methods  Modifier and Type Method and Description static void cleanup(org.apache.commons.logging.Log log,               Closeable... closeables) Close the Closeable objects and ignore any IOException or   null pointers. static void closeSocket(Socket sock) Closes the socket ignoring IOException static void closeStream(Closeable stream) Closes the stream ignoring IOException. static void copyBytes(InputStream in,                   OutputStream out,                   Configuration conf) Copies from one stream to another. static void copyBytes(InputStream in,                   OutputStream out,                   Configuration conf,                   boolean close) Copies from one stream to another. static void copyBytes(InputStream in,                   OutputStream out,                   int buffSize) Copies from one stream to another. static void copyBytes(InputStream in,                   OutputStream out,                   int buffSize,                   boolean close) Copies from one stream to another. static void copyBytes(InputStream in,                   OutputStream out,                   long count,                   boolean close) Copies count bytes from one stream to another. static List<String> listDirectory(File dir,                           FilenameFilter filter) Return the complete list of files in a directory as strings.  This is better than File#listDir because it does not ignore IOExceptions. static void readFully(InputStream in,                   byte[] buf,                   int off,                   int len) Reads len bytes in a loop. static void skipFully(InputStream in,                   long len) Similar to readFully(). static int wrappedReadForCompressedData(InputStream is,                                                         byte[] buf,                                                         int off,                                                         int len) Utility wrapper for reading from InputStream. static void writeFully(FileChannel fc,                     ByteBuffer buf,                     long offset) Write a ByteBuffer to a FileChannel at a given offset,   handling short writes. static void writeFully(WritableByteChannel bc,                     ByteBuffer buf) Write a ByteBuffer to a WritableByteChannel, handling short writes. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail IOUtils public IOUtils() Method Detail copyBytes public static void copyBytes(InputStream in,              OutputStream out,              int buffSize,              boolean close)                       throws IOException Copies from one stream to another. Parameters:in - InputStrem to read fromout - OutputStream to write tobuffSize - the size of the bufferclose - whether or not close the InputStream and   OutputStream at the end. The streams are closed in the finally clause. Throws: IOException copyBytes public static void copyBytes(InputStream in,              OutputStream out,              int buffSize)                       throws IOException Copies from one stream to another. Parameters:in - InputStrem to read fromout - OutputStream to write tobuffSize - the size of the buffer Throws: IOException copyBytes public static void copyBytes(InputStream in,              OutputStream out,              Configuration conf)                       throws IOException Copies from one stream to another. closes the input and output streams   at the end. Parameters:in - InputStrem to read fromout - OutputStream to write toconf - the Configuration object Throws: IOException copyBytes public static void copyBytes(InputStream in,              OutputStream out,              Configuration conf,              boolean close)                       throws IOException Copies from one stream to another. Parameters:in - InputStream to read fromout - OutputStream to write toconf - the Configuration objectclose - whether or not close the InputStream and   OutputStream at the end. The streams are closed in the finally clause. Throws: IOException copyBytes public static void copyBytes(InputStream in,              OutputStream out,              long count,              boolean close)                       throws IOException Copies count bytes from one stream to another. Parameters:in - InputStream to read fromout - OutputStream to write tocount - number of bytes to copyclose - whether to close the streams Throws: IOException - if bytes can not be read or written wrappedReadForCompressedData public static int wrappedReadForCompressedData(InputStream is,                                byte[] buf,                                int off,                                int len)                                         throws IOException Utility wrapper for reading from InputStream. It catches any errors  thrown by the underlying stream (either IO or decompression-related), and  re-throws as an IOException. Parameters:is - - InputStream to be read frombuf - - buffer the data is read intooff - - offset within buflen - - amount of data to be read Returns:number of bytes read Throws: IOException readFully public static void readFully(InputStream in,              byte[] buf,              int off,              int len)                       throws IOException Reads len bytes in a loop. Parameters:in - InputStream to read frombuf - The buffer to filloff - offset from the bufferlen - the length of bytes to read Throws: IOException - if it could not read requested number of bytes   for any reason (including EOF) skipFully public static void skipFully(InputStream in,              long len)                       throws IOException Similar to readFully(). Skips bytes in a loop. Parameters:in - The InputStream to skip bytes fromlen - number of bytes to skip. Throws: IOException - if it could not skip requested number of bytes   for any reason (including EOF) cleanup public static void cleanup(org.apache.commons.logging.Log log,            Closeable... closeables) Close the Closeable objects and ignore any IOException or   null pointers. Must only be used for cleanup in exception handlers. Parameters:log - the log to record problems to at debug level. Can be null.closeables - the objects to close closeStream public static void closeStream(Closeable stream) Closes the stream ignoring IOException.  Must only be called in cleaning up from exception handlers. Parameters:stream - the Stream to close closeSocket public static void closeSocket(Socket sock) Closes the socket ignoring IOException Parameters:sock - the Socket to close writeFully public static void writeFully(WritableByteChannel bc,               ByteBuffer buf)                        throws IOException Write a ByteBuffer to a WritableByteChannel, handling short writes. Parameters:bc - The WritableByteChannel to write tobuf - The input buffer Throws: IOException - On I/O error writeFully public static void writeFully(FileChannel fc,               ByteBuffer buf,               long offset)                        throws IOException Write a ByteBuffer to a FileChannel at a given offset,   handling short writes. Parameters:fc - The FileChannel to write tobuf - The input bufferoffset - The offset in the file to start writing at Throws: IOException - On I/O error listDirectory public static List<String> listDirectory(File dir,                          FilenameFilter filter)                                   throws IOException Return the complete list of files in a directory as strings.  This is better than File#listDir because it does not ignore IOExceptions. Parameters:dir - The directory to list.filter - If non-null, the filter to use when listing                          this directory. Returns:The list of files in the directory. Throws: IOException - On I/O error Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  IPList (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="IPList (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util Interface IPList @InterfaceStability.Unstable @InterfaceAudience.Public public interface IPList Method Summary Methods  Modifier and Type Method and Description boolean isIn(String ipAddress) returns true if the ipAddress is in the IPList. Method Detail isIn boolean isIn(String ipAddress) returns true if the ipAddress is in the IPList. Parameters:ipAddress -  Returns:boolean value indicating whether the ipAddress is in the IPList Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  IdMappingServiceProvider (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="IdMappingServiceProvider (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.security Interface IdMappingServiceProvider @InterfaceAudience.Public @InterfaceStability.Evolving public interface IdMappingServiceProvider An interface for the implementation of  mapping  and  mapping Method Summary Methods  Modifier and Type Method and Description int getGid(String group)  int getGidAllowingUnknown(String group)  String getGroupName(int gid,                         String unknown)  int getUid(String user)  int getUidAllowingUnknown(String user)  String getUserName(int uid,                       String unknown)  Method Detail getUid int getUid(String user)            throws IOException Throws: IOException getGid int getGid(String group)            throws IOException Throws: IOException getUserName String getUserName(int uid,                  String unknown) getGroupName String getGroupName(int gid,                   String unknown) getUidAllowingUnknown int getUidAllowingUnknown(String user) getGidAllowingUnknown int getGidAllowingUnknown(String group) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  IdentityMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="IdentityMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred.lib Class IdentityMapper<K,V> java.lang.Object org.apache.hadoop.mapred.MapReduceBase org.apache.hadoop.mapred.lib.IdentityMapper<K,V> All Implemented Interfaces: Closeable, AutoCloseable, JobConfigurable, Mapper<K,V,K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class IdentityMapper<K,V> extends MapReduceBase implements Mapper<K,V,K,V> Implements the identity function, mapping inputs directly to outputs. Constructor Summary Constructors  Constructor and Description IdentityMapper()  Method Summary Methods  Modifier and Type Method and Description void map(K key,       V val,       OutputCollector<K,V> output,       Reporter reporter) The identify function. Methods inherited from class org.apache.hadoop.mapred.MapReduceBase close, configure Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.mapred.JobConfigurable configure Methods inherited from interface java.io.Closeable close Constructor Detail IdentityMapper public IdentityMapper() Method Detail map public void map(K key,        V val,        OutputCollector<K,V> output,        Reporter reporter)          throws IOException The identify function.  Input key/value pair is written directly to  output. Specified by: map in interface Mapper<K,V,K,V> Parameters:key - the input key.val - the input value.output - collects mapped keys and values.reporter - facility to report progress. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  IdentityReducer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="IdentityReducer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred.lib Class IdentityReducer<K,V> java.lang.Object org.apache.hadoop.mapred.MapReduceBase org.apache.hadoop.mapred.lib.IdentityReducer<K,V> All Implemented Interfaces: Closeable, AutoCloseable, JobConfigurable, Reducer<K,V,K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class IdentityReducer<K,V> extends MapReduceBase implements Reducer<K,V,K,V> Performs no reduction, writing all input values directly to the output. Constructor Summary Constructors  Constructor and Description IdentityReducer()  Method Summary Methods  Modifier and Type Method and Description void reduce(K key,             Iterator<V> values,             OutputCollector<K,V> output,             Reporter reporter) Writes all keys and values directly to output. Methods inherited from class org.apache.hadoop.mapred.MapReduceBase close, configure Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.mapred.JobConfigurable configure Methods inherited from interface java.io.Closeable close Constructor Detail IdentityReducer public IdentityReducer() Method Detail reduce public void reduce(K key,           Iterator<V> values,           OutputCollector<K,V> output,           Reporter reporter)             throws IOException Writes all keys and values directly to output. Specified by: reduce in interface Reducer<K,V,K,V> Parameters:key - the key.values - the list of values to reduce.output - to collect keys and combined values.reporter - facility to report progress. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Index (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Index (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Interface Index Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public interface Index Interface that acts as an iterator for deserializing maps.  The deserializer returns an instance that the record uses to  read vectors and maps. An example of usage is as follows:    Index idx = startVector(...);  while (!idx.done()) {    .... // read element of a vector    idx.incr();  }   Method Summary Methods  Modifier and Type Method and Description boolean done() Deprecated.    void incr() Deprecated.    Method Detail done boolean done() Deprecated.  incr void incr() Deprecated.  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InnerJoinRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InnerJoinRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class InnerJoinRecordReader<K extends WritableComparable<?>> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader<K,X> org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader<K,Writable,TupleWritable> org.apache.hadoop.mapreduce.lib.join.JoinRecordReader<K> org.apache.hadoop.mapreduce.lib.join.InnerJoinRecordReader<K> All Implemented Interfaces: Closeable, AutoCloseable, Comparable<ComposableRecordReader<K,?>>, Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class InnerJoinRecordReader<K extends WritableComparable<?>> extends JoinRecordReader<K> Full inner join. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader conf, jc, key, keyclass, kids, value Method Summary Methods  Modifier and Type Method and Description protected boolean combine(Object[] srcs,               TupleWritable dst) Return true iff the tuple is full (all data sources contain this key). Methods inherited from class org.apache.hadoop.mapreduce.lib.join.JoinRecordReader createValue, getDelegate, nextKeyValue Methods inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader accept, add, close, compareTo, createKey, createTupleWritable, fillJoinCollector, getComparator, getConf, getCurrentKey, getCurrentValue, getProgress, getRecordReaderQueue, hasNext, id, initialize, key, key, setConf, skip Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail combine protected boolean combine(Object[] srcs,               TupleWritable dst) Return true iff the tuple is full (all data sources contain this key). Specified by: combine in class CompositeRecordReader<K extends WritableComparable<?>,Writable,TupleWritable> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class InputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> Direct Known Subclasses: ComposableInputFormat, CompositeInputFormat, DBInputFormat, FileInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public abstract class InputFormat<K,V> extends Object InputFormat describes the input-specification for a   Map-Reduce job.     The Map-Reduce framework relies on the InputFormat of the  job to:          Validate the input-specification of the job.         Split-up the input file(s) into logical InputSplits, each of     which is then assigned to an individual Mapper.            Provide the RecordReader implementation to be used to glean    input records from the logical InputSplit for processing by     the Mapper.          The default behavior of file-based InputFormats, typically   sub-classes of FileInputFormat, is to split the   input into logical InputSplits based on the total size, in   bytes, of the input files. However, the FileSystem blocksize of    the input files is treated as an upper bound for input splits. A lower bound   on the split size can be set via     mapreduce.input.fileinputformat.split.minsize.    Clearly, logical splits based on input-size is insufficient for many   applications since record boundaries are to respected. In such cases, the  application has to also implement a RecordReader on whom lies the  responsibility to respect record-boundaries and present a record-oriented  view of the logical InputSplit to the individual task. See Also:InputSplit,  RecordReader,  FileInputFormat Constructor Summary Constructors  Constructor and Description InputFormat()  Method Summary Methods  Modifier and Type Method and Description abstract RecordReader<K,V> createRecordReader(InputSplit split,                                     TaskAttemptContext context) Create a record reader for a given split. abstract List<InputSplit> getSplits(JobContext context) Logically split the set of input files for the job. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail InputFormat public InputFormat() Method Detail getSplits public abstract List<InputSplit> getSplits(JobContext context)                                     throws IOException,                                            InterruptedException Logically split the set of input files for the job.      Each InputSplit is then assigned to an individual Mapper  for processing.  Note: The split is a logical split of the inputs and the  input files are not physically split into chunks. For e.g. a split could  be <input-file-path, start, offset> tuple. The InputFormat  also creates the RecordReader to read the InputSplit. Parameters:context - job configuration. Returns:an array of InputSplits for the job. Throws: IOException InterruptedException createRecordReader public abstract RecordReader<K,V> createRecordReader(InputSplit split,                                    TaskAttemptContext context)                                               throws IOException,                                                      InterruptedException Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InputSampler (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InputSampler (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.partition Class InputSampler<K,V> java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.mapreduce.lib.partition.InputSampler<K,V> All Implemented Interfaces: Configurable, Tool Direct Known Subclasses: InputSampler @InterfaceAudience.Public @InterfaceStability.Stable public class InputSampler<K,V> extends Configured implements Tool Utility for collecting samples and writing a partition file for  TotalOrderPartitioner. Constructor Summary Constructors  Constructor and Description InputSampler(Configuration conf)  Method Summary Methods  Modifier and Type Method and Description static void main(String[] args)  int run(String[] args) Driver for InputSampler from the command line. static <K,V> void writePartitionFile(Job job,                                     org.apache.hadoop.mapreduce.lib.partition.InputSampler.Sampler<K,V> sampler) Write a partition file for the given job, using the Sampler provided. Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Constructor Detail InputSampler public InputSampler(Configuration conf) Method Detail writePartitionFile public static <K,V> void writePartitionFile(Job job,                             org.apache.hadoop.mapreduce.lib.partition.InputSampler.Sampler<K,V> sampler)                                throws IOException,                                       ClassNotFoundException,                                       InterruptedException Write a partition file for the given job, using the Sampler provided.  Queries the sampler for a sample keyset, sorts by the output key  comparator, selects the keys for each rank, and writes to the destination  returned from TotalOrderPartitioner.getPartitionFile(org.apache.hadoop.conf.Configuration). Throws: IOException ClassNotFoundException InterruptedException run public int run(String[] args)         throws Exception Driver for InputSampler from the command line.  Configures a JobConf instance and calls writePartitionFile(org.apache.hadoop.mapreduce.Job, org.apache.hadoop.mapreduce.lib.partition.InputSampler.Sampler<K, V>). Specified by: run in interface Tool Parameters:args - command specific arguments. Returns:exit code. Throws: Exception main public static void main(String[] args)                  throws Exception Throws: Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InputSplit (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InputSplit (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class InputSplit java.lang.Object org.apache.hadoop.mapreduce.InputSplit Direct Known Subclasses: CombineFileSplit, CompositeInputSplit, FileSplit, FileSplit @InterfaceAudience.Public @InterfaceStability.Stable public abstract class InputSplit extends Object InputSplit represents the data to be processed by an   individual Mapper.   Typically, it presents a byte-oriented view on the input and is the   responsibility of RecordReader of the job to process this and present  a record-oriented view. See Also:InputFormat,  RecordReader Constructor Summary Constructors  Constructor and Description InputSplit()  Method Summary Methods  Modifier and Type Method and Description abstract long getLength() Get the size of the split, so that the input splits can be sorted by size. SplitLocationInfo[] getLocationInfo() Gets info about which nodes the input split is stored on and how it is  stored at each location. abstract String[] getLocations() Get the list of nodes by name where the data for the split would be local. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail InputSplit public InputSplit() Method Detail getLength public abstract long getLength()                         throws IOException,                                InterruptedException Get the size of the split, so that the input splits can be sorted by size. Returns:the number of bytes in the split Throws: IOException InterruptedException getLocations public abstract String[] getLocations()                                throws IOException,                                       InterruptedException Get the list of nodes by name where the data for the split would be local.  The locations do not need to be serialized. Returns:a new array of the node nodes. Throws: IOException InterruptedException getLocationInfo @InterfaceStability.Evolving public SplitLocationInfo[] getLocationInfo()                                     throws IOException Gets info about which nodes the input split is stored on and how it is  stored at each location. Returns:list of SplitLocationInfos describing how the split     data is stored at each location. A null value indicates that all the     locations have the data stored on disk. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InputSplitWithLocationInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InputSplitWithLocationInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Interface InputSplitWithLocationInfo All Superinterfaces: InputSplit, Writable All Known Implementing Classes: FileSplit @InterfaceAudience.Public @InterfaceStability.Evolving public interface InputSplitWithLocationInfo extends InputSplit Method Summary Methods  Modifier and Type Method and Description SplitLocationInfo[] getLocationInfo() Gets info about which nodes the input split is stored on and how it is  stored at each location. Methods inherited from interface org.apache.hadoop.mapred.InputSplit getLength, getLocations Methods inherited from interface org.apache.hadoop.io.Writable readFields, write Method Detail getLocationInfo SplitLocationInfo[] getLocationInfo()                                     throws IOException Gets info about which nodes the input split is stored on and how it is  stored at each location. Returns:list of SplitLocationInfos describing how the split     data is stored at each location. A null value indicates that all the     locations have the data stored on disk. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  IntSumReducer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="IntSumReducer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.reduce Class IntSumReducer<Key> java.lang.Object org.apache.hadoop.mapreduce.Reducer<Key,IntWritable,Key,IntWritable> org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer<Key> @InterfaceAudience.Public @InterfaceStability.Stable public class IntSumReducer<Key> extends Reducer<Key,IntWritable,Key,IntWritable> Constructor Summary Constructors  Constructor and Description IntSumReducer()  Method Summary Methods  Modifier and Type Method and Description void reduce(Key key,             Iterable<IntWritable> values,             org.apache.hadoop.mapreduce.Reducer.Context context) This method is called once for each key. Methods inherited from class org.apache.hadoop.mapreduce.Reducer cleanup, run, setup Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail IntSumReducer public IntSumReducer() Method Detail reduce public void reduce(Key key,           Iterable<IntWritable> values,           org.apache.hadoop.mapreduce.Reducer.Context context)             throws IOException,                    InterruptedException Description copied from class: Reducer This method is called once for each key. Most applications will define  their reduce class by overriding this method. The default implementation  is an identity function. Overrides: reduce in class Reducer<Key,IntWritable,Key,IntWritable> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  IntWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="IntWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class IntWritable java.lang.Object org.apache.hadoop.io.IntWritable All Implemented Interfaces: Comparable<IntWritable>, Writable, WritableComparable<IntWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class IntWritable extends Object implements WritableComparable<IntWritable> A WritableComparable for ints. Constructor Summary Constructors  Constructor and Description IntWritable()  IntWritable(int value)  Method Summary Methods  Modifier and Type Method and Description int compareTo(IntWritable o) Compares two IntWritables. boolean equals(Object o) Returns true iff o is a IntWritable with the same value. int get() Return the value of this IntWritable. int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(int value) Set the value of this IntWritable. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail IntWritable public IntWritable() IntWritable public IntWritable(int value) Method Detail set public void set(int value) Set the value of this IntWritable. get public int get() Return the value of this IntWritable. readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object o) Returns true iff o is a IntWritable with the same value. Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(IntWritable o) Compares two IntWritables. Specified by: compareTo in interface Comparable<IntWritable> toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  IntegerSplitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="IntegerSplitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class IntegerSplitter java.lang.Object org.apache.hadoop.mapreduce.lib.db.IntegerSplitter All Implemented Interfaces: DBSplitter Direct Known Subclasses: DateSplitter @InterfaceAudience.Public @InterfaceStability.Evolving public class IntegerSplitter extends Object implements DBSplitter Implement DBSplitter over integer values. Constructor Summary Constructors  Constructor and Description IntegerSplitter()  Method Summary Methods  Modifier and Type Method and Description List<InputSplit> split(Configuration conf,           ResultSet results,           String colName) Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail IntegerSplitter public IntegerSplitter() Method Detail split public List<InputSplit> split(Configuration conf,                      ResultSet results,                      String colName)                        throws SQLException Description copied from interface: DBSplitter Given a ResultSet containing one record (and already advanced to that record)  with two columns (a low value, and a high value, both of the same type), determine  a set of splits that span the given values. Specified by: split in interface DBSplitter Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InterfaceAudience (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InterfaceAudience (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.classification Class InterfaceAudience java.lang.Object org.apache.hadoop.classification.InterfaceAudience @InterfaceAudience.Public @InterfaceStability.Evolving public class InterfaceAudience extends Object Annotation to inform users of a package, class or method's intended audience.  Currently the audience can be InterfaceAudience.Public, InterfaceAudience.LimitedPrivate or  InterfaceAudience.Private.   All public classes must have InterfaceAudience annotation.     Public classes that are not marked with this annotation must be  considered by default as InterfaceAudience.Private.     External applications must only use classes that are marked  InterfaceAudience.Public. Avoid using non public classes as these classes  could be removed or change in incompatible ways.    Hadoop projects must only use classes that are marked  InterfaceAudience.LimitedPrivate or InterfaceAudience.Public     Methods may have a different annotation that it is more restrictive  compared to the audience classification of the class. Example: A class   might be InterfaceAudience.Public, but a method may be InterfaceAudience.LimitedPrivate   Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InterfaceStability (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InterfaceStability (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.classification Class InterfaceStability java.lang.Object org.apache.hadoop.classification.InterfaceStability @InterfaceAudience.Public @InterfaceStability.Evolving public class InterfaceStability extends Object Annotation to inform users of how much to rely on a particular package,  class or method not changing over time. Currently the stability can be  InterfaceStability.Stable, InterfaceStability.Evolving or InterfaceStability.Unstable.     All classes that are annotated with InterfaceAudience.Public or  InterfaceAudience.LimitedPrivate must have InterfaceStability annotation.   Classes that are InterfaceAudience.Private are to be considered unstable unless  a different InterfaceStability annotation states otherwise.  Incompatible changes must not be made to classes marked as stable.   Constructor Summary Constructors  Constructor and Description InterfaceStability()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail InterfaceStability public InterfaceStability() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Interns (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Interns (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class Interns java.lang.Object org.apache.hadoop.metrics2.lib.Interns @InterfaceAudience.Public @InterfaceStability.Evolving public class Interns extends Object Helpers to create interned metrics info Constructor Summary Constructors  Constructor and Description Interns()  Method Summary Methods  Modifier and Type Method and Description static MetricsInfo info(String name,         String description) Get a metric info object static MetricsTag tag(MetricsInfo info,       String value) Get a metrics tag static MetricsTag tag(String name,       String description,       String value) Get a metrics tag Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Interns public Interns() Method Detail info public static MetricsInfo info(String name,                String description) Get a metric info object Parameters:name - description -  Returns:an interned metric info object tag public static MetricsTag tag(MetricsInfo info,              String value) Get a metrics tag Parameters:info - of the tagvalue - of the tag Returns:an interned metrics tag tag public static MetricsTag tag(String name,              String description,              String value) Get a metrics tag Parameters:name - of the tagdescription - of the tagvalue - of the tag Returns:an interned metrics tag Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InvalidFileTypeException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InvalidFileTypeException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class InvalidFileTypeException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.mapred.InvalidFileTypeException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class InvalidFileTypeException extends IOException Used when file type differs from the desired file type. like   getting a file when a directory is expected. Or a wrong file type. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description InvalidFileTypeException()  InvalidFileTypeException(String msg)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail InvalidFileTypeException public InvalidFileTypeException() InvalidFileTypeException public InvalidFileTypeException(String msg) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InvalidInputException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InvalidInputException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class InvalidInputException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.mapreduce.lib.input.InvalidInputException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class InvalidInputException extends IOException This class wraps a list of problems with the input, so that the user  can get a list of problems together instead of finding and fixing them one   by one. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description InvalidInputException(List<IOException> probs) Create the exception with the given list. Method Summary Methods  Modifier and Type Method and Description String getMessage() Get a summary message of the problems found. List<IOException> getProblems() Get the complete list of the problems reported. Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail InvalidInputException public InvalidInputException(List<IOException> probs) Create the exception with the given list. Parameters:probs - the list of problems to report. this list is not copied. Method Detail getProblems public List<IOException> getProblems() Get the complete list of the problems reported. Returns:the list of problems, which must not be modified getMessage public String getMessage() Get a summary message of the problems found. Overrides: getMessage in class Throwable Returns:the concatenated messages from all of the problems. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InvalidJobConfException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InvalidJobConfException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class InvalidJobConfException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.mapred.InvalidJobConfException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class InvalidJobConfException extends IOException This exception is thrown when jobconf misses some mendatory attributes  or value of some attributes is invalid. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description InvalidJobConfException()  InvalidJobConfException(String msg)  InvalidJobConfException(String msg,                                               Throwable t)  InvalidJobConfException(Throwable t)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail InvalidJobConfException public InvalidJobConfException() InvalidJobConfException public InvalidJobConfException(String msg) InvalidJobConfException public InvalidJobConfException(String msg,                        Throwable t) InvalidJobConfException public InvalidJobConfException(Throwable t) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InvalidPathException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InvalidPathException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class InvalidPathException java.lang.Object java.lang.Throwable java.lang.Exception java.lang.RuntimeException java.lang.IllegalArgumentException org.apache.hadoop.HadoopIllegalArgumentException org.apache.hadoop.fs.InvalidPathException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class InvalidPathException extends HadoopIllegalArgumentException Path string is invalid either because it has invalid characters or due to  other file system specific reasons. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description InvalidPathException(String path) Constructs exception with the specified detail message. InvalidPathException(String path,                                         String reason) Constructs exception with the specified detail message. Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail InvalidPathException public InvalidPathException(String path) Constructs exception with the specified detail message. Parameters:path - invalid path. InvalidPathException public InvalidPathException(String path,                     String reason) Constructs exception with the specified detail message. Parameters:path - invalid path.reason - Reason path is invalid Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InvalidPathnameException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InvalidPathnameException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.exceptions Class InvalidPathnameException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.PathIOException org.apache.hadoop.registry.client.exceptions.RegistryIOException org.apache.hadoop.registry.client.exceptions.InvalidPathnameException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class InvalidPathnameException extends RegistryIOException A path name was invalid. This is raised when a path string has  characters in it that are not permitted. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description InvalidPathnameException(String path,                                                 String message)  InvalidPathnameException(String path,                                                 String message,                                                 Throwable cause)  Method Summary Methods inherited from class org.apache.hadoop.fs.PathIOException getMessage, getPath, getTargetPath, setOperation, setTargetPath Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail InvalidPathnameException public InvalidPathnameException(String path,                         String message) InvalidPathnameException public InvalidPathnameException(String path,                         String message,                         Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InvalidRecordException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InvalidRecordException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.exceptions Class InvalidRecordException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.PathIOException org.apache.hadoop.registry.client.exceptions.RegistryIOException org.apache.hadoop.registry.client.exceptions.InvalidRecordException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class InvalidRecordException extends RegistryIOException Raised if an attempt to parse a record failed. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description InvalidRecordException(String path,                                             String error)  InvalidRecordException(String path,                                             String error,                                             Throwable cause)  Method Summary Methods inherited from class org.apache.hadoop.fs.PathIOException getMessage, getPath, getTargetPath, setOperation, setTargetPath Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail InvalidRecordException public InvalidRecordException(String path,                       String error) InvalidRecordException public InvalidRecordException(String path,                       String error,                       Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InvalidStateTransitonException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InvalidStateTransitonException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.state Class InvalidStateTransitonException java.lang.Object java.lang.Throwable java.lang.Exception java.lang.RuntimeException org.apache.hadoop.yarn.exceptions.YarnRuntimeException org.apache.hadoop.yarn.state.InvalidStateTransitonException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class InvalidStateTransitonException extends org.apache.hadoop.yarn.exceptions.YarnRuntimeException See Also:Serialized Form Constructor Summary Constructors  Constructor and Description InvalidStateTransitonException(Enum<?> currentState,                                                             Enum<?> event)  Method Summary Methods  Modifier and Type Method and Description Enum<?> getCurrentState()  Enum<?> getEvent()  Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail InvalidStateTransitonException public InvalidStateTransitonException(Enum<?> currentState,                               Enum<?> event) Method Detail getCurrentState public Enum<?> getCurrentState() getEvent public Enum<?> getEvent() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  InverseMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="InverseMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.map Class InverseMapper<K,V> java.lang.Object org.apache.hadoop.mapreduce.Mapper<K,V,V,K> org.apache.hadoop.mapreduce.lib.map.InverseMapper<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class InverseMapper<K,V> extends Mapper<K,V,V,K> A Mapper that swaps keys and values. Constructor Summary Constructors  Constructor and Description InverseMapper()  Method Summary Methods  Modifier and Type Method and Description void map(K key,       V value,       org.apache.hadoop.mapreduce.Mapper.Context context) The inverse function. Methods inherited from class org.apache.hadoop.mapreduce.Mapper cleanup, run, setup Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail InverseMapper public InverseMapper() Method Detail map public void map(K key,        V value,        org.apache.hadoop.mapreduce.Mapper.Context context)          throws IOException,                 InterruptedException The inverse function.  Input keys and values are swapped. Overrides: map in class Mapper<K,V,V,K> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JBoolean (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JBoolean (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JBoolean java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JBoolean Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JBoolean extends JType Constructor Summary Constructors  Constructor and Description JBoolean() Deprecated.  Creates a new instance of JBoolean Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JBoolean public JBoolean() Deprecated.  Creates a new instance of JBoolean Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JBuffer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JBuffer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JBuffer java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JBuffer Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JBuffer extends JType Code generator for "buffer" type. Constructor Summary Constructors  Constructor and Description JBuffer() Deprecated.  Creates a new instance of JBuffer Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JBuffer public JBuffer() Deprecated.  Creates a new instance of JBuffer Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JByte (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JByte (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JByte java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JByte Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JByte extends JType Code generator for "byte" type. Constructor Summary Constructors  Constructor and Description JByte() Deprecated.    Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JByte public JByte() Deprecated.  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JDouble (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JDouble (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JDouble java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JDouble Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JDouble extends JType Constructor Summary Constructors  Constructor and Description JDouble() Deprecated.  Creates a new instance of JDouble Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JDouble public JDouble() Deprecated.  Creates a new instance of JDouble Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JField (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JField (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JField<T> java.lang.Object org.apache.hadoop.record.compiler.JField<T> Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JField<T> extends Object A thin wrappper around record field. Constructor Summary Constructors  Constructor and Description JField(String name,             T type) Deprecated.  Creates a new instance of JField Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JField public JField(String name,       T type) Deprecated.  Creates a new instance of JField Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JFile (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JFile (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JFile java.lang.Object org.apache.hadoop.record.compiler.JFile Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JFile extends Object Container for the Hadoop Record DDL.  The main components of the file are filename, list of included files,  and records defined in that file. Constructor Summary Constructors  Constructor and Description JFile(String name,           ArrayList<JFile> inclFiles,           ArrayList<JRecord> recList) Deprecated.  Creates a new instance of JFile Method Summary Methods  Modifier and Type Method and Description int genCode(String language,               String destDir,               ArrayList<String> options) Deprecated.  Generate record code in given language. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JFile public JFile(String name,      ArrayList<JFile> inclFiles,      ArrayList<JRecord> recList) Deprecated.  Creates a new instance of JFile Parameters:name - possibly full pathname to the fileinclFiles - included files (as JFile)recList - List of records defined within this file Method Detail genCode public int genCode(String language,           String destDir,           ArrayList<String> options)             throws IOException Deprecated.  Generate record code in given language. Language should be all   lowercase. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JFloat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JFloat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JFloat java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JFloat Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JFloat extends JType Constructor Summary Constructors  Constructor and Description JFloat() Deprecated.  Creates a new instance of JFloat Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JFloat public JFloat() Deprecated.  Creates a new instance of JFloat Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JInt (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JInt (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JInt java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JInt Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JInt extends JType Code generator for "int" type Constructor Summary Constructors  Constructor and Description JInt() Deprecated.  Creates a new instance of JInt Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JInt public JInt() Deprecated.  Creates a new instance of JInt Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JLong (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JLong (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JLong java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JLong Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JLong extends JType Code generator for "long" type Constructor Summary Constructors  Constructor and Description JLong() Deprecated.  Creates a new instance of JLong Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JLong public JLong() Deprecated.  Creates a new instance of JLong Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JMap (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JMap (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JMap java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JMap Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JMap extends JType Constructor Summary Constructors  Constructor and Description JMap(JType t1,         JType t2) Deprecated.  Creates a new instance of JMap Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JMap public JMap(JType t1,     JType t2) Deprecated.  Creates a new instance of JMap Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JRecord (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JRecord (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JRecord java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JRecord Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JRecord extends JType Constructor Summary Constructors  Constructor and Description JRecord(String name,               ArrayList<JField<JType>> flist) Deprecated.  Creates a new instance of JRecord Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JRecord public JRecord(String name,        ArrayList<JField<JType>> flist) Deprecated.  Creates a new instance of JRecord Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JString (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JString (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JString java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JString Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JString extends JType Constructor Summary Constructors  Constructor and Description JString() Deprecated.  Creates a new instance of JString Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JString public JString() Deprecated.  Creates a new instance of JString Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JType (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JType (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JType java.lang.Object org.apache.hadoop.record.compiler.JType Direct Known Subclasses: JBoolean, JBuffer, JByte, JDouble, JFloat, JInt, JLong, JMap, JRecord, JString, JVector Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public abstract class JType extends Object Abstract Base class for all types supported by Hadoop Record I/O. Constructor Summary Constructors  Constructor and Description JType() Deprecated.    Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JType public JType() Deprecated.  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JVector (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JVector (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler Class JVector java.lang.Object org.apache.hadoop.record.compiler.JType org.apache.hadoop.record.compiler.JVector Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class JVector extends JType Constructor Summary Constructors  Constructor and Description JVector(JType t) Deprecated.  Creates a new instance of JVector Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JVector public JVector(JType t) Deprecated.  Creates a new instance of JVector Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JavaSerialization (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JavaSerialization (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.serializer Class JavaSerialization java.lang.Object org.apache.hadoop.io.serializer.JavaSerialization All Implemented Interfaces: org.apache.hadoop.io.serializer.Serialization<Serializable> @InterfaceAudience.Public @InterfaceStability.Unstable public class JavaSerialization extends Object implements org.apache.hadoop.io.serializer.Serialization<Serializable>  An experimental Serialization for Java Serializable classes.   See Also:JavaSerializationComparator Constructor Summary Constructors  Constructor and Description JavaSerialization()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JavaSerialization public JavaSerialization() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JavaSerializationComparator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JavaSerializationComparator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.serializer Class JavaSerializationComparator<T extends Serializable & Comparable<T>> java.lang.Object org.apache.hadoop.io.serializer.DeserializerComparator<T> org.apache.hadoop.io.serializer.JavaSerializationComparator<T> Type Parameters:T -  All Implemented Interfaces: Comparator<T>, RawComparator<T> @InterfaceAudience.Public @InterfaceStability.Unstable public class JavaSerializationComparator<T extends Serializable & Comparable<T>> extends org.apache.hadoop.io.serializer.DeserializerComparator<T>  A RawComparator that uses a JavaSerialization  Deserializer to deserialize objects that are then compared via  their Comparable interfaces.   See Also:JavaSerialization Constructor Summary Constructors  Constructor and Description JavaSerializationComparator()  Method Summary Methods inherited from class org.apache.hadoop.io.serializer.DeserializerComparator compare Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface java.util.Comparator equals Constructor Detail JavaSerializationComparator @InterfaceAudience.Private public JavaSerializationComparator()                             throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Job (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Job (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class Job java.lang.Object org.apache.hadoop.mapreduce.task.JobContextImpl org.apache.hadoop.mapreduce.Job All Implemented Interfaces: JobContext, org.apache.hadoop.mapreduce.MRJobConfig @InterfaceAudience.Public @InterfaceStability.Evolving public class Job extends org.apache.hadoop.mapreduce.task.JobContextImpl implements JobContext The job submitter's view of the Job.    It allows the user to configure the  job, submit it, control its execution, and query the state. The set methods  only work until the job is submitted, afterwards they will throw an   IllegalStateException.       Normally the user creates the application, describes various facets of the  job via Job and then submits the job and monitor its progress.    Here is an example on how to submit a job:        // Create a new Job      Job job = Job.getInstance();      job.setJarByClass(MyJob.class);            // Specify various job-specific parameters           job.setJobName("myjob");            job.setInputPath(new Path("in"));      job.setOutputPath(new Path("out"));            job.setMapperClass(MyJob.MyMapper.class);      job.setReducerClass(MyJob.MyReducer.class);      // Submit the job, then poll for progress until the job is complete      job.waitForCompletion(true);   Field Summary Fields  Modifier and Type Field and Description static String COMPLETION_POLL_INTERVAL_KEY Key in mapred-*.xml that sets completionPollInvervalMillis static int DEFAULT_SUBMIT_REPLICATION  static String OUTPUT_FILTER  static String PROGRESS_MONITOR_POLL_INTERVAL_KEY Key in mapred-*.xml that sets progMonitorPollIntervalMillis static String SUBMIT_REPLICATION  static String USED_GENERIC_PARSER  Fields inherited from class org.apache.hadoop.mapreduce.task.JobContextImpl conf, credentials, ugi Fields inherited from interface org.apache.hadoop.mapreduce.MRJobConfig APPLICATION_ATTEMPT_ID, APPLICATION_MASTER_CLASS, CACHE_ARCHIVES, CACHE_ARCHIVES_SIZES, CACHE_ARCHIVES_TIMESTAMPS, CACHE_ARCHIVES_VISIBILITIES, CACHE_FILE_TIMESTAMPS, CACHE_FILE_VISIBILITIES, CACHE_FILES, CACHE_FILES_SIZES, CACHE_LOCALARCHIVES, CACHE_LOCALFILES, CACHE_SYMLINK, CLASSPATH_ARCHIVES, CLASSPATH_FILES, COMBINE_CLASS_ATTR, COMBINE_RECORDS_BEFORE_PROGRESS, COMBINER_GROUP_COMPARATOR_CLASS, COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, COUNTER_GROUP_NAME_MAX_DEFAULT, COUNTER_GROUP_NAME_MAX_KEY, COUNTER_GROUPS_MAX_DEFAULT, COUNTER_GROUPS_MAX_KEY, COUNTER_NAME_MAX_DEFAULT, COUNTER_NAME_MAX_KEY, COUNTERS_MAX_DEFAULT, COUNTERS_MAX_KEY, DEFAULT_JOB_ACL_MODIFY_JOB, DEFAULT_JOB_ACL_VIEW_JOB, DEFAULT_JOB_AM_ACCESS_DISABLED, DEFAULT_JOB_RUNNING_MAP_LIMIT, DEFAULT_JOB_RUNNING_REDUCE_LIMIT, DEFAULT_JOB_TOKEN_TRACKING_IDS_ENABLED, DEFAULT_LOG_LEVEL, DEFAULT_MAP_CPU_VCORES, DEFAULT_MAP_MEMORY_MB, DEFAULT_MAPRED_ADMIN_JAVA_OPTS, DEFAULT_MAPRED_ADMIN_USER_ENV, DEFAULT_MAPREDUCE_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_CROSS_PLATFORM_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA, DEFAULT_MAX_ALLOWED_FETCH_FAILURES_FRACTION, DEFAULT_MAX_FETCH_FAILURES_NOTIFICATIONS, DEFAULT_MAX_SHUFFLE_FETCH_HOST_FAILURES, DEFAULT_MAX_SHUFFLE_FETCH_RETRY_DELAY, DEFAULT_MR_AM_ADMIN_COMMAND_OPTS, DEFAULT_MR_AM_COMMAND_OPTS, DEFAULT_MR_AM_COMMIT_WINDOW_MS, DEFAULT_MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, DEFAULT_MR_AM_CPU_VCORES, DEFAULT_MR_AM_HARD_KILL_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, DEFAULT_MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERCENT, DEFAULT_MR_AM_JOB_CLIENT_THREAD_COUNT, DEFAULT_MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, DEFAULT_MR_AM_JOB_REDUCE_RAMP_UP_LIMIT, DEFAULT_MR_AM_LOG_BACKUPS, DEFAULT_MR_AM_LOG_KB, DEFAULT_MR_AM_LOG_LEVEL, DEFAULT_MR_AM_MAX_ATTEMPTS, DEFAULT_MR_AM_NUM_PROGRESS_SPLITS, DEFAULT_MR_AM_PROFILE, DEFAULT_MR_AM_STAGING_DIR, DEFAULT_MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, DEFAULT_MR_AM_TASK_LISTENER_THREAD_COUNT, DEFAULT_MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, DEFAULT_MR_AM_TO_RM_WAIT_INTERVAL_MS, DEFAULT_MR_AM_VMEM_MB, DEFAULT_MR_CLIENT_JOB_MAX_RETRIES, DEFAULT_MR_CLIENT_JOB_RETRY_INTERVAL, DEFAULT_MR_CLIENT_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, DEFAULT_MR_JOB_END_NOTIFICATION_TIMEOUT, DEFAULT_MR_JOB_REDUCER_PREEMPT_DELAY_SEC, DEFAULT_REDUCE_CPU_VCORES, DEFAULT_REDUCE_MEMORY_MB, DEFAULT_REDUCE_SEPARATE_SHUFFLE_LOG, DEFAULT_SHELL, DEFAULT_SHUFFLE_FETCH_RETRY_INTERVAL_MS, DEFAULT_SHUFFLE_INPUT_BUFFER_PERCENT, DEFAULT_SHUFFLE_LOG_BACKUPS, DEFAULT_SHUFFLE_LOG_KB, DEFAULT_SPECULATIVE_MINIMUM_ALLOWED_TASKS, DEFAULT_SPECULATIVE_RETRY_AFTER_NO_SPECULATE, DEFAULT_SPECULATIVE_RETRY_AFTER_SPECULATE, DEFAULT_SPECULATIVECAP_RUNNING_TASKS, DEFAULT_SPECULATIVECAP_TOTAL_TASKS, DEFAULT_SPLIT_METAINFO_MAXSIZE, DEFAULT_TASK_ISMAP, DEFAULT_TASK_LOG_BACKUPS, DEFAULT_TASK_PROFILE_PARAMS, GROUP_COMPARATOR_CLASS, HADOOP_WORK_DIR, ID, INDEX_CACHE_MEMORY_LIMIT, INPUT_FORMAT_CLASS_ATTR, IO_SORT_FACTOR, IO_SORT_MB, JAR, JAR_UNPACK_PATTERN, JOB_ACL_MODIFY_JOB, JOB_ACL_VIEW_JOB, JOB_AM_ACCESS_DISABLED, JOB_CANCEL_DELEGATION_TOKEN, JOB_CONF_FILE, JOB_JAR, JOB_JOBTRACKER_ID, JOB_LOCAL_DIR, JOB_NAME, JOB_NAMENODES, JOB_RUNNING_MAP_LIMIT, JOB_RUNNING_REDUCE_LIMIT, JOB_SPLIT, JOB_SPLIT_METAINFO, JOB_SUBMIT_DIR, JOB_SUBMITHOST, JOB_SUBMITHOSTADDR, JOB_TAGS, JOB_TOKEN_TRACKING_IDS, JOB_TOKEN_TRACKING_IDS_ENABLED, JOB_UBERTASK_ENABLE, JOB_UBERTASK_MAXBYTES, JOB_UBERTASK_MAXMAPS, JOB_UBERTASK_MAXREDUCES, JVM_NUMTASKS_TORUN, KEY_COMPARATOR, MAP_CLASS_ATTR, MAP_COMBINE_MIN_SPILLS, MAP_CPU_VCORES, MAP_DEBUG_SCRIPT, MAP_ENV, MAP_FAILURES_MAX_PERCENT, MAP_INPUT_FILE, MAP_INPUT_PATH, MAP_INPUT_START, MAP_JAVA_OPTS, MAP_LOG_LEVEL, MAP_MAX_ATTEMPTS, MAP_MEMORY_MB, MAP_OUTPUT_COLLECTOR_CLASS_ATTR, MAP_OUTPUT_COMPRESS, MAP_OUTPUT_COMPRESS_CODEC, MAP_OUTPUT_KEY_CLASS, MAP_OUTPUT_KEY_FIELD_SEPERATOR, MAP_OUTPUT_VALUE_CLASS, MAP_SKIP_INCR_PROC_COUNT, MAP_SKIP_MAX_RECORDS, MAP_SORT_SPILL_PERCENT, MAP_SPECULATIVE, MAPRED_ADMIN_USER_ENV, MAPRED_ADMIN_USER_SHELL, MAPRED_MAP_ADMIN_JAVA_OPTS, MAPRED_REDUCE_ADMIN_JAVA_OPTS, MAPREDUCE_APPLICATION_CLASSPATH, MAPREDUCE_APPLICATION_FRAMEWORK_PATH, MAPREDUCE_JOB_CLASSLOADER, MAPREDUCE_JOB_CLASSLOADER_SYSTEM_CLASSES, MAPREDUCE_JOB_CREDENTIALS_BINARY, MAPREDUCE_JOB_DIR, MAPREDUCE_JOB_EMIT_TIMELINE_DATA, MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE, MAPREDUCE_JOB_SHUFFLE_PROVIDER_SERVICES, MAPREDUCE_JOB_USER_CLASSPATH_FIRST, MAPREDUCE_V2_CHILD_CLASS, MAX_ALLOWED_FETCH_FAILURES_FRACTION, MAX_FETCH_FAILURES_NOTIFICATIONS, MAX_SHUFFLE_FETCH_HOST_FAILURES, MAX_SHUFFLE_FETCH_RETRY_DELAY, MAX_TASK_FAILURES_PER_TRACKER, MR_AM_ADMIN_COMMAND_OPTS, MR_AM_ADMIN_USER_ENV, MR_AM_COMMAND_OPTS, MR_AM_COMMIT_WINDOW_MS, MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, MR_AM_CPU_VCORES, MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR, MR_AM_ENV, MR_AM_HARD_KILL_TIMEOUT_MS, MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERECENT, MR_AM_JOB_CLIENT_PORT_RANGE, MR_AM_JOB_CLIENT_THREAD_COUNT, MR_AM_JOB_NODE_BLACKLISTING_ENABLE, MR_AM_JOB_RECOVERY_ENABLE, MR_AM_JOB_RECOVERY_ENABLE_DEFAULT, MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, MR_AM_JOB_REDUCE_RAMPUP_UP_LIMIT, MR_AM_JOB_SPECULATOR, MR_AM_LOG_BACKUPS, MR_AM_LOG_KB, MR_AM_LOG_LEVEL, MR_AM_MAX_ATTEMPTS, MR_AM_NUM_PROGRESS_SPLITS, MR_AM_PREFIX, MR_AM_PROFILE, MR_AM_PROFILE_PARAMS, MR_AM_SECURITY_SERVICE_AUTHORIZATION_CLIENT, MR_AM_SECURITY_SERVICE_AUTHORIZATION_TASK_UMBILICAL, MR_AM_STAGING_DIR, MR_AM_TASK_ESTIMATOR, MR_AM_TASK_ESTIMATOR_EXPONENTIAL_RATE_ENABLE, MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, MR_AM_TASK_LISTENER_THREAD_COUNT, MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, MR_AM_TO_RM_WAIT_INTERVAL_MS, MR_AM_VMEM_MB, MR_APPLICATION_TYPE, MR_CLIENT_JOB_MAX_RETRIES, MR_CLIENT_JOB_RETRY_INTERVAL, MR_CLIENT_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, MR_ENCRYPTED_INTERMEDIATE_DATA, MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, MR_JOB_END_NOTIFICATION_MAX_ATTEMPTS, MR_JOB_END_NOTIFICATION_MAX_RETRY_INTERVAL, MR_JOB_END_NOTIFICATION_PROXY, MR_JOB_END_NOTIFICATION_TIMEOUT, MR_JOB_END_NOTIFICATION_URL, MR_JOB_END_RETRY_ATTEMPTS, MR_JOB_END_RETRY_INTERVAL, MR_JOB_REDUCER_PREEMPT_DELAY_SEC, MR_PREFIX, NUM_MAP_PROFILES, NUM_MAPS, NUM_REDUCE_PROFILES, NUM_REDUCES, OUTPUT, OUTPUT_FORMAT_CLASS_ATTR, OUTPUT_KEY_CLASS, OUTPUT_VALUE_CLASS, PARTITIONER_CLASS_ATTR, PRESERVE_FAILED_TASK_FILES, PRESERVE_FILES_PATTERN, PRIORITY, QUEUE_NAME, RECORDS_BEFORE_PROGRESS, REDUCE_CLASS_ATTR, REDUCE_CPU_VCORES, REDUCE_DEBUG_SCRIPT, REDUCE_ENV, REDUCE_FAILURES_MAXPERCENT, REDUCE_INPUT_BUFFER_PERCENT, REDUCE_JAVA_OPTS, REDUCE_LOG_LEVEL, REDUCE_MARKRESET_BUFFER_PERCENT, REDUCE_MARKRESET_BUFFER_SIZE, REDUCE_MAX_ATTEMPTS, REDUCE_MEMORY_MB, REDUCE_MEMORY_TOTAL_BYTES, REDUCE_MEMTOMEM_ENABLED, REDUCE_MEMTOMEM_THRESHOLD, REDUCE_MERGE_INMEM_THRESHOLD, REDUCE_SEPARATE_SHUFFLE_LOG, REDUCE_SKIP_INCR_PROC_COUNT, REDUCE_SKIP_MAXGROUPS, REDUCE_SPECULATIVE, RESERVATION_ID, SETUP_CLEANUP_NEEDED, SHUFFLE_CONNECT_TIMEOUT, SHUFFLE_FETCH_FAILURES, SHUFFLE_FETCH_RETRY_ENABLED, SHUFFLE_FETCH_RETRY_INTERVAL_MS, SHUFFLE_FETCH_RETRY_TIMEOUT_MS, SHUFFLE_INPUT_BUFFER_PERCENT, SHUFFLE_LOG_BACKUPS, SHUFFLE_LOG_KB, SHUFFLE_MEMORY_LIMIT_PERCENT, SHUFFLE_MERGE_PERCENT, SHUFFLE_NOTIFY_READERROR, SHUFFLE_PARALLEL_COPIES, SHUFFLE_READ_TIMEOUT, SKIP_OUTDIR, SKIP_RECORDS, SKIP_START_ATTEMPTS, SPECULATIVE_MINIMUM_ALLOWED_TASKS, SPECULATIVE_RETRY_AFTER_NO_SPECULATE, SPECULATIVE_RETRY_AFTER_SPECULATE, SPECULATIVE_SLOWNODE_THRESHOLD, SPECULATIVE_SLOWTASK_THRESHOLD, SPECULATIVECAP, SPECULATIVECAP_RUNNING_TASKS, SPECULATIVECAP_TOTAL_TASKS, SPLIT_FILE, SPLIT_METAINFO_MAXSIZE, STDERR_LOGFILE_ENV, STDOUT_LOGFILE_ENV, TASK_ATTEMPT_ID, TASK_CLEANUP_NEEDED, TASK_DEBUGOUT_LINES, TASK_ID, TASK_ISMAP, TASK_LOG_BACKUPS, TASK_MAP_PROFILE_PARAMS, TASK_OUTPUT_DIR, TASK_PARTITION, TASK_PROFILE, TASK_PROFILE_PARAMS, TASK_REDUCE_PROFILE_PARAMS, TASK_TIMEOUT, TASK_TIMEOUT_CHECK_INTERVAL_MS, TASK_USERLOG_LIMIT, USER_LOG_RETAIN_HOURS, USER_NAME, WORKDIR, WORKFLOW_ADJACENCY_PREFIX_PATTERN, WORKFLOW_ADJACENCY_PREFIX_STRING, WORKFLOW_ID, WORKFLOW_NAME, WORKFLOW_NODE_NAME, WORKFLOW_TAGS, WORKING_DIR Constructor Summary Constructors  Constructor and Description Job() Deprecated.  Use getInstance() Job(Configuration conf) Deprecated.  Use getInstance(Configuration) Job(Configuration conf,       String jobName) Deprecated.  Use getInstance(Configuration, String) Method Summary Methods  Modifier and Type Method and Description void addArchiveToClassPath(Path archive) Add an archive path to the current set of classpath entries. void addCacheArchive(URI uri) Add a archives to be localized void addCacheFile(URI uri) Add a file to be localized void addFileToClassPath(Path file) Add an file path to the current set of classpath entries It adds the file  to cache as well. float cleanupProgress() Get the progress of the job's cleanup-tasks, as a float between 0.0   and 1.0. void createSymlink() Deprecated.  void failTask(TaskAttemptID taskId) Fail indicated task attempt. static int getCompletionPollInterval(Configuration conf) The interval at which waitForCompletion() should check. Counters getCounters() Gets the counters for this job. long getFinishTime() Get finish time of the job. String getHistoryUrl()  static Job getInstance() Creates a new Job with no particular Cluster . static Job getInstance(Cluster ignored) Deprecated.  Use getInstance() static Job getInstance(Cluster ignored,                       Configuration conf) Deprecated.  Use getInstance(Configuration) static Job getInstance(Configuration conf) Creates a new Job with no particular Cluster and a   given Configuration. static Job getInstance(Configuration conf,                       String jobName) Creates a new Job with no particular Cluster and a given jobName. static Job getInstance(JobStatus status,                       Configuration conf) Creates a new Job with no particular Cluster and given  Configuration and JobStatus. String getJobFile() Get the path of the submitted job configuration. String getJobName() The user-specified job name. org.apache.hadoop.mapreduce.JobStatus.State getJobState() Returns the current state of the Job. JobPriority getPriority() Get scheduling info of the job. static int getProgressPollInterval(Configuration conf) The interval at which monitorAndPrintJob() prints status ReservationId getReservationId() Get the reservation to which the job is submitted to, if any String getSchedulingInfo() Get scheduling info of the job. long getStartTime() Get start time of the job. JobStatus getStatus()  TaskCompletionEvent[] getTaskCompletionEvents(int startFrom) Get events indicating completion (success/failure) of component tasks. TaskCompletionEvent[] getTaskCompletionEvents(int startFrom,                                               int numEvents) Get events indicating completion (success/failure) of component tasks. String[] getTaskDiagnostics(TaskAttemptID taskid) Gets the diagnostic messages for a given task attempt. static org.apache.hadoop.mapreduce.Job.TaskStatusFilter getTaskOutputFilter(Configuration conf) Get the task output filter. org.apache.hadoop.mapreduce.TaskReport[] getTaskReports(TaskType type) Get the information of the current state of the tasks of a job. String getTrackingURL() Get the URL where some job progress information will be displayed. boolean isComplete() Check if the job is finished or not. boolean isRetired()  boolean isSuccessful() Check if the job completed successfully. boolean isUber()  void killJob() Kill the running job. void killTask(TaskAttemptID taskId) Kill indicated task attempt. float mapProgress() Get the progress of the job's map-tasks, as a float between 0.0   and 1.0. boolean monitorAndPrintJob() Monitor a job and print status in real-time as progress is made and tasks   fail. float reduceProgress() Get the progress of the job's reduce-tasks, as a float between 0.0   and 1.0. void setCacheArchives(URI[] archives) Set the given set of archives void setCacheFiles(URI[] files) Set the given set of files void setCancelDelegationTokenUponJobCompletion(boolean value) Sets the flag that will allow the JobTracker to cancel the HDFS delegation  tokens upon job completion. void setCombinerClass(Class<? extends Reducer> cls) Set the combiner class for the job. void setCombinerKeyGroupingComparatorClass(Class<? extends RawComparator> cls) Define the comparator that controls which keys are grouped together  for a single call to combiner,  Reducer.reduce(Object, Iterable,  org.apache.hadoop.mapreduce.Reducer.Context) void setGroupingComparatorClass(Class<? extends RawComparator> cls) Define the comparator that controls which keys are grouped together  for a single call to   Reducer.reduce(Object, Iterable,                         org.apache.hadoop.mapreduce.Reducer.Context) void setInputFormatClass(Class<? extends InputFormat> cls) Set the InputFormat for the job. void setJar(String jar) Set the job jar void setJarByClass(Class<?> cls) Set the Jar by finding where a given class came from. void setJobName(String name) Set the user-specified job name. void setJobSetupCleanupNeeded(boolean needed) Specify whether job-setup and job-cleanup is needed for the job void setMapOutputKeyClass(Class<?> theClass) Set the key class for the map output data. void setMapOutputValueClass(Class<?> theClass) Set the value class for the map output data. void setMapperClass(Class<? extends Mapper> cls) Set the Mapper for the job. void setMapSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job for map tasks. void setMaxMapAttempts(int n) Expert: Set the number of maximum attempts that will be made to run a  map task. void setMaxReduceAttempts(int n) Expert: Set the number of maximum attempts that will be made to run a  reduce task. void setNumReduceTasks(int tasks) Set the number of reduce tasks for the job. void setOutputFormatClass(Class<? extends OutputFormat> cls) Set the OutputFormat for the job. void setOutputKeyClass(Class<?> theClass) Set the key class for the job output data. void setOutputValueClass(Class<?> theClass) Set the value class for job outputs. void setPartitionerClass(Class<? extends Partitioner> cls) Set the Partitioner for the job. void setPriority(JobPriority priority) Set the priority of a running job. void setProfileEnabled(boolean newValue) Set whether the system should collect profiler information for some of   the tasks in this job? The information is stored in the user log   directory. void setProfileParams(String value) Set the profiler configuration arguments. void setProfileTaskRange(boolean isMap,                                       String newValue) Set the ranges of maps or reduces to profile. void setReducerClass(Class<? extends Reducer> cls) Set the Reducer for the job. void setReduceSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job for reduce tasks. void setReservationId(ReservationId reservationId) Set the reservation to which the job is submitted to void setSortComparatorClass(Class<? extends RawComparator> cls) Define the comparator that controls how the keys are sorted before they  are passed to the Reducer. void setSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job. static void setTaskOutputFilter(Configuration conf,                                       org.apache.hadoop.mapreduce.Job.TaskStatusFilter newValue) Modify the Configuration to set the task output filter. float setupProgress() Get the progress of the job's setup-tasks, as a float between 0.0   and 1.0. void setUser(String user) Set the reported username for this job. void setWorkingDirectory(Path dir) Set the current working directory for the default file system. void submit() Submit the job to the cluster and return immediately. String toString() Dump stats to screen. boolean waitForCompletion(boolean verbose) Submit the job to the cluster and wait for it to finish. Methods inherited from class org.apache.hadoop.mapreduce.task.JobContextImpl getArchiveClassPaths, getArchiveTimestamps, getCacheArchives, getCacheFiles, getCombinerClass, getCombinerKeyGroupingComparator, getConfiguration, getCredentials, getFileClassPaths, getFileTimestamps, getGroupingComparator, getInputFormatClass, getJar, getJobID, getJobSetupCleanupNeeded, getLocalCacheArchives, getLocalCacheFiles, getMapOutputKeyClass, getMapOutputValueClass, getMapperClass, getMaxMapAttempts, getMaxReduceAttempts, getNumReduceTasks, getOutputFormatClass, getOutputKeyClass, getOutputValueClass, getPartitionerClass, getProfileEnabled, getProfileParams, getProfileTaskRange, getReducerClass, getSortComparator, getSymlink, getTaskCleanupNeeded, getUser, getWorkingDirectory, setJobID Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Methods inherited from interface org.apache.hadoop.mapreduce.JobContext getArchiveClassPaths, getArchiveTimestamps, getCacheArchives, getCacheFiles, getCombinerClass, getCombinerKeyGroupingComparator, getConfiguration, getCredentials, getFileClassPaths, getFileTimestamps, getGroupingComparator, getInputFormatClass, getJar, getJobID, getJobSetupCleanupNeeded, getLocalCacheArchives, getLocalCacheFiles, getMapOutputKeyClass, getMapOutputValueClass, getMapperClass, getMaxMapAttempts, getMaxReduceAttempts, getNumReduceTasks, getOutputFormatClass, getOutputKeyClass, getOutputValueClass, getPartitionerClass, getProfileEnabled, getProfileParams, getProfileTaskRange, getReducerClass, getSortComparator, getSymlink, getTaskCleanupNeeded, getUser, getWorkingDirectory Field Detail OUTPUT_FILTER public static final String OUTPUT_FILTER See Also:Constant Field Values COMPLETION_POLL_INTERVAL_KEY public static final String COMPLETION_POLL_INTERVAL_KEY Key in mapred-*.xml that sets completionPollInvervalMillis See Also:Constant Field Values PROGRESS_MONITOR_POLL_INTERVAL_KEY public static final String PROGRESS_MONITOR_POLL_INTERVAL_KEY Key in mapred-*.xml that sets progMonitorPollIntervalMillis See Also:Constant Field Values USED_GENERIC_PARSER public static final String USED_GENERIC_PARSER See Also:Constant Field Values SUBMIT_REPLICATION public static final String SUBMIT_REPLICATION See Also:Constant Field Values DEFAULT_SUBMIT_REPLICATION public static final int DEFAULT_SUBMIT_REPLICATION See Also:Constant Field Values Constructor Detail Job @Deprecated public Job()     throws IOException Deprecated. Use getInstance() Throws: IOException Job @Deprecated public Job(Configuration conf)     throws IOException Deprecated. Use getInstance(Configuration) Throws: IOException Job @Deprecated public Job(Configuration conf,               String jobName)     throws IOException Deprecated. Use getInstance(Configuration, String) Throws: IOException Method Detail getInstance public static Job getInstance()                        throws IOException Creates a new Job with no particular Cluster .  A Cluster will be created with a generic Configuration. Returns:the Job , with no connection to a cluster yet. Throws: IOException getInstance public static Job getInstance(Configuration conf)                        throws IOException Creates a new Job with no particular Cluster and a   given Configuration.    The Job makes a copy of the Configuration so   that any necessary internal modifications do not reflect on the incoming   parameter.    A Cluster will be created from the conf parameter only when it's needed. Parameters:conf - the configuration Returns:the Job , with no connection to a cluster yet. Throws: IOException getInstance public static Job getInstance(Configuration conf,               String jobName)                        throws IOException Creates a new Job with no particular Cluster and a given jobName.  A Cluster will be created from the conf parameter only when it's needed.  The Job makes a copy of the Configuration so   that any necessary internal modifications do not reflect on the incoming   parameter. Parameters:conf - the configuration Returns:the Job , with no connection to a cluster yet. Throws: IOException getInstance public static Job getInstance(JobStatus status,               Configuration conf)                        throws IOException Creates a new Job with no particular Cluster and given  Configuration and JobStatus.  A Cluster will be created from the conf parameter only when it's needed.    The Job makes a copy of the Configuration so   that any necessary internal modifications do not reflect on the incoming   parameter. Parameters:status - job statusconf - job configuration Returns:the Job , with no connection to a cluster yet. Throws: IOException getInstance @Deprecated public static Job getInstance(Cluster ignored)                        throws IOException Deprecated. Use getInstance() Creates a new Job with no particular Cluster.  A Cluster will be created from the conf parameter only when it's needed.  The Job makes a copy of the Configuration so   that any necessary internal modifications do not reflect on the incoming   parameter. Parameters:ignored -  Returns:the Job , with no connection to a cluster yet. Throws: IOException getInstance @Deprecated public static Job getInstance(Cluster ignored,                          Configuration conf)                        throws IOException Deprecated. Use getInstance(Configuration) Creates a new Job with no particular Cluster and given  Configuration.  A Cluster will be created from the conf parameter only when it's needed.    The Job makes a copy of the Configuration so   that any necessary internal modifications do not reflect on the incoming   parameter. Parameters:ignored - conf - job configuration Returns:the Job , with no connection to a cluster yet. Throws: IOException getStatus public JobStatus getStatus()                     throws IOException,                            InterruptedException Throws: IOException InterruptedException getJobState public org.apache.hadoop.mapreduce.JobStatus.State getJobState()                                                         throws IOException,                                                                InterruptedException Returns the current state of the Job. Returns:JobStatus#State Throws: IOException InterruptedException getTrackingURL public String getTrackingURL() Get the URL where some job progress information will be displayed. Returns:the URL where some job progress information will be displayed. getJobFile public String getJobFile() Get the path of the submitted job configuration. Returns:the path of the submitted job configuration. getStartTime public long getStartTime() Get start time of the job. Returns:the start time of the job getFinishTime public long getFinishTime()                    throws IOException,                           InterruptedException Get finish time of the job. Returns:the finish time of the job Throws: IOException InterruptedException getSchedulingInfo public String getSchedulingInfo() Get scheduling info of the job. Returns:the scheduling info of the job getPriority public JobPriority getPriority()                         throws IOException,                                InterruptedException Get scheduling info of the job. Returns:the scheduling info of the job Throws: IOException InterruptedException getJobName public String getJobName() The user-specified job name. Specified by: getJobName in interface JobContext Overrides: getJobName in class org.apache.hadoop.mapreduce.task.JobContextImpl Returns:the job's name, defaulting to "". getHistoryUrl public String getHistoryUrl()                      throws IOException,                             InterruptedException Throws: IOException InterruptedException isRetired public boolean isRetired()                   throws IOException,                          InterruptedException Throws: IOException InterruptedException toString public String toString() Dump stats to screen. Overrides: toString in class Object getTaskReports public org.apache.hadoop.mapreduce.TaskReport[] getTaskReports(TaskType type)                                                         throws IOException,                                                                InterruptedException Get the information of the current state of the tasks of a job. Parameters:type - Type of the task Returns:the list of all of the map tips. Throws: IOException InterruptedException mapProgress public float mapProgress()                   throws IOException Get the progress of the job's map-tasks, as a float between 0.0   and 1.0.  When all map tasks have completed, the function returns 1.0. Returns:the progress of the job's map-tasks. Throws: IOException reduceProgress public float reduceProgress()                      throws IOException Get the progress of the job's reduce-tasks, as a float between 0.0   and 1.0.  When all reduce tasks have completed, the function returns 1.0. Returns:the progress of the job's reduce-tasks. Throws: IOException cleanupProgress public float cleanupProgress()                       throws IOException,                              InterruptedException Get the progress of the job's cleanup-tasks, as a float between 0.0   and 1.0.  When all cleanup tasks have completed, the function returns 1.0. Returns:the progress of the job's cleanup-tasks. Throws: IOException InterruptedException setupProgress public float setupProgress()                     throws IOException Get the progress of the job's setup-tasks, as a float between 0.0   and 1.0.  When all setup tasks have completed, the function returns 1.0. Returns:the progress of the job's setup-tasks. Throws: IOException isComplete public boolean isComplete()                    throws IOException Check if the job is finished or not.   This is a non-blocking call. Returns:true if the job is complete, else false. Throws: IOException isSuccessful public boolean isSuccessful()                      throws IOException Check if the job completed successfully. Returns:true if the job succeeded, else false. Throws: IOException killJob public void killJob()              throws IOException Kill the running job.  Blocks until all job tasks have been  killed as well.  If the job is no longer running, it simply returns. Throws: IOException setPriority public void setPriority(JobPriority priority)                  throws IOException,                         InterruptedException Set the priority of a running job. Parameters:priority - the new priority for the job. Throws: IOException InterruptedException getTaskCompletionEvents public TaskCompletionEvent[] getTaskCompletionEvents(int startFrom,                                             int numEvents)                                               throws IOException,                                                      InterruptedException Get events indicating completion (success/failure) of component tasks. Parameters:startFrom - index to start fetching events fromnumEvents - number of events to fetch Returns:an array of TaskCompletionEvents Throws: IOException InterruptedException getTaskCompletionEvents public TaskCompletionEvent[] getTaskCompletionEvents(int startFrom)                                               throws IOException Get events indicating completion (success/failure) of component tasks. Parameters:startFrom - index to start fetching events from Returns:an array of TaskCompletionEvents Throws: IOException killTask public void killTask(TaskAttemptID taskId)               throws IOException Kill indicated task attempt. Parameters:taskId - the id of the task to be terminated. Throws: IOException failTask public void failTask(TaskAttemptID taskId)               throws IOException Fail indicated task attempt. Parameters:taskId - the id of the task to be terminated. Throws: IOException getCounters public Counters getCounters()                      throws IOException Gets the counters for this job. May return null if the job has been  retired and the job is no longer in the completed job store. Returns:the counters for this job. Throws: IOException getTaskDiagnostics public String[] getTaskDiagnostics(TaskAttemptID taskid)                             throws IOException,                                    InterruptedException Gets the diagnostic messages for a given task attempt. Parameters:taskid -  Returns:the list of diagnostic messages for the task Throws: IOException InterruptedException setNumReduceTasks public void setNumReduceTasks(int tasks)                        throws IllegalStateException Set the number of reduce tasks for the job. Parameters:tasks - the number of reduce tasks Throws: IllegalStateException - if the job is submitted setWorkingDirectory public void setWorkingDirectory(Path dir)                          throws IOException Set the current working directory for the default file system. Parameters:dir - the new current working directory. Throws: IllegalStateException - if the job is submitted IOException setInputFormatClass public void setInputFormatClass(Class<? extends InputFormat> cls)                          throws IllegalStateException Set the InputFormat for the job. Parameters:cls - the InputFormat to use Throws: IllegalStateException - if the job is submitted setOutputFormatClass public void setOutputFormatClass(Class<? extends OutputFormat> cls)                           throws IllegalStateException Set the OutputFormat for the job. Parameters:cls - the OutputFormat to use Throws: IllegalStateException - if the job is submitted setMapperClass public void setMapperClass(Class<? extends Mapper> cls)                     throws IllegalStateException Set the Mapper for the job. Parameters:cls - the Mapper to use Throws: IllegalStateException - if the job is submitted setJarByClass public void setJarByClass(Class<?> cls) Set the Jar by finding where a given class came from. Parameters:cls - the example class setJar public void setJar(String jar) Set the job jar setUser public void setUser(String user) Set the reported username for this job. Parameters:user - the username for this job. setCombinerClass public void setCombinerClass(Class<? extends Reducer> cls)                       throws IllegalStateException Set the combiner class for the job. Parameters:cls - the combiner to use Throws: IllegalStateException - if the job is submitted setReducerClass public void setReducerClass(Class<? extends Reducer> cls)                      throws IllegalStateException Set the Reducer for the job. Parameters:cls - the Reducer to use Throws: IllegalStateException - if the job is submitted setPartitionerClass public void setPartitionerClass(Class<? extends Partitioner> cls)                          throws IllegalStateException Set the Partitioner for the job. Parameters:cls - the Partitioner to use Throws: IllegalStateException - if the job is submitted setMapOutputKeyClass public void setMapOutputKeyClass(Class<?> theClass)                           throws IllegalStateException Set the key class for the map output data. This allows the user to  specify the map output key class to be different than the final output  value class. Parameters:theClass - the map output key class. Throws: IllegalStateException - if the job is submitted setMapOutputValueClass public void setMapOutputValueClass(Class<?> theClass)                             throws IllegalStateException Set the value class for the map output data. This allows the user to  specify the map output value class to be different than the final output  value class. Parameters:theClass - the map output value class. Throws: IllegalStateException - if the job is submitted setOutputKeyClass public void setOutputKeyClass(Class<?> theClass)                        throws IllegalStateException Set the key class for the job output data. Parameters:theClass - the key class for the job output data. Throws: IllegalStateException - if the job is submitted setOutputValueClass public void setOutputValueClass(Class<?> theClass)                          throws IllegalStateException Set the value class for job outputs. Parameters:theClass - the value class for job outputs. Throws: IllegalStateException - if the job is submitted setCombinerKeyGroupingComparatorClass public void setCombinerKeyGroupingComparatorClass(Class<? extends RawComparator> cls)                                            throws IllegalStateException Define the comparator that controls which keys are grouped together  for a single call to combiner,  Reducer.reduce(Object, Iterable,  org.apache.hadoop.mapreduce.Reducer.Context) Parameters:cls - the raw comparator to use Throws: IllegalStateException - if the job is submitted setSortComparatorClass public void setSortComparatorClass(Class<? extends RawComparator> cls)                             throws IllegalStateException Define the comparator that controls how the keys are sorted before they  are passed to the Reducer. Parameters:cls - the raw comparator Throws: IllegalStateException - if the job is submittedSee Also:setCombinerKeyGroupingComparatorClass(Class) setGroupingComparatorClass public void setGroupingComparatorClass(Class<? extends RawComparator> cls)                                 throws IllegalStateException Define the comparator that controls which keys are grouped together  for a single call to   Reducer.reduce(Object, Iterable,                         org.apache.hadoop.mapreduce.Reducer.Context) Parameters:cls - the raw comparator to use Throws: IllegalStateException - if the job is submittedSee Also:setCombinerKeyGroupingComparatorClass(Class) setJobName public void setJobName(String name)                 throws IllegalStateException Set the user-specified job name. Parameters:name - the job's new name. Throws: IllegalStateException - if the job is submitted setSpeculativeExecution public void setSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job. Parameters:speculativeExecution - true if speculative execution                               should be turned on, else false. setMapSpeculativeExecution public void setMapSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job for map tasks. Parameters:speculativeExecution - true if speculative execution                               should be turned on for map tasks,                              else false. setReduceSpeculativeExecution public void setReduceSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job for reduce tasks. Parameters:speculativeExecution - true if speculative execution                               should be turned on for reduce tasks,                              else false. setJobSetupCleanupNeeded public void setJobSetupCleanupNeeded(boolean needed) Specify whether job-setup and job-cleanup is needed for the job Parameters:needed - If true, job-setup and job-cleanup will be                considered from OutputCommitter                 else ignored. setCacheArchives public void setCacheArchives(URI[] archives) Set the given set of archives Parameters:archives - The list of archives that need to be localized setCacheFiles public void setCacheFiles(URI[] files) Set the given set of files Parameters:files - The list of files that need to be localized addCacheArchive public void addCacheArchive(URI uri) Add a archives to be localized Parameters:uri - The uri of the cache to be localized addCacheFile public void addCacheFile(URI uri) Add a file to be localized Parameters:uri - The uri of the cache to be localized addFileToClassPath public void addFileToClassPath(Path file)                         throws IOException Add an file path to the current set of classpath entries It adds the file  to cache as well.    Files added with this method will not be unpacked while being added to the  classpath.  To add archives to classpath, use the addArchiveToClassPath(Path)  method instead. Parameters:file - Path of the file to be added Throws: IOException addArchiveToClassPath public void addArchiveToClassPath(Path archive)                            throws IOException Add an archive path to the current set of classpath entries. It adds the  archive to cache as well.    Archive files will be unpacked and added to the classpath  when being distributed. Parameters:archive - Path of the archive to be added Throws: IOException createSymlink @Deprecated public void createSymlink() Deprecated.  Originally intended to enable symlinks, but currently symlinks cannot be  disabled. setMaxMapAttempts public void setMaxMapAttempts(int n) Expert: Set the number of maximum attempts that will be made to run a  map task. Parameters:n - the number of attempts per map task. setMaxReduceAttempts public void setMaxReduceAttempts(int n) Expert: Set the number of maximum attempts that will be made to run a  reduce task. Parameters:n - the number of attempts per reduce task. setProfileEnabled public void setProfileEnabled(boolean newValue) Set whether the system should collect profiler information for some of   the tasks in this job? The information is stored in the user log   directory. Parameters:newValue - true means it should be gathered setProfileParams public void setProfileParams(String value) Set the profiler configuration arguments. If the string contains a '%s' it  will be replaced with the name of the profiling output file when the task  runs.  This value is passed to the task child JVM on the command line. Parameters:value - the configuration string setProfileTaskRange public void setProfileTaskRange(boolean isMap,                        String newValue) Set the ranges of maps or reduces to profile. setProfileEnabled(true)   must also be called. Parameters:newValue - a set of integer ranges of the map ids setCancelDelegationTokenUponJobCompletion public void setCancelDelegationTokenUponJobCompletion(boolean value) Sets the flag that will allow the JobTracker to cancel the HDFS delegation  tokens upon job completion. Defaults to true. submit public void submit()             throws IOException,                    InterruptedException,                    ClassNotFoundException Submit the job to the cluster and return immediately. Throws: IOException InterruptedException ClassNotFoundException waitForCompletion public boolean waitForCompletion(boolean verbose)                           throws IOException,                                  InterruptedException,                                  ClassNotFoundException Submit the job to the cluster and wait for it to finish. Parameters:verbose - print the progress to the user Returns:true if the job succeeded Throws: IOException - thrown if the communication with the           JobTracker is lost InterruptedException ClassNotFoundException monitorAndPrintJob public boolean monitorAndPrintJob()                            throws IOException,                                   InterruptedException Monitor a job and print status in real-time as progress is made and tasks   fail. Returns:true if the job succeeded Throws: IOException - if communication to the JobTracker fails InterruptedException getProgressPollInterval public static int getProgressPollInterval(Configuration conf) The interval at which monitorAndPrintJob() prints status getCompletionPollInterval public static int getCompletionPollInterval(Configuration conf) The interval at which waitForCompletion() should check. getTaskOutputFilter public static org.apache.hadoop.mapreduce.Job.TaskStatusFilter getTaskOutputFilter(Configuration conf) Get the task output filter. Parameters:conf - the configuration. Returns:the filter level. setTaskOutputFilter public static void setTaskOutputFilter(Configuration conf,                        org.apache.hadoop.mapreduce.Job.TaskStatusFilter newValue) Modify the Configuration to set the task output filter. Parameters:conf - the Configuration to modify.newValue - the value to set. isUber public boolean isUber()                throws IOException,                       InterruptedException Throws: IOException InterruptedException getReservationId public ReservationId getReservationId() Get the reservation to which the job is submitted to, if any Returns:the reservationId the identifier of the job's reservation, null if          the job does not have any reservation associated with it setReservationId public void setReservationId(ReservationId reservationId) Set the reservation to which the job is submitted to Parameters:reservationId - the reservationId to set Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobClient (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobClient (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class JobClient java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.mapreduce.tools.CLI org.apache.hadoop.mapred.JobClient All Implemented Interfaces: Configurable, Tool @InterfaceAudience.Public @InterfaceStability.Stable public class JobClient extends CLI JobClient is the primary interface for the user-job to interact  with the cluster.    JobClient provides facilities to submit jobs, track their   progress, access component-tasks' reports/logs, get the Map-Reduce cluster  status information etc.    The job submission process involves:          Checking the input and output specifications of the job.            Computing the InputSplits for the job.            Setup the requisite accounting information for the DistributedCache     of the job, if necessary.            Copying the job's jar and configuration to the map-reduce system directory     on the distributed file-system.             Submitting the job to the cluster and optionally monitoring    it's status.           Normally the user creates the application, describes various facets of the  job via JobConf and then uses the JobClient to submit   the job and monitor its progress.    Here is an example on how to use JobClient:        // Create a new JobConf      JobConf job = new JobConf(new Configuration(), MyJob.class);            // Specify various job-specific parameters           job.setJobName("myjob");            job.setInputPath(new Path("in"));      job.setOutputPath(new Path("out"));            job.setMapperClass(MyJob.MyMapper.class);      job.setReducerClass(MyJob.MyReducer.class);      // Submit the job, then poll for progress until the job is complete      JobClient.runJob(job);      Job Control    At times clients would chain map-reduce jobs to accomplish complex tasks   which cannot be done via a single map-reduce job. This is fairly easy since   the output of the job, typically, goes to distributed file-system and that   can be used as the input for the next job.    However, this also means that the onus on ensuring jobs are complete   (success/failure) lies squarely on the clients. In such situations the   various job-control options are:          runJob(JobConf) : submits the job and returns only after     the job has completed.            submitJob(JobConf) : only submits the job, then poll the     returned handle to the RunningJob to query status and make     scheduling decisions.            JobConf.setJobEndNotificationURI(String) : setup a notification    on job-completion, thus avoiding polling.       See Also:JobConf,  ClusterStatus,  Tool,  DistributedCache Field Summary Fields inherited from class org.apache.hadoop.mapreduce.tools.CLI cluster Constructor Summary Constructors  Constructor and Description JobClient() Create a job client. JobClient(Configuration conf) Build a job client with the given Configuration,   and connect to the default cluster JobClient(InetSocketAddress jobTrackAddr,                   Configuration conf) Build a job client, connect to the indicated job tracker. JobClient(JobConf conf) Build a job client with the given JobConf, and connect to the   default cluster Method Summary Methods  Modifier and Type Method and Description void cancelDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> token) Deprecated.  Use Token.cancel(org.apache.hadoop.conf.Configuration) instead void close() Close the JobClient. void displayTasks(JobID jobId,                         String type,                         String state) Display the information about a job's tasks, of a particular type and  in a particular state JobStatus[] getAllJobs() Get the jobs that are submitted. JobQueueInfo[] getChildQueues(String queueName) Returns an array of queue information objects about immediate children  of queue queueName. TaskReport[] getCleanupTaskReports(JobID jobId) Get the information of the current state of the cleanup tasks of a job. Cluster getClusterHandle() Get a handle to the Cluster ClusterStatus getClusterStatus() Get status information about the Map-Reduce cluster. ClusterStatus getClusterStatus(boolean detailed) Get status information about the Map-Reduce cluster. protected long getCounter(Counters cntrs,                     String counterGroupName,                     String counterName)  int getDefaultMaps() Get status information about the max available Maps in the cluster. int getDefaultReduces() Get status information about the max available Reduces in the cluster. org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> getDelegationToken(Text renewer) Get a delegation token for the user from the JobTracker. FileSystem getFs() Get a filesystem handle. RunningJob getJob(JobID jobid) Get an RunningJob object to track an ongoing job. RunningJob getJob(String jobid) Deprecated.  Applications should rather use getJob(JobID). protected RunningJob getJobInner(JobID jobid)  JobStatus[] getJobsFromQueue(String queueName) Gets all the jobs which were added to particular Job Queue TaskReport[] getMapTaskReports(JobID jobId) Get the information of the current state of the map tasks of a job. TaskReport[] getMapTaskReports(String jobId) Deprecated.  Applications should rather use getMapTaskReports(JobID) org.apache.hadoop.mapred.QueueAclsInfo[] getQueueAclsForCurrentUser() Gets the Queue ACLs for current user JobQueueInfo getQueueInfo(String queueName) Gets the queue information associated to a particular Job Queue JobQueueInfo[] getQueues() Return an array of queue information objects about all the Job Queues  configured. TaskReport[] getReduceTaskReports(JobID jobId) Get the information of the current state of the reduce tasks of a job. TaskReport[] getReduceTaskReports(String jobId) Deprecated.  Applications should rather use getReduceTaskReports(JobID) JobQueueInfo[] getRootQueues() Returns an array of queue information objects about root level queues  configured TaskReport[] getSetupTaskReports(JobID jobId) Get the information of the current state of the setup tasks of a job. Path getStagingAreaDir() Fetch the staging area directory for the application Path getSystemDir() Grab the jobtracker system directory path where job-specific files are to be placed. org.apache.hadoop.mapred.JobClient.TaskStatusFilter getTaskOutputFilter() Deprecated.  static org.apache.hadoop.mapred.JobClient.TaskStatusFilter getTaskOutputFilter(JobConf job) Get the task output filter out of the JobConf. void init(JobConf conf) Connect to the default cluster static boolean isJobDirValid(Path jobDirPath,                           FileSystem fs) Checks if the job directory is clean and has all the required components  for (re) starting the job JobStatus[] jobsToComplete() Get the jobs that are not completed and not failed. static void main(String[] argv)  boolean monitorAndPrintJob(JobConf conf,                                     RunningJob job) Monitor a job and print status in real-time as progress is made and tasks   fail. long renewDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> token) Deprecated.  Use Token.renew(org.apache.hadoop.conf.Configuration) instead static RunningJob runJob(JobConf job) Utility that submits a job, then polls for progress until the job is  complete. void setTaskOutputFilter(org.apache.hadoop.mapred.JobClient.TaskStatusFilter newValue) Deprecated.  static void setTaskOutputFilter(JobConf job,                                       org.apache.hadoop.mapred.JobClient.TaskStatusFilter newValue) Modify the JobConf to set the task output filter. RunningJob submitJob(JobConf conf) Submit a job to the MR system. RunningJob submitJob(String jobFile) Submit a job to the MR system. Methods inherited from class org.apache.hadoop.mapreduce.tools.CLI displayJobList, displayTasks, run Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Constructor Detail JobClient public JobClient() Create a job client. JobClient public JobClient(JobConf conf)           throws IOException Build a job client with the given JobConf, and connect to the   default cluster Parameters:conf - the job configuration. Throws: IOException JobClient public JobClient(Configuration conf)           throws IOException Build a job client with the given Configuration,   and connect to the default cluster Parameters:conf - the configuration. Throws: IOException JobClient public JobClient(InetSocketAddress jobTrackAddr,          Configuration conf)           throws IOException Build a job client, connect to the indicated job tracker. Parameters:jobTrackAddr - the job tracker to connect to.conf - configuration. Throws: IOException Method Detail init public void init(JobConf conf)           throws IOException Connect to the default cluster Parameters:conf - the job configuration. Throws: IOException close public void close()            throws IOException Close the JobClient. Throws: IOException getFs public FileSystem getFs()                  throws IOException Get a filesystem handle.  We need this to prepare jobs  for submission to the MapReduce system. Returns:the filesystem handle. Throws: IOException getClusterHandle public Cluster getClusterHandle() Get a handle to the Cluster submitJob public RunningJob submitJob(String jobFile)                      throws FileNotFoundException,                             InvalidJobConfException,                             IOException Submit a job to the MR system.    This returns a handle to the RunningJob which can be used to track  the running-job. Parameters:jobFile - the job configuration. Returns:a handle to the RunningJob which can be used to track the          running-job. Throws: FileNotFoundException InvalidJobConfException IOException submitJob public RunningJob submitJob(JobConf conf)                      throws FileNotFoundException,                             IOException Submit a job to the MR system.  This returns a handle to the RunningJob which can be used to track  the running-job. Parameters:conf - the job configuration. Returns:a handle to the RunningJob which can be used to track the          running-job. Throws: FileNotFoundException IOException getJobInner protected RunningJob getJobInner(JobID jobid)                           throws IOException Throws: IOException getJob public RunningJob getJob(JobID jobid)                   throws IOException Get an RunningJob object to track an ongoing job.  Returns  null if the id does not correspond to any known job. Parameters:jobid - the jobid of the job. Returns:the RunningJob handle to track the job, null if the          jobid doesn't correspond to any known job. Throws: IOException getJob @Deprecated public RunningJob getJob(String jobid)                   throws IOException Deprecated. Applications should rather use getJob(JobID). Throws: IOException getMapTaskReports public TaskReport[] getMapTaskReports(JobID jobId)                                throws IOException Get the information of the current state of the map tasks of a job. Parameters:jobId - the job to query. Returns:the list of all of the map tips. Throws: IOException getMapTaskReports @Deprecated public TaskReport[] getMapTaskReports(String jobId)                                throws IOException Deprecated. Applications should rather use getMapTaskReports(JobID) Throws: IOException getReduceTaskReports public TaskReport[] getReduceTaskReports(JobID jobId)                                   throws IOException Get the information of the current state of the reduce tasks of a job. Parameters:jobId - the job to query. Returns:the list of all of the reduce tips. Throws: IOException getCleanupTaskReports public TaskReport[] getCleanupTaskReports(JobID jobId)                                    throws IOException Get the information of the current state of the cleanup tasks of a job. Parameters:jobId - the job to query. Returns:the list of all of the cleanup tips. Throws: IOException getSetupTaskReports public TaskReport[] getSetupTaskReports(JobID jobId)                                  throws IOException Get the information of the current state of the setup tasks of a job. Parameters:jobId - the job to query. Returns:the list of all of the setup tips. Throws: IOException getReduceTaskReports @Deprecated public TaskReport[] getReduceTaskReports(String jobId)                                   throws IOException Deprecated. Applications should rather use getReduceTaskReports(JobID) Throws: IOException displayTasks public void displayTasks(JobID jobId,                 String type,                 String state)                   throws IOException Display the information about a job's tasks, of a particular type and  in a particular state Parameters:jobId - the ID of the jobtype - the type of the task (map/reduce/setup/cleanup)state - the state of the task   (pending/running/completed/failed/killed) Throws: IOException getClusterStatus public ClusterStatus getClusterStatus()                                throws IOException Get status information about the Map-Reduce cluster. Returns:the status information about the Map-Reduce cluster as an object          of ClusterStatus. Throws: IOException getClusterStatus public ClusterStatus getClusterStatus(boolean detailed)                                throws IOException Get status information about the Map-Reduce cluster. Parameters:detailed - if true then get a detailed status including the          tracker names Returns:the status information about the Map-Reduce cluster as an object          of ClusterStatus. Throws: IOException jobsToComplete public JobStatus[] jobsToComplete()                            throws IOException Get the jobs that are not completed and not failed. Returns:array of JobStatus for the running/to-be-run jobs. Throws: IOException getAllJobs public JobStatus[] getAllJobs()                        throws IOException Get the jobs that are submitted. Returns:array of JobStatus for the submitted jobs. Throws: IOException runJob public static RunningJob runJob(JobConf job)                          throws IOException Utility that submits a job, then polls for progress until the job is  complete. Parameters:job - the job configuration. Throws: IOException - if the job fails monitorAndPrintJob public boolean monitorAndPrintJob(JobConf conf,                          RunningJob job)                            throws IOException,                                   InterruptedException Monitor a job and print status in real-time as progress is made and tasks   fail. Parameters:conf - the job's configurationjob - the job to track Returns:true if the job succeeded Throws: IOException - if communication to the JobTracker fails InterruptedException setTaskOutputFilter @Deprecated public void setTaskOutputFilter(org.apache.hadoop.mapred.JobClient.TaskStatusFilter newValue) Deprecated.  Sets the output filter for tasks. only those tasks are printed whose  output matches the filter. Parameters:newValue - task filter. getTaskOutputFilter public static org.apache.hadoop.mapred.JobClient.TaskStatusFilter getTaskOutputFilter(JobConf job) Get the task output filter out of the JobConf. Parameters:job - the JobConf to examine. Returns:the filter level. setTaskOutputFilter public static void setTaskOutputFilter(JobConf job,                        org.apache.hadoop.mapred.JobClient.TaskStatusFilter newValue) Modify the JobConf to set the task output filter. Parameters:job - the JobConf to modify.newValue - the value to set. getTaskOutputFilter @Deprecated public org.apache.hadoop.mapred.JobClient.TaskStatusFilter getTaskOutputFilter() Deprecated.  Returns task output filter. Returns:task filter. getCounter protected long getCounter(Counters cntrs,               String counterGroupName,               String counterName)                    throws IOException Overrides: getCounter in class CLI Throws: IOException getDefaultMaps public int getDefaultMaps()                    throws IOException Get status information about the max available Maps in the cluster. Returns:the max available Maps in the cluster Throws: IOException getDefaultReduces public int getDefaultReduces()                       throws IOException Get status information about the max available Reduces in the cluster. Returns:the max available Reduces in the cluster Throws: IOException getSystemDir public Path getSystemDir() Grab the jobtracker system directory path where job-specific files are to be placed. Returns:the system directory where job-specific files are to be placed. isJobDirValid public static boolean isJobDirValid(Path jobDirPath,                     FileSystem fs)                              throws IOException Checks if the job directory is clean and has all the required components  for (re) starting the job Throws: IOException getStagingAreaDir public Path getStagingAreaDir()                        throws IOException Fetch the staging area directory for the application Returns:path to staging area directory Throws: IOException getRootQueues public JobQueueInfo[] getRootQueues()                              throws IOException Returns an array of queue information objects about root level queues  configured Returns:the array of root level JobQueueInfo objects Throws: IOException getChildQueues public JobQueueInfo[] getChildQueues(String queueName)                               throws IOException Returns an array of queue information objects about immediate children  of queue queueName. Parameters:queueName -  Returns:the array of immediate children JobQueueInfo objects Throws: IOException getQueues public JobQueueInfo[] getQueues()                          throws IOException Return an array of queue information objects about all the Job Queues  configured. Returns:Array of JobQueueInfo objects Throws: IOException getJobsFromQueue public JobStatus[] getJobsFromQueue(String queueName)                              throws IOException Gets all the jobs which were added to particular Job Queue Parameters:queueName - name of the Job Queue Returns:Array of jobs present in the job queue Throws: IOException getQueueInfo public JobQueueInfo getQueueInfo(String queueName)                           throws IOException Gets the queue information associated to a particular Job Queue Parameters:queueName - name of the job queue. Returns:Queue information associated to particular queue. Throws: IOException getQueueAclsForCurrentUser public org.apache.hadoop.mapred.QueueAclsInfo[] getQueueAclsForCurrentUser()                                                                     throws IOException Gets the Queue ACLs for current user Returns:array of QueueAclsInfo object for current user. Throws: IOException getDelegationToken public org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> getDelegationToken(Text renewer)                                                                                                                                            throws IOException,                                                                                                                                                   InterruptedException Get a delegation token for the user from the JobTracker. Parameters:renewer - the user who can renew the token Returns:the new token Throws: IOException InterruptedException renewDelegationToken public long renewDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> token)                           throws org.apache.hadoop.security.token.SecretManager.InvalidToken,                                  IOException,                                  InterruptedException Deprecated. Use Token.renew(org.apache.hadoop.conf.Configuration) instead Renew a delegation token Parameters:token - the token to renew Returns:true if the renewal went well Throws: org.apache.hadoop.security.token.SecretManager.InvalidToken IOException InterruptedException cancelDelegationToken public void cancelDelegationToken(org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.delegation.DelegationTokenIdentifier> token)                            throws org.apache.hadoop.security.token.SecretManager.InvalidToken,                                   IOException,                                   InterruptedException Deprecated. Use Token.cancel(org.apache.hadoop.conf.Configuration) instead Cancel a delegation token from the JobTracker Parameters:token - the token to cancel Throws: IOException org.apache.hadoop.security.token.SecretManager.InvalidToken InterruptedException main public static void main(String[] argv)                  throws Exception Throws: Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobConf (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobConf (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class JobConf java.lang.Object org.apache.hadoop.conf.Configuration org.apache.hadoop.mapred.JobConf All Implemented Interfaces: Iterable<Map.Entry<String,String>>, Writable @InterfaceAudience.Public @InterfaceStability.Stable public class JobConf extends Configuration A map/reduce job configuration.    JobConf is the primary interface for a user to describe a   map-reduce job to the Hadoop framework for execution. The framework tries to  faithfully execute the job as-is described by JobConf, however:          Some configuration parameters might have been marked as         final by administrators and hence cannot be altered.            While some job parameters are straight-forward to set     (e.g. setNumReduceTasks(int)), some parameters interact subtly    with the rest of the framework and/or job-configuration and is relatively    more complex for the user to control finely    (e.g. setNumMapTasks(int)).          JobConf typically specifies the Mapper, combiner   (if any), Partitioner, Reducer, InputFormat and   OutputFormat implementations to be used etc.  Optionally JobConf is used to specify other advanced facets   of the job such as Comparators to be used, files to be put in    the DistributedCache, whether or not intermediate and/or job outputs   are to be compressed (and how), debugability via user-provided scripts   ( setMapDebugScript(String)/setReduceDebugScript(String)),  for doing post-processing on task logs, task's stdout, stderr, syslog.   and etc.    Here is an example on how to configure a job via JobConf:        // Create a new JobConf      JobConf job = new JobConf(new Configuration(), MyJob.class);            // Specify various job-specific parameters           job.setJobName("myjob");            FileInputFormat.setInputPaths(job, new Path("in"));      FileOutputFormat.setOutputPath(job, new Path("out"));            job.setMapperClass(MyJob.MyMapper.class);      job.setCombinerClass(MyJob.MyReducer.class);      job.setReducerClass(MyJob.MyReducer.class);            job.setInputFormat(SequenceFileInputFormat.class);      job.setOutputFormat(SequenceFileOutputFormat.class);   See Also:JobClient,  ClusterStatus,  Tool,  DistributedCache Field Summary Fields  Modifier and Type Field and Description static org.apache.log4j.Level DEFAULT_LOG_LEVEL Default logging level for map/reduce tasks. static String DEFAULT_MAPRED_TASK_JAVA_OPTS  static boolean DEFAULT_MAPREDUCE_RECOVER_JOB Deprecated.  static String DEFAULT_QUEUE_NAME Name of the queue to which jobs will be submitted, if no queue  name is mentioned. static long DISABLED_MEMORY_LIMIT Deprecated.  static String MAPRED_JOB_MAP_MEMORY_MB_PROPERTY Deprecated.  static String MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY Deprecated.  static String MAPRED_LOCAL_DIR_PROPERTY Property name for the configuration property mapreduce.cluster.local.dir static String MAPRED_MAP_TASK_ENV Configuration key to set the environment of the child map tasks. static String MAPRED_MAP_TASK_JAVA_OPTS Configuration key to set the java command line options for the map tasks. static String MAPRED_MAP_TASK_LOG_LEVEL Configuration key to set the logging Level for the map task. static String MAPRED_MAP_TASK_ULIMIT Deprecated.  Configuration key to set the maximum virtual memory available to the  map tasks (in kilo-bytes). This has been deprecated and will no  longer have any effect. static String MAPRED_REDUCE_TASK_ENV Configuration key to set the environment of the child reduce tasks. static String MAPRED_REDUCE_TASK_JAVA_OPTS Configuration key to set the java command line options for the reduce tasks. static String MAPRED_REDUCE_TASK_LOG_LEVEL Configuration key to set the logging Level for the reduce task. static String MAPRED_REDUCE_TASK_ULIMIT Deprecated.  Configuration key to set the maximum virtual memory available to the  reduce tasks (in kilo-bytes). This has been deprecated and will no  longer have any effect. static String MAPRED_TASK_DEFAULT_MAXVMEM_PROPERTY Deprecated.   static String MAPRED_TASK_ENV Deprecated.  Use MAPRED_MAP_TASK_ENV or                   MAPRED_REDUCE_TASK_ENV static String MAPRED_TASK_JAVA_OPTS Deprecated.  Use MAPRED_MAP_TASK_JAVA_OPTS or                   MAPRED_REDUCE_TASK_JAVA_OPTS static String MAPRED_TASK_MAXPMEM_PROPERTY Deprecated.   static String MAPRED_TASK_MAXVMEM_PROPERTY Deprecated.  Use MAPREDUCE_JOB_MAP_MEMORY_MB_PROPERTY and  MAPREDUCE_JOB_REDUCE_MEMORY_MB_PROPERTY static String MAPRED_TASK_ULIMIT Deprecated.  Configuration key to set the maximum virtual memory available to the child  map and reduce tasks (in kilo-bytes). This has been deprecated and will no  longer have any effect. static String MAPREDUCE_RECOVER_JOB Deprecated.  static Pattern UNPACK_JAR_PATTERN_DEFAULT Pattern for the default unpacking behavior for job jars static String UPPER_LIMIT_ON_TASK_VMEM_PROPERTY Deprecated.   static String WORKFLOW_ADJACENCY_PREFIX_PATTERN Deprecated.  static String WORKFLOW_ADJACENCY_PREFIX_STRING Deprecated.  static String WORKFLOW_ID Deprecated.  static String WORKFLOW_NAME Deprecated.  static String WORKFLOW_NODE_NAME Deprecated.  static String WORKFLOW_TAGS Deprecated.  Constructor Summary Constructors  Constructor and Description JobConf() Construct a map/reduce job configuration. JobConf(boolean loadDefaults) A new map/reduce configuration where the behavior of reading from the  default resources can be turned off. JobConf(Class exampleClass) Construct a map/reduce job configuration. JobConf(Configuration conf) Construct a map/reduce job configuration. JobConf(Configuration conf,               Class exampleClass) Construct a map/reduce job configuration. JobConf(Path config) Construct a map/reduce configuration. JobConf(String config) Construct a map/reduce configuration. Method Summary Methods  Modifier and Type Method and Description void deleteLocalFiles() Deprecated.  void deleteLocalFiles(String subdir)  static String findContainingJar(Class my_class) Find a jar that contains a class of the same name, if any. Class<? extends Reducer> getCombinerClass() Get the user-defined combiner class used to combine map-outputs   before being sent to the reducers. RawComparator getCombinerKeyGroupingComparator() Get the user defined WritableComparable comparator for  grouping keys of inputs to the combiner. boolean getCompressMapOutput() Are the outputs of the maps be compressed? org.apache.hadoop.security.Credentials getCredentials() Get credentials for the job. InputFormat getInputFormat() Get the InputFormat implementation for the map-reduce job,  defaults to TextInputFormat if not specified explicity. String getJar() Get the user jar for the map-reduce job. Pattern getJarUnpackPattern() Get the pattern for jar contents to unpack on the tasktracker String getJobEndNotificationURI() Get the uri to be invoked in-order to send a notification after the job   has completed (success/failure). String getJobLocalDir() Get job-specific shared directory for use as scratch space String getJobName() Get the user-specified job name. JobPriority getJobPriority() Get the JobPriority for this job. boolean getKeepFailedTaskFiles() Should the temporary files for failed tasks be kept? String getKeepTaskFilesPattern() Get the regular expression that is matched against the task names  to see if we need to keep the files. String getKeyFieldComparatorOption() Get the KeyFieldBasedComparator options String getKeyFieldPartitionerOption() Get the KeyFieldBasedPartitioner options String[] getLocalDirs()  Path getLocalPath(String pathString) Constructs a local file name. String getMapDebugScript() Get the map task's debug script. Class<? extends CompressionCodec> getMapOutputCompressorClass(Class<? extends CompressionCodec> defaultValue) Get the CompressionCodec for compressing the map outputs. Class<?> getMapOutputKeyClass() Get the key class for the map output data. Class<?> getMapOutputValueClass() Get the value class for the map output data. Class<? extends Mapper> getMapperClass() Get the Mapper class for the job. Class<? extends MapRunnable> getMapRunnerClass() Get the MapRunnable class for the job. boolean getMapSpeculativeExecution() Should speculative execution be used for this job for map tasks?   Defaults to true. int getMaxMapAttempts() Get the configured number of maximum attempts that will be made to run a  map task, as specified by the mapreduce.map.maxattempts  property. int getMaxMapTaskFailuresPercent() Get the maximum percentage of map tasks that can fail without   the job being aborted. long getMaxPhysicalMemoryForTask() Deprecated.  this variable is deprecated and nolonger in use. int getMaxReduceAttempts() Get the configured number of maximum attempts  that will be made to run a  reduce task, as specified by the mapreduce.reduce.maxattempts  property. int getMaxReduceTaskFailuresPercent() Get the maximum percentage of reduce tasks that can fail without   the job being aborted. int getMaxTaskFailuresPerTracker() Expert: Get the maximum no. long getMaxVirtualMemoryForTask() Deprecated.  Use getMemoryForMapTask() and              getMemoryForReduceTask() long getMemoryForMapTask() Get memory required to run a map task of the job, in MB. long getMemoryForReduceTask() Get memory required to run a reduce task of the job, in MB. int getNumMapTasks() Get configured the number of reduce tasks for this job. int getNumReduceTasks() Get configured the number of reduce tasks for this job. int getNumTasksToExecutePerJvm() Get the number of tasks that a spawned JVM should execute OutputCommitter getOutputCommitter() Get the OutputCommitter implementation for the map-reduce job,  defaults to FileOutputCommitter if not specified explicitly. OutputFormat getOutputFormat() Get the OutputFormat implementation for the map-reduce job,  defaults to TextOutputFormat if not specified explicity. Class<?> getOutputKeyClass() Get the key class for the job output data. RawComparator getOutputKeyComparator() Get the RawComparator comparator used to compare keys. Class<?> getOutputValueClass() Get the value class for job outputs. RawComparator getOutputValueGroupingComparator() Get the user defined WritableComparable comparator for   grouping keys of inputs to the reduce. Class<? extends Partitioner> getPartitionerClass() Get the Partitioner used to partition Mapper-outputs   to be sent to the Reducers. boolean getProfileEnabled() Get whether the task profiling is enabled. String getProfileParams() Get the profiler configuration arguments. org.apache.hadoop.conf.Configuration.IntegerRanges getProfileTaskRange(boolean isMap) Get the range of maps or reduces to profile. String getQueueName() Return the name of the queue to which this job is submitted. String getReduceDebugScript() Get the reduce task's debug Script Class<? extends Reducer> getReducerClass() Get the Reducer class for the job. boolean getReduceSpeculativeExecution() Should speculative execution be used for this job for reduce tasks?   Defaults to true. String getSessionId() Deprecated.  boolean getSpeculativeExecution() Should speculative execution be used for this job?   Defaults to true. boolean getUseNewMapper() Should the framework use the new context-object code for running  the mapper? boolean getUseNewReducer() Should the framework use the new context-object code for running  the reducer? String getUser() Get the reported username for this job. Path getWorkingDirectory() Get the current working directory for the default file system. static long normalizeMemoryConfigValue(long val) Normalize the negative values in configuration void setCombinerClass(Class<? extends Reducer> theClass) Set the user-defined combiner class used to combine map-outputs   before being sent to the reducers. void setCombinerKeyGroupingComparator(Class<? extends RawComparator> theClass) Set the user defined RawComparator comparator for  grouping keys in the input to the combiner. void setCompressMapOutput(boolean compress) Should the map outputs be compressed before transfer? void setInputFormat(Class<? extends InputFormat> theClass) Set the InputFormat implementation for the map-reduce job. void setJar(String jar) Set the user jar for the map-reduce job. void setJarByClass(Class cls) Set the job's jar file by finding an example class location. void setJobEndNotificationURI(String uri) Set the uri to be invoked in-order to send a notification after the job  has completed (success/failure). void setJobName(String name) Set the user-specified job name. void setJobPriority(JobPriority prio) Set JobPriority for this job. void setKeepFailedTaskFiles(boolean keep) Set whether the framework should keep the intermediate files for   failed tasks. void setKeepTaskFilesPattern(String pattern) Set a regular expression for task names that should be kept. void setKeyFieldComparatorOptions(String keySpec) Set the KeyFieldBasedComparator options used to compare keys. void setKeyFieldPartitionerOptions(String keySpec) Set the KeyFieldBasedPartitioner options used for   Partitioner void setMapDebugScript(String mDbgScript) Set the debug script to run when the map tasks fail. void setMapOutputCompressorClass(Class<? extends CompressionCodec> codecClass) Set the given class as the  CompressionCodec for the map outputs. void setMapOutputKeyClass(Class<?> theClass) Set the key class for the map output data. void setMapOutputValueClass(Class<?> theClass) Set the value class for the map output data. void setMapperClass(Class<? extends Mapper> theClass) Set the Mapper class for the job. void setMapRunnerClass(Class<? extends MapRunnable> theClass) Expert: Set the MapRunnable class for the job. void setMapSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job for map tasks. void setMaxMapAttempts(int n) Expert: Set the number of maximum attempts that will be made to run a  map task. void setMaxMapTaskFailuresPercent(int percent) Expert: Set the maximum percentage of map tasks that can fail without the  job being aborted. void setMaxPhysicalMemoryForTask(long mem) Deprecated.  void setMaxReduceAttempts(int n) Expert: Set the number of maximum attempts that will be made to run a  reduce task. void setMaxReduceTaskFailuresPercent(int percent) Set the maximum percentage of reduce tasks that can fail without the job  being aborted. void setMaxTaskFailuresPerTracker(int noFailures) Set the maximum no. void setMaxVirtualMemoryForTask(long vmem) Deprecated.  Use setMemoryForMapTask(long mem)  and   Use setMemoryForReduceTask(long mem) void setMemoryForMapTask(long mem)  void setMemoryForReduceTask(long mem)  void setNumMapTasks(int n) Set the number of map tasks for this job. void setNumReduceTasks(int n) Set the requisite number of reduce tasks for this job. void setNumTasksToExecutePerJvm(int numTasks) Sets the number of tasks that a spawned task JVM should run  before it exits void setOutputCommitter(Class<? extends OutputCommitter> theClass) Set the OutputCommitter implementation for the map-reduce job. void setOutputFormat(Class<? extends OutputFormat> theClass) Set the OutputFormat implementation for the map-reduce job. void setOutputKeyClass(Class<?> theClass) Set the key class for the job output data. void setOutputKeyComparatorClass(Class<? extends RawComparator> theClass) Set the RawComparator comparator used to compare keys. void setOutputValueClass(Class<?> theClass) Set the value class for job outputs. void setOutputValueGroupingComparator(Class<? extends RawComparator> theClass) Set the user defined RawComparator comparator for   grouping keys in the input to the reduce. void setPartitionerClass(Class<? extends Partitioner> theClass) Set the Partitioner class used to partition   Mapper-outputs to be sent to the Reducers. void setProfileEnabled(boolean newValue) Set whether the system should collect profiler information for some of   the tasks in this job? The information is stored in the user log   directory. void setProfileParams(String value) Set the profiler configuration arguments. void setProfileTaskRange(boolean isMap,                                       String newValue) Set the ranges of maps or reduces to profile. void setQueueName(String queueName) Set the name of the queue to which this job should be submitted. void setReduceDebugScript(String rDbgScript) Set the debug script to run when the reduce tasks fail. void setReducerClass(Class<? extends Reducer> theClass) Set the Reducer class for the job. void setReduceSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job for reduce tasks. void setSessionId(String sessionId) Deprecated.  void setSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job. void setUseNewMapper(boolean flag) Set whether the framework should use the new api for the mapper. void setUseNewReducer(boolean flag) Set whether the framework should use the new api for the reducer. void setUser(String user) Set the reported username for this job. void setWorkingDirectory(Path dir) Set the current working directory for the default file system. Methods inherited from class org.apache.hadoop.conf.Configuration addDefaultResource, addDeprecation, addDeprecation, addDeprecation, addDeprecation, addDeprecations, addResource, addResource, addResource, addResource, addResource, addResource, clear, dumpConfiguration, dumpDeprecatedKeys, get, get, getBoolean, getClass, getClass, getClassByName, getClassByNameOrNull, getClasses, getClassLoader, getConfResourceAsInputStream, getConfResourceAsReader, getDouble, getEnum, getFile, getFinalParameters, getFloat, getInstances, getInt, getInts, getLocalPath, getLong, getLongBytes, getPassword, getPasswordFromConfig, getPasswordFromCredentialProviders, getPattern, getPropertySources, getProps, getRange, getRaw, getResource, getSocketAddr, getSocketAddr, getStringCollection, getStrings, getStrings, getTimeDuration, getTrimmed, getTrimmed, getTrimmedStringCollection, getTrimmedStrings, getTrimmedStrings, getValByRegex, hasWarnedDeprecation, isDeprecated, iterator, main, onlyKeyExists, readFields, reloadConfiguration, set, set, setAllowNullValueProperties, setBoolean, setBooleanIfUnset, setClass, setClassLoader, setDeprecatedProperties, setDouble, setEnum, setFloat, setIfUnset, setInt, setLong, setPattern, setQuietMode, setSocketAddr, setStrings, setTimeDuration, size, toString, unset, updateConnectAddr, updateConnectAddr, write, writeXml, writeXml Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail MAPRED_TASK_MAXVMEM_PROPERTY @Deprecated public static final String MAPRED_TASK_MAXVMEM_PROPERTY Deprecated. Use MAPREDUCE_JOB_MAP_MEMORY_MB_PROPERTY and  MAPREDUCE_JOB_REDUCE_MEMORY_MB_PROPERTY See Also:Constant Field Values UPPER_LIMIT_ON_TASK_VMEM_PROPERTY @Deprecated public static final String UPPER_LIMIT_ON_TASK_VMEM_PROPERTY Deprecated.  See Also:Constant Field Values MAPRED_TASK_DEFAULT_MAXVMEM_PROPERTY @Deprecated public static final String MAPRED_TASK_DEFAULT_MAXVMEM_PROPERTY Deprecated.  See Also:Constant Field Values MAPRED_TASK_MAXPMEM_PROPERTY @Deprecated public static final String MAPRED_TASK_MAXPMEM_PROPERTY Deprecated.  See Also:Constant Field Values DISABLED_MEMORY_LIMIT @Deprecated public static final long DISABLED_MEMORY_LIMIT Deprecated.  A value which if set for memory related configuration options,  indicates that the options are turned off.  Deprecated because it makes no sense in the context of MR2. See Also:Constant Field Values MAPRED_LOCAL_DIR_PROPERTY public static final String MAPRED_LOCAL_DIR_PROPERTY Property name for the configuration property mapreduce.cluster.local.dir See Also:Constant Field Values DEFAULT_QUEUE_NAME public static final String DEFAULT_QUEUE_NAME Name of the queue to which jobs will be submitted, if no queue  name is mentioned. See Also:Constant Field Values MAPRED_JOB_MAP_MEMORY_MB_PROPERTY @Deprecated public static final String MAPRED_JOB_MAP_MEMORY_MB_PROPERTY Deprecated.  The variable is kept for M/R 1.x applications, while M/R 2.x applications  should use MAPREDUCE_JOB_MAP_MEMORY_MB_PROPERTY See Also:Constant Field Values MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY @Deprecated public static final String MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY Deprecated.  The variable is kept for M/R 1.x applications, while M/R 2.x applications  should use MAPREDUCE_JOB_REDUCE_MEMORY_MB_PROPERTY See Also:Constant Field Values UNPACK_JAR_PATTERN_DEFAULT public static final Pattern UNPACK_JAR_PATTERN_DEFAULT Pattern for the default unpacking behavior for job jars MAPRED_TASK_JAVA_OPTS @Deprecated public static final String MAPRED_TASK_JAVA_OPTS Deprecated. Use MAPRED_MAP_TASK_JAVA_OPTS or                   MAPRED_REDUCE_TASK_JAVA_OPTS Configuration key to set the java command line options for the child  map and reduce tasks.    Java opts for the task tracker child processes.  The following symbol, if present, will be interpolated: @taskid@.   It is replaced by current TaskID. Any other occurrences of '@' will go   unchanged.  For example, to enable verbose gc logging to a file named for the taskid in  /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:           -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc    The configuration variable MAPRED_TASK_ENV can be used to pass   other environment variables to the child processes. See Also:Constant Field Values MAPRED_MAP_TASK_JAVA_OPTS public static final String MAPRED_MAP_TASK_JAVA_OPTS Configuration key to set the java command line options for the map tasks.    Java opts for the task tracker child map processes.  The following symbol, if present, will be interpolated: @taskid@.   It is replaced by current TaskID. Any other occurrences of '@' will go   unchanged.  For example, to enable verbose gc logging to a file named for the taskid in  /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:           -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc    The configuration variable MAPRED_MAP_TASK_ENV can be used to pass   other environment variables to the map processes. See Also:Constant Field Values MAPRED_REDUCE_TASK_JAVA_OPTS public static final String MAPRED_REDUCE_TASK_JAVA_OPTS Configuration key to set the java command line options for the reduce tasks.    Java opts for the task tracker child reduce processes.  The following symbol, if present, will be interpolated: @taskid@.   It is replaced by current TaskID. Any other occurrences of '@' will go   unchanged.  For example, to enable verbose gc logging to a file named for the taskid in  /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:           -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc    The configuration variable MAPRED_REDUCE_TASK_ENV can be used to   pass process environment variables to the reduce processes. See Also:Constant Field Values DEFAULT_MAPRED_TASK_JAVA_OPTS public static final String DEFAULT_MAPRED_TASK_JAVA_OPTS See Also:Constant Field Values MAPRED_TASK_ULIMIT @Deprecated public static final String MAPRED_TASK_ULIMIT Deprecated. Configuration key to set the maximum virtual memory available to the child  map and reduce tasks (in kilo-bytes). This has been deprecated and will no  longer have any effect. See Also:Constant Field Values MAPRED_MAP_TASK_ULIMIT @Deprecated public static final String MAPRED_MAP_TASK_ULIMIT Deprecated. Configuration key to set the maximum virtual memory available to the  map tasks (in kilo-bytes). This has been deprecated and will no  longer have any effect. See Also:Constant Field Values MAPRED_REDUCE_TASK_ULIMIT @Deprecated public static final String MAPRED_REDUCE_TASK_ULIMIT Deprecated. Configuration key to set the maximum virtual memory available to the  reduce tasks (in kilo-bytes). This has been deprecated and will no  longer have any effect. See Also:Constant Field Values MAPRED_TASK_ENV @Deprecated public static final String MAPRED_TASK_ENV Deprecated. Use MAPRED_MAP_TASK_ENV or                   MAPRED_REDUCE_TASK_ENV Configuration key to set the environment of the child map/reduce tasks.    The format of the value is k1=v1,k2=v2. Further it can   reference existing environment variables via $key on  Linux or %key% on Windows.    Example:       A=foo - This will set the env variable A to foo.      B=$X:c This is inherit tasktracker's X env variable on Linux.      B=%X%;c This is inherit tasktracker's X env variable on Windows.    See Also:Constant Field Values MAPRED_MAP_TASK_ENV public static final String MAPRED_MAP_TASK_ENV Configuration key to set the environment of the child map tasks.    The format of the value is k1=v1,k2=v2. Further it can  reference existing environment variables via $key on  Linux or %key% on Windows.    Example:       A=foo - This will set the env variable A to foo.      B=$X:c This is inherit tasktracker's X env variable on Linux.      B=%X%;c This is inherit tasktracker's X env variable on Windows.    See Also:Constant Field Values MAPRED_REDUCE_TASK_ENV public static final String MAPRED_REDUCE_TASK_ENV Configuration key to set the environment of the child reduce tasks.    The format of the value is k1=v1,k2=v2. Further it can   reference existing environment variables via $key on  Linux or %key% on Windows.    Example:       A=foo - This will set the env variable A to foo.      B=$X:c This is inherit tasktracker's X env variable on Linux.      B=%X%;c This is inherit tasktracker's X env variable on Windows.    See Also:Constant Field Values MAPRED_MAP_TASK_LOG_LEVEL public static final String MAPRED_MAP_TASK_LOG_LEVEL Configuration key to set the logging Level for the map task.  The allowed logging levels are:  OFF, FATAL, ERROR, WARN, INFO, DEBUG, TRACE and ALL. See Also:Constant Field Values MAPRED_REDUCE_TASK_LOG_LEVEL public static final String MAPRED_REDUCE_TASK_LOG_LEVEL Configuration key to set the logging Level for the reduce task.  The allowed logging levels are:  OFF, FATAL, ERROR, WARN, INFO, DEBUG, TRACE and ALL. See Also:Constant Field Values DEFAULT_LOG_LEVEL public static final org.apache.log4j.Level DEFAULT_LOG_LEVEL Default logging level for map/reduce tasks. WORKFLOW_ID @Deprecated public static final String WORKFLOW_ID Deprecated.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.WORKFLOW_ID instead See Also:Constant Field Values WORKFLOW_NAME @Deprecated public static final String WORKFLOW_NAME Deprecated.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.WORKFLOW_NAME instead See Also:Constant Field Values WORKFLOW_NODE_NAME @Deprecated public static final String WORKFLOW_NODE_NAME Deprecated.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.WORKFLOW_NODE_NAME instead See Also:Constant Field Values WORKFLOW_ADJACENCY_PREFIX_STRING @Deprecated public static final String WORKFLOW_ADJACENCY_PREFIX_STRING Deprecated.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.WORKFLOW_ADJACENCY_PREFIX_STRING instead See Also:Constant Field Values WORKFLOW_ADJACENCY_PREFIX_PATTERN @Deprecated public static final String WORKFLOW_ADJACENCY_PREFIX_PATTERN Deprecated.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.WORKFLOW_ADJACENCY_PREFIX_PATTERN instead See Also:Constant Field Values WORKFLOW_TAGS @Deprecated public static final String WORKFLOW_TAGS Deprecated.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  use MRJobConfig.WORKFLOW_TAGS instead See Also:Constant Field Values MAPREDUCE_RECOVER_JOB @Deprecated public static final String MAPREDUCE_RECOVER_JOB Deprecated.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  not use it See Also:Constant Field Values DEFAULT_MAPREDUCE_RECOVER_JOB @Deprecated public static final boolean DEFAULT_MAPREDUCE_RECOVER_JOB Deprecated.  The variable is kept for M/R 1.x applications, M/R 2.x applications should  not use it See Also:Constant Field Values Constructor Detail JobConf public JobConf() Construct a map/reduce job configuration. JobConf public JobConf(Class exampleClass) Construct a map/reduce job configuration. Parameters:exampleClass - a class whose containing jar is used as the job's jar. JobConf public JobConf(Configuration conf) Construct a map/reduce job configuration. Parameters:conf - a Configuration whose settings will be inherited. JobConf public JobConf(Configuration conf,        Class exampleClass) Construct a map/reduce job configuration. Parameters:conf - a Configuration whose settings will be inherited.exampleClass - a class whose containing jar is used as the job's jar. JobConf public JobConf(String config) Construct a map/reduce configuration. Parameters:config - a Configuration-format XML job description file. JobConf public JobConf(Path config) Construct a map/reduce configuration. Parameters:config - a Configuration-format XML job description file. JobConf public JobConf(boolean loadDefaults) A new map/reduce configuration where the behavior of reading from the  default resources can be turned off.    If the parameter loadDefaults is false, the new instance  will not load resources from the default files. Parameters:loadDefaults - specifies whether to load from the default files Method Detail getCredentials public org.apache.hadoop.security.Credentials getCredentials() Get credentials for the job. Returns:credentials for the job getJar public String getJar() Get the user jar for the map-reduce job. Returns:the user jar for the map-reduce job. setJar public void setJar(String jar) Set the user jar for the map-reduce job. Parameters:jar - the user jar for the map-reduce job. getJarUnpackPattern public Pattern getJarUnpackPattern() Get the pattern for jar contents to unpack on the tasktracker setJarByClass public void setJarByClass(Class cls) Set the job's jar file by finding an example class location. Parameters:cls - the example class. getLocalDirs public String[] getLocalDirs()                       throws IOException Throws: IOException deleteLocalFiles @Deprecated public void deleteLocalFiles()                       throws IOException Deprecated.  Use MRAsyncDiskService.moveAndDeleteAllVolumes instead. Throws: IOException deleteLocalFiles public void deleteLocalFiles(String subdir)                       throws IOException Throws: IOException getLocalPath public Path getLocalPath(String pathString)                   throws IOException Constructs a local file name. Files are distributed among configured  local directories. Throws: IOException getUser public String getUser() Get the reported username for this job. Returns:the username setUser public void setUser(String user) Set the reported username for this job. Parameters:user - the username for this job. setKeepFailedTaskFiles public void setKeepFailedTaskFiles(boolean keep) Set whether the framework should keep the intermediate files for   failed tasks. Parameters:keep - true if framework should keep the intermediate files               for failed tasks, false otherwise. getKeepFailedTaskFiles public boolean getKeepFailedTaskFiles() Should the temporary files for failed tasks be kept? Returns:should the files be kept? setKeepTaskFilesPattern public void setKeepTaskFilesPattern(String pattern) Set a regular expression for task names that should be kept.   The regular expression ".*_m_000123_0" would keep the files  for the first instance of map 123 that ran. Parameters:pattern - the java.util.regex.Pattern to match against the          task names. getKeepTaskFilesPattern public String getKeepTaskFilesPattern() Get the regular expression that is matched against the task names  to see if we need to keep the files. Returns:the pattern as a string, if it was set, othewise null. setWorkingDirectory public void setWorkingDirectory(Path dir) Set the current working directory for the default file system. Parameters:dir - the new current working directory. getWorkingDirectory public Path getWorkingDirectory() Get the current working directory for the default file system. Returns:the directory name. setNumTasksToExecutePerJvm public void setNumTasksToExecutePerJvm(int numTasks) Sets the number of tasks that a spawned task JVM should run  before it exits Parameters:numTasks - the number of tasks to execute; defaults to 1;  -1 signifies no limit getNumTasksToExecutePerJvm public int getNumTasksToExecutePerJvm() Get the number of tasks that a spawned JVM should execute getInputFormat public InputFormat getInputFormat() Get the InputFormat implementation for the map-reduce job,  defaults to TextInputFormat if not specified explicity. Returns:the InputFormat implementation for the map-reduce job. setInputFormat public void setInputFormat(Class<? extends InputFormat> theClass) Set the InputFormat implementation for the map-reduce job. Parameters:theClass - the InputFormat implementation for the map-reduce                   job. getOutputFormat public OutputFormat getOutputFormat() Get the OutputFormat implementation for the map-reduce job,  defaults to TextOutputFormat if not specified explicity. Returns:the OutputFormat implementation for the map-reduce job. getOutputCommitter public OutputCommitter getOutputCommitter() Get the OutputCommitter implementation for the map-reduce job,  defaults to FileOutputCommitter if not specified explicitly. Returns:the OutputCommitter implementation for the map-reduce job. setOutputCommitter public void setOutputCommitter(Class<? extends OutputCommitter> theClass) Set the OutputCommitter implementation for the map-reduce job. Parameters:theClass - the OutputCommitter implementation for the map-reduce                   job. setOutputFormat public void setOutputFormat(Class<? extends OutputFormat> theClass) Set the OutputFormat implementation for the map-reduce job. Parameters:theClass - the OutputFormat implementation for the map-reduce                   job. setCompressMapOutput public void setCompressMapOutput(boolean compress) Should the map outputs be compressed before transfer? Parameters:compress - should the map outputs be compressed? getCompressMapOutput public boolean getCompressMapOutput() Are the outputs of the maps be compressed? Returns:true if the outputs of the maps are to be compressed,          false otherwise. setMapOutputCompressorClass public void setMapOutputCompressorClass(Class<? extends CompressionCodec> codecClass) Set the given class as the  CompressionCodec for the map outputs. Parameters:codecClass - the CompressionCodec class that will compress                      the map outputs. getMapOutputCompressorClass public Class<? extends CompressionCodec> getMapOutputCompressorClass(Class<? extends CompressionCodec> defaultValue) Get the CompressionCodec for compressing the map outputs. Parameters:defaultValue - the CompressionCodec to return if not set Returns:the CompressionCodec class that should be used to compress the           map outputs. Throws: IllegalArgumentException - if the class was specified, but not found getMapOutputKeyClass public Class<?> getMapOutputKeyClass() Get the key class for the map output data. If it is not set, use the  (final) output key class. This allows the map output key class to be  different than the final output key class. Returns:the map output key class. setMapOutputKeyClass public void setMapOutputKeyClass(Class<?> theClass) Set the key class for the map output data. This allows the user to  specify the map output key class to be different than the final output  value class. Parameters:theClass - the map output key class. getMapOutputValueClass public Class<?> getMapOutputValueClass() Get the value class for the map output data. If it is not set, use the  (final) output value class This allows the map output value class to be  different than the final output value class. Returns:the map output value class. setMapOutputValueClass public void setMapOutputValueClass(Class<?> theClass) Set the value class for the map output data. This allows the user to  specify the map output value class to be different than the final output  value class. Parameters:theClass - the map output value class. getOutputKeyClass public Class<?> getOutputKeyClass() Get the key class for the job output data. Returns:the key class for the job output data. setOutputKeyClass public void setOutputKeyClass(Class<?> theClass) Set the key class for the job output data. Parameters:theClass - the key class for the job output data. getOutputKeyComparator public RawComparator getOutputKeyComparator() Get the RawComparator comparator used to compare keys. Returns:the RawComparator comparator used to compare keys. setOutputKeyComparatorClass public void setOutputKeyComparatorClass(Class<? extends RawComparator> theClass) Set the RawComparator comparator used to compare keys. Parameters:theClass - the RawComparator comparator used to                   compare keys.See Also:setOutputValueGroupingComparator(Class) setKeyFieldComparatorOptions public void setKeyFieldComparatorOptions(String keySpec) Set the KeyFieldBasedComparator options used to compare keys. Parameters:keySpec - the key specification of the form -k pos1[,pos2], where,   pos is of the form f[.c][opts], where f is the number   of the key field to use, and c is the number of the first character from   the beginning of the field. Fields and character posns are numbered    starting with 1; a character position of zero in pos2 indicates the   field's last character. If '.c' is omitted from pos1, it defaults to 1   (the beginning of the field); if omitted from pos2, it defaults to 0    (the end of the field). opts are ordering options. The supported options   are:     -n, (Sort numerically)     -r, (Reverse the result of comparison) getKeyFieldComparatorOption public String getKeyFieldComparatorOption() Get the KeyFieldBasedComparator options setKeyFieldPartitionerOptions public void setKeyFieldPartitionerOptions(String keySpec) Set the KeyFieldBasedPartitioner options used for   Partitioner Parameters:keySpec - the key specification of the form -k pos1[,pos2], where,   pos is of the form f[.c][opts], where f is the number   of the key field to use, and c is the number of the first character from   the beginning of the field. Fields and character posns are numbered    starting with 1; a character position of zero in pos2 indicates the   field's last character. If '.c' is omitted from pos1, it defaults to 1   (the beginning of the field); if omitted from pos2, it defaults to 0    (the end of the field). getKeyFieldPartitionerOption public String getKeyFieldPartitionerOption() Get the KeyFieldBasedPartitioner options getCombinerKeyGroupingComparator public RawComparator getCombinerKeyGroupingComparator() Get the user defined WritableComparable comparator for  grouping keys of inputs to the combiner. Returns:comparator set by the user for grouping values.See Also:for details. getOutputValueGroupingComparator public RawComparator getOutputValueGroupingComparator() Get the user defined WritableComparable comparator for   grouping keys of inputs to the reduce. Returns:comparator set by the user for grouping values.See Also:for details. setCombinerKeyGroupingComparator public void setCombinerKeyGroupingComparator(Class<? extends RawComparator> theClass) Set the user defined RawComparator comparator for  grouping keys in the input to the combiner.  This comparator should be provided if the equivalence rules for keys  for sorting the intermediates are different from those for grouping keys  before each call to  Reducer.reduce(Object, java.util.Iterator, OutputCollector, Reporter).  For key-value pairs (K1,V1) and (K2,V2), the values (V1, V2) are passed  in a single call to the reduce function if K1 and K2 compare as equal.  Since setOutputKeyComparatorClass(Class) can be used to control  how keys are sorted, this can be used in conjunction to simulate  secondary sort on values.  Note: This is not a guarantee of the combiner sort being  stable in any sense. (In any case, with the order of available  map-outputs to the combiner being non-deterministic, it wouldn't make  that much sense.) Parameters:theClass - the comparator class to be used for grouping keys for the  combiner. It should implement RawComparator.See Also:setOutputKeyComparatorClass(Class) setOutputValueGroupingComparator public void setOutputValueGroupingComparator(Class<? extends RawComparator> theClass) Set the user defined RawComparator comparator for   grouping keys in the input to the reduce.    This comparator should be provided if the equivalence rules for keys  for sorting the intermediates are different from those for grouping keys  before each call to   Reducer.reduce(Object, java.util.Iterator, OutputCollector, Reporter).     For key-value pairs (K1,V1) and (K2,V2), the values (V1, V2) are passed  in a single call to the reduce function if K1 and K2 compare as equal.    Since setOutputKeyComparatorClass(Class) can be used to control   how keys are sorted, this can be used in conjunction to simulate   secondary sort on values.     Note: This is not a guarantee of the reduce sort being   stable in any sense. (In any case, with the order of available   map-outputs to the reduce being non-deterministic, it wouldn't make   that much sense.) Parameters:theClass - the comparator class to be used for grouping keys.                   It should implement RawComparator.See Also:setOutputKeyComparatorClass(Class),  setCombinerKeyGroupingComparator(Class) getUseNewMapper public boolean getUseNewMapper() Should the framework use the new context-object code for running  the mapper? Returns:true, if the new api should be used setUseNewMapper public void setUseNewMapper(boolean flag) Set whether the framework should use the new api for the mapper.  This is the default for jobs submitted with the new Job api. Parameters:flag - true, if the new api should be used getUseNewReducer public boolean getUseNewReducer() Should the framework use the new context-object code for running  the reducer? Returns:true, if the new api should be used setUseNewReducer public void setUseNewReducer(boolean flag) Set whether the framework should use the new api for the reducer.   This is the default for jobs submitted with the new Job api. Parameters:flag - true, if the new api should be used getOutputValueClass public Class<?> getOutputValueClass() Get the value class for job outputs. Returns:the value class for job outputs. setOutputValueClass public void setOutputValueClass(Class<?> theClass) Set the value class for job outputs. Parameters:theClass - the value class for job outputs. getMapperClass public Class<? extends Mapper> getMapperClass() Get the Mapper class for the job. Returns:the Mapper class for the job. setMapperClass public void setMapperClass(Class<? extends Mapper> theClass) Set the Mapper class for the job. Parameters:theClass - the Mapper class for the job. getMapRunnerClass public Class<? extends MapRunnable> getMapRunnerClass() Get the MapRunnable class for the job. Returns:the MapRunnable class for the job. setMapRunnerClass public void setMapRunnerClass(Class<? extends MapRunnable> theClass) Expert: Set the MapRunnable class for the job.    Typically used to exert greater control on Mappers. Parameters:theClass - the MapRunnable class for the job. getPartitionerClass public Class<? extends Partitioner> getPartitionerClass() Get the Partitioner used to partition Mapper-outputs   to be sent to the Reducers. Returns:the Partitioner used to partition map-outputs. setPartitionerClass public void setPartitionerClass(Class<? extends Partitioner> theClass) Set the Partitioner class used to partition   Mapper-outputs to be sent to the Reducers. Parameters:theClass - the Partitioner used to partition map-outputs. getReducerClass public Class<? extends Reducer> getReducerClass() Get the Reducer class for the job. Returns:the Reducer class for the job. setReducerClass public void setReducerClass(Class<? extends Reducer> theClass) Set the Reducer class for the job. Parameters:theClass - the Reducer class for the job. getCombinerClass public Class<? extends Reducer> getCombinerClass() Get the user-defined combiner class used to combine map-outputs   before being sent to the reducers. Typically the combiner is same as the  the Reducer for the job i.e. getReducerClass(). Returns:the user-defined combiner class used to combine map-outputs. setCombinerClass public void setCombinerClass(Class<? extends Reducer> theClass) Set the user-defined combiner class used to combine map-outputs   before being sent to the reducers.     The combiner is an application-specified aggregation operation, which  can help cut down the amount of data transferred between the   Mapper and the Reducer, leading to better performance.    The framework may invoke the combiner 0, 1, or multiple times, in both  the mapper and reducer tasks. In general, the combiner is called as the  sort/merge result is written to disk. The combiner must:       be side-effect free     have the same input and output key types and the same input and          output value types      Typically the combiner is same as the Reducer for the    job i.e. setReducerClass(Class). Parameters:theClass - the user-defined combiner class used to combine                   map-outputs. getSpeculativeExecution public boolean getSpeculativeExecution() Should speculative execution be used for this job?   Defaults to true. Returns:true if speculative execution be used for this job,          false otherwise. setSpeculativeExecution public void setSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job. Parameters:speculativeExecution - true if speculative execution                               should be turned on, else false. getMapSpeculativeExecution public boolean getMapSpeculativeExecution() Should speculative execution be used for this job for map tasks?   Defaults to true. Returns:true if speculative execution be                             used for this job for map tasks,          false otherwise. setMapSpeculativeExecution public void setMapSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job for map tasks. Parameters:speculativeExecution - true if speculative execution                               should be turned on for map tasks,                              else false. getReduceSpeculativeExecution public boolean getReduceSpeculativeExecution() Should speculative execution be used for this job for reduce tasks?   Defaults to true. Returns:true if speculative execution be used                             for reduce tasks for this job,          false otherwise. setReduceSpeculativeExecution public void setReduceSpeculativeExecution(boolean speculativeExecution) Turn speculative execution on or off for this job for reduce tasks. Parameters:speculativeExecution - true if speculative execution                               should be turned on for reduce tasks,                              else false. getNumMapTasks public int getNumMapTasks() Get configured the number of reduce tasks for this job.  Defaults to 1. Returns:the number of reduce tasks for this job. setNumMapTasks public void setNumMapTasks(int n) Set the number of map tasks for this job.    Note: This is only a hint to the framework. The actual   number of spawned map tasks depends on the number of InputSplits   generated by the job's InputFormat.getSplits(JobConf, int).     A custom InputFormat is typically used to accurately control   the number of map tasks for the job.    How many maps?    The number of maps is usually driven by the total size of the inputs   i.e. total number of blocks of the input files.     The right level of parallelism for maps seems to be around 10-100 maps   per-node, although it has been set up to 300 or so for very cpu-light map   tasks. Task setup takes awhile, so it is best if the maps take at least a   minute to execute.    The default behavior of file-based InputFormats is to split the   input into logical InputSplits based on the total size, in   bytes, of input files. However, the FileSystem blocksize of the   input files is treated as an upper bound for input splits. A lower bound   on the split size can be set via     mapreduce.input.fileinputformat.split.minsize.     Thus, if you expect 10TB of input data and have a blocksize of 128MB,   you'll end up with 82,000 maps, unless setNumMapTasks(int) is   used to set it even higher. Parameters:n - the number of map tasks for this job.See Also:InputFormat.getSplits(JobConf, int),  FileInputFormat,  FileSystem.getDefaultBlockSize(),  FileStatus.getBlockSize() getNumReduceTasks public int getNumReduceTasks() Get configured the number of reduce tasks for this job. Defaults to   1. Returns:the number of reduce tasks for this job. setNumReduceTasks public void setNumReduceTasks(int n) Set the requisite number of reduce tasks for this job.    How many reduces?    The right number of reduces seems to be 0.95 or   1.75 multiplied by (<no. of nodes> *     mapreduce.tasktracker.reduce.tasks.maximum).      With 0.95 all of the reduces can launch immediately and   start transfering map outputs as the maps finish. With 1.75   the faster nodes will finish their first round of reduces and launch a   second wave of reduces doing a much better job of load balancing.    Increasing the number of reduces increases the framework overhead, but   increases load balancing and lowers the cost of failures.    The scaling factors above are slightly less than whole numbers to   reserve a few reduce slots in the framework for speculative-tasks, failures  etc.   Reducer NONE    It is legal to set the number of reduce-tasks to zero.    In this case the output of the map-tasks directly go to distributed   file-system, to the path set by   FileOutputFormat.setOutputPath(JobConf, Path). Also, the   framework doesn't sort the map-outputs before writing it out to HDFS. Parameters:n - the number of reduce tasks for this job. getMaxMapAttempts public int getMaxMapAttempts() Get the configured number of maximum attempts that will be made to run a  map task, as specified by the mapreduce.map.maxattempts  property. If this property is not already set, the default is 4 attempts. Returns:the max number of attempts per map task. setMaxMapAttempts public void setMaxMapAttempts(int n) Expert: Set the number of maximum attempts that will be made to run a  map task. Parameters:n - the number of attempts per map task. getMaxReduceAttempts public int getMaxReduceAttempts() Get the configured number of maximum attempts  that will be made to run a  reduce task, as specified by the mapreduce.reduce.maxattempts  property. If this property is not already set, the default is 4 attempts. Returns:the max number of attempts per reduce task. setMaxReduceAttempts public void setMaxReduceAttempts(int n) Expert: Set the number of maximum attempts that will be made to run a  reduce task. Parameters:n - the number of attempts per reduce task. getJobName public String getJobName() Get the user-specified job name. This is only used to identify the   job to the user. Returns:the job's name, defaulting to "". setJobName public void setJobName(String name) Set the user-specified job name. Parameters:name - the job's new name. getSessionId @Deprecated public String getSessionId() Deprecated.  Get the user-specified session identifier. The default is the empty string.  The session identifier is used to tag metric data that is reported to some  performance metrics system via the org.apache.hadoop.metrics API.  The   session identifier is intended, in particular, for use by Hadoop-On-Demand   (HOD) which allocates a virtual Hadoop cluster dynamically and transiently.   HOD will set the session identifier by modifying the mapred-site.xml file   before starting the cluster.  When not running under HOD, this identifer is expected to remain set to   the empty string. Returns:the session identifier, defaulting to "". setSessionId @Deprecated public void setSessionId(String sessionId) Deprecated.  Set the user-specified session identifier. Parameters:sessionId - the new session id. setMaxTaskFailuresPerTracker public void setMaxTaskFailuresPerTracker(int noFailures) Set the maximum no. of failures of a given job per tasktracker.  If the no. of task failures exceeds noFailures, the   tasktracker is blacklisted for this job. Parameters:noFailures - maximum no. of failures of a given job per tasktracker. getMaxTaskFailuresPerTracker public int getMaxTaskFailuresPerTracker() Expert: Get the maximum no. of failures of a given job per tasktracker.  If the no. of task failures exceeds this, the tasktracker is  blacklisted for this job. Returns:the maximum no. of failures of a given job per tasktracker. getMaxMapTaskFailuresPercent public int getMaxMapTaskFailuresPercent() Get the maximum percentage of map tasks that can fail without   the job being aborted.     Each map task is executed a minimum of getMaxMapAttempts()   attempts before being declared as failed.     Defaults to zero, i.e. any failed map-task results in  the job being declared as JobStatus.FAILED. Returns:the maximum percentage of map tasks that can fail without          the job being aborted. setMaxMapTaskFailuresPercent public void setMaxMapTaskFailuresPercent(int percent) Expert: Set the maximum percentage of map tasks that can fail without the  job being aborted.     Each map task is executed a minimum of getMaxMapAttempts() attempts   before being declared as failed. Parameters:percent - the maximum percentage of map tasks that can fail without                  the job being aborted. getMaxReduceTaskFailuresPercent public int getMaxReduceTaskFailuresPercent() Get the maximum percentage of reduce tasks that can fail without   the job being aborted.     Each reduce task is executed a minimum of getMaxReduceAttempts()   attempts before being declared as failed.    Defaults to zero, i.e. any failed reduce-task results   in the job being declared as JobStatus.FAILED. Returns:the maximum percentage of reduce tasks that can fail without          the job being aborted. setMaxReduceTaskFailuresPercent public void setMaxReduceTaskFailuresPercent(int percent) Set the maximum percentage of reduce tasks that can fail without the job  being aborted.    Each reduce task is executed a minimum of getMaxReduceAttempts()   attempts before being declared as failed. Parameters:percent - the maximum percentage of reduce tasks that can fail without                  the job being aborted. setJobPriority public void setJobPriority(JobPriority prio) Set JobPriority for this job. Parameters:prio - the JobPriority for this job. getJobPriority public JobPriority getJobPriority() Get the JobPriority for this job. Returns:the JobPriority for this job. getProfileEnabled public boolean getProfileEnabled() Get whether the task profiling is enabled. Returns:true if some tasks will be profiled setProfileEnabled public void setProfileEnabled(boolean newValue) Set whether the system should collect profiler information for some of   the tasks in this job? The information is stored in the user log   directory. Parameters:newValue - true means it should be gathered getProfileParams public String getProfileParams() Get the profiler configuration arguments.  The default value for this property is  "-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s" Returns:the parameters to pass to the task child to configure profiling setProfileParams public void setProfileParams(String value) Set the profiler configuration arguments. If the string contains a '%s' it  will be replaced with the name of the profiling output file when the task  runs.  This value is passed to the task child JVM on the command line. Parameters:value - the configuration string getProfileTaskRange public org.apache.hadoop.conf.Configuration.IntegerRanges getProfileTaskRange(boolean isMap) Get the range of maps or reduces to profile. Parameters:isMap - is the task a map? Returns:the task ranges setProfileTaskRange public void setProfileTaskRange(boolean isMap,                        String newValue) Set the ranges of maps or reduces to profile. setProfileEnabled(true)   must also be called. Parameters:newValue - a set of integer ranges of the map ids setMapDebugScript public void setMapDebugScript(String mDbgScript) Set the debug script to run when the map tasks fail.    The debug script can aid debugging of failed map tasks. The script is   given task's stdout, stderr, syslog, jobconf files as arguments.    The debug command, run on the node where the map failed, is:    $script $stdout $stderr $syslog $jobconf.       The script file is distributed through DistributedCache   APIs. The script needs to be symlinked.     Here is an example on how to submit a script     job.setMapDebugScript("./myscript");  DistributedCache.createSymlink(job);  DistributedCache.addCacheFile("/debug/scripts/myscript#myscript");   Parameters:mDbgScript - the script name getMapDebugScript public String getMapDebugScript() Get the map task's debug script. Returns:the debug Script for the mapred job for failed map tasks.See Also:setMapDebugScript(String) setReduceDebugScript public void setReduceDebugScript(String rDbgScript) Set the debug script to run when the reduce tasks fail.    The debug script can aid debugging of failed reduce tasks. The script  is given task's stdout, stderr, syslog, jobconf files as arguments.    The debug command, run on the node where the map failed, is:    $script $stdout $stderr $syslog $jobconf.       The script file is distributed through DistributedCache   APIs. The script file needs to be symlinked     Here is an example on how to submit a script     job.setReduceDebugScript("./myscript");  DistributedCache.createSymlink(job);  DistributedCache.addCacheFile("/debug/scripts/myscript#myscript");   Parameters:rDbgScript - the script name getReduceDebugScript public String getReduceDebugScript() Get the reduce task's debug Script Returns:the debug script for the mapred job for failed reduce tasks.See Also:setReduceDebugScript(String) getJobEndNotificationURI public String getJobEndNotificationURI() Get the uri to be invoked in-order to send a notification after the job   has completed (success/failure). Returns:the job end notification uri, null if it hasn't          been set.See Also:setJobEndNotificationURI(String) setJobEndNotificationURI public void setJobEndNotificationURI(String uri) Set the uri to be invoked in-order to send a notification after the job  has completed (success/failure).    The uri can contain 2 special parameters: $jobId and   $jobStatus. Those, if present, are replaced by the job's   identifier and completion-status respectively.    This is typically used by application-writers to implement chaining of   Map-Reduce jobs in an asynchronous manner. Parameters:uri - the job end notification uriSee Also:JobStatus getJobLocalDir public String getJobLocalDir() Get job-specific shared directory for use as scratch space      When a job starts, a shared directory is created at location    ${mapreduce.cluster.local.dir}/taskTracker/$user/jobcache/$jobid/work/ .  This directory is exposed to the users through   mapreduce.job.local.dir .  So, the tasks can use this space   as scratch space and share files among them.   This value is available as System property also. Returns:The localized job specific shared directory getMemoryForMapTask public long getMemoryForMapTask() Get memory required to run a map task of the job, in MB.    If a value is specified in the configuration, it is returned.  Else, it returns MRJobConfig.DEFAULT_MAP_MEMORY_MB.    For backward compatibility, if the job configuration sets the  key MAPRED_TASK_MAXVMEM_PROPERTY to a value different  from DISABLED_MEMORY_LIMIT, that value will be used  after converting it from bytes to MB. Returns:memory required to run a map task of the job, in MB, setMemoryForMapTask public void setMemoryForMapTask(long mem) getMemoryForReduceTask public long getMemoryForReduceTask() Get memory required to run a reduce task of the job, in MB.    If a value is specified in the configuration, it is returned.  Else, it returns MRJobConfig.DEFAULT_REDUCE_MEMORY_MB.    For backward compatibility, if the job configuration sets the  key MAPRED_TASK_MAXVMEM_PROPERTY to a value different  from DISABLED_MEMORY_LIMIT, that value will be used  after converting it from bytes to MB. Returns:memory required to run a reduce task of the job, in MB. setMemoryForReduceTask public void setMemoryForReduceTask(long mem) getQueueName public String getQueueName() Return the name of the queue to which this job is submitted.  Defaults to 'default'. Returns:name of the queue setQueueName public void setQueueName(String queueName) Set the name of the queue to which this job should be submitted. Parameters:queueName - Name of the queue normalizeMemoryConfigValue public static long normalizeMemoryConfigValue(long val) Normalize the negative values in configuration Parameters:val -  Returns:normalized value findContainingJar public static String findContainingJar(Class my_class) Find a jar that contains a class of the same name, if any.  It will return a jar file, even if that is not the first thing  on the class path that has a class with the same name. Parameters:my_class - the class to find. Returns:a jar file that contains the class, or null. getMaxVirtualMemoryForTask @Deprecated public long getMaxVirtualMemoryForTask() Deprecated. Use getMemoryForMapTask() and              getMemoryForReduceTask() Get the memory required to run a task of this job, in bytes. See  MAPRED_TASK_MAXVMEM_PROPERTY    This method is deprecated. Now, different memory limits can be  set for map and reduce tasks of a job, in MB.     For backward compatibility, if the job configuration sets the  key MAPRED_TASK_MAXVMEM_PROPERTY, that value is returned.   Otherwise, this method will return the larger of the values returned by   getMemoryForMapTask() and getMemoryForReduceTask()  after converting them into bytes. Returns:Memory required to run a task of this job, in bytes.See Also:setMaxVirtualMemoryForTask(long) setMaxVirtualMemoryForTask @Deprecated public void setMaxVirtualMemoryForTask(long vmem) Deprecated. Use setMemoryForMapTask(long mem)  and   Use setMemoryForReduceTask(long mem) Set the maximum amount of memory any task of this job can use. See  MAPRED_TASK_MAXVMEM_PROPERTY    mapred.task.maxvmem is split into  mapreduce.map.memory.mb  and mapreduce.map.memory.mb,mapred  each of the new key are set  as mapred.task.maxvmem / 1024  as new values are in MB Parameters:vmem - Maximum amount of virtual memory in bytes any task of this job              can use.See Also:getMaxVirtualMemoryForTask() getMaxPhysicalMemoryForTask @Deprecated public long getMaxPhysicalMemoryForTask() Deprecated. this variable is deprecated and nolonger in use. setMaxPhysicalMemoryForTask @Deprecated public void setMaxPhysicalMemoryForTask(long mem) Deprecated.  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobConfigurable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobConfigurable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Interface JobConfigurable All Known Subinterfaces: Mapper<K1,V1,K2,V2>, MapRunnable<K1,V1,K2,V2>, Partitioner<K2,V2>, Reducer<K2,V2,K3,V3> All Known Implementing Classes: BinaryPartitioner, ChainMapper, ChainReducer, DBInputFormat, FieldSelectionMapReduce, FixedLengthInputFormat, HashPartitioner, IdentityMapper, IdentityReducer, InverseMapper, KeyFieldBasedComparator, KeyFieldBasedPartitioner, KeyValueTextInputFormat, LongSumReducer, MapReduceBase, MapRunner, MultithreadedMapRunner, NLineInputFormat, RegexMapper, TextInputFormat, TokenCountMapper, TotalOrderPartitioner, ValueAggregatorCombiner, ValueAggregatorJobBase, ValueAggregatorMapper, ValueAggregatorReducer @InterfaceAudience.Public @InterfaceStability.Stable public interface JobConfigurable That what may be configured. Method Summary Methods  Modifier and Type Method and Description void configure(JobConf job) Initializes a new instance from a JobConf. Method Detail configure void configure(JobConf job) Initializes a new instance from a JobConf. Parameters:job - the configuration Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Interface JobContext All Superinterfaces: org.apache.hadoop.mapreduce.MRJobConfig All Known Subinterfaces: JobContext, MapContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT>, ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT>, TaskAttemptContext, TaskAttemptContext, TaskInputOutputContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> All Known Implementing Classes: Job, org.apache.hadoop.mapreduce.task.JobContextImpl @InterfaceAudience.Public @InterfaceStability.Evolving public interface JobContext extends org.apache.hadoop.mapreduce.MRJobConfig A read-only view of the job that is provided to the tasks while they  are running. Field Summary Fields inherited from interface org.apache.hadoop.mapreduce.MRJobConfig APPLICATION_ATTEMPT_ID, APPLICATION_MASTER_CLASS, CACHE_ARCHIVES, CACHE_ARCHIVES_SIZES, CACHE_ARCHIVES_TIMESTAMPS, CACHE_ARCHIVES_VISIBILITIES, CACHE_FILE_TIMESTAMPS, CACHE_FILE_VISIBILITIES, CACHE_FILES, CACHE_FILES_SIZES, CACHE_LOCALARCHIVES, CACHE_LOCALFILES, CACHE_SYMLINK, CLASSPATH_ARCHIVES, CLASSPATH_FILES, COMBINE_CLASS_ATTR, COMBINE_RECORDS_BEFORE_PROGRESS, COMBINER_GROUP_COMPARATOR_CLASS, COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, COUNTER_GROUP_NAME_MAX_DEFAULT, COUNTER_GROUP_NAME_MAX_KEY, COUNTER_GROUPS_MAX_DEFAULT, COUNTER_GROUPS_MAX_KEY, COUNTER_NAME_MAX_DEFAULT, COUNTER_NAME_MAX_KEY, COUNTERS_MAX_DEFAULT, COUNTERS_MAX_KEY, DEFAULT_JOB_ACL_MODIFY_JOB, DEFAULT_JOB_ACL_VIEW_JOB, DEFAULT_JOB_AM_ACCESS_DISABLED, DEFAULT_JOB_RUNNING_MAP_LIMIT, DEFAULT_JOB_RUNNING_REDUCE_LIMIT, DEFAULT_JOB_TOKEN_TRACKING_IDS_ENABLED, DEFAULT_LOG_LEVEL, DEFAULT_MAP_CPU_VCORES, DEFAULT_MAP_MEMORY_MB, DEFAULT_MAPRED_ADMIN_JAVA_OPTS, DEFAULT_MAPRED_ADMIN_USER_ENV, DEFAULT_MAPREDUCE_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_CROSS_PLATFORM_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA, DEFAULT_MAX_ALLOWED_FETCH_FAILURES_FRACTION, DEFAULT_MAX_FETCH_FAILURES_NOTIFICATIONS, DEFAULT_MAX_SHUFFLE_FETCH_HOST_FAILURES, DEFAULT_MAX_SHUFFLE_FETCH_RETRY_DELAY, DEFAULT_MR_AM_ADMIN_COMMAND_OPTS, DEFAULT_MR_AM_COMMAND_OPTS, DEFAULT_MR_AM_COMMIT_WINDOW_MS, DEFAULT_MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, DEFAULT_MR_AM_CPU_VCORES, DEFAULT_MR_AM_HARD_KILL_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, DEFAULT_MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERCENT, DEFAULT_MR_AM_JOB_CLIENT_THREAD_COUNT, DEFAULT_MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, DEFAULT_MR_AM_JOB_REDUCE_RAMP_UP_LIMIT, DEFAULT_MR_AM_LOG_BACKUPS, DEFAULT_MR_AM_LOG_KB, DEFAULT_MR_AM_LOG_LEVEL, DEFAULT_MR_AM_MAX_ATTEMPTS, DEFAULT_MR_AM_NUM_PROGRESS_SPLITS, DEFAULT_MR_AM_PROFILE, DEFAULT_MR_AM_STAGING_DIR, DEFAULT_MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, DEFAULT_MR_AM_TASK_LISTENER_THREAD_COUNT, DEFAULT_MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, DEFAULT_MR_AM_TO_RM_WAIT_INTERVAL_MS, DEFAULT_MR_AM_VMEM_MB, DEFAULT_MR_CLIENT_JOB_MAX_RETRIES, DEFAULT_MR_CLIENT_JOB_RETRY_INTERVAL, DEFAULT_MR_CLIENT_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, DEFAULT_MR_JOB_END_NOTIFICATION_TIMEOUT, DEFAULT_MR_JOB_REDUCER_PREEMPT_DELAY_SEC, DEFAULT_REDUCE_CPU_VCORES, DEFAULT_REDUCE_MEMORY_MB, DEFAULT_REDUCE_SEPARATE_SHUFFLE_LOG, DEFAULT_SHELL, DEFAULT_SHUFFLE_FETCH_RETRY_INTERVAL_MS, DEFAULT_SHUFFLE_INPUT_BUFFER_PERCENT, DEFAULT_SHUFFLE_LOG_BACKUPS, DEFAULT_SHUFFLE_LOG_KB, DEFAULT_SPECULATIVE_MINIMUM_ALLOWED_TASKS, DEFAULT_SPECULATIVE_RETRY_AFTER_NO_SPECULATE, DEFAULT_SPECULATIVE_RETRY_AFTER_SPECULATE, DEFAULT_SPECULATIVECAP_RUNNING_TASKS, DEFAULT_SPECULATIVECAP_TOTAL_TASKS, DEFAULT_SPLIT_METAINFO_MAXSIZE, DEFAULT_TASK_ISMAP, DEFAULT_TASK_LOG_BACKUPS, DEFAULT_TASK_PROFILE_PARAMS, GROUP_COMPARATOR_CLASS, HADOOP_WORK_DIR, ID, INDEX_CACHE_MEMORY_LIMIT, INPUT_FORMAT_CLASS_ATTR, IO_SORT_FACTOR, IO_SORT_MB, JAR, JAR_UNPACK_PATTERN, JOB_ACL_MODIFY_JOB, JOB_ACL_VIEW_JOB, JOB_AM_ACCESS_DISABLED, JOB_CANCEL_DELEGATION_TOKEN, JOB_CONF_FILE, JOB_JAR, JOB_JOBTRACKER_ID, JOB_LOCAL_DIR, JOB_NAME, JOB_NAMENODES, JOB_RUNNING_MAP_LIMIT, JOB_RUNNING_REDUCE_LIMIT, JOB_SPLIT, JOB_SPLIT_METAINFO, JOB_SUBMIT_DIR, JOB_SUBMITHOST, JOB_SUBMITHOSTADDR, JOB_TAGS, JOB_TOKEN_TRACKING_IDS, JOB_TOKEN_TRACKING_IDS_ENABLED, JOB_UBERTASK_ENABLE, JOB_UBERTASK_MAXBYTES, JOB_UBERTASK_MAXMAPS, JOB_UBERTASK_MAXREDUCES, JVM_NUMTASKS_TORUN, KEY_COMPARATOR, MAP_CLASS_ATTR, MAP_COMBINE_MIN_SPILLS, MAP_CPU_VCORES, MAP_DEBUG_SCRIPT, MAP_ENV, MAP_FAILURES_MAX_PERCENT, MAP_INPUT_FILE, MAP_INPUT_PATH, MAP_INPUT_START, MAP_JAVA_OPTS, MAP_LOG_LEVEL, MAP_MAX_ATTEMPTS, MAP_MEMORY_MB, MAP_OUTPUT_COLLECTOR_CLASS_ATTR, MAP_OUTPUT_COMPRESS, MAP_OUTPUT_COMPRESS_CODEC, MAP_OUTPUT_KEY_CLASS, MAP_OUTPUT_KEY_FIELD_SEPERATOR, MAP_OUTPUT_VALUE_CLASS, MAP_SKIP_INCR_PROC_COUNT, MAP_SKIP_MAX_RECORDS, MAP_SORT_SPILL_PERCENT, MAP_SPECULATIVE, MAPRED_ADMIN_USER_ENV, MAPRED_ADMIN_USER_SHELL, MAPRED_MAP_ADMIN_JAVA_OPTS, MAPRED_REDUCE_ADMIN_JAVA_OPTS, MAPREDUCE_APPLICATION_CLASSPATH, MAPREDUCE_APPLICATION_FRAMEWORK_PATH, MAPREDUCE_JOB_CLASSLOADER, MAPREDUCE_JOB_CLASSLOADER_SYSTEM_CLASSES, MAPREDUCE_JOB_CREDENTIALS_BINARY, MAPREDUCE_JOB_DIR, MAPREDUCE_JOB_EMIT_TIMELINE_DATA, MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE, MAPREDUCE_JOB_SHUFFLE_PROVIDER_SERVICES, MAPREDUCE_JOB_USER_CLASSPATH_FIRST, MAPREDUCE_V2_CHILD_CLASS, MAX_ALLOWED_FETCH_FAILURES_FRACTION, MAX_FETCH_FAILURES_NOTIFICATIONS, MAX_SHUFFLE_FETCH_HOST_FAILURES, MAX_SHUFFLE_FETCH_RETRY_DELAY, MAX_TASK_FAILURES_PER_TRACKER, MR_AM_ADMIN_COMMAND_OPTS, MR_AM_ADMIN_USER_ENV, MR_AM_COMMAND_OPTS, MR_AM_COMMIT_WINDOW_MS, MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, MR_AM_CPU_VCORES, MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR, MR_AM_ENV, MR_AM_HARD_KILL_TIMEOUT_MS, MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERECENT, MR_AM_JOB_CLIENT_PORT_RANGE, MR_AM_JOB_CLIENT_THREAD_COUNT, MR_AM_JOB_NODE_BLACKLISTING_ENABLE, MR_AM_JOB_RECOVERY_ENABLE, MR_AM_JOB_RECOVERY_ENABLE_DEFAULT, MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, MR_AM_JOB_REDUCE_RAMPUP_UP_LIMIT, MR_AM_JOB_SPECULATOR, MR_AM_LOG_BACKUPS, MR_AM_LOG_KB, MR_AM_LOG_LEVEL, MR_AM_MAX_ATTEMPTS, MR_AM_NUM_PROGRESS_SPLITS, MR_AM_PREFIX, MR_AM_PROFILE, MR_AM_PROFILE_PARAMS, MR_AM_SECURITY_SERVICE_AUTHORIZATION_CLIENT, MR_AM_SECURITY_SERVICE_AUTHORIZATION_TASK_UMBILICAL, MR_AM_STAGING_DIR, MR_AM_TASK_ESTIMATOR, MR_AM_TASK_ESTIMATOR_EXPONENTIAL_RATE_ENABLE, MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, MR_AM_TASK_LISTENER_THREAD_COUNT, MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, MR_AM_TO_RM_WAIT_INTERVAL_MS, MR_AM_VMEM_MB, MR_APPLICATION_TYPE, MR_CLIENT_JOB_MAX_RETRIES, MR_CLIENT_JOB_RETRY_INTERVAL, MR_CLIENT_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, MR_ENCRYPTED_INTERMEDIATE_DATA, MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, MR_JOB_END_NOTIFICATION_MAX_ATTEMPTS, MR_JOB_END_NOTIFICATION_MAX_RETRY_INTERVAL, MR_JOB_END_NOTIFICATION_PROXY, MR_JOB_END_NOTIFICATION_TIMEOUT, MR_JOB_END_NOTIFICATION_URL, MR_JOB_END_RETRY_ATTEMPTS, MR_JOB_END_RETRY_INTERVAL, MR_JOB_REDUCER_PREEMPT_DELAY_SEC, MR_PREFIX, NUM_MAP_PROFILES, NUM_MAPS, NUM_REDUCE_PROFILES, NUM_REDUCES, OUTPUT, OUTPUT_FORMAT_CLASS_ATTR, OUTPUT_KEY_CLASS, OUTPUT_VALUE_CLASS, PARTITIONER_CLASS_ATTR, PRESERVE_FAILED_TASK_FILES, PRESERVE_FILES_PATTERN, PRIORITY, QUEUE_NAME, RECORDS_BEFORE_PROGRESS, REDUCE_CLASS_ATTR, REDUCE_CPU_VCORES, REDUCE_DEBUG_SCRIPT, REDUCE_ENV, REDUCE_FAILURES_MAXPERCENT, REDUCE_INPUT_BUFFER_PERCENT, REDUCE_JAVA_OPTS, REDUCE_LOG_LEVEL, REDUCE_MARKRESET_BUFFER_PERCENT, REDUCE_MARKRESET_BUFFER_SIZE, REDUCE_MAX_ATTEMPTS, REDUCE_MEMORY_MB, REDUCE_MEMORY_TOTAL_BYTES, REDUCE_MEMTOMEM_ENABLED, REDUCE_MEMTOMEM_THRESHOLD, REDUCE_MERGE_INMEM_THRESHOLD, REDUCE_SEPARATE_SHUFFLE_LOG, REDUCE_SKIP_INCR_PROC_COUNT, REDUCE_SKIP_MAXGROUPS, REDUCE_SPECULATIVE, RESERVATION_ID, SETUP_CLEANUP_NEEDED, SHUFFLE_CONNECT_TIMEOUT, SHUFFLE_FETCH_FAILURES, SHUFFLE_FETCH_RETRY_ENABLED, SHUFFLE_FETCH_RETRY_INTERVAL_MS, SHUFFLE_FETCH_RETRY_TIMEOUT_MS, SHUFFLE_INPUT_BUFFER_PERCENT, SHUFFLE_LOG_BACKUPS, SHUFFLE_LOG_KB, SHUFFLE_MEMORY_LIMIT_PERCENT, SHUFFLE_MERGE_PERCENT, SHUFFLE_NOTIFY_READERROR, SHUFFLE_PARALLEL_COPIES, SHUFFLE_READ_TIMEOUT, SKIP_OUTDIR, SKIP_RECORDS, SKIP_START_ATTEMPTS, SPECULATIVE_MINIMUM_ALLOWED_TASKS, SPECULATIVE_RETRY_AFTER_NO_SPECULATE, SPECULATIVE_RETRY_AFTER_SPECULATE, SPECULATIVE_SLOWNODE_THRESHOLD, SPECULATIVE_SLOWTASK_THRESHOLD, SPECULATIVECAP, SPECULATIVECAP_RUNNING_TASKS, SPECULATIVECAP_TOTAL_TASKS, SPLIT_FILE, SPLIT_METAINFO_MAXSIZE, STDERR_LOGFILE_ENV, STDOUT_LOGFILE_ENV, TASK_ATTEMPT_ID, TASK_CLEANUP_NEEDED, TASK_DEBUGOUT_LINES, TASK_ID, TASK_ISMAP, TASK_LOG_BACKUPS, TASK_MAP_PROFILE_PARAMS, TASK_OUTPUT_DIR, TASK_PARTITION, TASK_PROFILE, TASK_PROFILE_PARAMS, TASK_REDUCE_PROFILE_PARAMS, TASK_TIMEOUT, TASK_TIMEOUT_CHECK_INTERVAL_MS, TASK_USERLOG_LIMIT, USER_LOG_RETAIN_HOURS, USER_NAME, WORKDIR, WORKFLOW_ADJACENCY_PREFIX_PATTERN, WORKFLOW_ADJACENCY_PREFIX_STRING, WORKFLOW_ID, WORKFLOW_NAME, WORKFLOW_NODE_NAME, WORKFLOW_TAGS, WORKING_DIR Method Summary Methods  Modifier and Type Method and Description Path[] getArchiveClassPaths() Get the archive entries in classpath as an array of Path String[] getArchiveTimestamps() Get the timestamps of the archives. URI[] getCacheArchives() Get cache archives set in the Configuration URI[] getCacheFiles() Get cache files set in the Configuration Class<? extends Reducer<?,?,?,?>> getCombinerClass() Get the combiner class for the job. RawComparator<?> getCombinerKeyGroupingComparator() Get the user defined RawComparator comparator for  grouping keys of inputs to the combiner. Configuration getConfiguration() Return the configuration for the job. org.apache.hadoop.security.Credentials getCredentials() Get credentials for the job. Path[] getFileClassPaths() Get the file entries in classpath as an array of Path String[] getFileTimestamps() Get the timestamps of the files. RawComparator<?> getGroupingComparator() Get the user defined RawComparator comparator for  grouping keys of inputs to the reduce. Class<? extends InputFormat<?,?>> getInputFormatClass() Get the InputFormat class for the job. String getJar() Get the pathname of the job's jar. JobID getJobID() Get the unique ID for the job. String getJobName() Get the user-specified job name. boolean getJobSetupCleanupNeeded() Get whether job-setup and job-cleanup is needed for the job Path[] getLocalCacheArchives() Deprecated.  the array returned only includes the items the were   downloaded. There is no way to map this to what is returned by  getCacheArchives(). Path[] getLocalCacheFiles() Deprecated.  the array returned only includes the items the were   downloaded. There is no way to map this to what is returned by  getCacheFiles(). Class<?> getMapOutputKeyClass() Get the key class for the map output data. Class<?> getMapOutputValueClass() Get the value class for the map output data. Class<? extends Mapper<?,?,?,?>> getMapperClass() Get the Mapper class for the job. int getMaxMapAttempts() Get the configured number of maximum attempts that will be made to run a  map task, as specified by the mapred.map.max.attempts  property. int getMaxReduceAttempts() Get the configured number of maximum attempts  that will be made to run a  reduce task, as specified by the mapred.reduce.max.attempts  property. int getNumReduceTasks() Get configured the number of reduce tasks for this job. Class<? extends OutputFormat<?,?>> getOutputFormatClass() Get the OutputFormat class for the job. Class<?> getOutputKeyClass() Get the key class for the job output data. Class<?> getOutputValueClass() Get the value class for job outputs. Class<? extends Partitioner<?,?>> getPartitionerClass() Get the Partitioner class for the job. boolean getProfileEnabled() Get whether the task profiling is enabled. String getProfileParams() Get the profiler configuration arguments. org.apache.hadoop.conf.Configuration.IntegerRanges getProfileTaskRange(boolean isMap) Get the range of maps or reduces to profile. Class<? extends Reducer<?,?,?,?>> getReducerClass() Get the Reducer class for the job. RawComparator<?> getSortComparator() Get the RawComparator comparator used to compare keys. boolean getSymlink() Deprecated.  boolean getTaskCleanupNeeded() Get whether task-cleanup is needed for the job String getUser() Get the reported username for this job. Path getWorkingDirectory() Get the current working directory for the default file system. Method Detail getConfiguration Configuration getConfiguration() Return the configuration for the job. Returns:the shared configuration object getCredentials org.apache.hadoop.security.Credentials getCredentials() Get credentials for the job. Returns:credentials for the job getJobID JobID getJobID() Get the unique ID for the job. Returns:the object with the job id getNumReduceTasks int getNumReduceTasks() Get configured the number of reduce tasks for this job. Defaults to   1. Returns:the number of reduce tasks for this job. getWorkingDirectory Path getWorkingDirectory()                          throws IOException Get the current working directory for the default file system. Returns:the directory name. Throws: IOException getOutputKeyClass Class<?> getOutputKeyClass() Get the key class for the job output data. Returns:the key class for the job output data. getOutputValueClass Class<?> getOutputValueClass() Get the value class for job outputs. Returns:the value class for job outputs. getMapOutputKeyClass Class<?> getMapOutputKeyClass() Get the key class for the map output data. If it is not set, use the  (final) output key class. This allows the map output key class to be  different than the final output key class. Returns:the map output key class. getMapOutputValueClass Class<?> getMapOutputValueClass() Get the value class for the map output data. If it is not set, use the  (final) output value class This allows the map output value class to be  different than the final output value class. Returns:the map output value class. getJobName String getJobName() Get the user-specified job name. This is only used to identify the   job to the user. Returns:the job's name, defaulting to "". getInputFormatClass Class<? extends InputFormat<?,?>> getInputFormatClass()                                                       throws ClassNotFoundException Get the InputFormat class for the job. Returns:the InputFormat class for the job. Throws: ClassNotFoundException getMapperClass Class<? extends Mapper<?,?,?,?>> getMapperClass()                                                 throws ClassNotFoundException Get the Mapper class for the job. Returns:the Mapper class for the job. Throws: ClassNotFoundException getCombinerClass Class<? extends Reducer<?,?,?,?>> getCombinerClass()                                                    throws ClassNotFoundException Get the combiner class for the job. Returns:the combiner class for the job. Throws: ClassNotFoundException getReducerClass Class<? extends Reducer<?,?,?,?>> getReducerClass()                                                   throws ClassNotFoundException Get the Reducer class for the job. Returns:the Reducer class for the job. Throws: ClassNotFoundException getOutputFormatClass Class<? extends OutputFormat<?,?>> getOutputFormatClass()                                                         throws ClassNotFoundException Get the OutputFormat class for the job. Returns:the OutputFormat class for the job. Throws: ClassNotFoundException getPartitionerClass Class<? extends Partitioner<?,?>> getPartitionerClass()                                                       throws ClassNotFoundException Get the Partitioner class for the job. Returns:the Partitioner class for the job. Throws: ClassNotFoundException getSortComparator RawComparator<?> getSortComparator() Get the RawComparator comparator used to compare keys. Returns:the RawComparator comparator used to compare keys. getJar String getJar() Get the pathname of the job's jar. Returns:the pathname getCombinerKeyGroupingComparator RawComparator<?> getCombinerKeyGroupingComparator() Get the user defined RawComparator comparator for  grouping keys of inputs to the combiner. Returns:comparator set by the user for grouping values.See Also:Job.setCombinerKeyGroupingComparatorClass(Class) getGroupingComparator RawComparator<?> getGroupingComparator() Get the user defined RawComparator comparator for  grouping keys of inputs to the reduce. Returns:comparator set by the user for grouping values.See Also:Job.setGroupingComparatorClass(Class),  getCombinerKeyGroupingComparator() getJobSetupCleanupNeeded boolean getJobSetupCleanupNeeded() Get whether job-setup and job-cleanup is needed for the job Returns:boolean getTaskCleanupNeeded boolean getTaskCleanupNeeded() Get whether task-cleanup is needed for the job Returns:boolean getProfileEnabled boolean getProfileEnabled() Get whether the task profiling is enabled. Returns:true if some tasks will be profiled getProfileParams String getProfileParams() Get the profiler configuration arguments.  The default value for this property is  "-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s" Returns:the parameters to pass to the task child to configure profiling getProfileTaskRange org.apache.hadoop.conf.Configuration.IntegerRanges getProfileTaskRange(boolean isMap) Get the range of maps or reduces to profile. Parameters:isMap - is the task a map? Returns:the task ranges getUser String getUser() Get the reported username for this job. Returns:the username getSymlink @Deprecated boolean getSymlink() Deprecated.  Originally intended to check if symlinks should be used, but currently  symlinks cannot be disabled. Returns:true getArchiveClassPaths Path[] getArchiveClassPaths() Get the archive entries in classpath as an array of Path getCacheArchives URI[] getCacheArchives()                        throws IOException Get cache archives set in the Configuration Returns:A URI array of the caches set in the Configuration Throws: IOException getCacheFiles URI[] getCacheFiles()                     throws IOException Get cache files set in the Configuration Returns:A URI array of the files set in the Configuration Throws: IOException getLocalCacheArchives @Deprecated Path[] getLocalCacheArchives()                              throws IOException Deprecated. the array returned only includes the items the were   downloaded. There is no way to map this to what is returned by  getCacheArchives(). Return the path array of the localized caches Returns:A path array of localized caches Throws: IOException getLocalCacheFiles @Deprecated Path[] getLocalCacheFiles()                           throws IOException Deprecated. the array returned only includes the items the were   downloaded. There is no way to map this to what is returned by  getCacheFiles(). Return the path array of the localized files Returns:A path array of localized files Throws: IOException getFileClassPaths Path[] getFileClassPaths() Get the file entries in classpath as an array of Path getArchiveTimestamps String[] getArchiveTimestamps() Get the timestamps of the archives.  Used by internal  DistributedCache and MapReduce code. Returns:a string array of timestamps getFileTimestamps String[] getFileTimestamps() Get the timestamps of the files.  Used by internal  DistributedCache and MapReduce code. Returns:a string array of timestamps getMaxMapAttempts int getMaxMapAttempts() Get the configured number of maximum attempts that will be made to run a  map task, as specified by the mapred.map.max.attempts  property. If this property is not already set, the default is 4 attempts. Returns:the max number of attempts per map task. getMaxReduceAttempts int getMaxReduceAttempts() Get the configured number of maximum attempts  that will be made to run a  reduce task, as specified by the mapred.reduce.max.attempts  property. If this property is not already set, the default is 4 attempts. Returns:the max number of attempts per reduce task. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobControl (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobControl (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.jobcontrol Class JobControl java.lang.Object org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl All Implemented Interfaces: Runnable Direct Known Subclasses: JobControl @InterfaceAudience.Public @InterfaceStability.Evolving public class JobControl extends Object implements Runnable This class encapsulates a set of MapReduce jobs and its dependency.       It tracks the states of the jobs by placing them into different tables   according to their states.       This class provides APIs for the client app to add a job to the group    and to get the jobs in the group in different states. When a job is    added, an ID unique to the group is assigned to the job.       This class has a thread that submits jobs when they become ready,    monitors the states of the running jobs, and updates the states of jobs   based on the state changes of their depending jobs states. The class    provides APIs for suspending/resuming the thread, and    for stopping the thread. Constructor Summary Constructors  Constructor and Description JobControl(String groupName) Construct a job control for a group of jobs. Method Summary Methods  Modifier and Type Method and Description String addJob(ControlledJob aJob) Add a new controlled job. String addJob(Job aJob) Add a new job. void addJobCollection(Collection<ControlledJob> jobs) Add a collection of jobs boolean allFinished()  List<ControlledJob> getFailedJobList()  List<ControlledJob> getReadyJobsList()  List<ControlledJob> getRunningJobList()  List<ControlledJob> getSuccessfulJobList()  org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.ThreadState getThreadState()  List<ControlledJob> getWaitingJobList()  void resume() resume the suspended thread void run() The main loop for the thread. void stop() set the thread state to STOPPING so that the   thread will stop when it wakes up. void suspend() suspend the running thread Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JobControl public JobControl(String groupName) Construct a job control for a group of jobs. Parameters:groupName - a name identifying this group Method Detail getWaitingJobList public List<ControlledJob> getWaitingJobList() Returns:the jobs in the waiting state getRunningJobList public List<ControlledJob> getRunningJobList() Returns:the jobs in the running state getReadyJobsList public List<ControlledJob> getReadyJobsList() Returns:the jobs in the ready state getSuccessfulJobList public List<ControlledJob> getSuccessfulJobList() Returns:the jobs in the success state getFailedJobList public List<ControlledJob> getFailedJobList() addJob public String addJob(ControlledJob aJob) Add a new controlled job. Parameters:aJob - the new controlled job addJob public String addJob(Job aJob) Add a new job. Parameters:aJob - the new job addJobCollection public void addJobCollection(Collection<ControlledJob> jobs) Add a collection of jobs Parameters:jobs -  getThreadState public org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.ThreadState getThreadState() Returns:the thread state stop public void stop() set the thread state to STOPPING so that the   thread will stop when it wakes up. suspend public void suspend() suspend the running thread resume public void resume() resume the suspended thread allFinished public boolean allFinished() run public void run() The main loop for the thread.   The loop does the following:         Check the states of the running jobs         Update the states of waiting jobs         Submit the jobs in ready state Specified by: run in interface Runnable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobCounter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobCounter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.mapreduce Enum JobCounter java.lang.Object java.lang.Enum<JobCounter> org.apache.hadoop.mapreduce.JobCounter All Implemented Interfaces: Serializable, Comparable<JobCounter> @InterfaceAudience.Public @InterfaceStability.Evolving public enum JobCounter extends Enum<JobCounter> Enum Constant Summary Enum Constants  Enum Constant and Description DATA_LOCAL_MAPS  FALLOW_SLOTS_MILLIS_MAPS Deprecated.  FALLOW_SLOTS_MILLIS_REDUCES Deprecated.  MB_MILLIS_MAPS  MB_MILLIS_REDUCES  MILLIS_MAPS  MILLIS_REDUCES  NUM_FAILED_MAPS  NUM_FAILED_REDUCES  NUM_FAILED_UBERTASKS  NUM_KILLED_MAPS  NUM_KILLED_REDUCES  NUM_UBER_SUBMAPS  NUM_UBER_SUBREDUCES  OTHER_LOCAL_MAPS  RACK_LOCAL_MAPS  SLOTS_MILLIS_MAPS Deprecated.  SLOTS_MILLIS_REDUCES Deprecated.  TOTAL_LAUNCHED_MAPS  TOTAL_LAUNCHED_REDUCES  TOTAL_LAUNCHED_UBERTASKS  VCORES_MILLIS_MAPS  VCORES_MILLIS_REDUCES  Method Summary Methods  Modifier and Type Method and Description static JobCounter valueOf(String name) Returns the enum constant of this type with the specified name. static JobCounter[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail NUM_FAILED_MAPS public static final JobCounter NUM_FAILED_MAPS NUM_FAILED_REDUCES public static final JobCounter NUM_FAILED_REDUCES NUM_KILLED_MAPS public static final JobCounter NUM_KILLED_MAPS NUM_KILLED_REDUCES public static final JobCounter NUM_KILLED_REDUCES TOTAL_LAUNCHED_MAPS public static final JobCounter TOTAL_LAUNCHED_MAPS TOTAL_LAUNCHED_REDUCES public static final JobCounter TOTAL_LAUNCHED_REDUCES OTHER_LOCAL_MAPS public static final JobCounter OTHER_LOCAL_MAPS DATA_LOCAL_MAPS public static final JobCounter DATA_LOCAL_MAPS RACK_LOCAL_MAPS public static final JobCounter RACK_LOCAL_MAPS SLOTS_MILLIS_MAPS @Deprecated public static final JobCounter SLOTS_MILLIS_MAPS Deprecated.  SLOTS_MILLIS_REDUCES @Deprecated public static final JobCounter SLOTS_MILLIS_REDUCES Deprecated.  FALLOW_SLOTS_MILLIS_MAPS @Deprecated public static final JobCounter FALLOW_SLOTS_MILLIS_MAPS Deprecated.  FALLOW_SLOTS_MILLIS_REDUCES @Deprecated public static final JobCounter FALLOW_SLOTS_MILLIS_REDUCES Deprecated.  TOTAL_LAUNCHED_UBERTASKS public static final JobCounter TOTAL_LAUNCHED_UBERTASKS NUM_UBER_SUBMAPS public static final JobCounter NUM_UBER_SUBMAPS NUM_UBER_SUBREDUCES public static final JobCounter NUM_UBER_SUBREDUCES NUM_FAILED_UBERTASKS public static final JobCounter NUM_FAILED_UBERTASKS MILLIS_MAPS public static final JobCounter MILLIS_MAPS MILLIS_REDUCES public static final JobCounter MILLIS_REDUCES VCORES_MILLIS_MAPS public static final JobCounter VCORES_MILLIS_MAPS VCORES_MILLIS_REDUCES public static final JobCounter VCORES_MILLIS_REDUCES MB_MILLIS_MAPS public static final JobCounter MB_MILLIS_MAPS MB_MILLIS_REDUCES public static final JobCounter MB_MILLIS_REDUCES Method Detail values public static JobCounter[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (JobCounter c : JobCounter.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static JobCounter valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobID (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobID (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class JobID java.lang.Object org.apache.hadoop.mapreduce.ID org.apache.hadoop.mapred.ID org.apache.hadoop.mapreduce.JobID All Implemented Interfaces: Comparable<ID>, Writable, WritableComparable<ID> Direct Known Subclasses: JobID @InterfaceAudience.Public @InterfaceStability.Stable public class JobID extends ID implements Comparable<ID> JobID represents the immutable and unique identifier for   the job. JobID consists of two parts. First part   represents the jobtracker identifier, so that jobID to jobtracker map   is defined. For cluster setup this string is the jobtracker   start time, for local setting, it is "local" and a random number.  Second part of the JobID is the job number.    An example JobID is :   job_200707121733_0003 , which represents the third job   running at the jobtracker started at 200707121733.     Applications should never construct or parse JobID strings, but rather   use appropriate constructors or forName(String) method. See Also:TaskID,  TaskAttemptID Field Summary Fields  Modifier and Type Field and Description protected static NumberFormat idFormat  static String JOB  static String JOBID_REGEX  Fields inherited from class org.apache.hadoop.mapreduce.ID id, SEPARATOR Constructor Summary Constructors  Constructor and Description JobID()  JobID(String jtIdentifier,           int id) Constructs a JobID object Method Summary Methods  Modifier and Type Method and Description StringBuilder appendTo(StringBuilder builder) Add the stuff after the "job" prefix to the given builder. int compareTo(ID o) Compare JobIds by first jtIdentifiers, then by job numbers boolean equals(Object o)  static JobID forName(String str) Construct a JobId object from given string String getJtIdentifier()  int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.mapreduce.ID getId Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail JOB public static final String JOB See Also:Constant Field Values JOBID_REGEX public static final String JOBID_REGEX See Also:Constant Field Values idFormat protected static final NumberFormat idFormat Constructor Detail JobID public JobID(String jtIdentifier,      int id) Constructs a JobID object Parameters:jtIdentifier - jobTracker identifierid - job number JobID public JobID() Method Detail getJtIdentifier public String getJtIdentifier() equals public boolean equals(Object o) Overrides: equals in class ID compareTo public int compareTo(ID o) Compare JobIds by first jtIdentifiers, then by job numbers Specified by: compareTo in interface Comparable<ID> Overrides: compareTo in class ID appendTo public StringBuilder appendTo(StringBuilder builder) Add the stuff after the "job" prefix to the given builder. This is useful,  because the sub-ids use this substring at the start of their string. Parameters:builder - the builder to append to Returns:the builder that was passed in hashCode public int hashCode() Overrides: hashCode in class ID toString public String toString() Overrides: toString in class ID readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Overrides: readFields in class ID Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Overrides: write in class ID Parameters:out - DataOuput to serialize this object into. Throws: IOException forName public static JobID forName(String str)                      throws IllegalArgumentException Construct a JobId object from given string Returns:constructed JobId object or null if the given String is null Throws: IllegalArgumentException - if the given string is malformed Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobPriority (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobPriority (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.mapreduce Enum JobPriority java.lang.Object java.lang.Enum<JobPriority> org.apache.hadoop.mapreduce.JobPriority All Implemented Interfaces: Serializable, Comparable<JobPriority> @InterfaceAudience.Public @InterfaceStability.Evolving public enum JobPriority extends Enum<JobPriority> Used to describe the priority of the running job. Enum Constant Summary Enum Constants  Enum Constant and Description HIGH  LOW  NORMAL  VERY_HIGH  VERY_LOW  Method Summary Methods  Modifier and Type Method and Description static JobPriority valueOf(String name) Returns the enum constant of this type with the specified name. static JobPriority[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail VERY_HIGH public static final JobPriority VERY_HIGH HIGH public static final JobPriority HIGH NORMAL public static final JobPriority NORMAL LOW public static final JobPriority LOW VERY_LOW public static final JobPriority VERY_LOW Method Detail values public static JobPriority[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (JobPriority c : JobPriority.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static JobPriority valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobQueueInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobQueueInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class JobQueueInfo java.lang.Object org.apache.hadoop.mapreduce.QueueInfo org.apache.hadoop.mapred.JobQueueInfo All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class JobQueueInfo extends QueueInfo Class that contains the information regarding the Job Queues which are   maintained by the Hadoop Map/Reduce framework. Constructor Summary Constructors  Constructor and Description JobQueueInfo() Default constructor for Job Queue Info. JobQueueInfo(String queueName,                         String schedulingInfo) Construct a new JobQueueInfo object using the queue name and the  scheduling information passed. Method Summary Methods  Modifier and Type Method and Description List<JobQueueInfo> getChildren()  String getQueueState() Deprecated.  Methods inherited from class org.apache.hadoop.mapreduce.QueueInfo getJobStatuses, getProperties, getQueueChildren, getQueueName, getSchedulingInfo, getState, readFields, setQueueChildren, setState, write Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JobQueueInfo public JobQueueInfo() Default constructor for Job Queue Info. JobQueueInfo public JobQueueInfo(String queueName,             String schedulingInfo) Construct a new JobQueueInfo object using the queue name and the  scheduling information passed. Parameters:queueName - Name of the job queueschedulingInfo - Scheduling Information associated with the job  queue Method Detail getQueueState @Deprecated public String getQueueState() Deprecated.  Use getState() instead getChildren public List<JobQueueInfo> getChildren() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JobStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JobStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class JobStatus java.lang.Object org.apache.hadoop.mapreduce.JobStatus All Implemented Interfaces: Cloneable, Writable Direct Known Subclasses: JobStatus @InterfaceAudience.Public @InterfaceStability.Evolving public class JobStatus extends Object implements Writable, Cloneable Describes the current status of a job. Constructor Summary Constructors  Constructor and Description JobStatus()  JobStatus(JobID jobid,                   float setupProgress,                   float mapProgress,                   float reduceProgress,                   float cleanupProgress,                   org.apache.hadoop.mapreduce.JobStatus.State runState,                   JobPriority jp,                   String user,                   String jobName,                   String jobFile,                   String trackingUrl) Create a job status object for a given jobid. JobStatus(JobID jobid,                   float setupProgress,                   float mapProgress,                   float reduceProgress,                   float cleanupProgress,                   org.apache.hadoop.mapreduce.JobStatus.State runState,                   JobPriority jp,                   String user,                   String jobName,                   String queue,                   String jobFile,                   String trackingUrl) Create a job status object for a given jobid. JobStatus(JobID jobid,                   float setupProgress,                   float mapProgress,                   float reduceProgress,                   float cleanupProgress,                   org.apache.hadoop.mapreduce.JobStatus.State runState,                   JobPriority jp,                   String user,                   String jobName,                   String queue,                   String jobFile,                   String trackingUrl,                   boolean isUber) Create a job status object for a given jobid. Method Summary Methods  Modifier and Type Method and Description Object clone()  float getCleanupProgress()  String getFailureInfo() Gets any available info on the reason of failure of the job. long getFinishTime() Get the finish time of the job. String getHistoryFile()  Map<org.apache.hadoop.mapreduce.JobACL,AccessControlList> getJobACLs() Get the job acls. String getJobFile() Get the configuration file for the job. JobID getJobID()  String getJobName() Get the user-specified job name. float getMapProgress()  int getNeededMem()  int getNumReservedSlots()  int getNumUsedSlots()  JobPriority getPriority() Return the priority of the job String getQueue() Get queue name float getReduceProgress()  int getReservedMem()  String getSchedulingInfo() Gets the Scheduling information associated to a particular Job. float getSetupProgress()  long getStartTime()  org.apache.hadoop.mapreduce.JobStatus.State getState()  String getTrackingUrl() Get the link to the web-ui for details of the job. int getUsedMem()  String getUsername()  boolean isJobComplete() Returns true if the status is for a completed job. boolean isRetired() Check whether the job has retired. boolean isUber() Whether job running in uber mode void readFields(DataInput in) Deserialize the fields of this object from in. protected void setCleanupProgress(float p) Sets the cleanup progress of this job protected void setFailureInfo(String failureInfo) Set diagnostic information. protected void setFinishTime(long finishTime) Set the finish time of the job protected void setHistoryFile(String historyFile) Set the job history file url for a completed job protected void setJobACLs(Map<org.apache.hadoop.mapreduce.JobACL,AccessControlList> acls) Set the job acls. protected void setMapProgress(float p) Sets the map progress of this job void setNeededMem(int n)  void setNumReservedSlots(int n)  void setNumUsedSlots(int n)  protected void setPriority(JobPriority jp) Set the priority of the job, defaulting to NORMAL. protected void setQueue(String queue) Set queue name protected void setReduceProgress(float p) Sets the reduce progress of this Job void setReservedMem(int r)  protected void setRetired() Set the job retire flag to true. protected void setSchedulingInfo(String schedulingInfo) Used to set the scheduling information associated to a particular Job. protected void setSetupProgress(float p) Sets the setup progress of this job protected void setStartTime(long startTime) Set the start time of the job protected void setState(org.apache.hadoop.mapreduce.JobStatus.State state) Change the current run state of the job. protected void setTrackingUrl(String trackingUrl) Set the link to the web-ui for details of the job. void setUber(boolean isUber) Set uber-mode flag void setUsedMem(int m)  protected void setUsername(String userName)  String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail JobStatus public JobStatus() JobStatus public JobStatus(JobID jobid,          float setupProgress,          float mapProgress,          float reduceProgress,          float cleanupProgress,          org.apache.hadoop.mapreduce.JobStatus.State runState,          JobPriority jp,          String user,          String jobName,          String jobFile,          String trackingUrl) Create a job status object for a given jobid. Parameters:jobid - The jobid of the jobsetupProgress - The progress made on the setupmapProgress - The progress made on the mapsreduceProgress - The progress made on the reducescleanupProgress - The progress made on the cleanuprunState - The current state of the jobjp - Priority of the job.user - userid of the person who submitted the job.jobName - user-specified job name.jobFile - job configuration file.trackingUrl - link to the web-ui for details of the job. JobStatus public JobStatus(JobID jobid,          float setupProgress,          float mapProgress,          float reduceProgress,          float cleanupProgress,          org.apache.hadoop.mapreduce.JobStatus.State runState,          JobPriority jp,          String user,          String jobName,          String queue,          String jobFile,          String trackingUrl) Create a job status object for a given jobid. Parameters:jobid - The jobid of the jobsetupProgress - The progress made on the setupmapProgress - The progress made on the mapsreduceProgress - The progress made on the reducescleanupProgress - The progress made on the cleanuprunState - The current state of the jobjp - Priority of the job.user - userid of the person who submitted the job.jobName - user-specified job name.queue - queue namejobFile - job configuration file.trackingUrl - link to the web-ui for details of the job. JobStatus public JobStatus(JobID jobid,          float setupProgress,          float mapProgress,          float reduceProgress,          float cleanupProgress,          org.apache.hadoop.mapreduce.JobStatus.State runState,          JobPriority jp,          String user,          String jobName,          String queue,          String jobFile,          String trackingUrl,          boolean isUber) Create a job status object for a given jobid. Parameters:jobid - The jobid of the jobsetupProgress - The progress made on the setupmapProgress - The progress made on the mapsreduceProgress - The progress made on the reducescleanupProgress - The progress made on the cleanuprunState - The current state of the jobjp - Priority of the job.user - userid of the person who submitted the job.jobName - user-specified job name.queue - queue namejobFile - job configuration file.trackingUrl - link to the web-ui for details of the job.isUber - Whether job running in uber mode Method Detail setMapProgress protected void setMapProgress(float p) Sets the map progress of this job Parameters:p - The value of map progress to set to setCleanupProgress protected void setCleanupProgress(float p) Sets the cleanup progress of this job Parameters:p - The value of cleanup progress to set to setSetupProgress protected void setSetupProgress(float p) Sets the setup progress of this job Parameters:p - The value of setup progress to set to setReduceProgress protected void setReduceProgress(float p) Sets the reduce progress of this Job Parameters:p - The value of reduce progress to set to setPriority protected void setPriority(JobPriority jp) Set the priority of the job, defaulting to NORMAL. Parameters:jp - new job priority setFinishTime protected void setFinishTime(long finishTime) Set the finish time of the job Parameters:finishTime - The finishTime of the job setHistoryFile protected void setHistoryFile(String historyFile) Set the job history file url for a completed job setTrackingUrl protected void setTrackingUrl(String trackingUrl) Set the link to the web-ui for details of the job. setRetired protected void setRetired() Set the job retire flag to true. setState protected void setState(org.apache.hadoop.mapreduce.JobStatus.State state) Change the current run state of the job. setStartTime protected void setStartTime(long startTime) Set the start time of the job Parameters:startTime - The startTime of the job setUsername protected void setUsername(String userName) Parameters:userName - The username of the job setSchedulingInfo protected void setSchedulingInfo(String schedulingInfo) Used to set the scheduling information associated to a particular Job. Parameters:schedulingInfo - Scheduling information of the job setJobACLs protected void setJobACLs(Map<org.apache.hadoop.mapreduce.JobACL,AccessControlList> acls) Set the job acls. Parameters:acls - Map from JobACL to AccessControlList setQueue protected void setQueue(String queue) Set queue name Parameters:queue - queue name setFailureInfo protected void setFailureInfo(String failureInfo) Set diagnostic information. Parameters:failureInfo - diagnostic information getQueue public String getQueue() Get queue name Returns:queue name getMapProgress public float getMapProgress() Returns:Percentage of progress in maps getCleanupProgress public float getCleanupProgress() Returns:Percentage of progress in cleanup getSetupProgress public float getSetupProgress() Returns:Percentage of progress in setup getReduceProgress public float getReduceProgress() Returns:Percentage of progress in reduce getState public org.apache.hadoop.mapreduce.JobStatus.State getState() Returns:running state of the job getStartTime public long getStartTime() Returns:start time of the job clone public Object clone() Overrides: clone in class Object getJobID public JobID getJobID() Returns:The jobid of the Job getUsername public String getUsername() Returns:the username of the job getSchedulingInfo public String getSchedulingInfo() Gets the Scheduling information associated to a particular Job. Returns:the scheduling information of the job getJobACLs public Map<org.apache.hadoop.mapreduce.JobACL,AccessControlList> getJobACLs() Get the job acls. Returns:a Map from JobACL to AccessControlList getPriority public JobPriority getPriority() Return the priority of the job Returns:job priority getFailureInfo public String getFailureInfo() Gets any available info on the reason of failure of the job. Returns:diagnostic information on why a job might have failed. isJobComplete public boolean isJobComplete() Returns true if the status is for a completed job. write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException getJobName public String getJobName() Get the user-specified job name. getJobFile public String getJobFile() Get the configuration file for the job. getTrackingUrl public String getTrackingUrl() Get the link to the web-ui for details of the job. getFinishTime public long getFinishTime() Get the finish time of the job. isRetired public boolean isRetired() Check whether the job has retired. getHistoryFile public String getHistoryFile() Returns:the job history file name for a completed job. If job is not   completed or history file not available then return null. getNumUsedSlots public int getNumUsedSlots() Returns:number of used mapred slots setNumUsedSlots public void setNumUsedSlots(int n) Parameters:n - number of used mapred slots getNumReservedSlots public int getNumReservedSlots() Returns:the number of reserved slots setNumReservedSlots public void setNumReservedSlots(int n) Parameters:n - the number of reserved slots getUsedMem public int getUsedMem() Returns:the used memory setUsedMem public void setUsedMem(int m) Parameters:m - the used memory getReservedMem public int getReservedMem() Returns:the reserved memory setReservedMem public void setReservedMem(int r) Parameters:r - the reserved memory getNeededMem public int getNeededMem() Returns:the needed memory setNeededMem public void setNeededMem(int n) Parameters:n - the needed memory isUber public boolean isUber() Whether job running in uber mode Returns:job in uber-mode setUber public void setUber(boolean isUber) Set uber-mode flag Parameters:isUber - Whether job running in uber-mode toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  JoinRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="JoinRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class JoinRecordReader<K extends WritableComparable<?>> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader<K,X> org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader<K,Writable,TupleWritable> org.apache.hadoop.mapreduce.lib.join.JoinRecordReader<K> All Implemented Interfaces: Closeable, AutoCloseable, Comparable<ComposableRecordReader<K,?>>, Configurable Direct Known Subclasses: InnerJoinRecordReader, OuterJoinRecordReader @InterfaceAudience.Public @InterfaceStability.Stable public abstract class JoinRecordReader<K extends WritableComparable<?>> extends CompositeRecordReader<K,Writable,TupleWritable> Base class for Composite joins returning Tuples of arbitrary Writables. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader conf, jc, key, keyclass, kids, value Constructor Summary Constructors  Constructor and Description JoinRecordReader(int id,                                 Configuration conf,                                 int capacity,                                 Class<? extends WritableComparator> cmpcl)  Method Summary Methods  Modifier and Type Method and Description TupleWritable createValue() Create instance of value. protected ResetableIterator<TupleWritable> getDelegate() Return an iterator wrapping the JoinCollector. boolean nextKeyValue() Emit the next set of key, value pairs as defined by the child  RecordReaders and operation associated with this composite RR. Methods inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader accept, add, close, combine, compareTo, createKey, createTupleWritable, fillJoinCollector, getComparator, getConf, getCurrentKey, getCurrentValue, getProgress, getRecordReaderQueue, hasNext, id, initialize, key, key, setConf, skip Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail JoinRecordReader public JoinRecordReader(int id,                 Configuration conf,                 int capacity,                 Class<? extends WritableComparator> cmpcl)                  throws IOException Throws: IOException Method Detail nextKeyValue public boolean nextKeyValue()                      throws IOException,                             InterruptedException Emit the next set of key, value pairs as defined by the child  RecordReaders and operation associated with this composite RR. Specified by: nextKeyValue in class RecordReader<K extends WritableComparable<?>,TupleWritable> Returns:true if a key/value pair was read Throws: IOException InterruptedException createValue public TupleWritable createValue() Description copied from class: ComposableRecordReader Create instance of value. getDelegate protected ResetableIterator<TupleWritable> getDelegate() Return an iterator wrapping the JoinCollector. Specified by: getDelegate in class CompositeRecordReader<K extends WritableComparable<?>,Writable,TupleWritable> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  KerberosDelegationTokenAuthenticator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="KerberosDelegationTokenAuthenticator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.security.token.delegation.web Class KerberosDelegationTokenAuthenticator java.lang.Object org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator org.apache.hadoop.security.token.delegation.web.KerberosDelegationTokenAuthenticator All Implemented Interfaces: org.apache.hadoop.security.authentication.client.Authenticator @InterfaceAudience.Public @InterfaceStability.Evolving public class KerberosDelegationTokenAuthenticator extends DelegationTokenAuthenticator The KerberosDelegationTokenAuthenticator provides support for  Kerberos SPNEGO authentication mechanism and support for Hadoop Delegation  Token operations.    It falls back to the PseudoDelegationTokenAuthenticator if the HTTP  endpoint does not trigger a SPNEGO authentication Field Summary Fields inherited from class org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator DELEGATION_PARAM, DELEGATION_TOKEN_HEADER, DELEGATION_TOKEN_JSON, DELEGATION_TOKEN_URL_STRING_JSON, OP_PARAM, RENEW_DELEGATION_TOKEN_JSON, RENEWER_PARAM, TOKEN_PARAM Constructor Summary Constructors  Constructor and Description KerberosDelegationTokenAuthenticator()  Method Summary Methods inherited from class org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator authenticate, cancelDelegationToken, cancelDelegationToken, getDelegationToken, getDelegationToken, renewDelegationToken, renewDelegationToken, setConnectionConfigurator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail KerberosDelegationTokenAuthenticator public KerberosDelegationTokenAuthenticator() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  KeyFieldBasedComparator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="KeyFieldBasedComparator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.partition Class KeyFieldBasedComparator<K,V> java.lang.Object org.apache.hadoop.io.WritableComparator org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator<K,V> All Implemented Interfaces: Comparator, Configurable, RawComparator Direct Known Subclasses: KeyFieldBasedComparator @InterfaceAudience.Public @InterfaceStability.Stable public class KeyFieldBasedComparator<K,V> extends WritableComparator implements Configurable This comparator implementation provides a subset of the features provided  by the Unix/GNU Sort. In particular, the supported features are:  -n, (Sort numerically)  -r, (Reverse the result of comparison)  -k pos1[,pos2], where pos is of the form f[.c][opts], where f is the number   of the field to use, and c is the number of the first character from the   beginning of the field. Fields and character posns are numbered starting   with 1; a character position of zero in pos2 indicates the field's last   character. If '.c' is omitted from pos1, it defaults to 1 (the beginning   of the field); if omitted from pos2, it defaults to 0 (the end of the   field). opts are ordering options (any of 'nr' as described above).   We assume that the fields in the key are separated by   MRJobConfig.MAP_OUTPUT_KEY_FIELD_SEPERATOR. Field Summary Fields  Modifier and Type Field and Description static String COMPARATOR_OPTIONS  Constructor Summary Constructors  Constructor and Description KeyFieldBasedComparator()  Method Summary Methods  Modifier and Type Method and Description int compare(byte[] b1,               int s1,               int l1,               byte[] b2,               int s2,               int l2) Optimization hook. Configuration getConf() Return the configuration used by this object. static String getKeyFieldComparatorOption(JobContext job) Get the KeyFieldBasedComparator options void setConf(Configuration conf) Set the configuration to be used by this object. static void setKeyFieldComparatorOptions(Job job,                                                         String keySpec) Set the KeyFieldBasedComparator options used to compare keys. Methods inherited from class org.apache.hadoop.io.WritableComparator compare, compare, compareBytes, define, get, get, getKeyClass, hashBytes, hashBytes, newKey, readDouble, readFloat, readInt, readLong, readUnsignedShort, readVInt, readVLong Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface java.util.Comparator equals Field Detail COMPARATOR_OPTIONS public static String COMPARATOR_OPTIONS Constructor Detail KeyFieldBasedComparator public KeyFieldBasedComparator() Method Detail setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable Overrides: setConf in class WritableComparator getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable Overrides: getConf in class WritableComparator compare public int compare(byte[] b1,           int s1,           int l1,           byte[] b2,           int s2,           int l2) Description copied from class: WritableComparator Optimization hook.  Override this to make SequenceFile.Sorter's scream.  The default implementation reads the data into two WritableComparables (using Writable.readFields(DataInput), then calls WritableComparator.compare(WritableComparable,WritableComparable). Specified by: compare in interface RawComparator Overrides: compare in class WritableComparator Parameters:b1 - The first byte array.s1 - The position index in b1. The object under comparison's starting index.l1 - The length of the object in b1.b2 - The second byte array.s2 - The position index in b2. The object under comparison's starting index.l2 - The length of the object under comparison in b2. Returns:An integer result of the comparison. setKeyFieldComparatorOptions public static void setKeyFieldComparatorOptions(Job job,                                 String keySpec) Set the KeyFieldBasedComparator options used to compare keys. Parameters:keySpec - the key specification of the form -k pos1[,pos2], where,   pos is of the form f[.c][opts], where f is the number   of the key field to use, and c is the number of the first character from   the beginning of the field. Fields and character posns are numbered    starting with 1; a character position of zero in pos2 indicates the   field's last character. If '.c' is omitted from pos1, it defaults to 1   (the beginning of the field); if omitted from pos2, it defaults to 0    (the end of the field). opts are ordering options. The supported options   are:     -n, (Sort numerically)     -r, (Reverse the result of comparison) getKeyFieldComparatorOption public static String getKeyFieldComparatorOption(JobContext job) Get the KeyFieldBasedComparator options Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  KeyFieldBasedPartitioner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="KeyFieldBasedPartitioner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.partition Class KeyFieldBasedPartitioner<K2,V2> java.lang.Object org.apache.hadoop.mapreduce.Partitioner<K2,V2> org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner<K2,V2> All Implemented Interfaces: Configurable Direct Known Subclasses: KeyFieldBasedPartitioner @InterfaceAudience.Public @InterfaceStability.Stable public class KeyFieldBasedPartitioner<K2,V2> extends Partitioner<K2,V2> implements Configurable Defines a way to partition keys based on certain key fields (also see   KeyFieldBasedComparator.   The key specification supported is of the form -k pos1[,pos2], where,   pos is of the form f[.c][opts], where f is the number   of the key field to use, and c is the number of the first character from   the beginning of the field. Fields and character posns are numbered    starting with 1; a character position of zero in pos2 indicates the   field's last character. If '.c' is omitted from pos1, it defaults to 1   (the beginning of the field); if omitted from pos2, it defaults to 0    (the end of the field). Field Summary Fields  Modifier and Type Field and Description static String PARTITIONER_OPTIONS  Constructor Summary Constructors  Constructor and Description KeyFieldBasedPartitioner()  Method Summary Methods  Modifier and Type Method and Description Configuration getConf() Return the configuration used by this object. String getKeyFieldPartitionerOption(JobContext job) Get the KeyFieldBasedPartitioner options protected int getPartition(int hash,                         int numReduceTasks)  int getPartition(K2 key,                         V2 value,                         int numReduceTasks) Get the partition number for a given key (hence record) given the total   number of partitions i.e. protected int hashCode(byte[] b,                 int start,                 int end,                 int currentHash)  void setConf(Configuration conf) Set the configuration to be used by this object. void setKeyFieldPartitionerOptions(Job job,                                                           String keySpec) Set the KeyFieldBasedPartitioner options used for   Partitioner Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail PARTITIONER_OPTIONS public static String PARTITIONER_OPTIONS Constructor Detail KeyFieldBasedPartitioner public KeyFieldBasedPartitioner() Method Detail setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable getPartition public int getPartition(K2 key,                V2 value,                int numReduceTasks) Description copied from class: Partitioner Get the partition number for a given key (hence record) given the total   number of partitions i.e. number of reduce-tasks for the job.      Typically a hash function on a all or a subset of the key. Specified by: getPartition in class Partitioner<K2,V2> Parameters:key - the key to be partioned.value - the entry value.numReduceTasks - the total number of partitions. Returns:the partition number for the key. hashCode protected int hashCode(byte[] b,            int start,            int end,            int currentHash) getPartition protected int getPartition(int hash,                int numReduceTasks) setKeyFieldPartitionerOptions public void setKeyFieldPartitionerOptions(Job job,                                  String keySpec) Set the KeyFieldBasedPartitioner options used for   Partitioner Parameters:keySpec - the key specification of the form -k pos1[,pos2], where,   pos is of the form f[.c][opts], where f is the number   of the key field to use, and c is the number of the first character from   the beginning of the field. Fields and character posns are numbered    starting with 1; a character position of zero in pos2 indicates the   field's last character. If '.c' is omitted from pos1, it defaults to 1   (the beginning of the field); if omitted from pos2, it defaults to 0    (the end of the field). getKeyFieldPartitionerOption public String getKeyFieldPartitionerOption(JobContext job) Get the KeyFieldBasedPartitioner options Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  KeyProvider (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="KeyProvider (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.crypto.key Class KeyProvider java.lang.Object org.apache.hadoop.crypto.key.KeyProvider @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class KeyProvider extends Object A provider of secret key material for Hadoop applications. Provides an  abstraction to separate key storage from users of encryption. It  is intended to support getting or storing keys in a variety of ways,  including third party bindings.    KeyProvider implementations must be thread safe. Field Summary Fields  Modifier and Type Field and Description static int DEFAULT_BITLENGTH  static String DEFAULT_BITLENGTH_NAME  static String DEFAULT_CIPHER  static String DEFAULT_CIPHER_NAME  Constructor Summary Constructors  Constructor and Description KeyProvider(Configuration conf) Constructor. Method Summary Methods  Modifier and Type Method and Description protected static String buildVersionName(String name,                                 int version) Build a version string from a basename and version number. void close() Can be used by implementing classes to close any resources  that require closing abstract org.apache.hadoop.crypto.key.KeyProvider.KeyVersion createKey(String name,                   byte[] material,                   org.apache.hadoop.crypto.key.KeyProvider.Options options) Create a new key. org.apache.hadoop.crypto.key.KeyProvider.KeyVersion createKey(String name,                   org.apache.hadoop.crypto.key.KeyProvider.Options options) Create a new key generating the material for it. abstract void deleteKey(String name) Delete the given key. static KeyProvider findProvider(List<KeyProvider> providerList,                         String keyName) Find the provider with the given key. abstract void flush() Ensures that any changes to the keys are written to persistent store. protected byte[] generateKey(int size,                       String algorithm) Generates a key material. static String getBaseName(String versionName) Split the versionName in to a base name. Configuration getConf() Return the provider configuration. org.apache.hadoop.crypto.key.KeyProvider.KeyVersion getCurrentKey(String name) Get the current version of the key, which should be used for encrypting new  data. abstract List<String> getKeys() Get the key names for all keys. org.apache.hadoop.crypto.key.KeyProvider.Metadata[] getKeysMetadata(String... names) Get key metadata in bulk. abstract org.apache.hadoop.crypto.key.KeyProvider.KeyVersion getKeyVersion(String versionName) Get the key material for a specific version of the key. abstract List<org.apache.hadoop.crypto.key.KeyProvider.KeyVersion> getKeyVersions(String name) Get the key material for all versions of a specific key name. abstract org.apache.hadoop.crypto.key.KeyProvider.Metadata getMetadata(String name) Get metadata about the key. boolean isTransient() Indicates whether this provider represents a store  that is intended for transient use - such as the UserProvider  is. static org.apache.hadoop.crypto.key.KeyProvider.Options options(Configuration conf) A helper function to create an options object. org.apache.hadoop.crypto.key.KeyProvider.KeyVersion rollNewVersion(String name) Roll a new version of the given key generating the material for it. abstract org.apache.hadoop.crypto.key.KeyProvider.KeyVersion rollNewVersion(String name,                             byte[] material) Roll a new version of the given key. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail DEFAULT_CIPHER_NAME public static final String DEFAULT_CIPHER_NAME See Also:Constant Field Values DEFAULT_CIPHER public static final String DEFAULT_CIPHER See Also:Constant Field Values DEFAULT_BITLENGTH_NAME public static final String DEFAULT_BITLENGTH_NAME See Also:Constant Field Values DEFAULT_BITLENGTH public static final int DEFAULT_BITLENGTH See Also:Constant Field Values Constructor Detail KeyProvider public KeyProvider(Configuration conf) Constructor. Parameters:conf - configuration for the provider Method Detail getConf public Configuration getConf() Return the provider configuration. Returns:the provider configuration options public static org.apache.hadoop.crypto.key.KeyProvider.Options options(Configuration conf) A helper function to create an options object. Parameters:conf - the configuration to use Returns:a new options object isTransient public boolean isTransient() Indicates whether this provider represents a store  that is intended for transient use - such as the UserProvider  is. These providers are generally used to provide access to  keying material rather than for long term storage. Returns:true if transient, false otherwise getKeyVersion public abstract org.apache.hadoop.crypto.key.KeyProvider.KeyVersion getKeyVersion(String versionName)                                                                            throws IOException Get the key material for a specific version of the key. This method is used  when decrypting data. Parameters:versionName - the name of a specific version of the key Returns:the key material Throws: IOException getKeys public abstract List<String> getKeys()                               throws IOException Get the key names for all keys. Returns:the list of key names Throws: IOException getKeysMetadata public org.apache.hadoop.crypto.key.KeyProvider.Metadata[] getKeysMetadata(String... names)                                                                     throws IOException Get key metadata in bulk. Parameters:names - the names of the keys to get Throws: IOException getKeyVersions public abstract List<org.apache.hadoop.crypto.key.KeyProvider.KeyVersion> getKeyVersions(String name)                                                                                   throws IOException Get the key material for all versions of a specific key name. Returns:the list of key material Throws: IOException getCurrentKey public org.apache.hadoop.crypto.key.KeyProvider.KeyVersion getCurrentKey(String name)                                                                   throws IOException Get the current version of the key, which should be used for encrypting new  data. Parameters:name - the base name of the key Returns:the version name of the current version of the key or null if the     key version doesn't exist Throws: IOException getMetadata public abstract org.apache.hadoop.crypto.key.KeyProvider.Metadata getMetadata(String name)                                                                        throws IOException Get metadata about the key. Parameters:name - the basename of the key Returns:the key's metadata or null if the key doesn't exist Throws: IOException createKey public abstract org.apache.hadoop.crypto.key.KeyProvider.KeyVersion createKey(String name,                                                             byte[] material,                                                             org.apache.hadoop.crypto.key.KeyProvider.Options options)                                                                        throws IOException Create a new key. The given key must not already exist. Parameters:name - the base name of the keymaterial - the key material for the first version of the key.options - the options for the new key. Returns:the version name of the first version of the key. Throws: IOException generateKey protected byte[] generateKey(int size,                  String algorithm)                       throws NoSuchAlgorithmException Generates a key material. Parameters:size - length of the key.algorithm - algorithm to use for generating the key. Returns:the generated key. Throws: NoSuchAlgorithmException createKey public org.apache.hadoop.crypto.key.KeyProvider.KeyVersion createKey(String name,                                                             org.apache.hadoop.crypto.key.KeyProvider.Options options)                                                               throws NoSuchAlgorithmException,                                                                      IOException Create a new key generating the material for it.  The given key must not already exist.    This implementation generates the key material and calls the  createKey(String, byte[], Options) method. Parameters:name - the base name of the keyoptions - the options for the new key. Returns:the version name of the first version of the key. Throws: IOException NoSuchAlgorithmException deleteKey public abstract void deleteKey(String name)                         throws IOException Delete the given key. Parameters:name - the name of the key to delete Throws: IOException rollNewVersion public abstract org.apache.hadoop.crypto.key.KeyProvider.KeyVersion rollNewVersion(String name,                                                                  byte[] material)                                                                             throws IOException Roll a new version of the given key. Parameters:name - the basename of the keymaterial - the new key material Returns:the name of the new version of the key Throws: IOException close public void close()            throws IOException Can be used by implementing classes to close any resources  that require closing Throws: IOException rollNewVersion public org.apache.hadoop.crypto.key.KeyProvider.KeyVersion rollNewVersion(String name)                                                                    throws NoSuchAlgorithmException,                                                                           IOException Roll a new version of the given key generating the material for it.    This implementation generates the key material and calls the  rollNewVersion(String, byte[]) method. Parameters:name - the basename of the key Returns:the name of the new version of the key Throws: IOException NoSuchAlgorithmException flush public abstract void flush()                     throws IOException Ensures that any changes to the keys are written to persistent store. Throws: IOException getBaseName public static String getBaseName(String versionName)                           throws IOException Split the versionName in to a base name. Converts "/aaa/bbb/3" to  "/aaa/bbb". Parameters:versionName - the version name to split Returns:the base name of the key Throws: IOException buildVersionName protected static String buildVersionName(String name,                       int version) Build a version string from a basename and version number. Converts  "/aaa/bbb" and 3 to "/aaa/bbb@3". Parameters:name - the basename of the keyversion - the version of the key Returns:the versionName of the key. findProvider public static KeyProvider findProvider(List<KeyProvider> providerList,                        String keyName)                                 throws IOException Find the provider with the given key. Parameters:providerList - the list of providerskeyName - the key name we are looking for Returns:the KeyProvider that has the key Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  KeyProviderFactory (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="KeyProviderFactory (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.crypto.key Class KeyProviderFactory java.lang.Object org.apache.hadoop.crypto.key.KeyProviderFactory @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class KeyProviderFactory extends Object A factory to create a list of KeyProvider based on the path given in a  Configuration. It uses a service loader interface to find the available  KeyProviders and create them based on the list of URIs. Field Summary Fields  Modifier and Type Field and Description static String KEY_PROVIDER_PATH  Constructor Summary Constructors  Constructor and Description KeyProviderFactory()  Method Summary Methods  Modifier and Type Method and Description abstract KeyProvider createProvider(URI providerName,                             Configuration conf)  static KeyProvider get(URI uri,       Configuration conf) Create a KeyProvider based on a provided URI. static List<KeyProvider> getProviders(Configuration conf)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail KEY_PROVIDER_PATH public static final String KEY_PROVIDER_PATH See Also:Constant Field Values Constructor Detail KeyProviderFactory public KeyProviderFactory() Method Detail createProvider public abstract KeyProvider createProvider(URI providerName,                          Configuration conf)                                     throws IOException Throws: IOException getProviders public static List<KeyProvider> getProviders(Configuration conf)                                       throws IOException Throws: IOException get public static KeyProvider get(URI uri,               Configuration conf)                        throws IOException Create a KeyProvider based on a provided URI. Parameters:uri - key provider URIconf - configuration to initialize the key provider Returns:the key provider for the specified URI, or NULL if          a provider for the specified URI scheme could not be found. Throws: IOException - thrown if the provider failed to initialize. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  KeyValueLineRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="KeyValueLineRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class KeyValueLineRecordReader java.lang.Object org.apache.hadoop.mapreduce.RecordReader<Text,Text> org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader All Implemented Interfaces: Closeable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Stable public class KeyValueLineRecordReader extends RecordReader<Text,Text> This class treats a line in the input as a key/value pair separated by a   separator character. The separator can be specified in config file   under the attribute name mapreduce.input.keyvaluelinerecordreader.key.value.separator. The default  separator is the tab character ('\t'). Field Summary Fields  Modifier and Type Field and Description static String KEY_VALUE_SEPERATOR  Constructor Summary Constructors  Constructor and Description KeyValueLineRecordReader(Configuration conf)  Method Summary Methods  Modifier and Type Method and Description void close() Close the record reader. static int findSeparator(byte[] utf,                           int start,                           int length,                           byte sep)  Text getCurrentKey() Get the current key Text getCurrentValue() Get the current value. Class getKeyClass()  float getProgress() The current progress of the record reader through its data. void initialize(InputSplit genericSplit,                     TaskAttemptContext context) Called once at initialization. boolean nextKeyValue() Read key/value pair in a line. static void setKeyValue(Text key,                       Text value,                       byte[] line,                       int lineLen,                       int pos)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail KEY_VALUE_SEPERATOR public static final String KEY_VALUE_SEPERATOR See Also:Constant Field Values Constructor Detail KeyValueLineRecordReader public KeyValueLineRecordReader(Configuration conf)                          throws IOException Throws: IOException Method Detail getKeyClass public Class getKeyClass() initialize public void initialize(InputSplit genericSplit,               TaskAttemptContext context)                 throws IOException Description copied from class: RecordReader Called once at initialization. Specified by: initialize in class RecordReader<Text,Text> Parameters:genericSplit - the split that defines the range of records to readcontext - the information about the task Throws: IOException findSeparator public static int findSeparator(byte[] utf,                 int start,                 int length,                 byte sep) setKeyValue public static void setKeyValue(Text key,                Text value,                byte[] line,                int lineLen,                int pos) nextKeyValue public boolean nextKeyValue()                      throws IOException Read key/value pair in a line. Specified by: nextKeyValue in class RecordReader<Text,Text> Returns:true if a key/value pair was read Throws: IOException getCurrentKey public Text getCurrentKey() Description copied from class: RecordReader Get the current key Specified by: getCurrentKey in class RecordReader<Text,Text> Returns:the current key or null if there is no current key getCurrentValue public Text getCurrentValue() Description copied from class: RecordReader Get the current value. Specified by: getCurrentValue in class RecordReader<Text,Text> Returns:the object that was read getProgress public float getProgress()                   throws IOException Description copied from class: RecordReader The current progress of the record reader through its data. Specified by: getProgress in class RecordReader<Text,Text> Returns:a number between 0.0 and 1.0 that is the fraction of the data read Throws: IOException close public void close()            throws IOException Description copied from class: RecordReader Close the record reader. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in class RecordReader<Text,Text> Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  KeyValueTextInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="KeyValueTextInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class KeyValueTextInputFormat java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<Text,Text> org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class KeyValueTextInputFormat extends FileInputFormat<Text,Text> An InputFormat for plain text files. Files are broken into lines.  Either line feed or carriage-return are used to signal end of line.   Each line is divided into key and value parts by a separator byte. If no  such a byte exists, the key will be the entire line and value will be empty.  The separator byte can be specified in config file under the attribute name  mapreduce.input.keyvaluelinerecordreader.key.value.separator. The default  is the tab character ('\t'). Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description KeyValueTextInputFormat()  Method Summary Methods  Modifier and Type Method and Description RecordReader<Text,Text> createRecordReader(InputSplit genericSplit,                                     TaskAttemptContext context) Create a record reader for a given split. protected boolean isSplitable(JobContext context,                       Path file) Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be. Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getFormatMinSplitSize, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, getSplits, listStatus, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail KeyValueTextInputFormat public KeyValueTextInputFormat() Method Detail isSplitable protected boolean isSplitable(JobContext context,                   Path file) Description copied from class: FileInputFormat Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be.    FileInputFormat implementations can override this and return  false to ensure that individual input files are never split-up  so that Mappers process entire files. Overrides: isSplitable in class FileInputFormat<Text,Text> Parameters:context - the job contextfile - the file name to check Returns:is this file splitable? createRecordReader public RecordReader<Text,Text> createRecordReader(InputSplit genericSplit,                                          TaskAttemptContext context)                                            throws IOException Description copied from class: InputFormat Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Specified by: createRecordReader in class InputFormat<Text,Text> Parameters:genericSplit - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  KillApplicationRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="KillApplicationRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class KillApplicationRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class KillApplicationRequest extends Object The request sent by the client to the ResourceManager  to abort a submitted application.    The request includes the ApplicationId of the application to be  aborted. See Also:ApplicationClientProtocol.forceKillApplication(KillApplicationRequest) Constructor Summary Constructors  Constructor and Description KillApplicationRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationId getApplicationId() Get the ApplicationId of the application to be aborted. static KillApplicationRequest newInstance(ApplicationId applicationId)  abstract void setApplicationId(ApplicationId applicationId)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail KillApplicationRequest public KillApplicationRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static KillApplicationRequest newInstance(ApplicationId applicationId) getApplicationId @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationId getApplicationId() Get the ApplicationId of the application to be aborted. Returns:ApplicationId of the application to be aborted setApplicationId @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setApplicationId(ApplicationId applicationId) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  KillApplicationResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="KillApplicationResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class KillApplicationResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class KillApplicationResponse extends Object The response sent by the ResourceManager to the client aborting  a submitted application.    The response, includes:            A flag which indicates that the process of killing the application is      completed or not.        Note: user is recommended to wait until this flag becomes true, otherwise if  the ResourceManager crashes before the process of killing the  application is completed, the ResourceManager may retry this  application on recovery. See Also:ApplicationClientProtocol.forceKillApplication(KillApplicationRequest) Constructor Summary Constructors  Constructor and Description KillApplicationResponse()  Method Summary Methods  Modifier and Type Method and Description abstract boolean getIsKillCompleted() Get the flag which indicates that the process of killing application is completed or not. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail KillApplicationResponse public KillApplicationResponse() Method Detail getIsKillCompleted @InterfaceAudience.Public @InterfaceStability.Stable public abstract boolean getIsKillCompleted() Get the flag which indicates that the process of killing application is completed or not. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LazyOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LazyOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class LazyOutputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class LazyOutputFormat<K,V> extends FilterOutputFormat<K,V> A Convenience class that creates output lazily.  Use in conjuction with org.apache.hadoop.mapreduce.lib.output.MultipleOutputs to recreate the  behaviour of org.apache.hadoop.mapred.lib.MultipleTextOutputFormat (etc) of the old Hadoop API.  See MultipleOutputs documentation for more information. Field Summary Fields  Modifier and Type Field and Description static String OUTPUT_FORMAT  Fields inherited from class org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat baseOut Constructor Summary Constructors  Constructor and Description LazyOutputFormat()  Method Summary Methods  Modifier and Type Method and Description void checkOutputSpecs(JobContext context) Check for validity of the output-specification for the job. OutputCommitter getOutputCommitter(TaskAttemptContext context) Get the output committer for this output format. RecordWriter<K,V> getRecordWriter(TaskAttemptContext context) Get the RecordWriter for the given task. static void setOutputFormatClass(Job job,                                         Class<? extends OutputFormat> theClass) Set the underlying output format for LazyOutputFormat. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail OUTPUT_FORMAT public static String OUTPUT_FORMAT Constructor Detail LazyOutputFormat public LazyOutputFormat() Method Detail setOutputFormatClass public static void setOutputFormatClass(Job job,                         Class<? extends OutputFormat> theClass) Set the underlying output format for LazyOutputFormat. Parameters:job - the Job to modifytheClass - the underlying class getRecordWriter public RecordWriter<K,V> getRecordWriter(TaskAttemptContext context)                                   throws IOException,                                          InterruptedException Description copied from class: OutputFormat Get the RecordWriter for the given task. Overrides: getRecordWriter in class FilterOutputFormat<K,V> Parameters:context - the information about the current task. Returns:a RecordWriter to write the output for the job. Throws: IOException InterruptedException checkOutputSpecs public void checkOutputSpecs(JobContext context)                       throws IOException,                              InterruptedException Description copied from class: OutputFormat Check for validity of the output-specification for the job.     This is to validate the output specification for the job when it is  a job is submitted.  Typically checks that it does not already exist,  throwing an exception when it already exists, so that output is not  overwritten. Overrides: checkOutputSpecs in class FilterOutputFormat<K,V> Parameters:context - information about the job Throws: IOException - when output should not be attempted InterruptedException getOutputCommitter public OutputCommitter getOutputCommitter(TaskAttemptContext context)                                    throws IOException,                                           InterruptedException Description copied from class: OutputFormat Get the output committer for this output format. This is responsible  for ensuring the output is committed correctly. Overrides: getOutputCommitter in class FilterOutputFormat<K,V> Parameters:context - the task context Returns:an output committer Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LifecycleEvent (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LifecycleEvent (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.service Class LifecycleEvent java.lang.Object org.apache.hadoop.service.LifecycleEvent All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class LifecycleEvent extends Object implements Serializable A serializable lifecycle event: the time a state  transition occurred, and what state was entered. See Also:Serialized Form Field Summary Fields  Modifier and Type Field and Description org.apache.hadoop.service.Service.STATE state new state long time Local time in milliseconds when the event occurred Constructor Summary Constructors  Constructor and Description LifecycleEvent()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail time public long time Local time in milliseconds when the event occurred state public org.apache.hadoop.service.Service.STATE state new state Constructor Detail LifecycleEvent public LifecycleEvent() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LocalFileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LocalFileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class LocalFileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem org.apache.hadoop.fs.FilterFileSystem org.apache.hadoop.fs.ChecksumFileSystem org.apache.hadoop.fs.LocalFileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class LocalFileSystem extends ChecksumFileSystem Implement the FileSystem API for the checksumed local filesystem. Field Summary Fields inherited from class org.apache.hadoop.fs.FilterFileSystem fs, swapScheme Fields inherited from class org.apache.hadoop.fs.FileSystem DEFAULT_FS, FS_DEFAULT_NAME_KEY, LOG, SHUTDOWN_HOOK_PRIORITY, statistics Constructor Summary Constructors  Constructor and Description LocalFileSystem()  LocalFileSystem(FileSystem rawLocalFileSystem)  Method Summary Methods  Modifier and Type Method and Description void copyFromLocalFile(boolean delSrc,                                   Path src,                                   Path dst) The src file is on the local disk. void copyToLocalFile(boolean delSrc,                               Path src,                               Path dst) The src file is under FS, and the dst is on the local disk. void createSymlink(Path target,                           Path link,                           boolean createParent) See FileContext.createSymlink(Path, Path, boolean) FileStatus getFileLinkStatus(Path f) See FileContext.getFileLinkStatus(Path) Path getLinkTarget(Path f) See FileContext.getLinkTarget(Path) FileSystem getRaw()  String getScheme() Return the protocol scheme for the FileSystem. void initialize(URI name,                     Configuration conf) Called after a new FileSystem instance is constructed. File pathToFile(Path path) Convert a path to a File. boolean reportChecksumFailure(Path p,                                           FSDataInputStream in,                                           long inPos,                                           FSDataInputStream sums,                                           long sumsPos) Moves files to a bad file directory on the same device, so that their  storage will not be reused. boolean supportsSymlinks() See AbstractFileSystem.supportsSymlinks() Methods inherited from class org.apache.hadoop.fs.ChecksumFileSystem append, completeLocalOutput, copyToLocalFile, create, createNonRecursive, delete, getApproxChkSumLength, getBytesPerSum, getChecksumFile, getChecksumFileLength, getChecksumLength, getRawFileSystem, isChecksumFile, listLocatedStatus, listStatus, mkdirs, open, rename, setConf, setReplication, setVerifyChecksum, setWriteChecksum, startLocalOutput, truncate Methods inherited from class org.apache.hadoop.fs.FilterFileSystem access, canonicalizeUri, checkPath, close, concat, copyFromLocalFile, copyFromLocalFile, create, createNonRecursive, createSnapshot, deleteSnapshot, getAclStatus, getCanonicalUri, getChildFileSystems, getConf, getDefaultBlockSize, getDefaultBlockSize, getDefaultReplication, getDefaultReplication, getFileBlockLocations, getFileChecksum, getFileChecksum, getFileStatus, getHomeDirectory, getInitialWorkingDirectory, getServerDefaults, getServerDefaults, getStatus, getUri, getUsed, getWorkingDirectory, getXAttr, getXAttrs, getXAttrs, listCorruptFileBlocks, listStatusIterator, listXAttrs, makeQualified, mkdirs, modifyAclEntries, primitiveCreate, primitiveMkdir, removeAcl, removeAclEntries, removeDefaultAcl, removeXAttr, renameSnapshot, resolveLink, resolvePath, setAcl, setOwner, setPermission, setTimes, setWorkingDirectory, setXAttr, setXAttr Methods inherited from class org.apache.hadoop.fs.FileSystem append, append, areSymlinksEnabled, cancelDeleteOnExit, clearStatistics, closeAll, closeAllForUGI, copyFromLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, create, createNewFile, createNonRecursive, createSnapshot, delete, deleteOnExit, enableSymlinks, exists, fixRelativePart, get, get, get, getAllStatistics, getBlockSize, getContentSummary, getDefaultPort, getDefaultUri, getFileBlockLocations, getFileSystemClass, getFSofPath, getLength, getLocal, getName, getNamed, getReplication, getStatistics, getStatistics, getStatus, globStatus, globStatus, isDirectory, isFile, listFiles, listLocatedStatus, listStatus, listStatus, listStatus, mkdirs, moveFromLocalFile, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveMkdir, printStatistics, processDeleteOnExit, rename, setDefaultUri, setDefaultUri Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail LocalFileSystem public LocalFileSystem() LocalFileSystem public LocalFileSystem(FileSystem rawLocalFileSystem) Method Detail initialize public void initialize(URI name,               Configuration conf)                 throws IOException Description copied from class: FilterFileSystem Called after a new FileSystem instance is constructed. Overrides: initialize in class FilterFileSystem Parameters:name - a uri whose authority section names the host, port, etc.    for this FileSystemconf - the configuration Throws: IOException getScheme public String getScheme() Return the protocol scheme for the FileSystem.   Overrides: getScheme in class FileSystem Returns:file getRaw public FileSystem getRaw() pathToFile public File pathToFile(Path path) Convert a path to a File. copyFromLocalFile public void copyFromLocalFile(boolean delSrc,                      Path src,                      Path dst)                        throws IOException Description copied from class: FilterFileSystem The src file is on the local disk.  Add it to FS at  the given dst name.  delSrc indicates if the source should be removed Overrides: copyFromLocalFile in class ChecksumFileSystem Parameters:delSrc - whether to delete the srcsrc - pathdst - path Throws: IOException copyToLocalFile public void copyToLocalFile(boolean delSrc,                    Path src,                    Path dst)                      throws IOException Description copied from class: ChecksumFileSystem The src file is under FS, and the dst is on the local disk.  Copy it from FS control to the local dst name. Overrides: copyToLocalFile in class ChecksumFileSystem Parameters:delSrc - whether to delete the srcsrc - pathdst - path Throws: IOException reportChecksumFailure public boolean reportChecksumFailure(Path p,                             FSDataInputStream in,                             long inPos,                             FSDataInputStream sums,                             long sumsPos) Moves files to a bad file directory on the same device, so that their  storage will not be reused. Overrides: reportChecksumFailure in class ChecksumFileSystem Parameters:p - the file name containing the errorin - the stream open on the fileinPos - the position of the beginning of the bad data in the filesums - the stream open on the checksum filesumsPos - the position of the beginning of the bad data in the checksum file Returns:if retry is neccessary supportsSymlinks public boolean supportsSymlinks() Description copied from class: FileSystem See AbstractFileSystem.supportsSymlinks() Overrides: supportsSymlinks in class FilterFileSystem createSymlink public void createSymlink(Path target,                  Path link,                  boolean createParent)                    throws IOException Description copied from class: FileSystem See FileContext.createSymlink(Path, Path, boolean) Overrides: createSymlink in class FilterFileSystem Throws: IOException getFileLinkStatus public FileStatus getFileLinkStatus(Path f)                              throws IOException Description copied from class: FileSystem See FileContext.getFileLinkStatus(Path) Overrides: getFileLinkStatus in class FilterFileSystem Throws: IOException getLinkTarget public Path getLinkTarget(Path f)                    throws IOException Description copied from class: FileSystem See FileContext.getLinkTarget(Path) Overrides: getLinkTarget in class FilterFileSystem Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LocalResource (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LocalResource (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class LocalResource java.lang.Object org.apache.hadoop.yarn.api.records.LocalResource @InterfaceAudience.Public @InterfaceStability.Stable public abstract class LocalResource extends Object LocalResource represents a local resource required to  run a container.    The NodeManager is responsible for localizing the resource   prior to launching the container.    Applications can specify LocalResourceType and   LocalResourceVisibility. See Also:LocalResourceType,  LocalResourceVisibility,  ContainerLaunchContext,  ApplicationSubmissionContext,  ContainerManagementProtocol.startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest) Constructor Summary Constructors  Constructor and Description LocalResource()  Method Summary Methods  Modifier and Type Method and Description abstract String getPattern() Get the pattern that should be used to extract entries from the  archive (only used when type is PATTERN). abstract URL getResource() Get the location of the resource to be localized. abstract boolean getShouldBeUploadedToSharedCache() NM uses it to decide whether if it is necessary to upload the resource to  the shared cache abstract long getSize() Get the size of the resource to be localized. abstract long getTimestamp() Get the original timestamp of the resource to be localized, used  for verification. abstract LocalResourceType getType() Get the LocalResourceType of the resource to be localized. abstract LocalResourceVisibility getVisibility() Get the LocalResourceVisibility of the resource to be   localized. static LocalResource newInstance(URL url,                       LocalResourceType type,                       LocalResourceVisibility visibility,                       long size,                       long timestamp)  static LocalResource newInstance(URL url,                       LocalResourceType type,                       LocalResourceVisibility visibility,                       long size,                       long timestamp,                       boolean shouldBeUploadedToSharedCache)  static LocalResource newInstance(URL url,                       LocalResourceType type,                       LocalResourceVisibility visibility,                       long size,                       long timestamp,                       String pattern)  static LocalResource newInstance(URL url,                       LocalResourceType type,                       LocalResourceVisibility visibility,                       long size,                       long timestamp,                       String pattern,                       boolean shouldBeUploadedToSharedCache)  abstract void setPattern(String pattern) Set the pattern that should be used to extract entries from the  archive (only used when type is PATTERN). abstract void setResource(URL resource) Set location of the resource to be localized. abstract void setShouldBeUploadedToSharedCache(boolean shouldBeUploadedToSharedCache) Inform NM whether upload to SCM is needed. abstract void setSize(long size) Set the size of the resource to be localized. abstract void setTimestamp(long timestamp) Set the timestamp of the resource to be localized, used  for verification. abstract void setType(LocalResourceType type) Set the LocalResourceType of the resource to be localized. abstract void setVisibility(LocalResourceVisibility visibility) Set the LocalResourceVisibility of the resource to be   localized. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail LocalResource public LocalResource() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static LocalResource newInstance(URL url,                                                                            LocalResourceType type,                                                                            LocalResourceVisibility visibility,                                                                            long size,                                                                            long timestamp,                                                                            String pattern) newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static LocalResource newInstance(URL url,                                                                              LocalResourceType type,                                                                              LocalResourceVisibility visibility,                                                                              long size,                                                                              long timestamp,                                                                              String pattern,                                                                              boolean shouldBeUploadedToSharedCache) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static LocalResource newInstance(URL url,                                                                            LocalResourceType type,                                                                            LocalResourceVisibility visibility,                                                                            long size,                                                                            long timestamp) newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static LocalResource newInstance(URL url,                                                                              LocalResourceType type,                                                                              LocalResourceVisibility visibility,                                                                              long size,                                                                              long timestamp,                                                                              boolean shouldBeUploadedToSharedCache) getResource @InterfaceAudience.Public @InterfaceStability.Stable public abstract URL getResource() Get the location of the resource to be localized. Returns:location of the resource to be localized setResource @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setResource(URL resource) Set location of the resource to be localized. Parameters:resource - location of the resource to be localized getSize @InterfaceAudience.Public @InterfaceStability.Stable public abstract long getSize() Get the size of the resource to be localized. Returns:size of the resource to be localized setSize @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setSize(long size) Set the size of the resource to be localized. Parameters:size - size of the resource to be localized getTimestamp @InterfaceAudience.Public @InterfaceStability.Stable public abstract long getTimestamp() Get the original timestamp of the resource to be localized, used  for verification. Returns:timestamp of the resource to be localized setTimestamp @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setTimestamp(long timestamp) Set the timestamp of the resource to be localized, used  for verification. Parameters:timestamp - timestamp of the resource to be localized getType @InterfaceAudience.Public @InterfaceStability.Stable public abstract LocalResourceType getType() Get the LocalResourceType of the resource to be localized. Returns:LocalResourceType of the resource to be localized setType @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setType(LocalResourceType type) Set the LocalResourceType of the resource to be localized. Parameters:type - LocalResourceType of the resource to be localized getVisibility @InterfaceAudience.Public @InterfaceStability.Stable public abstract LocalResourceVisibility getVisibility() Get the LocalResourceVisibility of the resource to be   localized. Returns:LocalResourceVisibility of the resource to be           localized setVisibility @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setVisibility(LocalResourceVisibility visibility) Set the LocalResourceVisibility of the resource to be   localized. Parameters:visibility - LocalResourceVisibility of the resource to be                     localized getPattern @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getPattern() Get the pattern that should be used to extract entries from the  archive (only used when type is PATTERN). Returns:pattern that should be used to extract entries from the   archive. setPattern @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setPattern(String pattern) Set the pattern that should be used to extract entries from the  archive (only used when type is PATTERN). Parameters:pattern - pattern that should be used to extract entries   from the archive. getShouldBeUploadedToSharedCache @InterfaceAudience.Public @InterfaceStability.Unstable public abstract boolean getShouldBeUploadedToSharedCache() NM uses it to decide whether if it is necessary to upload the resource to  the shared cache setShouldBeUploadedToSharedCache @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setShouldBeUploadedToSharedCache(boolean shouldBeUploadedToSharedCache) Inform NM whether upload to SCM is needed. Parameters:shouldBeUploadedToSharedCache - shouldBeUploadedToSharedCache           of this request Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LocalResourceType (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LocalResourceType (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum LocalResourceType java.lang.Object java.lang.Enum<LocalResourceType> org.apache.hadoop.yarn.api.records.LocalResourceType All Implemented Interfaces: Serializable, Comparable<LocalResourceType> @InterfaceAudience.Public @InterfaceStability.Stable public enum LocalResourceType extends Enum<LocalResourceType> LocalResourceType specifies the type  of a resource localized by the NodeManager.    The type can be one of:            FILE - Regular file i.e. uninterpreted bytes.              ARCHIVE - Archive, which is automatically unarchived by the      NodeManager.              PATTERN - A hybrid between ARCHIVE and FILE.       See Also:LocalResource,  ContainerLaunchContext,  ApplicationSubmissionContext,  ContainerManagementProtocol.startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest) Enum Constant Summary Enum Constants  Enum Constant and Description ARCHIVE Archive, which is automatically unarchived by the NodeManager. FILE Regular file i.e. PATTERN A hybrid between archive and file. Method Summary Methods  Modifier and Type Method and Description static LocalResourceType valueOf(String name) Returns the enum constant of this type with the specified name. static LocalResourceType[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail ARCHIVE public static final LocalResourceType ARCHIVE Archive, which is automatically unarchived by the NodeManager. FILE public static final LocalResourceType FILE Regular file i.e. uninterpreted bytes. PATTERN public static final LocalResourceType PATTERN A hybrid between archive and file.  Only part of the file is unarchived,  and the original file is left in place, but in the same directory as the  unarchived part.  The part that is unarchived is determined by pattern  in #LocalResource.  Currently only jars support pattern, all  others will be treated like a #ARCHIVE. Method Detail values public static LocalResourceType[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (LocalResourceType c : LocalResourceType.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static LocalResourceType valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LocalResourceVisibility (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LocalResourceVisibility (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum LocalResourceVisibility java.lang.Object java.lang.Enum<LocalResourceVisibility> org.apache.hadoop.yarn.api.records.LocalResourceVisibility All Implemented Interfaces: Serializable, Comparable<LocalResourceVisibility> @InterfaceAudience.Public @InterfaceStability.Stable public enum LocalResourceVisibility extends Enum<LocalResourceVisibility> LocalResourceVisibility specifies the visibility  of a resource localized by the NodeManager.    The visibility can be one of:      PUBLIC - Shared by all users on the node.          PRIVATE - Shared among all applications of the      same user on the node.              APPLICATION - Shared only among containers of the      same application on the node.       See Also:LocalResource,  ContainerLaunchContext,  ApplicationSubmissionContext,  ContainerManagementProtocol.startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest) Enum Constant Summary Enum Constants  Enum Constant and Description APPLICATION Shared only among containers of the same application on the node. PRIVATE Shared among all applications of the same user on the node. PUBLIC Shared by all users on the node. Method Summary Methods  Modifier and Type Method and Description static LocalResourceVisibility valueOf(String name) Returns the enum constant of this type with the specified name. static LocalResourceVisibility[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail PUBLIC public static final LocalResourceVisibility PUBLIC Shared by all users on the node. PRIVATE public static final LocalResourceVisibility PRIVATE Shared among all applications of the same user on the node. APPLICATION public static final LocalResourceVisibility APPLICATION Shared only among containers of the same application on the node. Method Detail values public static LocalResourceVisibility[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (LocalResourceVisibility c : LocalResourceVisibility.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static LocalResourceVisibility valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LocatedFileStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LocatedFileStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class LocatedFileStatus java.lang.Object org.apache.hadoop.fs.FileStatus org.apache.hadoop.fs.LocatedFileStatus All Implemented Interfaces: Comparable, Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class LocatedFileStatus extends FileStatus This class defines a FileStatus that includes a file's block locations. Constructor Summary Constructors  Constructor and Description LocatedFileStatus()  LocatedFileStatus(FileStatus stat,                                   BlockLocation[] locations) Constructor LocatedFileStatus(long length,                                   boolean isdir,                                   int block_replication,                                   long blocksize,                                   long modification_time,                                   long access_time,                                   FsPermission permission,                                   String owner,                                   String group,                                   Path symlink,                                   Path path,                                   BlockLocation[] locations) Constructor Method Summary Methods  Modifier and Type Method and Description int compareTo(Object o) Compare this object to another object boolean equals(Object o) Compare if this object is equal to another object BlockLocation[] getBlockLocations() Get the file's block locations int hashCode() Returns a hash code value for the object, which is defined as  the hash code of the path name. Methods inherited from class org.apache.hadoop.fs.FileStatus getAccessTime, getBlockSize, getGroup, getLen, getModificationTime, getOwner, getPath, getPermission, getReplication, getSymlink, isDir, isDirectory, isEncrypted, isFile, isSymlink, readFields, setGroup, setOwner, setPath, setPermission, setSymlink, toString, write Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail LocatedFileStatus public LocatedFileStatus() LocatedFileStatus public LocatedFileStatus(FileStatus stat,                  BlockLocation[] locations)                   throws IOException Constructor Parameters:stat - a file statuslocations - a file's block locations Throws: IOException LocatedFileStatus public LocatedFileStatus(long length,                  boolean isdir,                  int block_replication,                  long blocksize,                  long modification_time,                  long access_time,                  FsPermission permission,                  String owner,                  String group,                  Path symlink,                  Path path,                  BlockLocation[] locations) Constructor Parameters:length - a file's lengthisdir - if the path is a directoryblock_replication - the file's replication factorblocksize - a file's block sizemodification_time - a file's modification timeaccess_time - a file's access timepermission - a file's permissionowner - a file's ownergroup - a file's groupsymlink - symlink if the path is a symbolic linkpath - the path's qualified namelocations - a file's block locations Method Detail getBlockLocations public BlockLocation[] getBlockLocations() Get the file's block locations Returns:the file's block locations compareTo public int compareTo(Object o) Compare this object to another object Specified by: compareTo in interface Comparable Overrides: compareTo in class FileStatus Parameters:o - the object to be compared. Returns:a negative integer, zero, or a positive integer as this object    is less than, equal to, or greater than the specified object. Throws: ClassCastException - if the specified object's is not of           type FileStatus equals public boolean equals(Object o) Compare if this object is equal to another object Overrides: equals in class FileStatus Parameters:o - the object to be compared. Returns:true if two file status has the same path name; false if not. hashCode public int hashCode() Returns a hash code value for the object, which is defined as  the hash code of the path name. Overrides: hashCode in class FileStatus Returns:a hash code value for the path name. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LogAggregationContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LogAggregationContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class LogAggregationContext java.lang.Object org.apache.hadoop.yarn.api.records.LogAggregationContext @InterfaceStability.Evolving @InterfaceAudience.Public public abstract class LogAggregationContext extends Object LogAggregationContext represents all of the  information needed by the NodeManager to handle  the logs for an application.    It includes details such as:            includePattern. It uses Java Regex to filter the log files      which match the defined include pattern and those log files      will be uploaded when the application finishes.              excludePattern. It uses Java Regex to filter the log files      which match the defined exclude pattern and those log files      will not be uploaded when application finishes. If the log file      name matches both the include and the exclude pattern, this file      will be excluded eventually.              rolledLogsIncludePattern. It uses Java Regex to filter the log files      which match the defined include pattern and those log files      will be aggregated in a rolling fashion.              rolledLogsExcludePattern. It uses Java Regex to filter the log files      which match the defined exclude pattern and those log files      will not be aggregated in a rolling fashion. If the log file      name matches both the include and the exclude pattern, this file      will be excluded eventually.       See Also:ApplicationSubmissionContext Constructor Summary Constructors  Constructor and Description LogAggregationContext()  Method Summary Methods  Modifier and Type Method and Description abstract String getExcludePattern() Get exclude pattern. abstract String getIncludePattern() Get include pattern. abstract String getRolledLogsExcludePattern() Get exclude pattern for aggregation in a rolling fashion. abstract String getRolledLogsIncludePattern() Get include pattern in a rolling fashion. static LogAggregationContext newInstance(String includePattern,                       String excludePattern)  static LogAggregationContext newInstance(String includePattern,                       String excludePattern,                       String rolledLogsIncludePattern,                       String rolledLogsExcludePattern)  abstract void setExcludePattern(String excludePattern) Set exclude pattern. abstract void setIncludePattern(String includePattern) Set include pattern. abstract void setRolledLogsExcludePattern(String rolledLogsExcludePattern) Set exclude pattern for in a rolling fashion. abstract void setRolledLogsIncludePattern(String rolledLogsIncludePattern) Set include pattern in a rolling fashion. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail LogAggregationContext public LogAggregationContext() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static LogAggregationContext newInstance(String includePattern,                                                                                      String excludePattern) newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static LogAggregationContext newInstance(String includePattern,                                                                                      String excludePattern,                                                                                      String rolledLogsIncludePattern,                                                                                      String rolledLogsExcludePattern) getIncludePattern @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getIncludePattern() Get include pattern. This includePattern only takes affect  on logs that exist at the time of application finish. Returns:include pattern setIncludePattern @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setIncludePattern(String includePattern) Set include pattern. This includePattern only takes affect  on logs that exist at the time of application finish. Parameters:includePattern -  getExcludePattern @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getExcludePattern() Get exclude pattern. This excludePattern only takes affect  on logs that exist at the time of application finish. Returns:exclude pattern setExcludePattern @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setExcludePattern(String excludePattern) Set exclude pattern. This excludePattern only takes affect  on logs that exist at the time of application finish. Parameters:excludePattern -  getRolledLogsIncludePattern @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getRolledLogsIncludePattern() Get include pattern in a rolling fashion. Returns:include pattern setRolledLogsIncludePattern @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setRolledLogsIncludePattern(String rolledLogsIncludePattern) Set include pattern in a rolling fashion. Parameters:rolledLogsIncludePattern -  getRolledLogsExcludePattern @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getRolledLogsExcludePattern() Get exclude pattern for aggregation in a rolling fashion. Returns:exclude pattern setRolledLogsExcludePattern @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setRolledLogsExcludePattern(String rolledLogsExcludePattern) Set exclude pattern for in a rolling fashion. Parameters:rolledLogsExcludePattern -  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LoggingStateChangeListener (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LoggingStateChangeListener (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.service Class LoggingStateChangeListener java.lang.Object org.apache.hadoop.service.LoggingStateChangeListener All Implemented Interfaces: ServiceStateChangeListener @InterfaceAudience.Public @InterfaceStability.Evolving public class LoggingStateChangeListener extends Object implements ServiceStateChangeListener This is a state change listener that logs events at INFO level Constructor Summary Constructors  Constructor and Description LoggingStateChangeListener() Log events to the static log for this class LoggingStateChangeListener(org.apache.commons.logging.Log log) Log events to the given log Method Summary Methods  Modifier and Type Method and Description void stateChanged(Service service) Callback for a state change event: log it Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail LoggingStateChangeListener public LoggingStateChangeListener(org.apache.commons.logging.Log log) Log events to the given log Parameters:log - destination for events LoggingStateChangeListener public LoggingStateChangeListener() Log events to the static log for this class Method Detail stateChanged public void stateChanged(Service service) Callback for a state change event: log it Specified by: stateChanged in interface ServiceStateChangeListener Parameters:service - the service that has changed. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LogsCLI (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LogsCLI (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.cli Class LogsCLI java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.yarn.client.cli.LogsCLI All Implemented Interfaces: Configurable, Tool @InterfaceAudience.Public @InterfaceStability.Evolving public class LogsCLI extends Configured implements Tool Field Summary Fields  Modifier and Type Field and Description static String HELP_CMD  Constructor Summary Constructors  Constructor and Description LogsCLI()  Method Summary Methods  Modifier and Type Method and Description protected YarnClient createYarnClient()  static void main(String[] args)  int run(String[] args) Execute the command with the given arguments. Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Field Detail HELP_CMD public static final String HELP_CMD See Also:Constant Field Values Constructor Detail LogsCLI public LogsCLI() Method Detail run public int run(String[] args)         throws Exception Description copied from interface: Tool Execute the command with the given arguments. Specified by: run in interface Tool Parameters:args - command specific arguments. Returns:exit code. Throws: Exception createYarnClient protected YarnClient createYarnClient() main public static void main(String[] args)                  throws Exception Throws: Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LongSumReducer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LongSumReducer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.reduce Class LongSumReducer<KEY> java.lang.Object org.apache.hadoop.mapreduce.Reducer<KEY,LongWritable,KEY,LongWritable> org.apache.hadoop.mapreduce.lib.reduce.LongSumReducer<KEY> @InterfaceAudience.Public @InterfaceStability.Stable public class LongSumReducer<KEY> extends Reducer<KEY,LongWritable,KEY,LongWritable> Constructor Summary Constructors  Constructor and Description LongSumReducer()  Method Summary Methods  Modifier and Type Method and Description void reduce(KEY key,             Iterable<LongWritable> values,             org.apache.hadoop.mapreduce.Reducer.Context context) This method is called once for each key. Methods inherited from class org.apache.hadoop.mapreduce.Reducer cleanup, run, setup Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail LongSumReducer public LongSumReducer() Method Detail reduce public void reduce(KEY key,           Iterable<LongWritable> values,           org.apache.hadoop.mapreduce.Reducer.Context context)             throws IOException,                    InterruptedException Description copied from class: Reducer This method is called once for each key. Most applications will define  their reduce class by overriding this method. The default implementation  is an identity function. Overrides: reduce in class Reducer<KEY,LongWritable,KEY,LongWritable> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LongValueMax (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LongValueMax (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class LongValueMax java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax All Implemented Interfaces: ValueAggregator<String> Direct Known Subclasses: LongValueMax @InterfaceAudience.Public @InterfaceStability.Stable public class LongValueMax extends Object implements ValueAggregator<String> This class implements a value aggregator that maintain the maximum of   a sequence of long values. Constructor Summary Constructors  Constructor and Description LongValueMax() the default constructor Method Summary Methods  Modifier and Type Method and Description void addNextValue(long newVal) add a value to the aggregator void addNextValue(Object val) add a value to the aggregator ArrayList<String> getCombinerOutput()  String getReport()  long getVal()  void reset() reset the aggregator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail LongValueMax public LongValueMax() the default constructor Method Detail addNextValue public void addNextValue(Object val) add a value to the aggregator Specified by: addNextValue in interface ValueAggregator<String> Parameters:val - an object whose string representation represents a long value. addNextValue public void addNextValue(long newVal) add a value to the aggregator Parameters:newVal - a long value. getVal public long getVal() Returns:the aggregated value getReport public String getReport() Specified by: getReport in interface ValueAggregator<String> Returns:the string representation of the aggregated value reset public void reset() reset the aggregator Specified by: reset in interface ValueAggregator<String> getCombinerOutput public ArrayList<String> getCombinerOutput() Specified by: getCombinerOutput in interface ValueAggregator<String> Returns:return an array of one element. The element is a string          representation of the aggregated value. The return value is          expected to be used by the a combiner. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LongValueMin (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LongValueMin (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class LongValueMin java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin All Implemented Interfaces: ValueAggregator<String> Direct Known Subclasses: LongValueMin @InterfaceAudience.Public @InterfaceStability.Stable public class LongValueMin extends Object implements ValueAggregator<String> This class implements a value aggregator that maintain the minimum of   a sequence of long values. Constructor Summary Constructors  Constructor and Description LongValueMin() the default constructor Method Summary Methods  Modifier and Type Method and Description void addNextValue(long newVal) add a value to the aggregator void addNextValue(Object val) add a value to the aggregator ArrayList<String> getCombinerOutput()  String getReport()  long getVal()  void reset() reset the aggregator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail LongValueMin public LongValueMin() the default constructor Method Detail addNextValue public void addNextValue(Object val) add a value to the aggregator Specified by: addNextValue in interface ValueAggregator<String> Parameters:val - an object whose string representation represents a long value. addNextValue public void addNextValue(long newVal) add a value to the aggregator Parameters:newVal - a long value. getVal public long getVal() Returns:the aggregated value getReport public String getReport() Specified by: getReport in interface ValueAggregator<String> Returns:the string representation of the aggregated value reset public void reset() reset the aggregator Specified by: reset in interface ValueAggregator<String> getCombinerOutput public ArrayList<String> getCombinerOutput() Specified by: getCombinerOutput in interface ValueAggregator<String> Returns:return an array of one element. The element is a string          representation of the aggregated value. The return value is          expected to be used by the a combiner. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LongValueSum (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LongValueSum (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class LongValueSum java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum All Implemented Interfaces: ValueAggregator<String> Direct Known Subclasses: LongValueSum @InterfaceAudience.Public @InterfaceStability.Stable public class LongValueSum extends Object implements ValueAggregator<String> This class implements a value aggregator that sums up   a sequence of long values. Constructor Summary Constructors  Constructor and Description LongValueSum() the default constructor Method Summary Methods  Modifier and Type Method and Description void addNextValue(long val) add a value to the aggregator void addNextValue(Object val) add a value to the aggregator ArrayList<String> getCombinerOutput()  String getReport()  long getSum()  void reset() reset the aggregator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail LongValueSum public LongValueSum() the default constructor Method Detail addNextValue public void addNextValue(Object val) add a value to the aggregator Specified by: addNextValue in interface ValueAggregator<String> Parameters:val - an object whose string representation represents a long value. addNextValue public void addNextValue(long val) add a value to the aggregator Parameters:val - a long value. getSum public long getSum() Returns:the aggregated value getReport public String getReport() Specified by: getReport in interface ValueAggregator<String> Returns:the string representation of the aggregated value reset public void reset() reset the aggregator Specified by: reset in interface ValueAggregator<String> getCombinerOutput public ArrayList<String> getCombinerOutput() Specified by: getCombinerOutput in interface ValueAggregator<String> Returns:return an array of one element. The element is a string          representation of the aggregated value. The return value is          expected to be used by the a combiner. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  LongWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="LongWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class LongWritable java.lang.Object org.apache.hadoop.io.LongWritable All Implemented Interfaces: Comparable<LongWritable>, Writable, WritableComparable<LongWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class LongWritable extends Object implements WritableComparable<LongWritable> A WritableComparable for longs. Constructor Summary Constructors  Constructor and Description LongWritable()  LongWritable(long value)  Method Summary Methods  Modifier and Type Method and Description int compareTo(LongWritable o) Compares two LongWritables. boolean equals(Object o) Returns true iff o is a LongWritable with the same value. long get() Return the value of this LongWritable. int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(long value) Set the value of this LongWritable. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail LongWritable public LongWritable() LongWritable public LongWritable(long value) Method Detail set public void set(long value) Set the value of this LongWritable. get public long get() Return the value of this LongWritable. readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object o) Returns true iff o is a LongWritable with the same value. Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(LongWritable o) Compares two LongWritables. Specified by: compareTo in interface Comparable<LongWritable> toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MBeans (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MBeans (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.util Class MBeans java.lang.Object org.apache.hadoop.metrics2.util.MBeans @InterfaceAudience.Public @InterfaceStability.Stable public class MBeans extends Object This util class provides a method to register an MBean using  our standard naming convention as described in the doc   for {link register(String, String, Object) Constructor Summary Constructors  Constructor and Description MBeans()  Method Summary Methods  Modifier and Type Method and Description static ObjectName register(String serviceName,                 String nameName,                 Object theMbean) Register the MBean using our standard MBeanName format  "hadoop:service=,name="  Where the  and  are the supplied parameters static void unregister(ObjectName mbeanName)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MBeans public MBeans() Method Detail register public static ObjectName register(String serviceName,                   String nameName,                   Object theMbean) Register the MBean using our standard MBeanName format  "hadoop:service=,name="  Where the  and  are the supplied parameters Parameters:serviceName - nameName - theMbean - - the MBean to register Returns:the named used to register the MBean unregister public static void unregister(ObjectName mbeanName) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MD5Hash (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MD5Hash (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class MD5Hash java.lang.Object org.apache.hadoop.io.MD5Hash All Implemented Interfaces: Comparable<MD5Hash>, Writable, WritableComparable<MD5Hash> @InterfaceAudience.Public @InterfaceStability.Stable public class MD5Hash extends Object implements WritableComparable<MD5Hash> A Writable for MD5 hash values. Field Summary Fields  Modifier and Type Field and Description static int MD5_LEN  Constructor Summary Constructors  Constructor and Description MD5Hash() Constructs an MD5Hash. MD5Hash(byte[] digest) Constructs an MD5Hash with a specified value. MD5Hash(String hex) Constructs an MD5Hash from a hex string. Method Summary Methods  Modifier and Type Method and Description int compareTo(MD5Hash that) Compares this object with the specified object for order. static MD5Hash digest(byte[] data) Construct a hash value for a byte array. static MD5Hash digest(byte[] data,             int start,             int len) Construct a hash value for a byte array. static MD5Hash digest(InputStream in) Construct a hash value for the content from the InputStream. static MD5Hash digest(String string) Construct a hash value for a String. static MD5Hash digest(org.apache.hadoop.io.UTF8 utf8) Construct a hash value for a String. boolean equals(Object o) Returns true iff o is an MD5Hash whose digest contains the  same values. byte[] getDigest() Returns the digest bytes. static MessageDigest getDigester() Create a thread local MD5 digester long halfDigest() Construct a half-sized version of this MD5. int hashCode() Returns a hash code value for this object. int quarterDigest() Return a 32-bit digest of the MD5. static MD5Hash read(DataInput in) Constructs, reads and returns an instance. void readFields(DataInput in) Deserialize the fields of this object from in. void set(MD5Hash that) Copy the contents of another instance into this instance. void setDigest(String hex) Sets the digest value from a hex string. String toString() Returns a string representation of this object. void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail MD5_LEN public static final int MD5_LEN See Also:Constant Field Values Constructor Detail MD5Hash public MD5Hash() Constructs an MD5Hash. MD5Hash public MD5Hash(String hex) Constructs an MD5Hash from a hex string. MD5Hash public MD5Hash(byte[] digest) Constructs an MD5Hash with a specified value. Method Detail readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException read public static MD5Hash read(DataInput in)                     throws IOException Constructs, reads and returns an instance. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException set public void set(MD5Hash that) Copy the contents of another instance into this instance. getDigest public byte[] getDigest() Returns the digest bytes. digest public static MD5Hash digest(byte[] data) Construct a hash value for a byte array. getDigester public static MessageDigest getDigester() Create a thread local MD5 digester digest public static MD5Hash digest(InputStream in)                       throws IOException Construct a hash value for the content from the InputStream. Throws: IOException digest public static MD5Hash digest(byte[] data,              int start,              int len) Construct a hash value for a byte array. digest public static MD5Hash digest(String string) Construct a hash value for a String. digest public static MD5Hash digest(org.apache.hadoop.io.UTF8 utf8) Construct a hash value for a String. halfDigest public long halfDigest() Construct a half-sized version of this MD5.  Fits in a long quarterDigest public int quarterDigest() Return a 32-bit digest of the MD5. Returns:the first 4 bytes of the md5 equals public boolean equals(Object o) Returns true iff o is an MD5Hash whose digest contains the  same values. Overrides: equals in class Object hashCode public int hashCode() Returns a hash code value for this object.  Only uses the first 4 bytes, since md5s are evenly distributed. Overrides: hashCode in class Object compareTo public int compareTo(MD5Hash that) Compares this object with the specified object for order. Specified by: compareTo in interface Comparable<MD5Hash> toString public String toString() Returns a string representation of this object. Overrides: toString in class Object setDigest public void setDigest(String hex) Sets the digest value from a hex string. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MapContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MapContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Interface MapContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> Type Parameters:KEYIN - the key input type to the MapperVALUEIN - the value input type to the MapperKEYOUT - the key output type from the MapperVALUEOUT - the value output type from the Mapper All Superinterfaces: JobContext, org.apache.hadoop.mapreduce.MRJobConfig, Progressable, TaskAttemptContext, TaskInputOutputContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Evolving public interface MapContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends TaskInputOutputContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> The context that is given to the Mapper. Field Summary Fields inherited from interface org.apache.hadoop.mapreduce.MRJobConfig APPLICATION_ATTEMPT_ID, APPLICATION_MASTER_CLASS, CACHE_ARCHIVES, CACHE_ARCHIVES_SIZES, CACHE_ARCHIVES_TIMESTAMPS, CACHE_ARCHIVES_VISIBILITIES, CACHE_FILE_TIMESTAMPS, CACHE_FILE_VISIBILITIES, CACHE_FILES, CACHE_FILES_SIZES, CACHE_LOCALARCHIVES, CACHE_LOCALFILES, CACHE_SYMLINK, CLASSPATH_ARCHIVES, CLASSPATH_FILES, COMBINE_CLASS_ATTR, COMBINE_RECORDS_BEFORE_PROGRESS, COMBINER_GROUP_COMPARATOR_CLASS, COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, COUNTER_GROUP_NAME_MAX_DEFAULT, COUNTER_GROUP_NAME_MAX_KEY, COUNTER_GROUPS_MAX_DEFAULT, COUNTER_GROUPS_MAX_KEY, COUNTER_NAME_MAX_DEFAULT, COUNTER_NAME_MAX_KEY, COUNTERS_MAX_DEFAULT, COUNTERS_MAX_KEY, DEFAULT_JOB_ACL_MODIFY_JOB, DEFAULT_JOB_ACL_VIEW_JOB, DEFAULT_JOB_AM_ACCESS_DISABLED, DEFAULT_JOB_RUNNING_MAP_LIMIT, DEFAULT_JOB_RUNNING_REDUCE_LIMIT, DEFAULT_JOB_TOKEN_TRACKING_IDS_ENABLED, DEFAULT_LOG_LEVEL, DEFAULT_MAP_CPU_VCORES, DEFAULT_MAP_MEMORY_MB, DEFAULT_MAPRED_ADMIN_JAVA_OPTS, DEFAULT_MAPRED_ADMIN_USER_ENV, DEFAULT_MAPREDUCE_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_CROSS_PLATFORM_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA, DEFAULT_MAX_ALLOWED_FETCH_FAILURES_FRACTION, DEFAULT_MAX_FETCH_FAILURES_NOTIFICATIONS, DEFAULT_MAX_SHUFFLE_FETCH_HOST_FAILURES, DEFAULT_MAX_SHUFFLE_FETCH_RETRY_DELAY, DEFAULT_MR_AM_ADMIN_COMMAND_OPTS, DEFAULT_MR_AM_COMMAND_OPTS, DEFAULT_MR_AM_COMMIT_WINDOW_MS, DEFAULT_MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, DEFAULT_MR_AM_CPU_VCORES, DEFAULT_MR_AM_HARD_KILL_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, DEFAULT_MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERCENT, DEFAULT_MR_AM_JOB_CLIENT_THREAD_COUNT, DEFAULT_MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, DEFAULT_MR_AM_JOB_REDUCE_RAMP_UP_LIMIT, DEFAULT_MR_AM_LOG_BACKUPS, DEFAULT_MR_AM_LOG_KB, DEFAULT_MR_AM_LOG_LEVEL, DEFAULT_MR_AM_MAX_ATTEMPTS, DEFAULT_MR_AM_NUM_PROGRESS_SPLITS, DEFAULT_MR_AM_PROFILE, DEFAULT_MR_AM_STAGING_DIR, DEFAULT_MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, DEFAULT_MR_AM_TASK_LISTENER_THREAD_COUNT, DEFAULT_MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, DEFAULT_MR_AM_TO_RM_WAIT_INTERVAL_MS, DEFAULT_MR_AM_VMEM_MB, DEFAULT_MR_CLIENT_JOB_MAX_RETRIES, DEFAULT_MR_CLIENT_JOB_RETRY_INTERVAL, DEFAULT_MR_CLIENT_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, DEFAULT_MR_JOB_END_NOTIFICATION_TIMEOUT, DEFAULT_MR_JOB_REDUCER_PREEMPT_DELAY_SEC, DEFAULT_REDUCE_CPU_VCORES, DEFAULT_REDUCE_MEMORY_MB, DEFAULT_REDUCE_SEPARATE_SHUFFLE_LOG, DEFAULT_SHELL, DEFAULT_SHUFFLE_FETCH_RETRY_INTERVAL_MS, DEFAULT_SHUFFLE_INPUT_BUFFER_PERCENT, DEFAULT_SHUFFLE_LOG_BACKUPS, DEFAULT_SHUFFLE_LOG_KB, DEFAULT_SPECULATIVE_MINIMUM_ALLOWED_TASKS, DEFAULT_SPECULATIVE_RETRY_AFTER_NO_SPECULATE, DEFAULT_SPECULATIVE_RETRY_AFTER_SPECULATE, DEFAULT_SPECULATIVECAP_RUNNING_TASKS, DEFAULT_SPECULATIVECAP_TOTAL_TASKS, DEFAULT_SPLIT_METAINFO_MAXSIZE, DEFAULT_TASK_ISMAP, DEFAULT_TASK_LOG_BACKUPS, DEFAULT_TASK_PROFILE_PARAMS, GROUP_COMPARATOR_CLASS, HADOOP_WORK_DIR, ID, INDEX_CACHE_MEMORY_LIMIT, INPUT_FORMAT_CLASS_ATTR, IO_SORT_FACTOR, IO_SORT_MB, JAR, JAR_UNPACK_PATTERN, JOB_ACL_MODIFY_JOB, JOB_ACL_VIEW_JOB, JOB_AM_ACCESS_DISABLED, JOB_CANCEL_DELEGATION_TOKEN, JOB_CONF_FILE, JOB_JAR, JOB_JOBTRACKER_ID, JOB_LOCAL_DIR, JOB_NAME, JOB_NAMENODES, JOB_RUNNING_MAP_LIMIT, JOB_RUNNING_REDUCE_LIMIT, JOB_SPLIT, JOB_SPLIT_METAINFO, JOB_SUBMIT_DIR, JOB_SUBMITHOST, JOB_SUBMITHOSTADDR, JOB_TAGS, JOB_TOKEN_TRACKING_IDS, JOB_TOKEN_TRACKING_IDS_ENABLED, JOB_UBERTASK_ENABLE, JOB_UBERTASK_MAXBYTES, JOB_UBERTASK_MAXMAPS, JOB_UBERTASK_MAXREDUCES, JVM_NUMTASKS_TORUN, KEY_COMPARATOR, MAP_CLASS_ATTR, MAP_COMBINE_MIN_SPILLS, MAP_CPU_VCORES, MAP_DEBUG_SCRIPT, MAP_ENV, MAP_FAILURES_MAX_PERCENT, MAP_INPUT_FILE, MAP_INPUT_PATH, MAP_INPUT_START, MAP_JAVA_OPTS, MAP_LOG_LEVEL, MAP_MAX_ATTEMPTS, MAP_MEMORY_MB, MAP_OUTPUT_COLLECTOR_CLASS_ATTR, MAP_OUTPUT_COMPRESS, MAP_OUTPUT_COMPRESS_CODEC, MAP_OUTPUT_KEY_CLASS, MAP_OUTPUT_KEY_FIELD_SEPERATOR, MAP_OUTPUT_VALUE_CLASS, MAP_SKIP_INCR_PROC_COUNT, MAP_SKIP_MAX_RECORDS, MAP_SORT_SPILL_PERCENT, MAP_SPECULATIVE, MAPRED_ADMIN_USER_ENV, MAPRED_ADMIN_USER_SHELL, MAPRED_MAP_ADMIN_JAVA_OPTS, MAPRED_REDUCE_ADMIN_JAVA_OPTS, MAPREDUCE_APPLICATION_CLASSPATH, MAPREDUCE_APPLICATION_FRAMEWORK_PATH, MAPREDUCE_JOB_CLASSLOADER, MAPREDUCE_JOB_CLASSLOADER_SYSTEM_CLASSES, MAPREDUCE_JOB_CREDENTIALS_BINARY, MAPREDUCE_JOB_DIR, MAPREDUCE_JOB_EMIT_TIMELINE_DATA, MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE, MAPREDUCE_JOB_SHUFFLE_PROVIDER_SERVICES, MAPREDUCE_JOB_USER_CLASSPATH_FIRST, MAPREDUCE_V2_CHILD_CLASS, MAX_ALLOWED_FETCH_FAILURES_FRACTION, MAX_FETCH_FAILURES_NOTIFICATIONS, MAX_SHUFFLE_FETCH_HOST_FAILURES, MAX_SHUFFLE_FETCH_RETRY_DELAY, MAX_TASK_FAILURES_PER_TRACKER, MR_AM_ADMIN_COMMAND_OPTS, MR_AM_ADMIN_USER_ENV, MR_AM_COMMAND_OPTS, MR_AM_COMMIT_WINDOW_MS, MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, MR_AM_CPU_VCORES, MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR, MR_AM_ENV, MR_AM_HARD_KILL_TIMEOUT_MS, MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERECENT, MR_AM_JOB_CLIENT_PORT_RANGE, MR_AM_JOB_CLIENT_THREAD_COUNT, MR_AM_JOB_NODE_BLACKLISTING_ENABLE, MR_AM_JOB_RECOVERY_ENABLE, MR_AM_JOB_RECOVERY_ENABLE_DEFAULT, MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, MR_AM_JOB_REDUCE_RAMPUP_UP_LIMIT, MR_AM_JOB_SPECULATOR, MR_AM_LOG_BACKUPS, MR_AM_LOG_KB, MR_AM_LOG_LEVEL, MR_AM_MAX_ATTEMPTS, MR_AM_NUM_PROGRESS_SPLITS, MR_AM_PREFIX, MR_AM_PROFILE, MR_AM_PROFILE_PARAMS, MR_AM_SECURITY_SERVICE_AUTHORIZATION_CLIENT, MR_AM_SECURITY_SERVICE_AUTHORIZATION_TASK_UMBILICAL, MR_AM_STAGING_DIR, MR_AM_TASK_ESTIMATOR, MR_AM_TASK_ESTIMATOR_EXPONENTIAL_RATE_ENABLE, MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, MR_AM_TASK_LISTENER_THREAD_COUNT, MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, MR_AM_TO_RM_WAIT_INTERVAL_MS, MR_AM_VMEM_MB, MR_APPLICATION_TYPE, MR_CLIENT_JOB_MAX_RETRIES, MR_CLIENT_JOB_RETRY_INTERVAL, MR_CLIENT_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, MR_ENCRYPTED_INTERMEDIATE_DATA, MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, MR_JOB_END_NOTIFICATION_MAX_ATTEMPTS, MR_JOB_END_NOTIFICATION_MAX_RETRY_INTERVAL, MR_JOB_END_NOTIFICATION_PROXY, MR_JOB_END_NOTIFICATION_TIMEOUT, MR_JOB_END_NOTIFICATION_URL, MR_JOB_END_RETRY_ATTEMPTS, MR_JOB_END_RETRY_INTERVAL, MR_JOB_REDUCER_PREEMPT_DELAY_SEC, MR_PREFIX, NUM_MAP_PROFILES, NUM_MAPS, NUM_REDUCE_PROFILES, NUM_REDUCES, OUTPUT, OUTPUT_FORMAT_CLASS_ATTR, OUTPUT_KEY_CLASS, OUTPUT_VALUE_CLASS, PARTITIONER_CLASS_ATTR, PRESERVE_FAILED_TASK_FILES, PRESERVE_FILES_PATTERN, PRIORITY, QUEUE_NAME, RECORDS_BEFORE_PROGRESS, REDUCE_CLASS_ATTR, REDUCE_CPU_VCORES, REDUCE_DEBUG_SCRIPT, REDUCE_ENV, REDUCE_FAILURES_MAXPERCENT, REDUCE_INPUT_BUFFER_PERCENT, REDUCE_JAVA_OPTS, REDUCE_LOG_LEVEL, REDUCE_MARKRESET_BUFFER_PERCENT, REDUCE_MARKRESET_BUFFER_SIZE, REDUCE_MAX_ATTEMPTS, REDUCE_MEMORY_MB, REDUCE_MEMORY_TOTAL_BYTES, REDUCE_MEMTOMEM_ENABLED, REDUCE_MEMTOMEM_THRESHOLD, REDUCE_MERGE_INMEM_THRESHOLD, REDUCE_SEPARATE_SHUFFLE_LOG, REDUCE_SKIP_INCR_PROC_COUNT, REDUCE_SKIP_MAXGROUPS, REDUCE_SPECULATIVE, RESERVATION_ID, SETUP_CLEANUP_NEEDED, SHUFFLE_CONNECT_TIMEOUT, SHUFFLE_FETCH_FAILURES, SHUFFLE_FETCH_RETRY_ENABLED, SHUFFLE_FETCH_RETRY_INTERVAL_MS, SHUFFLE_FETCH_RETRY_TIMEOUT_MS, SHUFFLE_INPUT_BUFFER_PERCENT, SHUFFLE_LOG_BACKUPS, SHUFFLE_LOG_KB, SHUFFLE_MEMORY_LIMIT_PERCENT, SHUFFLE_MERGE_PERCENT, SHUFFLE_NOTIFY_READERROR, SHUFFLE_PARALLEL_COPIES, SHUFFLE_READ_TIMEOUT, SKIP_OUTDIR, SKIP_RECORDS, SKIP_START_ATTEMPTS, SPECULATIVE_MINIMUM_ALLOWED_TASKS, SPECULATIVE_RETRY_AFTER_NO_SPECULATE, SPECULATIVE_RETRY_AFTER_SPECULATE, SPECULATIVE_SLOWNODE_THRESHOLD, SPECULATIVE_SLOWTASK_THRESHOLD, SPECULATIVECAP, SPECULATIVECAP_RUNNING_TASKS, SPECULATIVECAP_TOTAL_TASKS, SPLIT_FILE, SPLIT_METAINFO_MAXSIZE, STDERR_LOGFILE_ENV, STDOUT_LOGFILE_ENV, TASK_ATTEMPT_ID, TASK_CLEANUP_NEEDED, TASK_DEBUGOUT_LINES, TASK_ID, TASK_ISMAP, TASK_LOG_BACKUPS, TASK_MAP_PROFILE_PARAMS, TASK_OUTPUT_DIR, TASK_PARTITION, TASK_PROFILE, TASK_PROFILE_PARAMS, TASK_REDUCE_PROFILE_PARAMS, TASK_TIMEOUT, TASK_TIMEOUT_CHECK_INTERVAL_MS, TASK_USERLOG_LIMIT, USER_LOG_RETAIN_HOURS, USER_NAME, WORKDIR, WORKFLOW_ADJACENCY_PREFIX_PATTERN, WORKFLOW_ADJACENCY_PREFIX_STRING, WORKFLOW_ID, WORKFLOW_NAME, WORKFLOW_NODE_NAME, WORKFLOW_TAGS, WORKING_DIR Method Summary Methods  Modifier and Type Method and Description InputSplit getInputSplit() Get the input split for this map. Methods inherited from interface org.apache.hadoop.mapreduce.TaskInputOutputContext getCurrentKey, getCurrentValue, getOutputCommitter, nextKeyValue, write Methods inherited from interface org.apache.hadoop.mapreduce.TaskAttemptContext getCounter, getCounter, getProgress, getStatus, getTaskAttemptID, setStatus Methods inherited from interface org.apache.hadoop.mapreduce.JobContext getArchiveClassPaths, getArchiveTimestamps, getCacheArchives, getCacheFiles, getCombinerClass, getCombinerKeyGroupingComparator, getConfiguration, getCredentials, getFileClassPaths, getFileTimestamps, getGroupingComparator, getInputFormatClass, getJar, getJobID, getJobName, getJobSetupCleanupNeeded, getLocalCacheArchives, getLocalCacheFiles, getMapOutputKeyClass, getMapOutputValueClass, getMapperClass, getMaxMapAttempts, getMaxReduceAttempts, getNumReduceTasks, getOutputFormatClass, getOutputKeyClass, getOutputValueClass, getPartitionerClass, getProfileEnabled, getProfileParams, getProfileTaskRange, getReducerClass, getSortComparator, getSymlink, getTaskCleanupNeeded, getUser, getWorkingDirectory Methods inherited from interface org.apache.hadoop.util.Progressable progress Method Detail getInputSplit InputSplit getInputSplit() Get the input split for this map. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MapFile (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MapFile (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class MapFile java.lang.Object org.apache.hadoop.io.MapFile Direct Known Subclasses: ArrayFile, SetFile @InterfaceAudience.Public @InterfaceStability.Stable public class MapFile extends Object A file-based map from keys to values.    A map is a directory containing two files, the data file,  containing all keys and values in the map, and a smaller index  file, containing a fraction of the keys.  The fraction is determined by  MapFile.Writer.getIndexInterval().  The index file is read entirely into memory.  Thus key implementations  should try to keep themselves small.  Map files are created by adding entries in-order.  To maintain a large  database, perform updates by copying the previous version of a database and  merging in a sorted change list, to create a new version of the database in  a new file.  Sorting large change lists can be done with SequenceFile.Sorter. Field Summary Fields  Modifier and Type Field and Description static String DATA_FILE_NAME The name of the data file. static String INDEX_FILE_NAME The name of the index file. Constructor Summary Constructors  Modifier Constructor and Description protected  MapFile()  Method Summary Methods  Modifier and Type Method and Description static void delete(FileSystem fs,             String name) Deletes the named map file. static long fix(FileSystem fs,       Path dir,       Class<? extends Writable> keyClass,       Class<? extends Writable> valueClass,       boolean dryrun,       Configuration conf) This method attempts to fix a corrupt MapFile by re-creating its index. static void main(String[] args)  static void rename(FileSystem fs,             String oldName,             String newName) Renames an existing map directory. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail INDEX_FILE_NAME public static final String INDEX_FILE_NAME The name of the index file. See Also:Constant Field Values DATA_FILE_NAME public static final String DATA_FILE_NAME The name of the data file. See Also:Constant Field Values Constructor Detail MapFile protected MapFile() Method Detail rename public static void rename(FileSystem fs,           String oldName,           String newName)                    throws IOException Renames an existing map directory. Throws: IOException delete public static void delete(FileSystem fs,           String name)                    throws IOException Deletes the named map file. Throws: IOException fix public static long fix(FileSystem fs,        Path dir,        Class<? extends Writable> keyClass,        Class<? extends Writable> valueClass,        boolean dryrun,        Configuration conf)                 throws Exception This method attempts to fix a corrupt MapFile by re-creating its index. Parameters:fs - filesystemdir - directory containing the MapFile data and indexkeyClass - key class (has to be a subclass of Writable)valueClass - value class (has to be a subclass of Writable)dryrun - do not perform any changes, just report what needs to be done Returns:number of valid entries in this MapFile, or -1 if no fixing was needed Throws: Exception main public static void main(String[] args)                  throws Exception Throws: Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MapFileOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MapFileOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class MapFileOutputFormat java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat<WritableComparable<?>,Writable> org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class MapFileOutputFormat extends FileOutputFormat<WritableComparable<?>,Writable> An OutputFormat that writes   MapFiles. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat BASE_OUTPUT_NAME, COMPRESS, COMPRESS_CODEC, COMPRESS_TYPE, OUTDIR, PART Constructor Summary Constructors  Constructor and Description MapFileOutputFormat()  Method Summary Methods  Modifier and Type Method and Description static <K extends WritableComparable<?>,V extends Writable> Writable getEntry(org.apache.hadoop.io.MapFile.Reader[] readers,                 Partitioner<K,V> partitioner,                 K key,                 V value) Get an entry from output generated by this class. static org.apache.hadoop.io.MapFile.Reader[] getReaders(Path dir,                     Configuration conf) Open the output generated by this format. RecordWriter<WritableComparable<?>,Writable> getRecordWriter(TaskAttemptContext context) Get the RecordWriter for the given task. Methods inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat checkOutputSpecs, getCompressOutput, getDefaultWorkFile, getOutputCommitter, getOutputCompressorClass, getOutputName, getOutputPath, getPathForWorkFile, getUniqueFile, getWorkOutputPath, setCompressOutput, setOutputCompressorClass, setOutputName, setOutputPath Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MapFileOutputFormat public MapFileOutputFormat() Method Detail getRecordWriter public RecordWriter<WritableComparable<?>,Writable> getRecordWriter(TaskAttemptContext context)                                                              throws IOException Description copied from class: OutputFormat Get the RecordWriter for the given task. Specified by: getRecordWriter in class FileOutputFormat<WritableComparable<?>,Writable> Parameters:context - the information about the current task. Returns:a RecordWriter to write the output for the job. Throws: IOException getReaders public static org.apache.hadoop.io.MapFile.Reader[] getReaders(Path dir,                                                Configuration conf)                                                         throws IOException Open the output generated by this format. Throws: IOException getEntry public static <K extends WritableComparable<?>,V extends Writable> Writable getEntry(org.apache.hadoop.io.MapFile.Reader[] readers,                                                                      Partitioner<K,V> partitioner,                                                                      K key,                                                                      V value)                          throws IOException Get an entry from output generated by this class. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MapReduceBase (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MapReduceBase (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class MapReduceBase java.lang.Object org.apache.hadoop.mapred.MapReduceBase All Implemented Interfaces: Closeable, AutoCloseable, JobConfigurable Direct Known Subclasses: IdentityMapper, IdentityReducer, InverseMapper, LongSumReducer, RegexMapper, TokenCountMapper @InterfaceAudience.Public @InterfaceStability.Stable public class MapReduceBase extends Object implements Closeable, JobConfigurable Base class for Mapper and Reducer implementations.    Provides default no-op implementations for a few methods, most non-trivial  applications need to override some of them. Constructor Summary Constructors  Constructor and Description MapReduceBase()  Method Summary Methods  Modifier and Type Method and Description void close() Default implementation that does nothing. void configure(JobConf job) Default implementation that does nothing. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MapReduceBase public MapReduceBase() Method Detail close public void close()            throws IOException Default implementation that does nothing. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Throws: IOException configure public void configure(JobConf job) Default implementation that does nothing. Specified by: configure in interface JobConfigurable Parameters:job - the configuration Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MapRunnable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MapRunnable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Interface MapRunnable<K1,V1,K2,V2> All Superinterfaces: JobConfigurable All Known Implementing Classes: MapRunner, MultithreadedMapRunner @InterfaceAudience.Public @InterfaceStability.Stable public interface MapRunnable<K1,V1,K2,V2> extends JobConfigurable Expert: Generic interface for Mappers.    Custom implementations of MapRunnable can exert greater   control on map processing e.g. multi-threaded, asynchronous mappers etc. See Also:Mapper Method Summary Methods  Modifier and Type Method and Description void run(RecordReader<K1,V1> input,       OutputCollector<K2,V2> output,       Reporter reporter) Start mapping input <key, value> pairs. Methods inherited from interface org.apache.hadoop.mapred.JobConfigurable configure Method Detail run void run(RecordReader<K1,V1> input,        OutputCollector<K2,V2> output,        Reporter reporter)          throws IOException Start mapping input <key, value> pairs.     Mapping of input records to output records is complete when this method   returns. Parameters:input - the RecordReader to read the input records.output - the OutputCollector to collect the outputrecords.reporter - Reporter to report progress, status-updates etc. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MapRunner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MapRunner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class MapRunner<K1,V1,K2,V2> java.lang.Object org.apache.hadoop.mapred.MapRunner<K1,V1,K2,V2> All Implemented Interfaces: JobConfigurable, MapRunnable<K1,V1,K2,V2> @InterfaceAudience.Public @InterfaceStability.Stable public class MapRunner<K1,V1,K2,V2> extends Object implements MapRunnable<K1,V1,K2,V2> Default MapRunnable implementation. Constructor Summary Constructors  Constructor and Description MapRunner()  Method Summary Methods  Modifier and Type Method and Description void configure(JobConf job) Initializes a new instance from a JobConf. protected Mapper<K1,V1,K2,V2> getMapper()  void run(RecordReader<K1,V1> input,       OutputCollector<K2,V2> output,       Reporter reporter) Start mapping input <key, value> pairs. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MapRunner public MapRunner() Method Detail configure public void configure(JobConf job) Description copied from interface: JobConfigurable Initializes a new instance from a JobConf. Specified by: configure in interface JobConfigurable Parameters:job - the configuration run public void run(RecordReader<K1,V1> input,        OutputCollector<K2,V2> output,        Reporter reporter)          throws IOException Description copied from interface: MapRunnable Start mapping input <key, value> pairs.     Mapping of input records to output records is complete when this method   returns. Specified by: run in interface MapRunnable<K1,V1,K2,V2> Parameters:input - the RecordReader to read the input records.output - the OutputCollector to collect the outputrecords.reporter - Reporter to report progress, status-updates etc. Throws: IOException getMapper protected Mapper<K1,V1,K2,V2> getMapper() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MapTypeID (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MapTypeID (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.meta Class MapTypeID java.lang.Object org.apache.hadoop.record.meta.TypeID org.apache.hadoop.record.meta.MapTypeID Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class MapTypeID extends TypeID Represents typeID for a Map Field Summary Fields inherited from class org.apache.hadoop.record.meta.TypeID BoolTypeID, BufferTypeID, ByteTypeID, DoubleTypeID, FloatTypeID, IntTypeID, LongTypeID, StringTypeID, typeVal Constructor Summary Constructors  Constructor and Description MapTypeID(TypeID typeIDKey,                   TypeID typeIDValue) Deprecated.    Method Summary Methods  Modifier and Type Method and Description boolean equals(Object o) Deprecated.  Two map  typeIDs are equal if their constituent elements have the   same type TypeID getKeyTypeID() Deprecated.  get the TypeID of the map's key element TypeID getValueTypeID() Deprecated.  get the TypeID of the map's value element int hashCode() Deprecated.  We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Methods inherited from class org.apache.hadoop.record.meta.TypeID getTypeVal Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail MapTypeID public MapTypeID(TypeID typeIDKey,          TypeID typeIDValue) Deprecated.  Method Detail getKeyTypeID public TypeID getKeyTypeID() Deprecated.  get the TypeID of the map's key element getValueTypeID public TypeID getValueTypeID() Deprecated.  get the TypeID of the map's value element equals public boolean equals(Object o) Deprecated.  Two map  typeIDs are equal if their constituent elements have the   same type Overrides: equals in class TypeID hashCode public int hashCode() Deprecated.  We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Overrides: hashCode in class TypeID Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MapWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MapWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class MapWritable java.lang.Object org.apache.hadoop.io.AbstractMapWritable org.apache.hadoop.io.MapWritable All Implemented Interfaces: Map<Writable,Writable>, Configurable, Writable @InterfaceAudience.Public @InterfaceStability.Stable public class MapWritable extends AbstractMapWritable implements Map<Writable,Writable> A Writable Map. Constructor Summary Constructors  Constructor and Description MapWritable() Default constructor. MapWritable(MapWritable other) Copy constructor. Method Summary Methods  Modifier and Type Method and Description void clear()  boolean containsKey(Object key)  boolean containsValue(Object value)  Set<Map.Entry<Writable,Writable>> entrySet()  boolean equals(Object obj)  Writable get(Object key)  int hashCode()  boolean isEmpty()  Set<Writable> keySet()  Writable put(Writable key,       Writable value)  void putAll(Map<? extends Writable,? extends Writable> t)  void readFields(DataInput in) Deserialize the fields of this object from in. Writable remove(Object key)  int size()  Collection<Writable> values()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.io.AbstractMapWritable addToMap, copy, getClass, getConf, getId, setConf Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail MapWritable public MapWritable() Default constructor. MapWritable public MapWritable(MapWritable other) Copy constructor. Parameters:other - the map to copy from Method Detail clear public void clear() Specified by: clear in interface Map<Writable,Writable> containsKey public boolean containsKey(Object key) Specified by: containsKey in interface Map<Writable,Writable> containsValue public boolean containsValue(Object value) Specified by: containsValue in interface Map<Writable,Writable> entrySet public Set<Map.Entry<Writable,Writable>> entrySet() Specified by: entrySet in interface Map<Writable,Writable> equals public boolean equals(Object obj) Specified by: equals in interface Map<Writable,Writable> Overrides: equals in class Object get public Writable get(Object key) Specified by: get in interface Map<Writable,Writable> hashCode public int hashCode() Specified by: hashCode in interface Map<Writable,Writable> Overrides: hashCode in class Object isEmpty public boolean isEmpty() Specified by: isEmpty in interface Map<Writable,Writable> keySet public Set<Writable> keySet() Specified by: keySet in interface Map<Writable,Writable> put public Writable put(Writable key,            Writable value) Specified by: put in interface Map<Writable,Writable> putAll public void putAll(Map<? extends Writable,? extends Writable> t) Specified by: putAll in interface Map<Writable,Writable> remove public Writable remove(Object key) Specified by: remove in interface Map<Writable,Writable> size public int size() Specified by: size in interface Map<Writable,Writable> values public Collection<Writable> values() Specified by: values in interface Map<Writable,Writable> write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Overrides: write in class AbstractMapWritable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Overrides: readFields in class AbstractMapWritable Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Mapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Mapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> java.lang.Object org.apache.hadoop.mapreduce.Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> Direct Known Subclasses: ChainMapper, FieldSelectionMapper, InverseMapper, MultithreadedMapper, RegexMapper, TokenCounterMapper, ValueAggregatorMapper, WrappedMapper @InterfaceAudience.Public @InterfaceStability.Stable public class Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends Object Maps input key/value pairs to a set of intermediate key/value pairs.      Maps are the individual tasks which transform input records into a   intermediate records. The transformed intermediate records need not be of   the same type as the input records. A given input pair may map to zero or   many output pairs.     The Hadoop Map-Reduce framework spawns one map task for each   InputSplit generated by the InputFormat for the job.  Mapper implementations can access the Configuration for   the job via the JobContext.getConfiguration().    The framework first calls   setup(org.apache.hadoop.mapreduce.Mapper.Context), followed by  map(Object, Object, org.apache.hadoop.mapreduce.Mapper.Context)  for each key/value pair in the InputSplit. Finally   cleanup(org.apache.hadoop.mapreduce.Mapper.Context) is called.    All intermediate values associated with a given output key are   subsequently grouped by the framework, and passed to a Reducer to    determine the final output. Users can control the sorting and grouping by   specifying two key RawComparator classes.  The Mapper outputs are partitioned per   Reducer. Users can control which keys (and hence records) go to   which Reducer by implementing a custom Partitioner.    Users can optionally specify a combiner, via   Job.setCombinerClass(Class), to perform local aggregation of the   intermediate outputs, which helps to cut down the amount of data transferred   from the Mapper to the Reducer.    Applications can specify if and how the intermediate  outputs are to be compressed and which CompressionCodecs are to be  used via the Configuration.     If the job has zero  reduces then the output of the Mapper is directly written  to the OutputFormat without sorting by keys.    Example:    public class TokenCounterMapper       extends Mapper<Object, Text, Text, IntWritable>{         private final static IntWritable one = new IntWritable(1);    private Text word = new Text();        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {      StringTokenizer itr = new StringTokenizer(value.toString());      while (itr.hasMoreTokens()) {        word.set(itr.nextToken());        context.write(word, one);      }    }  }    Applications may override the  run(org.apache.hadoop.mapreduce.Mapper.Context) method to exert  greater control on map processing e.g. multi-threaded Mappers   etc. See Also:InputFormat,  JobContext,  Partitioner,  Reducer Constructor Summary Constructors  Constructor and Description Mapper()  Method Summary Methods  Modifier and Type Method and Description protected void cleanup(org.apache.hadoop.mapreduce.Mapper.Context context) Called once at the end of the task. protected void map(KEYIN key,       VALUEIN value,       org.apache.hadoop.mapreduce.Mapper.Context context) Called once for each key/value pair in the input split. void run(org.apache.hadoop.mapreduce.Mapper.Context context) Expert users can override this method for more complete control over the  execution of the Mapper. protected void setup(org.apache.hadoop.mapreduce.Mapper.Context context) Called once at the beginning of the task. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Mapper public Mapper() Method Detail setup protected void setup(org.apache.hadoop.mapreduce.Mapper.Context context)               throws IOException,                      InterruptedException Called once at the beginning of the task. Throws: IOException InterruptedException map protected void map(KEYIN key,        VALUEIN value,        org.apache.hadoop.mapreduce.Mapper.Context context)             throws IOException,                    InterruptedException Called once for each key/value pair in the input split. Most applications  should override this, but the default is the identity function. Throws: IOException InterruptedException cleanup protected void cleanup(org.apache.hadoop.mapreduce.Mapper.Context context)                 throws IOException,                        InterruptedException Called once at the end of the task. Throws: IOException InterruptedException run public void run(org.apache.hadoop.mapreduce.Mapper.Context context)          throws IOException,                 InterruptedException Expert users can override this method for more complete control over the  execution of the Mapper. Parameters:context -  Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MarkableIterator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MarkableIterator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class MarkableIterator<VALUE> java.lang.Object org.apache.hadoop.mapreduce.MarkableIterator<VALUE> @InterfaceAudience.Public @InterfaceStability.Evolving public class MarkableIterator<VALUE> extends Object MarkableIterator is a wrapper iterator class that   implements the MarkableIteratorInterface. Constructor Summary Constructors  Constructor and Description MarkableIterator(Iterator<VALUE> itr) Create a new iterator layered on the input iterator Method Summary Methods  Modifier and Type Method and Description void clearMark() Clear any previously set mark boolean hasNext()  void mark() Mark the current record. VALUE next()  void remove()  void reset() Reset the iterator to the last record before a call to the previous mark Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MarkableIterator public MarkableIterator(Iterator<VALUE> itr) Create a new iterator layered on the input iterator Parameters:itr - underlying iterator that implements MarkableIteratorInterface Method Detail mark public void mark()           throws IOException Mark the current record. A subsequent call to reset will rewind  the iterator to this record. Throws: IOException reset public void reset()            throws IOException Reset the iterator to the last record before a call to the previous mark Throws: IOException clearMark public void clearMark()                throws IOException Clear any previously set mark Throws: IOException hasNext public boolean hasNext() next public VALUE next() remove public void remove() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetaBlockAlreadyExists (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetaBlockAlreadyExists (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.file.tfile Class MetaBlockAlreadyExists java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.io.file.tfile.MetaBlockAlreadyExists All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class MetaBlockAlreadyExists extends IOException Exception - Meta Block with the same name already exists. See Also:Serialized Form Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetaBlockDoesNotExist (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetaBlockDoesNotExist (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.file.tfile Class MetaBlockDoesNotExist java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.io.file.tfile.MetaBlockDoesNotExist All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class MetaBlockDoesNotExist extends IOException Exception - No such Meta Block with the given name. See Also:Serialized Form Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Metric (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Metric (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Required |  Optional Detail:  Element org.apache.hadoop.metrics2.annotation Annotation Type Metric @InterfaceAudience.Public @InterfaceStability.Evolving @Documented @Target(value={FIELD,METHOD}) @Retention(value=RUNTIME) public @interface Metric Annotation interface for a single metric Optional Element Summary Optional Elements  Modifier and Type Optional Element and Description String about  boolean always  String sampleName  org.apache.hadoop.metrics2.annotation.Metric.Type type  String[] value Shorthand for optional name and description String valueName  Element Detail value public abstract String[] value Shorthand for optional name and description Returns:{description} or {name, description} Default: {} about public abstract String about Returns:optional description of the metric Default: "" sampleName public abstract String sampleName Returns:optional sample name for MutableStat/Rate/Rates Default: "Ops" valueName public abstract String valueName Returns:optional value name for MutableStat/Rate/Rates Default: "Time" always public abstract boolean always Returns:true to create a metric snapshot even if unchanged. Default: false type public abstract org.apache.hadoop.metrics2.annotation.Metric.Type type Returns:optional type (counter|gauge) of the metric Default: org.apache.hadoop.metrics2.annotation.Metric.Type.DEFAULT Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Required |  Optional Detail:  Element Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricValue (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricValue (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.spi Class MetricValue java.lang.Object org.apache.hadoop.metrics.spi.MetricValue @InterfaceAudience.Public @InterfaceStability.Evolving public class MetricValue extends Object A Number that is either an absolute or an incremental amount. Field Summary Fields  Modifier and Type Field and Description static boolean ABSOLUTE  static boolean INCREMENT  Constructor Summary Constructors  Constructor and Description MetricValue(Number number,                       boolean isIncrement) Creates a new instance of MetricValue Method Summary Methods  Modifier and Type Method and Description Number getNumber()  boolean isAbsolute()  boolean isIncrement()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail ABSOLUTE public static final boolean ABSOLUTE See Also:Constant Field Values INCREMENT public static final boolean INCREMENT See Also:Constant Field Values Constructor Detail MetricValue public MetricValue(Number number,            boolean isIncrement) Creates a new instance of MetricValue Method Detail isIncrement public boolean isIncrement() isAbsolute public boolean isAbsolute() getNumber public Number getNumber() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Metrics (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Metrics (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Required |  Optional Detail:  Element org.apache.hadoop.metrics2.annotation Annotation Type Metrics @InterfaceAudience.Public @InterfaceStability.Evolving @Documented @Target(value=TYPE) @Retention(value=RUNTIME) public @interface Metrics Annotation interface for a group of metrics Required Element Summary Required Elements  Modifier and Type Required Element and Description String context  Optional Element Summary Optional Elements  Modifier and Type Optional Element and Description String about  String name  Element Detail context public abstract String context Returns:the context name for a group of metrics name public abstract String name Returns:the (record) name of the metrics Default: "" about public abstract String about Returns:the optional description of metrics Default: "" Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Required |  Optional Detail:  Element Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsCache (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsCache (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.util Class MetricsCache java.lang.Object org.apache.hadoop.metrics2.util.MetricsCache @InterfaceAudience.Public @InterfaceStability.Evolving public class MetricsCache extends Object A metrics cache for sinks that don't support sparse updates. Constructor Summary Constructors  Constructor and Description MetricsCache()  MetricsCache(int maxRecsPerName) Construct a metrics cache Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.metrics2.util.MetricsCache.Record get(String name,       Collection<MetricsTag> tags) Get the cached record org.apache.hadoop.metrics2.util.MetricsCache.Record update(MetricsRecord mr) Update the cache and return the current cache record org.apache.hadoop.metrics2.util.MetricsCache.Record update(MetricsRecord mr,             boolean includingTags) Update the cache and return the current cached record Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MetricsCache public MetricsCache() MetricsCache public MetricsCache(int maxRecsPerName) Construct a metrics cache Parameters:maxRecsPerName - limit of the number records per record name Method Detail update public org.apache.hadoop.metrics2.util.MetricsCache.Record update(MetricsRecord mr,                                                          boolean includingTags) Update the cache and return the current cached record Parameters:mr - the update recordincludingTags - cache tag values (for later lookup by name) if true Returns:the updated cache record update public org.apache.hadoop.metrics2.util.MetricsCache.Record update(MetricsRecord mr) Update the cache and return the current cache record Parameters:mr - the update record Returns:the updated cache record get public org.apache.hadoop.metrics2.util.MetricsCache.Record get(String name,                                                       Collection<MetricsTag> tags) Get the cached record Parameters:name - of the recordtags - of the record Returns:the cached record or null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsCollector (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsCollector (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Interface MetricsCollector @InterfaceAudience.Public @InterfaceStability.Evolving public interface MetricsCollector The metrics collector interface Method Summary Methods  Modifier and Type Method and Description MetricsRecordBuilder addRecord(MetricsInfo info) Add a metrics record MetricsRecordBuilder addRecord(String name) Add a metrics record Method Detail addRecord MetricsRecordBuilder addRecord(String name) Add a metrics record Parameters:name - of the record Returns:a metrics record builder for the record addRecord MetricsRecordBuilder addRecord(MetricsInfo info) Add a metrics record Parameters:info - of the record Returns:a metrics record builder for the record Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Class MetricsException java.lang.Object java.lang.Throwable java.lang.Exception java.lang.RuntimeException org.apache.hadoop.metrics2.MetricsException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class MetricsException extends RuntimeException A general metrics exception wrapper See Also:Serialized Form Constructor Summary Constructors  Constructor and Description MetricsException(String message) Construct the exception with a message MetricsException(String message,                                 Throwable cause) Construct the exception with a message and a cause MetricsException(Throwable cause) Construct the exception with a cause Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail MetricsException public MetricsException(String message) Construct the exception with a message Parameters:message - for the exception MetricsException public MetricsException(String message,                 Throwable cause) Construct the exception with a message and a cause Parameters:message - for the exceptioncause - of the exception MetricsException public MetricsException(Throwable cause) Construct the exception with a cause Parameters:cause - of the exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Class MetricsFilter java.lang.Object org.apache.hadoop.metrics2.MetricsFilter All Implemented Interfaces: MetricsPlugin Direct Known Subclasses: org.apache.hadoop.metrics2.filter.AbstractPatternFilter @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class MetricsFilter extends Object implements MetricsPlugin The metrics filter interface Constructor Summary Constructors  Constructor and Description MetricsFilter()  Method Summary Methods  Modifier and Type Method and Description abstract boolean accepts(Iterable<MetricsTag> tags) Whether to accept the tags boolean accepts(MetricsRecord record) Whether to accept the record abstract boolean accepts(MetricsTag tag) Whether to accept the tag abstract boolean accepts(String name) Whether to accept the name Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.metrics2.MetricsPlugin init Constructor Detail MetricsFilter public MetricsFilter() Method Detail accepts public abstract boolean accepts(String name) Whether to accept the name Parameters:name - to filter on Returns:true to accept; false otherwise. accepts public abstract boolean accepts(MetricsTag tag) Whether to accept the tag Parameters:tag - to filter on Returns:true to accept; false otherwise accepts public abstract boolean accepts(Iterable<MetricsTag> tags) Whether to accept the tags Parameters:tags - to filter on Returns:true to accept; false otherwise accepts public boolean accepts(MetricsRecord record) Whether to accept the record Parameters:record - to filter on Returns:true to accept; false otherwise. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Interface MetricsInfo All Known Implementing Classes: AbstractMetric, MetricsTag @InterfaceAudience.Public @InterfaceStability.Evolving public interface MetricsInfo Interface to provide immutable meta info for metrics Method Summary Methods  Modifier and Type Method and Description String description()  String name()  Method Detail name String name() Returns:the name of the metric/tag description String description() Returns:the description of the metric/tag Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsPlugin (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsPlugin (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Interface MetricsPlugin All Known Subinterfaces: MetricsSink All Known Implementing Classes: org.apache.hadoop.metrics2.filter.AbstractPatternFilter, FileSink, GlobFilter, GraphiteSink, MetricsFilter, RegexFilter @InterfaceAudience.Public @InterfaceStability.Evolving public interface MetricsPlugin The plugin interface for the metrics framework Method Summary Methods  Modifier and Type Method and Description void init(org.apache.commons.configuration.SubsetConfiguration conf) Initialize the plugin Method Detail init void init(org.apache.commons.configuration.SubsetConfiguration conf) Initialize the plugin Parameters:conf - the configuration object for the plugin Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsRecord (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsRecord (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Interface MetricsRecord @InterfaceAudience.Public @InterfaceStability.Evolving public interface MetricsRecord An immutable snapshot of metrics with a timestamp Method Summary Methods  Modifier and Type Method and Description String context()  String description()  Iterable<AbstractMetric> metrics() Get the metrics of the record String name()  Collection<MetricsTag> tags() Get the tags of the record  Note: returning a collection instead of iterable as we  need to use tags as keys (hence Collection#hashCode etc.) in maps long timestamp() Get the timestamp of the metrics Method Detail timestamp long timestamp() Get the timestamp of the metrics Returns:the timestamp name String name() Returns:the record name description String description() Returns:the description of the record context String context() Returns:the context name of the record tags Collection<MetricsTag> tags() Get the tags of the record  Note: returning a collection instead of iterable as we  need to use tags as keys (hence Collection#hashCode etc.) in maps Returns:an unmodifiable collection of tags metrics Iterable<AbstractMetric> metrics() Get the metrics of the record Returns:an immutable iterable interface for metrics Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsRecordBuilder (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsRecordBuilder (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Class MetricsRecordBuilder java.lang.Object org.apache.hadoop.metrics2.MetricsRecordBuilder @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class MetricsRecordBuilder extends Object The metrics record builder interface Constructor Summary Constructors  Constructor and Description MetricsRecordBuilder()  Method Summary Methods  Modifier and Type Method and Description abstract MetricsRecordBuilder add(AbstractMetric metric) Add a pre-made immutable metric object abstract MetricsRecordBuilder add(MetricsTag tag) Add an immutable metrics tag object abstract MetricsRecordBuilder addCounter(MetricsInfo info,                     int value) Add an integer metric abstract MetricsRecordBuilder addCounter(MetricsInfo info,                     long value) Add an long metric abstract MetricsRecordBuilder addGauge(MetricsInfo info,                 double value) Add a double gauge metric abstract MetricsRecordBuilder addGauge(MetricsInfo info,                 float value) Add a float gauge metric abstract MetricsRecordBuilder addGauge(MetricsInfo info,                 int value) Add a integer gauge metric abstract MetricsRecordBuilder addGauge(MetricsInfo info,                 long value) Add a long gauge metric MetricsCollector endRecord() Syntactic sugar to add multiple records in a collector in a one liner. abstract MetricsCollector parent()  abstract MetricsRecordBuilder setContext(String value) Set the context tag abstract MetricsRecordBuilder tag(MetricsInfo info,       String value) Add a metrics tag Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MetricsRecordBuilder public MetricsRecordBuilder() Method Detail tag public abstract MetricsRecordBuilder tag(MetricsInfo info,                        String value) Add a metrics tag Parameters:info - metadata of the tagvalue - of the tag Returns:self add public abstract MetricsRecordBuilder add(MetricsTag tag) Add an immutable metrics tag object Parameters:tag - a pre-made tag object (potentially save an object construction) Returns:self add public abstract MetricsRecordBuilder add(AbstractMetric metric) Add a pre-made immutable metric object Parameters:metric - the pre-made metric to save an object construction Returns:self setContext public abstract MetricsRecordBuilder setContext(String value) Set the context tag Parameters:value - of the context Returns:self addCounter public abstract MetricsRecordBuilder addCounter(MetricsInfo info,                               int value) Add an integer metric Parameters:info - metadata of the metricvalue - of the metric Returns:self addCounter public abstract MetricsRecordBuilder addCounter(MetricsInfo info,                               long value) Add an long metric Parameters:info - metadata of the metricvalue - of the metric Returns:self addGauge public abstract MetricsRecordBuilder addGauge(MetricsInfo info,                             int value) Add a integer gauge metric Parameters:info - metadata of the metricvalue - of the metric Returns:self addGauge public abstract MetricsRecordBuilder addGauge(MetricsInfo info,                             long value) Add a long gauge metric Parameters:info - metadata of the metricvalue - of the metric Returns:self addGauge public abstract MetricsRecordBuilder addGauge(MetricsInfo info,                             float value) Add a float gauge metric Parameters:info - metadata of the metricvalue - of the metric Returns:self addGauge public abstract MetricsRecordBuilder addGauge(MetricsInfo info,                             double value) Add a double gauge metric Parameters:info - metadata of the metricvalue - of the metric Returns:self parent public abstract MetricsCollector parent() Returns:the parent metrics collector object endRecord public MetricsCollector endRecord() Syntactic sugar to add multiple records in a collector in a one liner. Returns:the parent metrics collector object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsRecordImpl (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsRecordImpl (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.spi Class MetricsRecordImpl java.lang.Object org.apache.hadoop.metrics.spi.MetricsRecordImpl All Implemented Interfaces: org.apache.hadoop.metrics.MetricsRecord @InterfaceAudience.Public @InterfaceStability.Evolving public class MetricsRecordImpl extends Object implements org.apache.hadoop.metrics.MetricsRecord An implementation of MetricsRecord.  Keeps a back-pointer to the context  from which it was created, and delegates back to it on update  and remove(). Constructor Summary Constructors  Modifier Constructor and Description protected  MetricsRecordImpl(String recordName,                                   AbstractMetricsContext context) Creates a new instance of FileRecord Method Summary Methods  Modifier and Type Method and Description String getRecordName() Returns the record name. void incrMetric(String metricName,                     byte metricValue) Increments the named metric by the specified value. void incrMetric(String metricName,                     float metricValue) Increments the named metric by the specified value. void incrMetric(String metricName,                     int metricValue) Increments the named metric by the specified value. void incrMetric(String metricName,                     long metricValue) Increments the named metric by the specified value. void incrMetric(String metricName,                     short metricValue) Increments the named metric by the specified value. void remove() Removes the row, if it exists, in the buffered data table having tags   that equal the tags that have been set on this record. void removeTag(String tagName) Removes any tag of the specified name. void setMetric(String metricName,                   byte metricValue) Sets the named metric to the specified value. void setMetric(String metricName,                   float metricValue) Sets the named metric to the specified value. void setMetric(String metricName,                   int metricValue) Sets the named metric to the specified value. void setMetric(String metricName,                   long metricValue) Sets the named metric to the specified value. void setMetric(String metricName,                   short metricValue) Sets the named metric to the specified value. void setTag(String tagName,             byte tagValue) Sets the named tag to the specified value. void setTag(String tagName,             int tagValue) Sets the named tag to the specified value. void setTag(String tagName,             long tagValue) Sets the named tag to the specified value. void setTag(String tagName,             short tagValue) Sets the named tag to the specified value. void setTag(String tagName,             String tagValue) Sets the named tag to the specified value. void update() Updates the table of buffered data which is to be sent periodically. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MetricsRecordImpl protected MetricsRecordImpl(String recordName,                  AbstractMetricsContext context) Creates a new instance of FileRecord Method Detail getRecordName public String getRecordName() Returns the record name. Specified by: getRecordName in interface org.apache.hadoop.metrics.MetricsRecord Returns:the record name setTag public void setTag(String tagName,           String tagValue) Sets the named tag to the specified value. Specified by: setTag in interface org.apache.hadoop.metrics.MetricsRecord Parameters:tagName - name of the tagtagValue - new value of the tag Throws: org.apache.hadoop.metrics.MetricsException - if the tagName conflicts with the configuration setTag public void setTag(String tagName,           int tagValue) Sets the named tag to the specified value. Specified by: setTag in interface org.apache.hadoop.metrics.MetricsRecord Parameters:tagName - name of the tagtagValue - new value of the tag Throws: org.apache.hadoop.metrics.MetricsException - if the tagName conflicts with the configuration setTag public void setTag(String tagName,           long tagValue) Sets the named tag to the specified value. Specified by: setTag in interface org.apache.hadoop.metrics.MetricsRecord Parameters:tagName - name of the tagtagValue - new value of the tag Throws: org.apache.hadoop.metrics.MetricsException - if the tagName conflicts with the configuration setTag public void setTag(String tagName,           short tagValue) Sets the named tag to the specified value. Specified by: setTag in interface org.apache.hadoop.metrics.MetricsRecord Parameters:tagName - name of the tagtagValue - new value of the tag Throws: org.apache.hadoop.metrics.MetricsException - if the tagName conflicts with the configuration setTag public void setTag(String tagName,           byte tagValue) Sets the named tag to the specified value. Specified by: setTag in interface org.apache.hadoop.metrics.MetricsRecord Parameters:tagName - name of the tagtagValue - new value of the tag Throws: org.apache.hadoop.metrics.MetricsException - if the tagName conflicts with the configuration removeTag public void removeTag(String tagName) Removes any tag of the specified name. Specified by: removeTag in interface org.apache.hadoop.metrics.MetricsRecord Parameters:tagName - name of a tag setMetric public void setMetric(String metricName,              int metricValue) Sets the named metric to the specified value. Specified by: setMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - new value of the metric Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration setMetric public void setMetric(String metricName,              long metricValue) Sets the named metric to the specified value. Specified by: setMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - new value of the metric Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration setMetric public void setMetric(String metricName,              short metricValue) Sets the named metric to the specified value. Specified by: setMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - new value of the metric Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration setMetric public void setMetric(String metricName,              byte metricValue) Sets the named metric to the specified value. Specified by: setMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - new value of the metric Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration setMetric public void setMetric(String metricName,              float metricValue) Sets the named metric to the specified value. Specified by: setMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - new value of the metric Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration incrMetric public void incrMetric(String metricName,               int metricValue) Increments the named metric by the specified value. Specified by: incrMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - incremental value Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration incrMetric public void incrMetric(String metricName,               long metricValue) Increments the named metric by the specified value. Specified by: incrMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - incremental value Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration incrMetric public void incrMetric(String metricName,               short metricValue) Increments the named metric by the specified value. Specified by: incrMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - incremental value Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration incrMetric public void incrMetric(String metricName,               byte metricValue) Increments the named metric by the specified value. Specified by: incrMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - incremental value Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration incrMetric public void incrMetric(String metricName,               float metricValue) Increments the named metric by the specified value. Specified by: incrMetric in interface org.apache.hadoop.metrics.MetricsRecord Parameters:metricName - name of the metricmetricValue - incremental value Throws: org.apache.hadoop.metrics.MetricsException - if the metricName or the type of the metricValue   conflicts with the configuration update public void update() Updates the table of buffered data which is to be sent periodically.  If the tag values match an existing row, that row is updated;   otherwise, a new row is added. Specified by: update in interface org.apache.hadoop.metrics.MetricsRecord remove public void remove() Removes the row, if it exists, in the buffered data table having tags   that equal the tags that have been set on this record. Specified by: remove in interface org.apache.hadoop.metrics.MetricsRecord Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsRegistry (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsRegistry (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MetricsRegistry java.lang.Object org.apache.hadoop.metrics2.lib.MetricsRegistry @InterfaceAudience.Public @InterfaceStability.Evolving public class MetricsRegistry extends Object An optional metrics registry class for creating and maintaining a  collection of MetricsMutables, making writing metrics source easier. Constructor Summary Constructors  Constructor and Description MetricsRegistry(MetricsInfo info) Construct the registry with a metadata object MetricsRegistry(String name) Construct the registry with a record name Method Summary Methods  Modifier and Type Method and Description void add(String name,       long value) Add sample to a stat metric by name. MutableMetric get(String name) Get a metric by name MetricsTag getTag(String name) Get a tag by name MetricsInfo info()  MutableCounterInt newCounter(MetricsInfo info,                     int iVal) Create a mutable integer counter MutableCounterLong newCounter(MetricsInfo info,                     long iVal) Create a mutable long integer counter MutableCounterInt newCounter(String name,                     String desc,                     int iVal) Create a mutable integer counter MutableCounterLong newCounter(String name,                     String desc,                     long iVal) Create a mutable long integer counter MutableGaugeInt newGauge(MetricsInfo info,                 int iVal) Create a mutable integer gauge MutableGaugeLong newGauge(MetricsInfo info,                 long iVal) Create a mutable long integer gauge MutableGaugeInt newGauge(String name,                 String desc,                 int iVal) Create a mutable integer gauge MutableGaugeLong newGauge(String name,                 String desc,                 long iVal) Create a mutable long integer gauge MutableQuantiles newQuantiles(String name,                         String desc,                         String sampleName,                         String valueName,                         int interval) Create a mutable metric that estimates quantiles of a stream of values MutableRate newRate(String name) Create a mutable rate metric MutableRate newRate(String name,               String description) Create a mutable rate metric MutableRate newRate(String name,               String desc,               boolean extended) Create a mutable rate metric (for throughput measurement) MutableStat newStat(String name,               String desc,               String sampleName,               String valueName) Create a mutable metric with stats MutableStat newStat(String name,               String desc,               String sampleName,               String valueName,               boolean extended) Create a mutable metric with stats MetricsRegistry setContext(String name) Set the metrics context tag void snapshot(MetricsRecordBuilder builder,                 boolean all) Sample all the mutable metrics and put the snapshot in the builder MetricsRegistry tag(MetricsInfo info,       String value)  MetricsRegistry tag(MetricsInfo info,       String value,       boolean override) Add a tag to the metrics MetricsRegistry tag(String name,       String description,       String value) Add a tag to the metrics MetricsRegistry tag(String name,       String description,       String value,       boolean override) Add a tag to the metrics String toString()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail MetricsRegistry public MetricsRegistry(String name) Construct the registry with a record name Parameters:name - of the record of the metrics MetricsRegistry public MetricsRegistry(MetricsInfo info) Construct the registry with a metadata object Parameters:info - the info object for the metrics record/group Method Detail info public MetricsInfo info() Returns:the info object of the metrics registry get public MutableMetric get(String name) Get a metric by name Parameters:name - of the metric Returns:the metric object getTag public MetricsTag getTag(String name) Get a tag by name Parameters:name - of the tag Returns:the tag object newCounter public MutableCounterInt newCounter(String name,                            String desc,                            int iVal) Create a mutable integer counter Parameters:name - of the metricdesc - metric descriptioniVal - initial value Returns:a new counter object newCounter public MutableCounterInt newCounter(MetricsInfo info,                            int iVal) Create a mutable integer counter Parameters:info - metadata of the metriciVal - initial value Returns:a new counter object newCounter public MutableCounterLong newCounter(String name,                             String desc,                             long iVal) Create a mutable long integer counter Parameters:name - of the metricdesc - metric descriptioniVal - initial value Returns:a new counter object newCounter public MutableCounterLong newCounter(MetricsInfo info,                             long iVal) Create a mutable long integer counter Parameters:info - metadata of the metriciVal - initial value Returns:a new counter object newGauge public MutableGaugeInt newGauge(String name,                        String desc,                        int iVal) Create a mutable integer gauge Parameters:name - of the metricdesc - metric descriptioniVal - initial value Returns:a new gauge object newGauge public MutableGaugeInt newGauge(MetricsInfo info,                        int iVal) Create a mutable integer gauge Parameters:info - metadata of the metriciVal - initial value Returns:a new gauge object newGauge public MutableGaugeLong newGauge(String name,                         String desc,                         long iVal) Create a mutable long integer gauge Parameters:name - of the metricdesc - metric descriptioniVal - initial value Returns:a new gauge object newGauge public MutableGaugeLong newGauge(MetricsInfo info,                         long iVal) Create a mutable long integer gauge Parameters:info - metadata of the metriciVal - initial value Returns:a new gauge object newQuantiles public MutableQuantiles newQuantiles(String name,                             String desc,                             String sampleName,                             String valueName,                             int interval) Create a mutable metric that estimates quantiles of a stream of values Parameters:name - of the metricdesc - metric descriptionsampleName - of the metric (e.g., "Ops")valueName - of the metric (e.g., "Time" or "Latency")interval - rollover interval of estimator in seconds Returns:a new quantile estimator object newStat public MutableStat newStat(String name,                   String desc,                   String sampleName,                   String valueName,                   boolean extended) Create a mutable metric with stats Parameters:name - of the metricdesc - metric descriptionsampleName - of the metric (e.g., "Ops")valueName - of the metric (e.g., "Time" or "Latency")extended - produce extended stat (stdev, min/max etc.) if true. Returns:a new mutable stat metric object newStat public MutableStat newStat(String name,                   String desc,                   String sampleName,                   String valueName) Create a mutable metric with stats Parameters:name - of the metricdesc - metric descriptionsampleName - of the metric (e.g., "Ops")valueName - of the metric (e.g., "Time" or "Latency") Returns:a new mutable metric object newRate public MutableRate newRate(String name) Create a mutable rate metric Parameters:name - of the metric Returns:a new mutable metric object newRate public MutableRate newRate(String name,                   String description) Create a mutable rate metric Parameters:name - of the metricdescription - of the metric Returns:a new mutable rate metric object newRate public MutableRate newRate(String name,                   String desc,                   boolean extended) Create a mutable rate metric (for throughput measurement) Parameters:name - of the metricdesc - descriptionextended - produce extended stat (stdev/min/max etc.) if true Returns:a new mutable rate metric object add public void add(String name,        long value) Add sample to a stat metric by name. Parameters:name - of the metricvalue - of the snapshot to add setContext public MetricsRegistry setContext(String name) Set the metrics context tag Parameters:name - of the context Returns:the registry itself as a convenience tag public MetricsRegistry tag(String name,                   String description,                   String value) Add a tag to the metrics Parameters:name - of the tagdescription - of the tagvalue - of the tag Returns:the registry (for keep adding tags) tag public MetricsRegistry tag(String name,                   String description,                   String value,                   boolean override) Add a tag to the metrics Parameters:name - of the tagdescription - of the tagvalue - of the tagoverride - existing tag if true Returns:the registry (for keep adding tags) tag public MetricsRegistry tag(MetricsInfo info,                   String value,                   boolean override) Add a tag to the metrics Parameters:info - metadata of the tagvalue - of the tagoverride - existing tag if true Returns:the registry (for keep adding tags etc.) tag public MetricsRegistry tag(MetricsInfo info,                   String value) snapshot public void snapshot(MetricsRecordBuilder builder,             boolean all) Sample all the mutable metrics and put the snapshot in the builder Parameters:builder - to contain the metrics snapshotall - get all the metrics even if the values are not changed. toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsSink (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsSink (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Interface MetricsSink All Superinterfaces: MetricsPlugin All Known Implementing Classes: FileSink, GraphiteSink @InterfaceAudience.Public @InterfaceStability.Evolving public interface MetricsSink extends MetricsPlugin The metrics sink interface.   Implementations of this interface consume the MetricsRecord generated  from MetricsSource. It registers with MetricsSystem which  periodically pushes the MetricsRecord to the sink using  putMetrics(MetricsRecord) method.  If the implementing class also  implements Closeable, then the MetricsSystem will close the sink when  it is stopped. Method Summary Methods  Modifier and Type Method and Description void flush() Flush any buffered metrics void putMetrics(MetricsRecord record) Put a metrics record in the sink Methods inherited from interface org.apache.hadoop.metrics2.MetricsPlugin init Method Detail putMetrics void putMetrics(MetricsRecord record) Put a metrics record in the sink Parameters:record - the record to put flush void flush() Flush any buffered metrics Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsSource (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsSource (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Interface MetricsSource All Known Implementing Classes: AzureFileSystemInstrumentation @InterfaceAudience.Public @InterfaceStability.Evolving public interface MetricsSource The metrics source interface Method Summary Methods  Modifier and Type Method and Description void getMetrics(MetricsCollector collector,                     boolean all) Get metrics from the source Method Detail getMetrics void getMetrics(MetricsCollector collector,               boolean all) Get metrics from the source Parameters:collector - to contain the resulting metrics snapshotall - if true, return all metrics even if unchanged. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Class MetricsSystem java.lang.Object org.apache.hadoop.metrics2.MetricsSystem All Implemented Interfaces: MetricsSystemMXBean @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class MetricsSystem extends Object implements MetricsSystemMXBean The metrics system interface Constructor Summary Constructors  Constructor and Description MetricsSystem()  Method Summary Methods  Modifier and Type Method and Description abstract void publishMetricsNow() Requests an immediate publish of all metrics from sources to sinks. abstract void register(org.apache.hadoop.metrics2.MetricsSystem.Callback callback) Register a callback interface for JMX events abstract <T> T register(String name,                 String desc,                 T source) Register a metrics source abstract <T extends MetricsSink> T register(String name,                 String desc,                 T sink) Register a metrics sink <T> T register(T source) Register a metrics source (deriving name and description from the object) abstract boolean shutdown() Shutdown the metrics system completely (usually during server shutdown.)  The MetricsSystemMXBean will be unregistered. abstract void unregisterSource(String name) Unregister a metrics source Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.metrics2.MetricsSystemMXBean currentConfig, start, startMetricsMBeans, stop, stopMetricsMBeans Constructor Detail MetricsSystem public MetricsSystem() Method Detail register public abstract <T> T register(String name,              String desc,              T source) Register a metrics source Type Parameters:T - the actual type of the source objectParameters:source - object to registername - of the source. Must be unique or null (then extracted from               the annotations of the source object.)desc - the description of the source (or null. See above.) Returns:the source object Throws: MetricsException unregisterSource public abstract void unregisterSource(String name) Unregister a metrics source Parameters:name - of the source. This is the name you use to call register() register public <T> T register(T source) Register a metrics source (deriving name and description from the object) Type Parameters:T - the actual type of the source objectParameters:source - object to register Returns:the source object Throws: MetricsException register public abstract <T extends MetricsSink> T register(String name,                                  String desc,                                  T sink) Register a metrics sink Type Parameters:T - the type of the sinkParameters:sink - to registername - of the sink. Must be unique.desc - the description of the sink Returns:the sink Throws: MetricsException register public abstract void register(org.apache.hadoop.metrics2.MetricsSystem.Callback callback) Register a callback interface for JMX events Parameters:callback - the callback object implementing the MBean interface. publishMetricsNow public abstract void publishMetricsNow() Requests an immediate publish of all metrics from sources to sinks.    This is a "soft" request: the expectation is that a best effort will be  done to synchronously snapshot the metrics from all the sources and put  them in all the sinks (including flushing the sinks) before returning to  the caller. If this can't be accomplished in reasonable time it's OK to  return to the caller before everything is done. shutdown public abstract boolean shutdown() Shutdown the metrics system completely (usually during server shutdown.)  The MetricsSystemMXBean will be unregistered. Returns:true if shutdown completed Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsSystemMXBean (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsSystemMXBean (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Interface MetricsSystemMXBean All Known Implementing Classes: MetricsSystem @InterfaceAudience.Public @InterfaceStability.Evolving public interface MetricsSystemMXBean The JMX interface to the metrics system Method Summary Methods  Modifier and Type Method and Description String currentConfig()  void start() Start the metrics system void startMetricsMBeans() Start metrics MBeans void stop() Stop the metrics system void stopMetricsMBeans() Stop metrics MBeans. Method Detail start void start() Start the metrics system Throws: MetricsException stop void stop() Stop the metrics system Throws: MetricsException startMetricsMBeans void startMetricsMBeans() Start metrics MBeans Throws: MetricsException stopMetricsMBeans void stopMetricsMBeans() Stop metrics MBeans.  Note, it doesn't stop the metrics system control MBean,  i.e this interface. Throws: MetricsException currentConfig String currentConfig() Returns:the current config  Avoided getConfig, as it'll turn into a "Config" attribute,  which doesn't support multiple line values in jconsole. Throws: MetricsException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsTag (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsTag (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Class MetricsTag java.lang.Object org.apache.hadoop.metrics2.MetricsTag All Implemented Interfaces: MetricsInfo @InterfaceAudience.Public @InterfaceStability.Evolving public class MetricsTag extends Object implements MetricsInfo Immutable tag for metrics (for grouping on host/queue/username etc.) Constructor Summary Constructors  Constructor and Description MetricsTag(MetricsInfo info,                     String value) Construct the tag with name, description and value Method Summary Methods  Modifier and Type Method and Description String description()  boolean equals(Object obj)  int hashCode()  MetricsInfo info()  String name()  String toString()  String value() Get the value of the tag Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail MetricsTag public MetricsTag(MetricsInfo info,           String value) Construct the tag with name, description and value Parameters:info - of the tagvalue - of the tag Method Detail name public String name() Specified by: name in interface MetricsInfo Returns:the name of the metric/tag description public String description() Specified by: description in interface MetricsInfo Returns:the description of the metric/tag info public MetricsInfo info() Returns:the info object of the tag value public String value() Get the value of the tag Returns:the value equals public boolean equals(Object obj) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MetricsVisitor (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MetricsVisitor (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2 Interface MetricsVisitor @InterfaceAudience.Public @InterfaceStability.Evolving public interface MetricsVisitor A visitor interface for metrics Method Summary Methods  Modifier and Type Method and Description void counter(MetricsInfo info,               int value) Callback for integer value counters void counter(MetricsInfo info,               long value) Callback for long value counters void gauge(MetricsInfo info,           double value) Callback for double value gauges void gauge(MetricsInfo info,           float value) Callback for float value gauges void gauge(MetricsInfo info,           int value) Callback for integer value gauges void gauge(MetricsInfo info,           long value) Callback for long value gauges Method Detail gauge void gauge(MetricsInfo info,          int value) Callback for integer value gauges Parameters:info - the metric infovalue - of the metric gauge void gauge(MetricsInfo info,          long value) Callback for long value gauges Parameters:info - the metric infovalue - of the metric gauge void gauge(MetricsInfo info,          float value) Callback for float value gauges Parameters:info - the metric infovalue - of the metric gauge void gauge(MetricsInfo info,          double value) Callback for double value gauges Parameters:info - the metric infovalue - of the metric counter void counter(MetricsInfo info,            int value) Callback for integer value counters Parameters:info - the metric infovalue - of the metric counter void counter(MetricsInfo info,            long value) Callback for long value counters Parameters:info - the metric infovalue - of the metric Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MigrationTool (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MigrationTool (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.s3 Class MigrationTool java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.s3.MigrationTool All Implemented Interfaces: Configurable, Tool @InterfaceAudience.Public @InterfaceStability.Unstable public class MigrationTool extends Configured implements Tool  This class is a tool for migrating data from an older to a newer version  of an S3 filesystem.      All files in the filesystem are migrated by re-writing the block metadata  - no datafiles are touched.   Constructor Summary Constructors  Constructor and Description MigrationTool()  Method Summary Methods  Modifier and Type Method and Description void initialize(URI uri)  static void main(String[] args)  int run(String[] args) Execute the command with the given arguments. Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Constructor Detail MigrationTool public MigrationTool() Method Detail main public static void main(String[] args)                  throws Exception Throws: Exception run public int run(String[] args)         throws Exception Description copied from interface: Tool Execute the command with the given arguments. Specified by: run in interface Tool Parameters:args - command specific arguments. Returns:exit code. Throws: Exception initialize public void initialize(URI uri)                 throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MoveApplicationAcrossQueuesRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MoveApplicationAcrossQueuesRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class MoveApplicationAcrossQueuesRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class MoveApplicationAcrossQueuesRequest extends Object The request sent by the client to the ResourceManager  to move a submitted application to a different queue.    The request includes the ApplicationId of the application to be  moved and the queue to place it in. See Also:ApplicationClientProtocol.moveApplicationAcrossQueues(MoveApplicationAcrossQueuesRequest) Constructor Summary Constructors  Constructor and Description MoveApplicationAcrossQueuesRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationId getApplicationId() Get the ApplicationId of the application to be moved. abstract String getTargetQueue() Get the queue to place the application in. static MoveApplicationAcrossQueuesRequest newInstance(ApplicationId appId,                       String queue)  abstract void setApplicationId(ApplicationId appId) Set the ApplicationId of the application to be moved. abstract void setTargetQueue(String queue) Get the queue to place the application in. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MoveApplicationAcrossQueuesRequest public MoveApplicationAcrossQueuesRequest() Method Detail newInstance public static MoveApplicationAcrossQueuesRequest newInstance(ApplicationId appId,                                              String queue) getApplicationId public abstract ApplicationId getApplicationId() Get the ApplicationId of the application to be moved. Returns:ApplicationId of the application to be moved setApplicationId public abstract void setApplicationId(ApplicationId appId) Set the ApplicationId of the application to be moved. Parameters:appId - ApplicationId of the application to be moved getTargetQueue public abstract String getTargetQueue() Get the queue to place the application in. Returns:the name of the queue to place the application in setTargetQueue public abstract void setTargetQueue(String queue) Get the queue to place the application in. Parameters:queue - the name of the queue to place the application in Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MoveApplicationAcrossQueuesResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MoveApplicationAcrossQueuesResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class MoveApplicationAcrossQueuesResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse @InterfaceAudience.Public @InterfaceStability.Unstable public class MoveApplicationAcrossQueuesResponse extends Object  The response sent by the ResourceManager to the client moving  a submitted application to a different queue.      A response without exception means that the move has completed successfully.   See Also:ApplicationClientProtocol.moveApplicationAcrossQueues(MoveApplicationAcrossQueuesRequest) Constructor Summary Constructors  Constructor and Description MoveApplicationAcrossQueuesResponse()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MoveApplicationAcrossQueuesResponse public MoveApplicationAcrossQueuesResponse() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultiFileInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultiFileInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class MultiFileInputFormat<K,V> java.lang.Object org.apache.hadoop.mapred.FileInputFormat<K,V> org.apache.hadoop.mapred.MultiFileInputFormat<K,V> All Implemented Interfaces: InputFormat<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class MultiFileInputFormat<K,V> extends FileInputFormat<K,V> An abstract InputFormat that returns MultiFileSplit's  in getSplits(JobConf, int) method. Splits are constructed from   the files under the input paths. Each split returned contains nearly  equal content length.     Subclasses implement getRecordReader(InputSplit, JobConf, Reporter)  to construct RecordReader's for MultiFileSplit's. See Also:MultiFileSplit Field Summary Fields inherited from class org.apache.hadoop.mapred.FileInputFormat INPUT_DIR_RECURSIVE, LOG, NUM_INPUT_FILES Constructor Summary Constructors  Constructor and Description MultiFileInputFormat()  Method Summary Methods  Modifier and Type Method and Description abstract RecordReader<K,V> getRecordReader(InputSplit split,                               JobConf job,                               Reporter reporter) Get the RecordReader for the given InputSplit. InputSplit[] getSplits(JobConf job,                   int numSplits) Splits files returned by FileInputFormat.listStatus(JobConf) when  they're too big. Methods inherited from class org.apache.hadoop.mapred.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getInputPathFilter, getInputPaths, getSplitHosts, isSplitable, listStatus, makeSplit, makeSplit, setInputPathFilter, setInputPaths, setInputPaths, setMinSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MultiFileInputFormat public MultiFileInputFormat() Method Detail getSplits public InputSplit[] getSplits(JobConf job,                      int numSplits)                        throws IOException Description copied from class: FileInputFormat Splits files returned by FileInputFormat.listStatus(JobConf) when  they're too big. Specified by: getSplits in interface InputFormat<K,V> Overrides: getSplits in class FileInputFormat<K,V> Parameters:job - job configuration.numSplits - the desired number of splits, a hint. Returns:an array of InputSplits for the job. Throws: IOException getRecordReader public abstract RecordReader<K,V> getRecordReader(InputSplit split,                                 JobConf job,                                 Reporter reporter)                                            throws IOException Description copied from interface: InputFormat Get the RecordReader for the given InputSplit.  It is the responsibility of the RecordReader to respect  record boundaries while processing the logical split to present a   record-oriented view to the individual task. Specified by: getRecordReader in interface InputFormat<K,V> Specified by: getRecordReader in class FileInputFormat<K,V> Parameters:split - the InputSplitjob - the job that this split belongs to Returns:a RecordReader Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultiFileSplit (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultiFileSplit (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class MultiFileSplit java.lang.Object org.apache.hadoop.mapreduce.InputSplit org.apache.hadoop.mapreduce.lib.input.CombineFileSplit org.apache.hadoop.mapred.lib.CombineFileSplit org.apache.hadoop.mapred.MultiFileSplit All Implemented Interfaces: Writable, InputSplit @InterfaceAudience.Public @InterfaceStability.Stable public class MultiFileSplit extends CombineFileSplit A sub-collection of input files. Unlike FileSplit, MultiFileSplit   class does not represent a split of a file, but a split of input files   into smaller sets. The atomic unit of split is a file.    MultiFileSplit can be used to implement RecordReader's, with   reading one record per file. See Also:FileSplit,  MultiFileInputFormat Constructor Summary Constructors  Constructor and Description MultiFileSplit(JobConf job,                             Path[] files,                             long[] lengths)  Method Summary Methods  Modifier and Type Method and Description String[] getLocations() Returns all the Paths where this input-split resides String toString()  Methods inherited from class org.apache.hadoop.mapred.lib.CombineFileSplit getJob Methods inherited from class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit getLength, getLength, getLengths, getNumPaths, getOffset, getPath, getPaths, getStartOffsets, readFields, write Methods inherited from class org.apache.hadoop.mapreduce.InputSplit getLocationInfo Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Methods inherited from interface org.apache.hadoop.mapred.InputSplit getLength Methods inherited from interface org.apache.hadoop.io.Writable readFields, write Constructor Detail MultiFileSplit public MultiFileSplit(JobConf job,               Path[] files,               long[] lengths) Method Detail getLocations public String[] getLocations()                       throws IOException Description copied from class: CombineFileSplit Returns all the Paths where this input-split resides Specified by: getLocations in interface InputSplit Overrides: getLocations in class CombineFileSplit Returns:a new array of the node nodes. Throws: IOException toString public String toString() Overrides: toString in class CombineFileSplit Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultiFilterRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultiFilterRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class MultiFilterRecordReader<K extends WritableComparable<?>,V extends Writable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader<K,X> org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader<K,V,V> org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader<K,V> All Implemented Interfaces: Closeable, AutoCloseable, Comparable<ComposableRecordReader<K,?>>, Configurable Direct Known Subclasses: OverrideRecordReader @InterfaceAudience.Public @InterfaceStability.Stable public abstract class MultiFilterRecordReader<K extends WritableComparable<?>,V extends Writable> extends CompositeRecordReader<K,V,V> Base class for Composite join returning values derived from multiple  sources, but generally not tuples. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader conf, jc, key, keyclass, kids, value Constructor Summary Constructors  Constructor and Description MultiFilterRecordReader(int id,                                               Configuration conf,                                               int capacity,                                               Class<? extends WritableComparator> cmpcl)  Method Summary Methods  Modifier and Type Method and Description protected boolean combine(Object[] srcs,               TupleWritable dst) Default implementation offers emit(org.apache.hadoop.mapreduce.lib.join.TupleWritable) every Tuple from the  collector (the outer join of child RRs). protected abstract V emit(TupleWritable dst) For each tuple emitted, return a value (typically one of the values  in the tuple). protected ResetableIterator<V> getDelegate() Return an iterator returning a single value from the tuple. void initialize(InputSplit split,                     TaskAttemptContext context) Called once at initialization. boolean nextKeyValue() Read the next key, value pair. Methods inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader accept, add, close, compareTo, createKey, createTupleWritable, fillJoinCollector, getComparator, getConf, getCurrentKey, getCurrentValue, getProgress, getRecordReaderQueue, hasNext, id, key, key, setConf, skip Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MultiFilterRecordReader public MultiFilterRecordReader(int id,                        Configuration conf,                        int capacity,                        Class<? extends WritableComparator> cmpcl)                         throws IOException Throws: IOException Method Detail emit protected abstract V emit(TupleWritable dst)                                     throws IOException For each tuple emitted, return a value (typically one of the values  in the tuple).  Modifying the Writables in the tuple is permitted and unlikely to affect  join behavior in most cases, but it is not recommended. It's safer to  clone first. Throws: IOException combine protected boolean combine(Object[] srcs,               TupleWritable dst) Default implementation offers emit(org.apache.hadoop.mapreduce.lib.join.TupleWritable) every Tuple from the  collector (the outer join of child RRs). Specified by: combine in class CompositeRecordReader<K extends WritableComparable<?>,V extends Writable,V extends Writable> nextKeyValue public boolean nextKeyValue()                      throws IOException,                             InterruptedException Read the next key, value pair. Specified by: nextKeyValue in class RecordReader<K extends WritableComparable<?>,V extends Writable> Returns:true if a key/value pair was read Throws: IOException InterruptedException initialize public void initialize(InputSplit split,               TaskAttemptContext context)                 throws IOException,                        InterruptedException Description copied from class: RecordReader Called once at initialization. Overrides: initialize in class CompositeRecordReader<K extends WritableComparable<?>,V extends Writable,V extends Writable> Parameters:split - the split that defines the range of records to readcontext - the information about the task Throws: IOException InterruptedException getDelegate protected ResetableIterator<V> getDelegate() Return an iterator returning a single value from the tuple. Specified by: getDelegate in class CompositeRecordReader<K extends WritableComparable<?>,V extends Writable,V extends Writable> See Also:MultiFilterRecordReader.MultiFilterDelegationIterator Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultipleArcTransition (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultipleArcTransition (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.state Interface MultipleArcTransition<OPERAND,EVENT,STATE extends Enum<STATE>> @InterfaceAudience.Public @InterfaceStability.Evolving public interface MultipleArcTransition<OPERAND,EVENT,STATE extends Enum<STATE>> Hook for Transition.   Post state is decided by Transition hook. Post state must be one of the   valid post states registered in StateMachine. Method Summary Methods  Modifier and Type Method and Description STATE transition(OPERAND operand,                     EVENT event) Transition hook. Method Detail transition STATE transition(OPERAND operand,                EVENT event) Transition hook. Parameters:operand - the entity attached to the FSM, whose internal                  state may change.event - causal event Returns:the postState. Post state must be one of the                        valid post states registered in StateMachine. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultipleIOException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultipleIOException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class MultipleIOException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.io.MultipleIOException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class MultipleIOException extends IOException Encapsulate a list of IOException into an IOException See Also:Serialized Form Method Summary Methods  Modifier and Type Method and Description static IOException createIOException(List<IOException> exceptions) A convenient method to create an IOException. List<IOException> getExceptions()  Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Method Detail getExceptions public List<IOException> getExceptions() Returns:the underlying exceptions createIOException public static IOException createIOException(List<IOException> exceptions) A convenient method to create an IOException. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultipleInputs (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultipleInputs (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class MultipleInputs java.lang.Object org.apache.hadoop.mapreduce.lib.input.MultipleInputs @InterfaceAudience.Public @InterfaceStability.Stable public class MultipleInputs extends Object This class supports MapReduce jobs that have multiple input paths with  a different InputFormat and Mapper for each path Field Summary Fields  Modifier and Type Field and Description static String DIR_FORMATS  static String DIR_MAPPERS  Constructor Summary Constructors  Constructor and Description MultipleInputs()  Method Summary Methods  Modifier and Type Method and Description static void addInputPath(Job job,                         Path path,                         Class<? extends InputFormat> inputFormatClass) Add a Path with a custom InputFormat to the list of  inputs for the map-reduce job. static void addInputPath(Job job,                         Path path,                         Class<? extends InputFormat> inputFormatClass,                         Class<? extends Mapper> mapperClass) Add a Path with a custom InputFormat and  Mapper to the list of inputs for the map-reduce job. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail DIR_FORMATS public static final String DIR_FORMATS See Also:Constant Field Values DIR_MAPPERS public static final String DIR_MAPPERS See Also:Constant Field Values Constructor Detail MultipleInputs public MultipleInputs() Method Detail addInputPath public static void addInputPath(Job job,                 Path path,                 Class<? extends InputFormat> inputFormatClass) Add a Path with a custom InputFormat to the list of  inputs for the map-reduce job. Parameters:job - The Jobpath - Path to be added to the list of inputs for the jobinputFormatClass - InputFormat class to use for this path addInputPath public static void addInputPath(Job job,                 Path path,                 Class<? extends InputFormat> inputFormatClass,                 Class<? extends Mapper> mapperClass) Add a Path with a custom InputFormat and  Mapper to the list of inputs for the map-reduce job. Parameters:job - The Jobpath - Path to be added to the list of inputs for the jobinputFormatClass - InputFormat class to use for this pathmapperClass - Mapper class to use for this path Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultipleOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultipleOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred.lib Class MultipleOutputFormat<K,V> java.lang.Object org.apache.hadoop.mapred.FileOutputFormat<K,V> org.apache.hadoop.mapred.lib.MultipleOutputFormat<K,V> All Implemented Interfaces: OutputFormat<K,V> Direct Known Subclasses: MultipleSequenceFileOutputFormat, MultipleTextOutputFormat @InterfaceAudience.Public @InterfaceStability.Stable public abstract class MultipleOutputFormat<K,V> extends FileOutputFormat<K,V> This abstract class extends the FileOutputFormat, allowing to write the  output data to different output files. There are three basic use cases for  this class.    Case one: This class is used for a map reduce job with at least one reducer.  The reducer wants to write data to different files depending on the actual  keys. It is assumed that a key (or value) encodes the actual key (value)  and the desired location for the actual key (value).    Case two: This class is used for a map only job. The job wants to use an  output file name that is either a part of the input file name of the input  data, or some derivation of it.    Case three: This class is used for a map only job. The job wants to use an  output file name that depends on both the keys and the input file name, Constructor Summary Constructors  Constructor and Description MultipleOutputFormat()  Method Summary Methods  Modifier and Type Method and Description protected K generateActualKey(K key,                                   V value) Generate the actual key from the given key/value. protected V generateActualValue(K key,                                       V value) Generate the actual value from the given key and value. protected String generateFileNameForKeyValue(K key,                                                       V value,                                                       String name) Generate the file output file name based on the given key and the leaf file  name. protected String generateLeafFileName(String name) Generate the leaf name for the output file name. protected abstract RecordWriter<K,V> getBaseRecordWriter(FileSystem fs,                                       JobConf job,                                       String name,                                       Progressable arg3)  protected String getInputFileBasedOutputFileName(JobConf job,                                                               String name) Generate the outfile name based on a given anme and the input file name. RecordWriter<K,V> getRecordWriter(FileSystem fs,                               JobConf job,                               String name,                               Progressable arg3) Create a composite record writer that can write key/value data to different  output files Methods inherited from class org.apache.hadoop.mapred.FileOutputFormat checkOutputSpecs, getCompressOutput, getOutputCompressorClass, getOutputPath, getPathForCustomFile, getTaskOutputPath, getUniqueName, getWorkOutputPath, setCompressOutput, setOutputCompressorClass, setOutputPath Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MultipleOutputFormat public MultipleOutputFormat() Method Detail getRecordWriter public RecordWriter<K,V> getRecordWriter(FileSystem fs,                                 JobConf job,                                 String name,                                 Progressable arg3)                                   throws IOException Create a composite record writer that can write key/value data to different  output files Specified by: getRecordWriter in interface OutputFormat<K,V> Specified by: getRecordWriter in class FileOutputFormat<K,V> Parameters:fs - the file system to usejob - the job conf for the jobname - the leaf file name for the output file (such as part-00000")arg3 - a progressable for reporting progress. Returns:a composite record writer Throws: IOException generateLeafFileName protected String generateLeafFileName(String name) Generate the leaf name for the output file name. The default behavior does  not change the leaf file name (such as part-00000) Parameters:name - the leaf file name for the output file Returns:the given leaf file name generateFileNameForKeyValue protected String generateFileNameForKeyValue(K key,                                  V value,                                  String name) Generate the file output file name based on the given key and the leaf file  name. The default behavior is that the file name does not depend on the  key. Parameters:key - the key of the output dataname - the leaf file name Returns:generated file name generateActualKey protected K generateActualKey(K key,                   V value) Generate the actual key from the given key/value. The default behavior is that  the actual key is equal to the given key Parameters:key - the key of the output datavalue - the value of the output data Returns:the actual key derived from the given key/value generateActualValue protected V generateActualValue(K key,                     V value) Generate the actual value from the given key and value. The default behavior is that  the actual value is equal to the given value Parameters:key - the key of the output datavalue - the value of the output data Returns:the actual value derived from the given key/value getInputFileBasedOutputFileName protected String getInputFileBasedOutputFileName(JobConf job,                                      String name) Generate the outfile name based on a given anme and the input file name. If  the MRJobConfig.MAP_INPUT_FILE does not exists (i.e. this is not for a map only job),  the given name is returned unchanged. If the config value for  "num.of.trailing.legs.to.use" is not set, or set 0 or negative, the given  name is returned unchanged. Otherwise, return a file name consisting of the  N trailing legs of the input file name where N is the config value for  "num.of.trailing.legs.to.use". Parameters:job - the job configname - the output file name Returns:the outfile name based on a given anme and the input file name. getBaseRecordWriter protected abstract RecordWriter<K,V> getBaseRecordWriter(FileSystem fs,                                     JobConf job,                                     String name,                                     Progressable arg3)                                                   throws IOException Parameters:fs - the file system to usejob - a job conf objectname - the name of the file over which a record writer object will be           constructedarg3 - a progressable object Returns:A RecordWriter object over the given file Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultipleOutputs (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultipleOutputs (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class MultipleOutputs<KEYOUT,VALUEOUT> java.lang.Object org.apache.hadoop.mapreduce.lib.output.MultipleOutputs<KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Stable public class MultipleOutputs<KEYOUT,VALUEOUT> extends Object The MultipleOutputs class simplifies writing output data   to multiple outputs       Case one: writing to additional outputs other than the job default output.  Each additional output, or named output, may be configured with its own  OutputFormat, with its own key class and with its own value  class.        Case two: to write data to different files provided by user        MultipleOutputs supports counters, by default they are disabled. The   counters group is the MultipleOutputs class name. The names of the   counters are the same as the output name. These count the number records   written to each output name.      Usage pattern for job submission:    Job job = new Job();  FileInputFormat.setInputPath(job, inDir);  FileOutputFormat.setOutputPath(job, outDir);  job.setMapperClass(MOMap.class);  job.setReducerClass(MOReduce.class);  ...  // Defines additional single text based output 'text' for the job  MultipleOutputs.addNamedOutput(job, "text", TextOutputFormat.class,  LongWritable.class, Text.class);  // Defines additional sequence-file based output 'sequence' for the job  MultipleOutputs.addNamedOutput(job, "seq",    SequenceFileOutputFormat.class,    LongWritable.class, Text.class);  ...  job.waitForCompletion(true);  ...      Usage in Reducer:    <K, V> String generateFileName(K k, V v) {    return k.toString() + "_" + v.toString();  }    public class MOReduce extends    Reducer<WritableComparable, Writable,WritableComparable, Writable> {  private MultipleOutputs mos;  public void setup(Context context) {  ...  mos = new MultipleOutputs(context);  }  public void reduce(WritableComparable key, Iterator<Writable> values,  Context context)  throws IOException {  ...  mos.write("text", , key, new Text("Hello"));  mos.write("seq", LongWritable(1), new Text("Bye"), "seq_a");  mos.write("seq", LongWritable(2), key, new Text("Chau"), "seq_b");  mos.write(key, new Text("value"), generateFileName(key, new Text("value")));  ...  }  public void cleanup(Context) throws IOException {  mos.close();  ...  }  }        When used in conjuction with org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat,  MultipleOutputs can mimic the behaviour of MultipleTextOutputFormat and MultipleSequenceFileOutputFormat  from the old Hadoop API - ie, output can be written from the Reducer to more than one location.        Use MultipleOutputs.write(KEYOUT key, VALUEOUT value, String baseOutputPath) to write key and   value to a path specified by baseOutputPath, with no need to specify a named output:        private MultipleOutputs<Text, Text> out;    public void setup(Context context) {    out = new MultipleOutputs<Text, Text>(context);    ...  }    public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException {  for (Text t : values) {    out.write(key, t, generateFileName(<parameter list...>));    }  }    protected void cleanup(Context context) throws IOException, InterruptedException {    out.close();  }        Use your own code in generateFileName() to create a custom path to your results.   '/' characters in baseOutputPath will be translated into directory levels in your file system.   Also, append your custom-generated path with "part" or similar, otherwise your output will be -00000, -00001 etc.   No call to context.write() is necessary. See example generateFileName() code below.         private String generateFileName(Text k) {    // expect Text k in format "Surname|Forename"    String[] kStr = k.toString().split("\\|");        String sName = kStr[0];    String fName = kStr[1];    // example for k = Smith|John    // output written to /user/hadoop/path/to/output/Smith/John-r-00000 (etc)    return sName + "/" + fName;  }        Using MultipleOutputs in this way will still create zero-sized default output, eg part-00000.  To prevent this use LazyOutputFormat.setOutputFormatClass(job, TextOutputFormat.class);  instead of job.setOutputFormatClass(TextOutputFormat.class); in your Hadoop job configuration.   Constructor Summary Constructors  Constructor and Description MultipleOutputs(TaskInputOutputContext<?,?,KEYOUT,VALUEOUT> context) Creates and initializes multiple outputs support,  it should be instantiated in the Mapper/Reducer setup method. Method Summary Methods  Modifier and Type Method and Description static void addNamedOutput(Job job,                             String namedOutput,                             Class<? extends OutputFormat> outputFormatClass,                             Class<?> keyClass,                             Class<?> valueClass) Adds a named output for the job. void close() Closes all the opened outputs. static boolean getCountersEnabled(JobContext job) Returns if the counters for the named outputs are enabled or not. static void setCountersEnabled(Job job,                                     boolean enabled) Enables or disables counters for the named outputs. void write(KEYOUT key,           VALUEOUT value,           String baseOutputPath) Write key value to an output file name. <K,V> void write(String namedOutput,           K key,           V value) Write key and value to the namedOutput. <K,V> void write(String namedOutput,           K key,           V value,           String baseOutputPath) Write key and value to baseOutputPath using the namedOutput. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MultipleOutputs public MultipleOutputs(TaskInputOutputContext<?,?,KEYOUT,VALUEOUT> context) Creates and initializes multiple outputs support,  it should be instantiated in the Mapper/Reducer setup method. Parameters:context - the TaskInputOutputContext object Method Detail addNamedOutput public static void addNamedOutput(Job job,                   String namedOutput,                   Class<? extends OutputFormat> outputFormatClass,                   Class<?> keyClass,                   Class<?> valueClass) Adds a named output for the job. Parameters:job - job to add the named outputnamedOutput - named output name, it has to be a word, letters                           and numbers only, cannot be the word 'part' as                           that is reserved for the default output.outputFormatClass - OutputFormat class.keyClass - key classvalueClass - value class setCountersEnabled public static void setCountersEnabled(Job job,                       boolean enabled) Enables or disables counters for the named outputs.    The counters group is the MultipleOutputs class name.  The names of the counters are the same as the named outputs. These  counters count the number records written to each output name.  By default these counters are disabled. Parameters:job - job  to enable countersenabled - indicates if the counters will be enabled or not. getCountersEnabled public static boolean getCountersEnabled(JobContext job) Returns if the counters for the named outputs are enabled or not.  By default these counters are disabled. Parameters:job - the job Returns:TRUE if the counters are enabled, FALSE if they are disabled. write public <K,V> void write(String namedOutput,                K key,                V value)            throws IOException,                   InterruptedException Write key and value to the namedOutput.  Output path is a unique file generated for the namedOutput.  For example, {namedOutput}-(m|r)-{part-number} Parameters:namedOutput - the named output namekey - the keyvalue - the value Throws: IOException InterruptedException write public <K,V> void write(String namedOutput,                K key,                V value,                String baseOutputPath)            throws IOException,                   InterruptedException Write key and value to baseOutputPath using the namedOutput. Parameters:namedOutput - the named output namekey - the keyvalue - the valuebaseOutputPath - base-output path to write the record to.  Note: Framework will generate unique filename for the baseOutputPath Throws: IOException InterruptedException write public void write(KEYOUT key,          VALUEOUT value,          String baseOutputPath)            throws IOException,                   InterruptedException Write key value to an output file name.    Gets the record writer from job's output format.    Job's output format should be a FileOutputFormat. Parameters:key - the keyvalue - the valuebaseOutputPath - base-output path to write the record to.  Note: Framework will generate unique filename for the baseOutputPath Throws: IOException InterruptedException close public void close()            throws IOException,                   InterruptedException Closes all the opened outputs.    This should be called from cleanup method of map/reduce task.  If overridden subclasses must invoke super.close() at the  end of their close() Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultipleSequenceFileOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultipleSequenceFileOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred.lib Class MultipleSequenceFileOutputFormat<K,V> java.lang.Object org.apache.hadoop.mapred.FileOutputFormat<K,V> org.apache.hadoop.mapred.lib.MultipleOutputFormat<K,V> org.apache.hadoop.mapred.lib.MultipleSequenceFileOutputFormat<K,V> All Implemented Interfaces: OutputFormat<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class MultipleSequenceFileOutputFormat<K,V> extends MultipleOutputFormat<K,V> This class extends the MultipleOutputFormat, allowing to write the output data   to different output files in sequence file output format. Constructor Summary Constructors  Constructor and Description MultipleSequenceFileOutputFormat()  Method Summary Methods  Modifier and Type Method and Description protected RecordWriter<K,V> getBaseRecordWriter(FileSystem fs,                                       JobConf job,                                       String name,                                       Progressable arg3)  Methods inherited from class org.apache.hadoop.mapred.lib.MultipleOutputFormat generateActualKey, generateActualValue, generateFileNameForKeyValue, generateLeafFileName, getInputFileBasedOutputFileName, getRecordWriter Methods inherited from class org.apache.hadoop.mapred.FileOutputFormat checkOutputSpecs, getCompressOutput, getOutputCompressorClass, getOutputPath, getPathForCustomFile, getTaskOutputPath, getUniqueName, getWorkOutputPath, setCompressOutput, setOutputCompressorClass, setOutputPath Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MultipleSequenceFileOutputFormat public MultipleSequenceFileOutputFormat() Method Detail getBaseRecordWriter protected RecordWriter<K,V> getBaseRecordWriter(FileSystem fs,                                     JobConf job,                                     String name,                                     Progressable arg3)                                          throws IOException Specified by: getBaseRecordWriter in class MultipleOutputFormat<K,V> Parameters:fs - the file system to usejob - a job conf objectname - the name of the file over which a record writer object will be           constructedarg3 - a progressable object Returns:A RecordWriter object over the given file Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultipleTextOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultipleTextOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred.lib Class MultipleTextOutputFormat<K,V> java.lang.Object org.apache.hadoop.mapred.FileOutputFormat<K,V> org.apache.hadoop.mapred.lib.MultipleOutputFormat<K,V> org.apache.hadoop.mapred.lib.MultipleTextOutputFormat<K,V> All Implemented Interfaces: OutputFormat<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class MultipleTextOutputFormat<K,V> extends MultipleOutputFormat<K,V> This class extends the MultipleOutputFormat, allowing to write the output  data to different output files in Text output format. Constructor Summary Constructors  Constructor and Description MultipleTextOutputFormat()  Method Summary Methods  Modifier and Type Method and Description protected RecordWriter<K,V> getBaseRecordWriter(FileSystem fs,                                       JobConf job,                                       String name,                                       Progressable arg3)  Methods inherited from class org.apache.hadoop.mapred.lib.MultipleOutputFormat generateActualKey, generateActualValue, generateFileNameForKeyValue, generateLeafFileName, getInputFileBasedOutputFileName, getRecordWriter Methods inherited from class org.apache.hadoop.mapred.FileOutputFormat checkOutputSpecs, getCompressOutput, getOutputCompressorClass, getOutputPath, getPathForCustomFile, getTaskOutputPath, getUniqueName, getWorkOutputPath, setCompressOutput, setOutputCompressorClass, setOutputPath Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MultipleTextOutputFormat public MultipleTextOutputFormat() Method Detail getBaseRecordWriter protected RecordWriter<K,V> getBaseRecordWriter(FileSystem fs,                                     JobConf job,                                     String name,                                     Progressable arg3)                                          throws IOException Specified by: getBaseRecordWriter in class MultipleOutputFormat<K,V> Parameters:fs - the file system to usejob - a job conf objectname - the name of the file over which a record writer object will be           constructedarg3 - a progressable object Returns:A RecordWriter object over the given file Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultithreadedMapRunner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultithreadedMapRunner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred.lib Class MultithreadedMapRunner<K1,V1,K2,V2> java.lang.Object org.apache.hadoop.mapred.lib.MultithreadedMapRunner<K1,V1,K2,V2> All Implemented Interfaces: JobConfigurable, MapRunnable<K1,V1,K2,V2> @InterfaceAudience.Public @InterfaceStability.Stable public class MultithreadedMapRunner<K1,V1,K2,V2> extends Object implements MapRunnable<K1,V1,K2,V2> Multithreaded implementation for MapRunnable.    It can be used instead of the default implementation,  of MapRunner, when the Map  operation is not CPU bound in order to improve throughput.    Map implementations using this MapRunnable must be thread-safe.    The Map-Reduce job has to be configured to use this MapRunnable class (using  the JobConf.setMapRunnerClass method) and  the number of threads the thread-pool can use with the  mapred.map.multithreadedrunner.threads property, its default  value is 10 threads.   Constructor Summary Constructors  Constructor and Description MultithreadedMapRunner()  Method Summary Methods  Modifier and Type Method and Description void configure(JobConf jobConf) Initializes a new instance from a JobConf. void run(RecordReader<K1,V1> input,       OutputCollector<K2,V2> output,       Reporter reporter) Start mapping input <key, value> pairs. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MultithreadedMapRunner public MultithreadedMapRunner() Method Detail configure public void configure(JobConf jobConf) Description copied from interface: JobConfigurable Initializes a new instance from a JobConf. Specified by: configure in interface JobConfigurable Parameters:jobConf - the configuration run public void run(RecordReader<K1,V1> input,        OutputCollector<K2,V2> output,        Reporter reporter)          throws IOException Description copied from interface: MapRunnable Start mapping input <key, value> pairs.     Mapping of input records to output records is complete when this method   returns. Specified by: run in interface MapRunnable<K1,V1,K2,V2> Parameters:input - the RecordReader to read the input records.output - the OutputCollector to collect the outputrecords.reporter - Reporter to report progress, status-updates etc. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MultithreadedMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MultithreadedMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.map Class MultithreadedMapper<K1,V1,K2,V2> java.lang.Object org.apache.hadoop.mapreduce.Mapper<K1,V1,K2,V2> org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper<K1,V1,K2,V2> @InterfaceAudience.Public @InterfaceStability.Stable public class MultithreadedMapper<K1,V1,K2,V2> extends Mapper<K1,V1,K2,V2> Multithreaded implementation for @link org.apache.hadoop.mapreduce.Mapper.    It can be used instead of the default implementation,  MapRunner, when the Map operation is not CPU  bound in order to improve throughput.    Mapper implementations using this MapRunnable must be thread-safe.    The Map-Reduce job has to be configured with the mapper to use via   setMapperClass(Job, Class) and  the number of thread the thread-pool can use with the  getNumberOfThreads(JobContext) method. The default  value is 10 threads.   Field Summary Fields  Modifier and Type Field and Description static String MAP_CLASS  static String NUM_THREADS  Constructor Summary Constructors  Constructor and Description MultithreadedMapper()  Method Summary Methods  Modifier and Type Method and Description static <K1,V1,K2,V2> Class<Mapper<K1,V1,K2,V2>> getMapperClass(JobContext job) Get the application's mapper class. static int getNumberOfThreads(JobContext job) The number of threads in the thread pool that will run the map function. void run(org.apache.hadoop.mapreduce.Mapper.Context context) Run the application's maps using a thread pool. static <K1,V1,K2,V2> void setMapperClass(Job job,                             Class<? extends Mapper<K1,V1,K2,V2>> cls) Set the application's mapper class. static void setNumberOfThreads(Job job,                                     int threads) Set the number of threads in the pool for running maps. Methods inherited from class org.apache.hadoop.mapreduce.Mapper cleanup, map, setup Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail NUM_THREADS public static String NUM_THREADS MAP_CLASS public static String MAP_CLASS Constructor Detail MultithreadedMapper public MultithreadedMapper() Method Detail getNumberOfThreads public static int getNumberOfThreads(JobContext job) The number of threads in the thread pool that will run the map function. Parameters:job - the job Returns:the number of threads setNumberOfThreads public static void setNumberOfThreads(Job job,                       int threads) Set the number of threads in the pool for running maps. Parameters:job - the job to modifythreads - the new number of threads getMapperClass public static <K1,V1,K2,V2> Class<Mapper<K1,V1,K2,V2>> getMapperClass(JobContext job) Get the application's mapper class. Type Parameters:K1 - the map's input key typeV1 - the map's input value typeK2 - the map's output key typeV2 - the map's output value typeParameters:job - the job Returns:the mapper class to run setMapperClass public static <K1,V1,K2,V2> void setMapperClass(Job job,                                 Class<? extends Mapper<K1,V1,K2,V2>> cls) Set the application's mapper class. Type Parameters:K1 - the map input key typeV1 - the map input value typeK2 - the map output key typeV2 - the map output value typeParameters:job - the job to modifycls - the class to use as the mapper run public void run(org.apache.hadoop.mapreduce.Mapper.Context context)          throws IOException,                 InterruptedException Run the application's maps using a thread pool. Overrides: run in class Mapper<K1,V1,K2,V2> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableCounter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableCounter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableCounter java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableCounter Direct Known Subclasses: MutableCounterInt, MutableCounterLong @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class MutableCounter extends MutableMetric The mutable counter (monotonically increasing) metric interface Constructor Summary Constructors  Modifier Constructor and Description protected  MutableCounter(MetricsInfo info)  Method Summary Methods  Modifier and Type Method and Description abstract void incr() Increment the metric value by 1. protected MetricsInfo info()  Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MutableCounter protected MutableCounter(MetricsInfo info) Method Detail info protected MetricsInfo info() incr public abstract void incr() Increment the metric value by 1. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableCounterInt (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableCounterInt (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableCounterInt java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableCounter org.apache.hadoop.metrics2.lib.MutableCounterInt @InterfaceAudience.Public @InterfaceStability.Evolving public class MutableCounterInt extends MutableCounter A mutable int counter for implementing metrics sources Method Summary Methods  Modifier and Type Method and Description void incr() Increment the metric value by 1. void incr(int delta) Increment the value by a delta void snapshot(MetricsRecordBuilder builder,                 boolean all) Get a snapshot of the metric int value()  Methods inherited from class org.apache.hadoop.metrics2.lib.MutableCounter info Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail incr public void incr() Description copied from class: MutableCounter Increment the metric value by 1. Specified by: incr in class MutableCounter incr public void incr(int delta) Increment the value by a delta Parameters:delta - of the increment value public int value() snapshot public void snapshot(MetricsRecordBuilder builder,             boolean all) Description copied from class: MutableMetric Get a snapshot of the metric Specified by: snapshot in class MutableMetric Parameters:builder - the metrics record builderall - if true, snapshot unchanged metrics as well Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableCounterLong (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableCounterLong (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableCounterLong java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableCounter org.apache.hadoop.metrics2.lib.MutableCounterLong @InterfaceAudience.Public @InterfaceStability.Evolving public class MutableCounterLong extends MutableCounter A mutable long counter Method Summary Methods  Modifier and Type Method and Description void incr() Increment the metric value by 1. void incr(long delta) Increment the value by a delta void snapshot(MetricsRecordBuilder builder,                 boolean all) Get a snapshot of the metric long value()  Methods inherited from class org.apache.hadoop.metrics2.lib.MutableCounter info Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail incr public void incr() Description copied from class: MutableCounter Increment the metric value by 1. Specified by: incr in class MutableCounter incr public void incr(long delta) Increment the value by a delta Parameters:delta - of the increment value public long value() snapshot public void snapshot(MetricsRecordBuilder builder,             boolean all) Description copied from class: MutableMetric Get a snapshot of the metric Specified by: snapshot in class MutableMetric Parameters:builder - the metrics record builderall - if true, snapshot unchanged metrics as well Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableGauge (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableGauge (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableGauge java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableGauge Direct Known Subclasses: MutableGaugeInt, MutableGaugeLong @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class MutableGauge extends MutableMetric The mutable gauge metric interface Constructor Summary Constructors  Modifier Constructor and Description protected  MutableGauge(MetricsInfo info)  Method Summary Methods  Modifier and Type Method and Description abstract void decr() Decrement the value of the metric by 1 abstract void incr() Increment the value of the metric by 1 protected MetricsInfo info()  Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MutableGauge protected MutableGauge(MetricsInfo info) Method Detail info protected MetricsInfo info() incr public abstract void incr() Increment the value of the metric by 1 decr public abstract void decr() Decrement the value of the metric by 1 Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableGaugeInt (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableGaugeInt (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableGaugeInt java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableGauge org.apache.hadoop.metrics2.lib.MutableGaugeInt @InterfaceAudience.Public @InterfaceStability.Evolving public class MutableGaugeInt extends MutableGauge A mutable int gauge Method Summary Methods  Modifier and Type Method and Description void decr() Decrement the value of the metric by 1 void decr(int delta) decrement by delta void incr() Increment the value of the metric by 1 void incr(int delta) Increment by delta void set(int value) Set the value of the metric void snapshot(MetricsRecordBuilder builder,                 boolean all) Get a snapshot of the metric int value()  Methods inherited from class org.apache.hadoop.metrics2.lib.MutableGauge info Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail value public int value() incr public void incr() Description copied from class: MutableGauge Increment the value of the metric by 1 Specified by: incr in class MutableGauge incr public void incr(int delta) Increment by delta Parameters:delta - of the increment decr public void decr() Description copied from class: MutableGauge Decrement the value of the metric by 1 Specified by: decr in class MutableGauge decr public void decr(int delta) decrement by delta Parameters:delta - of the decrement set public void set(int value) Set the value of the metric Parameters:value - to set snapshot public void snapshot(MetricsRecordBuilder builder,             boolean all) Description copied from class: MutableMetric Get a snapshot of the metric Specified by: snapshot in class MutableMetric Parameters:builder - the metrics record builderall - if true, snapshot unchanged metrics as well Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableGaugeLong (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableGaugeLong (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableGaugeLong java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableGauge org.apache.hadoop.metrics2.lib.MutableGaugeLong @InterfaceAudience.Public @InterfaceStability.Evolving public class MutableGaugeLong extends MutableGauge A mutable long gauge Method Summary Methods  Modifier and Type Method and Description void decr() Decrement the value of the metric by 1 void decr(long delta) decrement by delta void incr() Increment the value of the metric by 1 void incr(long delta) Increment by delta void set(long value) Set the value of the metric void snapshot(MetricsRecordBuilder builder,                 boolean all) Get a snapshot of the metric long value()  Methods inherited from class org.apache.hadoop.metrics2.lib.MutableGauge info Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail value public long value() incr public void incr() Description copied from class: MutableGauge Increment the value of the metric by 1 Specified by: incr in class MutableGauge incr public void incr(long delta) Increment by delta Parameters:delta - of the increment decr public void decr() Description copied from class: MutableGauge Decrement the value of the metric by 1 Specified by: decr in class MutableGauge decr public void decr(long delta) decrement by delta Parameters:delta - of the decrement set public void set(long value) Set the value of the metric Parameters:value - to set snapshot public void snapshot(MetricsRecordBuilder builder,             boolean all) Description copied from class: MutableMetric Get a snapshot of the metric Specified by: snapshot in class MutableMetric Parameters:builder - the metrics record builderall - if true, snapshot unchanged metrics as well Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableMetric (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableMetric (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableMetric java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric Direct Known Subclasses: MutableCounter, MutableGauge, MutableQuantiles, MutableRates, MutableStat @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class MutableMetric extends Object The mutable metric interface Constructor Summary Constructors  Constructor and Description MutableMetric()  Method Summary Methods  Modifier and Type Method and Description boolean changed()  protected void clearChanged() Clear the changed flag in the snapshot operations protected void setChanged() Set the changed flag in mutable operations void snapshot(MetricsRecordBuilder builder) Get a snapshot of metric if changed abstract void snapshot(MetricsRecordBuilder builder,                 boolean all) Get a snapshot of the metric Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MutableMetric public MutableMetric() Method Detail snapshot public abstract void snapshot(MetricsRecordBuilder builder,             boolean all) Get a snapshot of the metric Parameters:builder - the metrics record builderall - if true, snapshot unchanged metrics as well snapshot public void snapshot(MetricsRecordBuilder builder) Get a snapshot of metric if changed Parameters:builder - the metrics record builder setChanged protected void setChanged() Set the changed flag in mutable operations clearChanged protected void clearChanged() Clear the changed flag in the snapshot operations changed public boolean changed() Returns:true if metric is changed since last snapshot/snapshot Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableQuantiles (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableQuantiles (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableQuantiles java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableQuantiles @InterfaceAudience.Public @InterfaceStability.Evolving public class MutableQuantiles extends MutableMetric Watches a stream of long values, maintaining online estimates of specific  quantiles with provably low error bounds. This is particularly useful for  accurate high-percentile (e.g. 95th, 99th) latency metrics. Field Summary Fields  Modifier and Type Field and Description protected Map<org.apache.hadoop.metrics2.util.Quantile,Long> previousSnapshot  static org.apache.hadoop.metrics2.util.Quantile[] quantiles  Constructor Summary Constructors  Constructor and Description MutableQuantiles(String name,                                 String description,                                 String sampleName,                                 String valueName,                                 int interval) Instantiates a new MutableQuantiles for a metric that rolls itself  over on the specified time interval. Method Summary Methods  Modifier and Type Method and Description void add(long value)  int getInterval()  void snapshot(MetricsRecordBuilder builder,                 boolean all) Get a snapshot of the metric Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail quantiles public static final org.apache.hadoop.metrics2.util.Quantile[] quantiles previousSnapshot protected Map<org.apache.hadoop.metrics2.util.Quantile,Long> previousSnapshot Constructor Detail MutableQuantiles public MutableQuantiles(String name,                 String description,                 String sampleName,                 String valueName,                 int interval) Instantiates a new MutableQuantiles for a metric that rolls itself  over on the specified time interval. Parameters:name - of the metricdescription - long-form textual description of the metricsampleName - type of items in the stream (e.g., "Ops")valueName - type of the valuesinterval - rollover interval (in seconds) of the estimator Method Detail snapshot public void snapshot(MetricsRecordBuilder builder,             boolean all) Description copied from class: MutableMetric Get a snapshot of the metric Specified by: snapshot in class MutableMetric Parameters:builder - the metrics record builderall - if true, snapshot unchanged metrics as well add public void add(long value) getInterval public int getInterval() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableRate (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableRate (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableRate java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableStat org.apache.hadoop.metrics2.lib.MutableRate @InterfaceAudience.Public @InterfaceStability.Evolving public class MutableRate extends MutableStat A convenient mutable metric for throughput measurement Method Summary Methods inherited from class org.apache.hadoop.metrics2.lib.MutableStat add, add, resetMinMax, setExtended, snapshot Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableRates (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableRates (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableRates java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableRates @InterfaceAudience.Public @InterfaceStability.Evolving public class MutableRates extends MutableMetric Helper class to manage a group of mutable rate metrics Method Summary Methods  Modifier and Type Method and Description void add(String name,       long elapsed) Add a rate sample for a rate metric void init(Class<?> protocol) Initialize the registry with all the methods in a protocol  so they all show up in the first snapshot. void snapshot(MetricsRecordBuilder rb,                 boolean all) Get a snapshot of the metric Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail init public void init(Class<?> protocol) Initialize the registry with all the methods in a protocol  so they all show up in the first snapshot.  Convenient for JMX implementations. Parameters:protocol - the protocol class add public void add(String name,        long elapsed) Add a rate sample for a rate metric Parameters:name - of the rate metricelapsed - time snapshot public void snapshot(MetricsRecordBuilder rb,             boolean all) Description copied from class: MutableMetric Get a snapshot of the metric Specified by: snapshot in class MutableMetric Parameters:rb - the metrics record builderall - if true, snapshot unchanged metrics as well Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MutableStat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MutableStat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.lib Class MutableStat java.lang.Object org.apache.hadoop.metrics2.lib.MutableMetric org.apache.hadoop.metrics2.lib.MutableStat Direct Known Subclasses: MutableRate @InterfaceAudience.Public @InterfaceStability.Evolving public class MutableStat extends MutableMetric A mutable metric with stats.  Useful for keeping throughput/latency stats. Constructor Summary Constructors  Constructor and Description MutableStat(String name,                       String description,                       String sampleName,                       String valueName) Construct a snapshot stat metric with extended stat off by default MutableStat(String name,                       String description,                       String sampleName,                       String valueName,                       boolean extended) Construct a sample statistics metric Method Summary Methods  Modifier and Type Method and Description void add(long value) Add a snapshot to the metric void add(long numSamples,       long sum) Add a number of samples and their sum to the running stat void resetMinMax() Reset the all time min max of the metric void setExtended(boolean extended) Set whether to display the extended stats (stdev, min/max etc.) or not void snapshot(MetricsRecordBuilder builder,                 boolean all) Get a snapshot of the metric Methods inherited from class org.apache.hadoop.metrics2.lib.MutableMetric changed, clearChanged, setChanged, snapshot Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MutableStat public MutableStat(String name,            String description,            String sampleName,            String valueName,            boolean extended) Construct a sample statistics metric Parameters:name - of the metricdescription - of the metricsampleName - of the metric (e.g. "Ops")valueName - of the metric (e.g. "Time", "Latency")extended - create extended stats (stdev, min/max etc.) by default. MutableStat public MutableStat(String name,            String description,            String sampleName,            String valueName) Construct a snapshot stat metric with extended stat off by default Parameters:name - of the metricdescription - of the metricsampleName - of the metric (e.g. "Ops")valueName - of the metric (e.g. "Time", "Latency") Method Detail setExtended public void setExtended(boolean extended) Set whether to display the extended stats (stdev, min/max etc.) or not Parameters:extended - enable/disable displaying extended stats add public void add(long numSamples,        long sum) Add a number of samples and their sum to the running stat Parameters:numSamples - number of samplessum - of the samples add public void add(long value) Add a snapshot to the metric Parameters:value - of the metric snapshot public void snapshot(MetricsRecordBuilder builder,             boolean all) Description copied from class: MutableMetric Get a snapshot of the metric Specified by: snapshot in class MutableMetric Parameters:builder - the metrics record builderall - if true, snapshot unchanged metrics as well resetMinMax public void resetMinMax() Reset the all time min max of the metric Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MySQLDBRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MySQLDBRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class MySQLDBRecordReader<T extends DBWritable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<LongWritable,T> org.apache.hadoop.mapreduce.lib.db.DBRecordReader<T> org.apache.hadoop.mapreduce.lib.db.MySQLDBRecordReader<T> All Implemented Interfaces: Closeable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Evolving public class MySQLDBRecordReader<T extends DBWritable> extends DBRecordReader<T> A RecordReader that reads records from a MySQL table. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader statement Constructor Summary Constructors  Constructor and Description MySQLDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                       Class<T> inputClass,                                       Configuration conf,                                       Connection conn,                                       DBConfiguration dbConfig,                                       String cond,                                       String[] fields,                                       String table)  Method Summary Methods  Modifier and Type Method and Description protected ResultSet executeQuery(String query)  Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader close, createValue, getConditions, getConnection, getCurrentKey, getCurrentValue, getDBConf, getFieldNames, getPos, getProgress, getSelectQuery, getSplit, getStatement, getTableName, initialize, next, nextKeyValue, setStatement Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MySQLDBRecordReader public MySQLDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                    Class<T> inputClass,                    Configuration conf,                    Connection conn,                    DBConfiguration dbConfig,                    String cond,                    String[] fields,                    String table)                     throws SQLException Throws: SQLException Method Detail executeQuery protected ResultSet executeQuery(String query)                           throws SQLException Overrides: executeQuery in class DBRecordReader<T extends DBWritable> Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  MySQLDataDrivenDBRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="MySQLDataDrivenDBRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class MySQLDataDrivenDBRecordReader<T extends DBWritable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<LongWritable,T> org.apache.hadoop.mapreduce.lib.db.DBRecordReader<T> org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader<T> org.apache.hadoop.mapreduce.lib.db.MySQLDataDrivenDBRecordReader<T> All Implemented Interfaces: Closeable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Evolving public class MySQLDataDrivenDBRecordReader<T extends DBWritable> extends DataDrivenDBRecordReader<T> A RecordReader that reads records from a MySQL table via DataDrivenDBRecordReader Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader statement Constructor Summary Constructors  Constructor and Description MySQLDataDrivenDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                                           Class<T> inputClass,                                                           Configuration conf,                                                           Connection conn,                                                           DBConfiguration dbConfig,                                                           String cond,                                                           String[] fields,                                                           String table)  Method Summary Methods  Modifier and Type Method and Description protected ResultSet executeQuery(String query)  Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader getSelectQuery Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader close, createValue, getConditions, getConnection, getCurrentKey, getCurrentValue, getDBConf, getFieldNames, getPos, getProgress, getSplit, getStatement, getTableName, initialize, next, nextKeyValue, setStatement Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail MySQLDataDrivenDBRecordReader public MySQLDataDrivenDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                              Class<T> inputClass,                              Configuration conf,                              Connection conn,                              DBConfiguration dbConfig,                              String cond,                              String[] fields,                              String table)                               throws SQLException Throws: SQLException Method Detail executeQuery protected ResultSet executeQuery(String query)                           throws SQLException Overrides: executeQuery in class DBRecordReader<T extends DBWritable> Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NLineInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NLineInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class NLineInputFormat java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<LongWritable,Text> org.apache.hadoop.mapreduce.lib.input.NLineInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class NLineInputFormat extends FileInputFormat<LongWritable,Text> NLineInputFormat which splits N lines of input as one split.  In many "pleasantly" parallel applications, each process/mapper   processes the same input file (s), but with computations are   controlled by different parameters.(Referred to as "parameter sweeps").  One way to achieve this, is to specify a set of parameters   (one set per line) as input in a control file   (which is the input path to the map-reduce application,  where as the input dataset is specified   via a config variable in JobConf.).    The NLineInputFormat can be used in such applications, that splits   the input file such that by default, one line is fed as  a value to one map task, and key is the offset.  i.e. (k,v) is (LongWritable, Text).  The location hints will span the whole mapred cluster. Field Summary Fields  Modifier and Type Field and Description static String LINES_PER_MAP  Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description NLineInputFormat()  Method Summary Methods  Modifier and Type Method and Description protected static FileSplit createFileSplit(Path fileName,                               long begin,                               long length) NLineInputFormat uses LineRecordReader, which always reads  (and consumes) at least one character out of its upper split  boundary. RecordReader<LongWritable,Text> createRecordReader(InputSplit genericSplit,                                     TaskAttemptContext context) Create a record reader for a given split. static int getNumLinesPerSplit(JobContext job) Get the number of lines per split List<InputSplit> getSplits(JobContext job) Logically splits the set of input files for the job, splits N lines  of the input as one split. static List<FileSplit> getSplitsForFile(FileStatus status,                                 Configuration conf,                                 int numLinesPerSplit)  static void setNumLinesPerSplit(Job job,                                       int numLines) Set the number of lines per split Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getFormatMinSplitSize, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, isSplitable, listStatus, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LINES_PER_MAP public static final String LINES_PER_MAP See Also:Constant Field Values Constructor Detail NLineInputFormat public NLineInputFormat() Method Detail createRecordReader public RecordReader<LongWritable,Text> createRecordReader(InputSplit genericSplit,                                                  TaskAttemptContext context)                                                    throws IOException Description copied from class: InputFormat Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Specified by: createRecordReader in class InputFormat<LongWritable,Text> Parameters:genericSplit - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException getSplits public List<InputSplit> getSplits(JobContext job)                            throws IOException Logically splits the set of input files for the job, splits N lines  of the input as one split. Overrides: getSplits in class FileInputFormat<LongWritable,Text> Parameters:job - the job context Returns:an array of InputSplits for the job. Throws: IOExceptionSee Also:FileInputFormat.getSplits(JobContext) getSplitsForFile public static List<FileSplit> getSplitsForFile(FileStatus status,                                Configuration conf,                                int numLinesPerSplit)                                         throws IOException Throws: IOException createFileSplit protected static FileSplit createFileSplit(Path fileName,                         long begin,                         long length) NLineInputFormat uses LineRecordReader, which always reads  (and consumes) at least one character out of its upper split  boundary. So to make sure that each mapper gets N lines, we  move back the upper split limits of each split   by one character here. Parameters:fileName - Path of filebegin - the position of the first byte in the file to processlength - number of bytes in InputSplit Returns:FileSplit setNumLinesPerSplit public static void setNumLinesPerSplit(Job job,                        int numLines) Set the number of lines per split Parameters:job - the job to modifynumLines - the number of lines per split getNumLinesPerSplit public static int getNumLinesPerSplit(JobContext job) Get the number of lines per split Parameters:job - the job Returns:the number of lines per split Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NMClient (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NMClient (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api Class NMClient java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.client.api.NMClient All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Stable public abstract class NMClient extends AbstractService Constructor Summary Constructors  Modifier Constructor and Description protected  NMClient(String name)  Method Summary Methods  Modifier and Type Method and Description abstract void cleanupRunningContainersOnStop(boolean enabled) Set whether the containers that are started by this client, and are  still running should be stopped when the client stops. static NMClient createNMClient() Create a new instance of NMClient. static NMClient createNMClient(String name) Create a new instance of NMClient. abstract ContainerStatus getContainerStatus(ContainerId containerId,                                     NodeId nodeId) Query the status of a container. NMTokenCache getNMTokenCache() Get the NM token cache of the NMClient. void setNMTokenCache(NMTokenCache nmTokenCache) Set the NM Token cache of the NMClient. abstract Map<String,ByteBuffer> startContainer(Container container,                             ContainerLaunchContext containerLaunchContext) Start an allocated container. abstract void stopContainer(ContainerId containerId,                           NodeId nodeId) Stop an started container. Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceInit, serviceStart, serviceStop, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail NMClient @InterfaceAudience.Private protected NMClient(String name) Method Detail createNMClient @InterfaceAudience.Public public static NMClient createNMClient() Create a new instance of NMClient. createNMClient @InterfaceAudience.Public public static NMClient createNMClient(String name) Create a new instance of NMClient. startContainer public abstract Map<String,ByteBuffer> startContainer(Container container,                                     ContainerLaunchContext containerLaunchContext)                                                throws YarnException,                                                       IOException Start an allocated container.  The ApplicationMaster or other applications that use the  client must provide the details of the allocated container, including the  Id, the assigned node's Id and the token via Container. In  addition, the AM needs to provide the ContainerLaunchContext as  well. Parameters:container - the allocated containercontainerLaunchContext - the context information needed by the                                NodeManager to launch the                                container Returns:a map between the auxiliary service names and their outputs Throws: YarnException IOException stopContainer public abstract void stopContainer(ContainerId containerId,                  NodeId nodeId)                             throws YarnException,                                    IOException Stop an started container. Parameters:containerId - the Id of the started containernodeId - the Id of the NodeManager Throws: YarnException IOException getContainerStatus public abstract ContainerStatus getContainerStatus(ContainerId containerId,                                  NodeId nodeId)                                             throws YarnException,                                                    IOException Query the status of a container. Parameters:containerId - the Id of the started containernodeId - the Id of the NodeManager Returns:the status of a container Throws: YarnException IOException cleanupRunningContainersOnStop public abstract void cleanupRunningContainersOnStop(boolean enabled) Set whether the containers that are started by this client, and are  still running should be stopped when the client stops. By default, the  feature should be enabled. However, containers will be stopped only    when service is stopped. i.e. after AbstractService.stop(). Parameters:enabled - whether the feature is enabled or not setNMTokenCache public void setNMTokenCache(NMTokenCache nmTokenCache) Set the NM Token cache of the NMClient. This cache must be  shared with the AMRMClient that requested the containers managed  by this NMClient    If a NM token cache is not set, the NMTokenCache.getSingleton()  singleton instance will be used. Parameters:nmTokenCache - the NM token cache to use. getNMTokenCache public NMTokenCache getNMTokenCache() Get the NM token cache of the NMClient. This cache must be  shared with the AMRMClient that requested the containers managed  by this NMClient    If a NM token cache is not set, the NMTokenCache.getSingleton()  singleton instance will be used. Returns:the NM token cache Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NMClientAsync (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NMClientAsync (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api.async Class NMClientAsync java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.client.api.async.NMClientAsync All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Stable public abstract class NMClientAsync extends AbstractService NMClientAsync handles communication with all the NodeManagers  and provides asynchronous updates on getting responses from them. It  maintains a thread pool to communicate with individual NMs where a number of  worker threads process requests to NMs by using NMClientImpl. The max  size of the thread pool is configurable through  YarnConfiguration.NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE.  It should be used in conjunction with a CallbackHandler. For example    class MyCallbackHandler implements NMClientAsync.CallbackHandler {    public void onContainerStarted(ContainerId containerId,        Map<String, ByteBuffer> allServiceResponse) {      [post process after the container is started, process the response]    }    public void onContainerStatusReceived(ContainerId containerId,        ContainerStatus containerStatus) {      [make use of the status of the container]    }    public void onContainerStopped(ContainerId containerId) {      [post process after the container is stopped]    }    public void onStartContainerError(        ContainerId containerId, Throwable t) {      [handle the raised exception]    }    public void onGetContainerStatusError(        ContainerId containerId, Throwable t) {      [handle the raised exception]    }    public void onStopContainerError(        ContainerId containerId, Throwable t) {      [handle the raised exception]    }  }      The client's life-cycle should be managed like the following:    NMClientAsync asyncClient =       NMClientAsync.createNMClientAsync(new MyCallbackhandler());  asyncClient.init(conf);  asyncClient.start();  asyncClient.startContainer(container, containerLaunchContext);  [... wait for container being started]  asyncClient.getContainerStatus(container.getId(), container.getNodeId(),      container.getContainerToken());  [... handle the status in the callback instance]  asyncClient.stopContainer(container.getId(), container.getNodeId(),      container.getContainerToken());  [... wait for container being stopped]  asyncClient.stop();     Field Summary Fields  Modifier and Type Field and Description protected org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler  protected NMClient client  Constructor Summary Constructors  Modifier Constructor and Description protected  NMClientAsync(org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler)  protected  NMClientAsync(String name,                           org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler)  protected  NMClientAsync(String name,                           NMClient client,                           org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler)  Method Summary Methods  Modifier and Type Method and Description static NMClientAsync createNMClientAsync(org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler)  org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler getCallbackHandler()  NMClient getClient()  abstract void getContainerStatusAsync(ContainerId containerId,                                               NodeId nodeId)  void setCallbackHandler(org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler)  void setClient(NMClient client)  abstract void startContainerAsync(Container container,                                       ContainerLaunchContext containerLaunchContext)  abstract void stopContainerAsync(ContainerId containerId,                                     NodeId nodeId)  Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceInit, serviceStart, serviceStop, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail client protected NMClient client callbackHandler protected org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler Constructor Detail NMClientAsync protected NMClientAsync(org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler) NMClientAsync protected NMClientAsync(String name,              org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler) NMClientAsync @InterfaceAudience.Private protected NMClientAsync(String name,                                        NMClient client,                                        org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler) Method Detail createNMClientAsync public static NMClientAsync createNMClientAsync(org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler) startContainerAsync public abstract void startContainerAsync(Container container,                        ContainerLaunchContext containerLaunchContext) stopContainerAsync public abstract void stopContainerAsync(ContainerId containerId,                       NodeId nodeId) getContainerStatusAsync public abstract void getContainerStatusAsync(ContainerId containerId,                            NodeId nodeId) getClient public NMClient getClient() setClient public void setClient(NMClient client) getCallbackHandler public org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler getCallbackHandler() setCallbackHandler public void setCallbackHandler(org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler callbackHandler) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NMProxy (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NMProxy (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client Class NMProxy java.lang.Object org.apache.hadoop.yarn.client.ServerProxy org.apache.hadoop.yarn.client.NMProxy @InterfaceAudience.Public @InterfaceStability.Unstable public class NMProxy extends ServerProxy Constructor Summary Constructors  Constructor and Description NMProxy()  Method Summary Methods  Modifier and Type Method and Description static <T> T createNMProxy(Configuration conf,                           Class<T> protocol,                           org.apache.hadoop.security.UserGroupInformation ugi,                           org.apache.hadoop.yarn.ipc.YarnRPC rpc,                           InetSocketAddress serverAddress)  Methods inherited from class org.apache.hadoop.yarn.client.ServerProxy createRetriableProxy, createRetryPolicy Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail NMProxy public NMProxy() Method Detail createNMProxy public static <T> T createNMProxy(Configuration conf,                   Class<T> protocol,                   org.apache.hadoop.security.UserGroupInformation ugi,                   org.apache.hadoop.yarn.ipc.YarnRPC rpc,                   InetSocketAddress serverAddress) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NMToken (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NMToken (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class NMToken java.lang.Object org.apache.hadoop.yarn.api.records.NMToken @InterfaceAudience.Public @InterfaceStability.Stable public abstract class NMToken extends Object The NMToken is used for authenticating communication with  NodeManager  It is issued by ResourceMananger when ApplicationMaster  negotiates resource with ResourceManager and  validated on NodeManager side. See Also:AllocateResponse.getNMTokens() Constructor Summary Constructors  Constructor and Description NMToken()  Method Summary Methods  Modifier and Type Method and Description boolean equals(Object obj)  abstract NodeId getNodeId() Get the NodeId of the NodeManager for which the NMToken  is used to authenticate. abstract Token getToken() Get the Token used for authenticating with NodeManager int hashCode()  abstract void setNodeId(NodeId nodeId)  abstract void setToken(Token token)  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail NMToken public NMToken() Method Detail getNodeId @InterfaceAudience.Public @InterfaceStability.Stable public abstract NodeId getNodeId() Get the NodeId of the NodeManager for which the NMToken  is used to authenticate. Returns:the NodeId of the NodeManager for which the  NMToken is used to authenticate. setNodeId @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setNodeId(NodeId nodeId) getToken @InterfaceAudience.Public @InterfaceStability.Stable public abstract Token getToken() Get the Token used for authenticating with NodeManager Returns:the Token used for authenticating with NodeManager setToken @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setToken(Token token) hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NMTokenCache (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NMTokenCache (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api Class NMTokenCache java.lang.Object org.apache.hadoop.yarn.client.api.NMTokenCache @InterfaceAudience.Public @InterfaceStability.Evolving public class NMTokenCache extends Object NMTokenCache manages NMTokens required for an Application Master  communicating with individual NodeManagers.    By default Yarn client libraries AMRMClient and NMClient use  getSingleton() instance of the cache.            Using the singleton instance of the cache is appropriate when running a      single ApplicationMaster in the same JVM.              When using the singleton, users don't need to do anything special,      AMRMClient and NMClient are already set up to use the      default singleton NMTokenCache          If running multiple Application Masters in the same JVM, a different cache  instance should be used for each Application Master.            If using the AMRMClient and the NMClient, setting up      and using an instance cache is as follows:      NMTokenCache nmTokenCache = new NMTokenCache();    AMRMClient rmClient = AMRMClient.createAMRMClient();    NMClient nmClient = NMClient.createNMClient();    nmClient.setNMTokenCache(nmTokenCache);    ...                If using the AMRMClientAsync and the NMClientAsync,      setting up and using an instance cache is as follows:      NMTokenCache nmTokenCache = new NMTokenCache();    AMRMClient rmClient = AMRMClient.createAMRMClient();    NMClient nmClient = NMClient.createNMClient();    nmClient.setNMTokenCache(nmTokenCache);    AMRMClientAsync rmClientAsync = new AMRMClientAsync(rmClient, 1000, [AMRM_CALLBACK]);    NMClientAsync nmClientAsync = new NMClientAsync("nmClient", nmClient, [NM_CALLBACK]);    ...                If using ApplicationMasterProtocol and      ContainerManagementProtocol directly, setting up and using an      instance cache is as follows:      NMTokenCache nmTokenCache = new NMTokenCache();    ...    ApplicationMasterProtocol amPro = ClientRMProxy.createRMProxy(conf, ApplicationMasterProtocol.class);    ...    AllocateRequest allocateRequest = ...    ...    AllocateResponse allocateResponse = rmClient.allocate(allocateRequest);    for (NMToken token : allocateResponse.getNMTokens()) {      nmTokenCache.setToken(token.getNodeId().toString(), token.getToken());    }    ...    ContainerManagementProtocolProxy nmPro = ContainerManagementProtocolProxy(conf, nmTokenCache);    ...    nmPro.startContainer(container, containerContext);    ...          It is also possible to mix the usage of a client (AMRMClient or  NMClient, or the async versions of them) with a protocol proxy  (ContainerManagementProtocolProxy or  ApplicationMasterProtocol). Constructor Summary Constructors  Constructor and Description NMTokenCache() Creates a NM token cache instance. Method Summary Methods  Modifier and Type Method and Description static Token getNMToken(String nodeAddr) Returns NMToken, null if absent. static NMTokenCache getSingleton() Returns the singleton NM token cache. Token getToken(String nodeAddr) Returns NMToken, null if absent static void setNMToken(String nodeAddr,                     Token token) Sets the NMToken for node address only in the singleton obtained from  getSingleton(). void setToken(String nodeAddr,                 Token token) Sets the NMToken for node address Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail NMTokenCache public NMTokenCache() Creates a NM token cache instance. Method Detail getSingleton public static NMTokenCache getSingleton() Returns the singleton NM token cache. Returns:the singleton NM token cache. getNMToken @InterfaceAudience.Public public static Token getNMToken(String nodeAddr) Returns NMToken, null if absent. Only the singleton obtained from  getSingleton() is looked at for the tokens. If you are using your  own NMTokenCache that is different from the singleton, use  getToken(String) Parameters:nodeAddr -  Returns:Token NMToken required for communicating with node manager setNMToken @InterfaceAudience.Public public static void setNMToken(String nodeAddr,                                        Token token) Sets the NMToken for node address only in the singleton obtained from  getSingleton(). If you are using your own NMTokenCache that is  different from the singleton, use setToken(String, Token) Parameters:nodeAddr - node address (host:port)token - NMToken getToken @InterfaceAudience.Public @InterfaceStability.Evolving public Token getToken(String nodeAddr) Returns NMToken, null if absent Parameters:nodeAddr -  Returns:Token NMToken required for communicating with node          manager setToken @InterfaceAudience.Public @InterfaceStability.Evolving public void setToken(String nodeAddr,                                                                  Token token) Sets the NMToken for node address Parameters:nodeAddr - node address (host:port)token - NMToken Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NMTokenIdentifier (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NMTokenIdentifier (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security Class NMTokenIdentifier java.lang.Object org.apache.hadoop.security.token.TokenIdentifier org.apache.hadoop.yarn.security.NMTokenIdentifier All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class NMTokenIdentifier extends org.apache.hadoop.security.token.TokenIdentifier Field Summary Fields  Modifier and Type Field and Description static Text KIND  Constructor Summary Constructors  Constructor and Description NMTokenIdentifier() Default constructor needed by RPC/Secret manager NMTokenIdentifier(ApplicationAttemptId appAttemptId,                                   NodeId nodeId,                                   String applicationSubmitter,                                   int masterKeyId)  Method Summary Methods  Modifier and Type Method and Description boolean equals(Object other)  ApplicationAttemptId getApplicationAttemptId()  String getApplicationSubmitter()  int getKeyId()  Text getKind() Get the token kind NodeId getNodeId()  org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.NMTokenIdentifierProto getProto()  org.apache.hadoop.security.UserGroupInformation getUser() Get the Ugi with the username encoded in the token identifier int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.security.token.TokenIdentifier getBytes, getTrackingId Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail KIND public static final Text KIND Constructor Detail NMTokenIdentifier public NMTokenIdentifier(ApplicationAttemptId appAttemptId,                  NodeId nodeId,                  String applicationSubmitter,                  int masterKeyId) NMTokenIdentifier public NMTokenIdentifier() Default constructor needed by RPC/Secret manager Method Detail getApplicationAttemptId public ApplicationAttemptId getApplicationAttemptId() getNodeId public NodeId getNodeId() getApplicationSubmitter public String getApplicationSubmitter() getKeyId public int getKeyId() write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Parameters:in - DataInput to deseriablize this object from. Throws: IOException getKind public Text getKind() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the token kind Specified by: getKind in class org.apache.hadoop.security.token.TokenIdentifier Returns:the kind of the token getUser public org.apache.hadoop.security.UserGroupInformation getUser() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the Ugi with the username encoded in the token identifier Specified by: getUser in class org.apache.hadoop.security.token.TokenIdentifier Returns:the username. null is returned if username in the identifier is          empty or null. getProto public org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.NMTokenIdentifierProto getProto() hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object other) Overrides: equals in class Object toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NativeAzureFileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NativeAzureFileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.azure Class NativeAzureFileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem org.apache.hadoop.fs.azure.NativeAzureFileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class NativeAzureFileSystem extends FileSystem A FileSystem for reading and writing files stored on Windows Azure. This implementation is  blob-based and stores files on Azure in their native form so they can be read  by other Azure tools. Field Summary Fields  Modifier and Type Field and Description static org.apache.commons.logging.Log LOG  static String SKIP_AZURE_METRICS_PROPERTY_NAME  Fields inherited from class org.apache.hadoop.fs.FileSystem DEFAULT_FS, FS_DEFAULT_NAME_KEY, SHUTDOWN_HOOK_PRIORITY, statistics Constructor Summary Constructors  Constructor and Description NativeAzureFileSystem()  NativeAzureFileSystem(org.apache.hadoop.fs.azure.NativeFileSystemStore store)  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.fs.azure.SelfRenewingLease acquireLease(Path path) Get a self-renewing lease on the specified file. FSDataOutputStream append(Path f,             int bufferSize,             Progressable progress) This optional operation is not yet supported. protected void checkPath(Path path) Check that a Path belongs to this FileSystem. void close() No more filesystem operations are needed. FSDataOutputStream create(Path f,             FsPermission permission,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream createNonRecursive(Path f,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     EnumSet<CreateFlag> flags,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. boolean delete(Path path) Deprecated.  boolean delete(Path f,             boolean recursive) Delete a file. boolean delete(Path f,             boolean recursive,             boolean skipParentFolderLastModifidedTimeUpdate) Delete the specified file or folder. void deleteFilesWithDanglingTempData(Path root) Looks under the given root path for any blob that are left "dangling",  meaning that they are place-holder blobs that we created while we upload  the data to a temporary blob, but for some reason we crashed in the middle  of the upload and left them there. protected void finalize()  BlockLocation[] getFileBlockLocations(FileStatus file,                                           long start,                                           long len) Return an array containing hostnames, offset and size of  portions of the given file. FileStatus getFileStatus(Path f) Return a file status object that represents the path. AzureFileSystemInstrumentation getInstrumentation() Gets the metrics source for this file system. String getScheme() Return the protocol scheme for the FileSystem. org.apache.hadoop.fs.azure.AzureNativeFileSystemStore getStore() For unit test purposes, retrieves the AzureNativeFileSystemStore store  backing this file system. URI getUri() Returns a URI whose scheme and authority identify this FileSystem. Path getWorkingDirectory() Get the current working directory for the given file system void initialize(URI uri,                     Configuration conf) Called after a new FileSystem instance is constructed. FileStatus[] listStatus(Path f) Retrieve the status of a given path if it is a file, or of all the  contained files if it is a directory. Path makeAbsolute(Path path) Get the absolute version of the path (fully qualified). boolean mkdirs(Path f,             FsPermission permission) Make the given file and all non-existent parents into  directories. boolean mkdirs(Path f,             FsPermission permission,             boolean noUmask)  static String newMetricsSourceName() Creates a new metrics source name that's unique within this process. FSDataInputStream open(Path f,         int bufferSize) Opens an FSDataInputStream at the indicated Path. String pathToKey(Path path) Convert the path to a key. void recoverFilesWithDanglingTempData(Path root,                                                                 Path destination) Looks under the given root path for any blob that are left "dangling",  meaning that they are place-holder blobs that we created while we upload  the data to a temporary blob, but for some reason we crashed in the middle  of the upload and left them there. boolean rename(Path src,             Path dst) Renames Path src to Path dst. void setOwner(Path p,                 String username,                 String groupname) Set owner of a path (i.e. void setPermission(Path p,                           FsPermission permission) Set permission of a path. void setWorkingDirectory(Path newDir) Set the working directory to the given directory. Methods inherited from class org.apache.hadoop.fs.FileSystem append, append, areSymlinksEnabled, cancelDeleteOnExit, canonicalizeUri, clearStatistics, closeAll, closeAllForUGI, completeLocalOutput, concat, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyToLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, create, create, createNewFile, createSnapshot, createSnapshot, createSymlink, deleteOnExit, deleteSnapshot, enableSymlinks, exists, fixRelativePart, get, get, get, getAclStatus, getAllStatistics, getBlockSize, getCanonicalUri, getContentSummary, getDefaultBlockSize, getDefaultBlockSize, getDefaultPort, getDefaultReplication, getDefaultReplication, getDefaultUri, getFileBlockLocations, getFileChecksum, getFileChecksum, getFileLinkStatus, getFileSystemClass, getFSofPath, getHomeDirectory, getInitialWorkingDirectory, getLength, getLinkTarget, getLocal, getName, getNamed, getReplication, getServerDefaults, getServerDefaults, getStatistics, getStatistics, getStatus, getStatus, getUsed, getXAttr, getXAttrs, getXAttrs, globStatus, globStatus, isDirectory, isFile, listCorruptFileBlocks, listFiles, listLocatedStatus, listLocatedStatus, listStatus, listStatus, listStatus, listStatusIterator, listXAttrs, makeQualified, mkdirs, mkdirs, modifyAclEntries, moveFromLocalFile, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveCreate, primitiveMkdir, primitiveMkdir, printStatistics, processDeleteOnExit, removeAcl, removeAclEntries, removeDefaultAcl, removeXAttr, rename, renameSnapshot, resolveLink, resolvePath, setAcl, setDefaultUri, setDefaultUri, setReplication, setTimes, setVerifyChecksum, setWriteChecksum, setXAttr, setXAttr, startLocalOutput, supportsSymlinks, truncate Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LOG public static final org.apache.commons.logging.Log LOG SKIP_AZURE_METRICS_PROPERTY_NAME public static final String SKIP_AZURE_METRICS_PROPERTY_NAME See Also:Constant Field Values Constructor Detail NativeAzureFileSystem public NativeAzureFileSystem() NativeAzureFileSystem public NativeAzureFileSystem(org.apache.hadoop.fs.azure.NativeFileSystemStore store) Method Detail getScheme public String getScheme() Description copied from class: FileSystem Return the protocol scheme for the FileSystem.    This implementation throws an UnsupportedOperationException. Overrides: getScheme in class FileSystem Returns:the protocol scheme for the FileSystem. newMetricsSourceName public static String newMetricsSourceName() Creates a new metrics source name that's unique within this process. checkPath protected void checkPath(Path path) Description copied from class: FileSystem Check that a Path belongs to this FileSystem. Overrides: checkPath in class FileSystem Parameters:path - to check initialize public void initialize(URI uri,               Configuration conf)                 throws IOException,                        IllegalArgumentException Description copied from class: FileSystem Called after a new FileSystem instance is constructed. Overrides: initialize in class FileSystem Parameters:uri - a uri whose authority section names the host, port, etc.    for this FileSystemconf - the configuration Throws: IOException IllegalArgumentException pathToKey public String pathToKey(Path path) Convert the path to a key. By convention, any leading or trailing slash is  removed, except for the special case of a single slash. makeAbsolute public Path makeAbsolute(Path path) Get the absolute version of the path (fully qualified).  This is public for testing purposes. Parameters:path -  Returns:fully qualified path getStore public org.apache.hadoop.fs.azure.AzureNativeFileSystemStore getStore() For unit test purposes, retrieves the AzureNativeFileSystemStore store  backing this file system. Returns:The store object. getInstrumentation public AzureFileSystemInstrumentation getInstrumentation() Gets the metrics source for this file system.  This is mainly here for unit testing purposes. Returns:the metrics source. append public FSDataOutputStream append(Path f,                         int bufferSize,                         Progressable progress)                           throws IOException This optional operation is not yet supported. Specified by: append in class FileSystem Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used.progress - for reporting progress if it is not null. Throws: IOException create public FSDataOutputStream create(Path f,                         FsPermission permission,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Specified by: create in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) acquireLease public org.apache.hadoop.fs.azure.SelfRenewingLease acquireLease(Path path)                                                           throws AzureException Get a self-renewing lease on the specified file. Throws: AzureException createNonRecursive public FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress)                                       throws IOException Description copied from class: FileSystem Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Overrides: createNonRecursive in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,  the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) createNonRecursive public FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     EnumSet<CreateFlag> flags,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress)                                       throws IOException Description copied from class: FileSystem Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Overrides: createNonRecursive in class FileSystem Parameters:f - the file name to openflags - CreateFlags to use for this stream.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) createNonRecursive public FSDataOutputStream createNonRecursive(Path f,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress)                                       throws IOException Description copied from class: FileSystem Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Overrides: createNonRecursive in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,  the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) delete @Deprecated public boolean delete(Path path)                throws IOException Deprecated.  Description copied from class: FileSystem Delete a file Overrides: delete in class FileSystem Throws: IOException delete public boolean delete(Path f,              boolean recursive)                throws IOException Description copied from class: FileSystem Delete a file. Specified by: delete in class FileSystem Parameters:f - the path to delete.recursive - if path is a directory and set to   true, the directory is deleted else throws an exception. In  case of a file the recursive can be set to either true or false. Returns:true if delete is successful else false. Throws: IOException delete public boolean delete(Path f,              boolean recursive,              boolean skipParentFolderLastModifidedTimeUpdate)                throws IOException Delete the specified file or folder. The parameter  skipParentFolderLastModifidedTimeUpdate  is used in the case of atomic folder rename redo. In that case, there is  a lease on the parent folder, so (without reworking the code) modifying  the parent folder update time will fail because of a conflict with the  lease. Since we are going to delete the folder soon anyway so accurate  modified time is not necessary, it's easier to just skip  the modified time update. Parameters:f - recursive - skipParentFolderLastModifidedTimeUpdate - If true, don't update the folder last  modified time. Returns:true if and only if the file is deleted Throws: IOException getFileStatus public FileStatus getFileStatus(Path f)                          throws IOException Description copied from class: FileSystem Return a file status object that represents the path. Specified by: getFileStatus in class FileSystem Parameters:f - The path we want information from Returns:a FileStatus object Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException getUri public URI getUri() Description copied from class: FileSystem Returns a URI whose scheme and authority identify this FileSystem. Specified by: getUri in class FileSystem listStatus public FileStatus[] listStatus(Path f)                         throws IOException Retrieve the status of a given path if it is a file, or of all the  contained files if it is a directory. Specified by: listStatus in class FileSystem Parameters:f - given path Returns:the statuses of the files/directories in the given patch Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException mkdirs public boolean mkdirs(Path f,              FsPermission permission)                throws IOException Description copied from class: FileSystem Make the given file and all non-existent parents into  directories. Has the semantics of Unix 'mkdir -p'.  Existence of the directory hierarchy is not an error. Specified by: mkdirs in class FileSystem Parameters:f - path to createpermission - to apply to f Throws: IOException mkdirs public boolean mkdirs(Path f,              FsPermission permission,              boolean noUmask)                throws IOException Throws: IOException open public FSDataInputStream open(Path f,                      int bufferSize)                        throws IOException Description copied from class: FileSystem Opens an FSDataInputStream at the indicated Path. Specified by: open in class FileSystem Parameters:f - the file name to openbufferSize - the size of the buffer to be used. Throws: IOException rename public boolean rename(Path src,              Path dst)                throws IOException Description copied from class: FileSystem Renames Path src to Path dst.  Can take place on local fs  or remote DFS. Specified by: rename in class FileSystem Parameters:src - path to be renameddst - new path after rename Returns:true if rename is successful Throws: IOException - on failure getFileBlockLocations public BlockLocation[] getFileBlockLocations(FileStatus file,                                     long start,                                     long len)                                       throws IOException Return an array containing hostnames, offset and size of  portions of the given file. For WASB we'll just lie and give  fake hosts to make sure we get many splits in MR jobs. Overrides: getFileBlockLocations in class FileSystem Parameters:file - FilesStatus to get data fromstart - offset into the given filelen - length for which to get locations for Throws: IOException setWorkingDirectory public void setWorkingDirectory(Path newDir) Set the working directory to the given directory. Specified by: setWorkingDirectory in class FileSystem getWorkingDirectory public Path getWorkingDirectory() Description copied from class: FileSystem Get the current working directory for the given file system Specified by: getWorkingDirectory in class FileSystem Returns:the directory pathname setPermission public void setPermission(Path p,                  FsPermission permission)                    throws IOException Description copied from class: FileSystem Set permission of a path. Overrides: setPermission in class FileSystem Throws: IOException setOwner public void setOwner(Path p,             String username,             String groupname)               throws IOException Description copied from class: FileSystem Set owner of a path (i.e. a file or a directory).  The parameters username and groupname cannot both be null. Overrides: setOwner in class FileSystem Parameters:p - The pathusername - If it is null, the original username remains unchanged.groupname - If it is null, the original groupname remains unchanged. Throws: IOException close public void close()            throws IOException Description copied from class: FileSystem No more filesystem operations are needed.  Will  release any held locks. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Overrides: close in class FileSystem Throws: IOException recoverFilesWithDanglingTempData public void recoverFilesWithDanglingTempData(Path root,                                     Path destination)                                       throws IOException Looks under the given root path for any blob that are left "dangling",  meaning that they are place-holder blobs that we created while we upload  the data to a temporary blob, but for some reason we crashed in the middle  of the upload and left them there. If any are found, we move them to the  destination given. Parameters:root - The root path to consider.destination - The destination path to move any recovered files to. Throws: IOException deleteFilesWithDanglingTempData public void deleteFilesWithDanglingTempData(Path root)                                      throws IOException Looks under the given root path for any blob that are left "dangling",  meaning that they are place-holder blobs that we created while we upload  the data to a temporary blob, but for some reason we crashed in the middle  of the upload and left them there. If any are found, we delete them. Parameters:root - The root path to consider. Throws: IOException finalize protected void finalize()                  throws Throwable Overrides: finalize in class Object Throws: Throwable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NativeS3FileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NativeS3FileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.s3native Class NativeS3FileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem org.apache.hadoop.fs.s3native.NativeS3FileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class NativeS3FileSystem extends FileSystem A FileSystem for reading and writing files stored on  Amazon S3.  Unlike S3FileSystem this implementation  stores files on S3 in their  native form so they can be read by other S3 tools.    A note about directories. S3 of course has no "native" support for them.  The idiom we choose then is: for any directory created by this class,  we use an empty object "#{dirpath}_$folder$" as a marker.  Further, to interoperate with other S3 tools, we also accept the following:      an object "#{dirpath}/' denoting a directory marker          if there exists any objects with the prefix "#{dirpath}/", then the      directory is said to exist              if both a file with the name of a directory and a marker for that      directory exists, then the *file masks the directory*, and the directory      is never returned.       See Also:S3FileSystem Field Summary Fields  Modifier and Type Field and Description static org.slf4j.Logger LOG  Fields inherited from class org.apache.hadoop.fs.FileSystem DEFAULT_FS, FS_DEFAULT_NAME_KEY, SHUTDOWN_HOOK_PRIORITY, statistics Constructor Summary Constructors  Constructor and Description NativeS3FileSystem()  NativeS3FileSystem(org.apache.hadoop.fs.s3native.NativeFileSystemStore store)  Method Summary Methods  Modifier and Type Method and Description FSDataOutputStream append(Path f,             int bufferSize,             Progressable progress) This optional operation is not yet supported. FSDataOutputStream create(Path f,             FsPermission permission,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. boolean delete(Path f,             boolean recurse) Delete a file. String getCanonicalServiceName() Get a canonical service name for this file system. long getDefaultBlockSize() Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. FileStatus getFileStatus(Path f) Return a file status object that represents the path. String getScheme() Return the protocol scheme for the FileSystem. URI getUri() Returns a URI whose scheme and authority identify this FileSystem. Path getWorkingDirectory() Get the current working directory for the given file system void initialize(URI uri,                     Configuration conf) Called after a new FileSystem instance is constructed. FileStatus[] listStatus(Path f)  If f is a file, this method will make a single call to S3. boolean mkdirs(Path f,             FsPermission permission) Make the given file and all non-existent parents into  directories. FSDataInputStream open(Path f,         int bufferSize) Opens an FSDataInputStream at the indicated Path. boolean rename(Path src,             Path dst) Renames Path src to Path dst. void setWorkingDirectory(Path newDir) Set the working directory to the given directory. Methods inherited from class org.apache.hadoop.fs.FileSystem append, append, areSymlinksEnabled, cancelDeleteOnExit, canonicalizeUri, checkPath, clearStatistics, close, closeAll, closeAllForUGI, completeLocalOutput, concat, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyToLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, create, create, createNewFile, createNonRecursive, createNonRecursive, createNonRecursive, createSnapshot, createSnapshot, createSymlink, delete, deleteOnExit, deleteSnapshot, enableSymlinks, exists, fixRelativePart, get, get, get, getAclStatus, getAllStatistics, getBlockSize, getCanonicalUri, getContentSummary, getDefaultBlockSize, getDefaultPort, getDefaultReplication, getDefaultReplication, getDefaultUri, getFileBlockLocations, getFileBlockLocations, getFileChecksum, getFileChecksum, getFileLinkStatus, getFileSystemClass, getFSofPath, getHomeDirectory, getInitialWorkingDirectory, getLength, getLinkTarget, getLocal, getName, getNamed, getReplication, getServerDefaults, getServerDefaults, getStatistics, getStatistics, getStatus, getStatus, getUsed, getXAttr, getXAttrs, getXAttrs, globStatus, globStatus, isDirectory, isFile, listCorruptFileBlocks, listFiles, listLocatedStatus, listLocatedStatus, listStatus, listStatus, listStatus, listStatusIterator, listXAttrs, makeQualified, mkdirs, mkdirs, modifyAclEntries, moveFromLocalFile, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveCreate, primitiveMkdir, primitiveMkdir, printStatistics, processDeleteOnExit, removeAcl, removeAclEntries, removeDefaultAcl, removeXAttr, rename, renameSnapshot, resolveLink, resolvePath, setAcl, setDefaultUri, setDefaultUri, setOwner, setPermission, setReplication, setTimes, setVerifyChecksum, setWriteChecksum, setXAttr, setXAttr, startLocalOutput, supportsSymlinks, truncate Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LOG public static final org.slf4j.Logger LOG Constructor Detail NativeS3FileSystem public NativeS3FileSystem() NativeS3FileSystem public NativeS3FileSystem(org.apache.hadoop.fs.s3native.NativeFileSystemStore store) Method Detail getScheme public String getScheme() Return the protocol scheme for the FileSystem. Overrides: getScheme in class FileSystem Returns:s3n initialize public void initialize(URI uri,               Configuration conf)                 throws IOException Description copied from class: FileSystem Called after a new FileSystem instance is constructed. Overrides: initialize in class FileSystem Parameters:uri - a uri whose authority section names the host, port, etc.    for this FileSystemconf - the configuration Throws: IOException append public FSDataOutputStream append(Path f,                         int bufferSize,                         Progressable progress)                           throws IOException This optional operation is not yet supported. Specified by: append in class FileSystem Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used.progress - for reporting progress if it is not null. Throws: IOException create public FSDataOutputStream create(Path f,                         FsPermission permission,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Specified by: create in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) delete public boolean delete(Path f,              boolean recurse)                throws IOException Description copied from class: FileSystem Delete a file. Specified by: delete in class FileSystem Parameters:f - the path to delete.recurse - if path is a directory and set to   true, the directory is deleted else throws an exception. In  case of a file the recursive can be set to either true or false. Returns:true if delete is successful else false. Throws: IOException getFileStatus public FileStatus getFileStatus(Path f)                          throws IOException Description copied from class: FileSystem Return a file status object that represents the path. Specified by: getFileStatus in class FileSystem Parameters:f - The path we want information from Returns:a FileStatus object Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException getUri public URI getUri() Description copied from class: FileSystem Returns a URI whose scheme and authority identify this FileSystem. Specified by: getUri in class FileSystem listStatus public FileStatus[] listStatus(Path f)                         throws IOException  If f is a file, this method will make a single call to S3.  If f is a directory, this method will make a maximum of  (n / 1000) + 2 calls to S3, where n is the total number of  files and directories contained directly in f.   Specified by: listStatus in class FileSystem Parameters:f - given path Returns:the statuses of the files/directories in the given patch Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException mkdirs public boolean mkdirs(Path f,              FsPermission permission)                throws IOException Description copied from class: FileSystem Make the given file and all non-existent parents into  directories. Has the semantics of Unix 'mkdir -p'.  Existence of the directory hierarchy is not an error. Specified by: mkdirs in class FileSystem Parameters:f - path to createpermission - to apply to f Throws: IOException open public FSDataInputStream open(Path f,                      int bufferSize)                        throws IOException Description copied from class: FileSystem Opens an FSDataInputStream at the indicated Path. Specified by: open in class FileSystem Parameters:f - the file name to openbufferSize - the size of the buffer to be used. Throws: IOException rename public boolean rename(Path src,              Path dst)                throws IOException Description copied from class: FileSystem Renames Path src to Path dst.  Can take place on local fs  or remote DFS. Specified by: rename in class FileSystem Parameters:src - path to be renameddst - new path after rename Returns:true if rename is successful Throws: IOException - on failure getDefaultBlockSize public long getDefaultBlockSize() Description copied from class: FileSystem Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. Overrides: getDefaultBlockSize in class FileSystem setWorkingDirectory public void setWorkingDirectory(Path newDir) Set the working directory to the given directory. Specified by: setWorkingDirectory in class FileSystem getWorkingDirectory public Path getWorkingDirectory() Description copied from class: FileSystem Get the current working directory for the given file system Specified by: getWorkingDirectory in class FileSystem Returns:the directory pathname getCanonicalServiceName public String getCanonicalServiceName() Description copied from class: FileSystem Get a canonical service name for this file system.  The token cache is  the only user of the canonical service name, and uses it to lookup this  filesystem's service tokens.  If file system provides a token of its own then it must have a canonical  name, otherwise canonical name can be null.    Default Impl: If the file system has child file systems   (such as an embedded file system) then it is assumed that the fs has no  tokens of its own and hence returns a null name; otherwise a service  name is built using Uri and port. Returns:a service string that uniquely identifies this file system, null          if the filesystem does not implement tokensSee Also:SecurityUtil.buildDTServiceName(URI, int) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NoChildrenForEphemeralsException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NoChildrenForEphemeralsException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.exceptions Class NoChildrenForEphemeralsException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.PathIOException org.apache.hadoop.registry.client.exceptions.RegistryIOException org.apache.hadoop.registry.client.exceptions.NoChildrenForEphemeralsException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class NoChildrenForEphemeralsException extends RegistryIOException This is a manifestation of the Zookeeper restrictions about  what nodes may act as parents.  Children are not allowed under ephemeral nodes. This is an aspect  of ZK which isn't directly exposed to the registry API. It may  surface if the registry is manipulated outside of the registry API. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description NoChildrenForEphemeralsException(String path,                                                                 String error)  NoChildrenForEphemeralsException(String path,                                                                 String error,                                                                 Throwable cause)  NoChildrenForEphemeralsException(String path,                                                                 Throwable cause)  Method Summary Methods inherited from class org.apache.hadoop.fs.PathIOException getMessage, getPath, getTargetPath, setOperation, setTargetPath Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail NoChildrenForEphemeralsException public NoChildrenForEphemeralsException(String path,                                 Throwable cause) NoChildrenForEphemeralsException public NoChildrenForEphemeralsException(String path,                                 String error) NoChildrenForEphemeralsException public NoChildrenForEphemeralsException(String path,                                 String error,                                 Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NoEmitMetricsContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NoEmitMetricsContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.spi Class NoEmitMetricsContext java.lang.Object org.apache.hadoop.metrics.spi.AbstractMetricsContext org.apache.hadoop.metrics.spi.NoEmitMetricsContext All Implemented Interfaces: org.apache.hadoop.metrics.MetricsContext @InterfaceAudience.Public @InterfaceStability.Evolving public class NoEmitMetricsContext extends AbstractMetricsContext A MetricsContext that does not emit data, but, unlike NullContextWithUpdate,  does save it for retrieval with getAllRecords().    This is useful if you want to support MetricsServlet, but  not emit metrics in any other way. Field Summary Fields inherited from interface org.apache.hadoop.metrics.MetricsContext DEFAULT_PERIOD Constructor Summary Constructors  Constructor and Description NoEmitMetricsContext() Creates a new instance of NullContextWithUpdateThread Method Summary Methods inherited from class org.apache.hadoop.metrics.spi.AbstractMetricsContext close, createRecord, flush, getAllRecords, getAttribute, getAttributeTable, getContextFactory, getContextName, getPeriod, isMonitoring, newRecord, parseAndSetPeriod, registerUpdater, remove, setPeriod, startMonitoring, stopMonitoring, unregisterUpdater, update Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail NoEmitMetricsContext @InterfaceAudience.Private public NoEmitMetricsContext() Creates a new instance of NullContextWithUpdateThread Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NoRecordException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NoRecordException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.exceptions Class NoRecordException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.PathIOException org.apache.hadoop.registry.client.exceptions.RegistryIOException org.apache.hadoop.registry.client.exceptions.NoRecordException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class NoRecordException extends RegistryIOException Raised if there is no ServiceRecord resolved at the end  of the specified path.    There may be valid data of some form at the end of the path, but it does  not appear to be a Service Record. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description NoRecordException(String path,                                   String error)  NoRecordException(String path,                                   String error,                                   Throwable cause)  Method Summary Methods inherited from class org.apache.hadoop.fs.PathIOException getMessage, getPath, getTargetPath, setOperation, setTargetPath Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail NoRecordException public NoRecordException(String path,                  String error) NoRecordException public NoRecordException(String path,                  String error,                  Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NodeId (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NodeId (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class NodeId java.lang.Object org.apache.hadoop.yarn.api.records.NodeId All Implemented Interfaces: Comparable<NodeId> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class NodeId extends Object implements Comparable<NodeId> NodeId is the unique identifier for a node.    It includes the hostname and port to uniquely   identify the node. Thus, it is unique across restarts of any   NodeManager. Constructor Summary Constructors  Constructor and Description NodeId()  Method Summary Methods  Modifier and Type Method and Description protected abstract void build()  int compareTo(NodeId other)  boolean equals(Object obj)  abstract String getHost() Get the hostname of the node. abstract int getPort() Get the port for communicating with the node. int hashCode()  String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail NodeId public NodeId() Method Detail getHost @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getHost() Get the hostname of the node. Returns:hostname of the node getPort @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getPort() Get the port for communicating with the node. Returns:port for communicating with the node toString public String toString() Overrides: toString in class Object hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object compareTo public int compareTo(NodeId other) Specified by: compareTo in interface Comparable<NodeId> build protected abstract void build() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NodeReport (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NodeReport (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class NodeReport java.lang.Object org.apache.hadoop.yarn.api.records.NodeReport @InterfaceAudience.Public @InterfaceStability.Stable public abstract class NodeReport extends Object NodeReport is a summary of runtime information of a node  in the cluster.    It includes details such as:      NodeId of the node.    HTTP Tracking URL of the node.    Rack name for the node.    Used Resource on the node.    Total available Resource of the node.    Number of running containers on the node.   See Also:ApplicationClientProtocol.getClusterNodes(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest) Constructor Summary Constructors  Constructor and Description NodeReport()  Method Summary Methods  Modifier and Type Method and Description abstract Resource getCapability() Get the total Resource on the node. abstract String getHealthReport() Get the diagnostic health report of the node. abstract String getHttpAddress() Get the http address of the node. abstract long getLastHealthReportTime() Get the last timestamp at which the health report was received. abstract NodeId getNodeId() Get the NodeId of the node. abstract Set<String> getNodeLabels() Get labels of this node abstract NodeState getNodeState() Get the NodeState of the node. abstract String getRackName() Get the rack name for the node. abstract Resource getUsed() Get used Resource on the node. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail NodeReport public NodeReport() Method Detail getNodeId @InterfaceAudience.Public @InterfaceStability.Stable public abstract NodeId getNodeId() Get the NodeId of the node. Returns:NodeId of the node getNodeState @InterfaceAudience.Public @InterfaceStability.Stable public abstract NodeState getNodeState() Get the NodeState of the node. Returns:NodeState of the node getHttpAddress @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getHttpAddress() Get the http address of the node. Returns:http address of the node getRackName @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getRackName() Get the rack name for the node. Returns:rack name for the node getUsed @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getUsed() Get used Resource on the node. Returns:used Resource on the node getCapability @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getCapability() Get the total Resource on the node. Returns:total Resource on the node getHealthReport @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getHealthReport() Get the diagnostic health report of the node. Returns:diagnostic health report of the node getLastHealthReportTime @InterfaceAudience.Public @InterfaceStability.Stable public abstract long getLastHealthReportTime() Get the last timestamp at which the health report was received. Returns:last timestamp at which the health report was received getNodeLabels @InterfaceAudience.Public @InterfaceStability.Stable public abstract Set<String> getNodeLabels() Get labels of this node Returns:labels of this node Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NodeState (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NodeState (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum NodeState java.lang.Object java.lang.Enum<NodeState> org.apache.hadoop.yarn.api.records.NodeState All Implemented Interfaces: Serializable, Comparable<NodeState> @InterfaceAudience.Public @InterfaceStability.Unstable public enum NodeState extends Enum<NodeState> State of a Node. Enum Constant Summary Enum Constants  Enum Constant and Description DECOMMISSIONED Node is out of service LOST Node has not sent a heartbeat for some configured time threshold NEW New node REBOOTED Node has rebooted RUNNING Running node UNHEALTHY Node is unhealthy Method Summary Methods  Modifier and Type Method and Description boolean isUnusable()  static NodeState valueOf(String name) Returns the enum constant of this type with the specified name. static NodeState[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail NEW public static final NodeState NEW New node RUNNING public static final NodeState RUNNING Running node UNHEALTHY public static final NodeState UNHEALTHY Node is unhealthy DECOMMISSIONED public static final NodeState DECOMMISSIONED Node is out of service LOST public static final NodeState LOST Node has not sent a heartbeat for some configured time threshold REBOOTED public static final NodeState REBOOTED Node has rebooted Method Detail values public static NodeState[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (NodeState c : NodeState.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static NodeState valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null isUnusable public boolean isUnusable() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NotInMountpointException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NotInMountpointException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.viewfs Class NotInMountpointException java.lang.Object java.lang.Throwable java.lang.Exception java.lang.RuntimeException java.lang.UnsupportedOperationException org.apache.hadoop.fs.viewfs.NotInMountpointException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class NotInMountpointException extends UnsupportedOperationException NotInMountpointException extends the UnsupportedOperationException.  Exception class used in cases where the given path is not mounted   through viewfs. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description NotInMountpointException(Path path,                                                 String operation)  NotInMountpointException(String operation)  Method Summary Methods  Modifier and Type Method and Description String getMessage()  Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail NotInMountpointException public NotInMountpointException(Path path,                         String operation) NotInMountpointException public NotInMountpointException(String operation) Method Detail getMessage public String getMessage() Overrides: getMessage in class Throwable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NullContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NullContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.spi Class NullContext java.lang.Object org.apache.hadoop.metrics.spi.AbstractMetricsContext org.apache.hadoop.metrics.spi.NullContext All Implemented Interfaces: org.apache.hadoop.metrics.MetricsContext @InterfaceAudience.Public @InterfaceStability.Evolving public class NullContext extends AbstractMetricsContext Null metrics context: a metrics context which does nothing.  Used as the  default context, so that no performance data is emitted if no configuration  data is found. Field Summary Fields inherited from interface org.apache.hadoop.metrics.MetricsContext DEFAULT_PERIOD Constructor Summary Constructors  Constructor and Description NullContext() Creates a new instance of NullContext Method Summary Methods inherited from class org.apache.hadoop.metrics.spi.AbstractMetricsContext close, createRecord, flush, getAllRecords, getAttribute, getAttributeTable, getContextFactory, getContextName, getPeriod, init, isMonitoring, newRecord, parseAndSetPeriod, registerUpdater, setPeriod, stopMonitoring, unregisterUpdater Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail NullContext @InterfaceAudience.Private public NullContext() Creates a new instance of NullContext Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NullContextWithUpdateThread (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NullContextWithUpdateThread (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.spi Class NullContextWithUpdateThread java.lang.Object org.apache.hadoop.metrics.spi.AbstractMetricsContext org.apache.hadoop.metrics.spi.NullContextWithUpdateThread All Implemented Interfaces: org.apache.hadoop.metrics.MetricsContext @InterfaceAudience.Public @InterfaceStability.Evolving public class NullContextWithUpdateThread extends AbstractMetricsContext A null context which has a thread calling   periodically when monitoring is started. This keeps the data sampled   correctly.  In all other respects, this is like the NULL context: No data is emitted.  This is suitable for Monitoring systems like JMX which reads the metrics   when someone reads the data from JMX.    The default impl of start and stop monitoring:   is the AbstractMetricsContext is good enough. Field Summary Fields inherited from interface org.apache.hadoop.metrics.MetricsContext DEFAULT_PERIOD Constructor Summary Constructors  Constructor and Description NullContextWithUpdateThread() Creates a new instance of NullContextWithUpdateThread Method Summary Methods inherited from class org.apache.hadoop.metrics.spi.AbstractMetricsContext close, createRecord, flush, getAllRecords, getAttribute, getAttributeTable, getContextFactory, getContextName, getPeriod, isMonitoring, newRecord, parseAndSetPeriod, registerUpdater, setPeriod, startMonitoring, stopMonitoring, unregisterUpdater Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail NullContextWithUpdateThread @InterfaceAudience.Private public NullContextWithUpdateThread() Creates a new instance of NullContextWithUpdateThread Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NullOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NullOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class NullOutputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.NullOutputFormat<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class NullOutputFormat<K,V> extends OutputFormat<K,V> Consume all outputs and put them in /dev/null. Constructor Summary Constructors  Constructor and Description NullOutputFormat()  Method Summary Methods  Modifier and Type Method and Description void checkOutputSpecs(JobContext context) Check for validity of the output-specification for the job. OutputCommitter getOutputCommitter(TaskAttemptContext context) Get the output committer for this output format. RecordWriter<K,V> getRecordWriter(TaskAttemptContext context) Get the RecordWriter for the given task. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail NullOutputFormat public NullOutputFormat() Method Detail getRecordWriter public RecordWriter<K,V> getRecordWriter(TaskAttemptContext context) Description copied from class: OutputFormat Get the RecordWriter for the given task. Specified by: getRecordWriter in class OutputFormat<K,V> Parameters:context - the information about the current task. Returns:a RecordWriter to write the output for the job. checkOutputSpecs public void checkOutputSpecs(JobContext context) Description copied from class: OutputFormat Check for validity of the output-specification for the job.     This is to validate the output specification for the job when it is  a job is submitted.  Typically checks that it does not already exist,  throwing an exception when it already exists, so that output is not  overwritten. Specified by: checkOutputSpecs in class OutputFormat<K,V> Parameters:context - information about the job getOutputCommitter public OutputCommitter getOutputCommitter(TaskAttemptContext context) Description copied from class: OutputFormat Get the output committer for this output format. This is responsible  for ensuring the output is committed correctly. Specified by: getOutputCommitter in class OutputFormat<K,V> Parameters:context - the task context Returns:an output committer Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  NullWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="NullWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class NullWritable java.lang.Object org.apache.hadoop.io.NullWritable All Implemented Interfaces: Comparable<NullWritable>, Writable, WritableComparable<NullWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class NullWritable extends Object implements WritableComparable<NullWritable> Singleton Writable with no data. Method Summary Methods  Modifier and Type Method and Description int compareTo(NullWritable other)  boolean equals(Object other)  static NullWritable get() Returns the single instance of this class. int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Method Detail get public static NullWritable get() Returns the single instance of this class. toString public String toString() Overrides: toString in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(NullWritable other) Specified by: compareTo in interface Comparable<NullWritable> equals public boolean equals(Object other) Overrides: equals in class Object readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ObjectWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ObjectWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class ObjectWritable java.lang.Object org.apache.hadoop.io.ObjectWritable All Implemented Interfaces: Configurable, Writable @InterfaceAudience.Public @InterfaceStability.Stable public class ObjectWritable extends Object implements Writable, Configurable A polymorphic Writable that writes an instance with it's class name.  Handles arrays, strings and primitive types without a Writable wrapper. Constructor Summary Constructors  Constructor and Description ObjectWritable()  ObjectWritable(Class declaredClass,                             Object instance)  ObjectWritable(Object instance)  Method Summary Methods  Modifier and Type Method and Description Object get() Return the instance, or null if none. Configuration getConf() Return the configuration used by this object. Class getDeclaredClass() Return the class this is meant to be. static Class<?> loadClass(Configuration conf,                   String className) Find and load the class with given name className by first finding  it in the specified conf. void readFields(DataInput in) Deserialize the fields of this object from in. static Object readObject(DataInput in,                     Configuration conf) Read a Writable, String, primitive type, or an array of  the preceding. static Object readObject(DataInput in,                     ObjectWritable objectWritable,                     Configuration conf) Read a Writable, String, primitive type, or an array of  the preceding. void set(Object instance) Reset the instance. void setConf(Configuration conf) Set the configuration to be used by this object. String toString()  void write(DataOutput out) Serialize the fields of this object to out. static void writeObject(DataOutput out,                       Object instance,                       Class declaredClass,                       Configuration conf) Write a Writable, String, primitive type, or an array of  the preceding. static void writeObject(DataOutput out,                       Object instance,                       Class declaredClass,                       Configuration conf,                       boolean allowCompactArrays) Write a Writable, String, primitive type, or an array of  the preceding. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ObjectWritable public ObjectWritable() ObjectWritable public ObjectWritable(Object instance) ObjectWritable public ObjectWritable(Class declaredClass,               Object instance) Method Detail get public Object get() Return the instance, or null if none. getDeclaredClass public Class getDeclaredClass() Return the class this is meant to be. set public void set(Object instance) Reset the instance. toString public String toString() Overrides: toString in class Object readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException writeObject public static void writeObject(DataOutput out,                Object instance,                Class declaredClass,                Configuration conf)                         throws IOException Write a Writable, String, primitive type, or an array of  the preceding. Throws: IOException writeObject public static void writeObject(DataOutput out,                Object instance,                Class declaredClass,                Configuration conf,                boolean allowCompactArrays)                         throws IOException Write a Writable, String, primitive type, or an array of  the preceding. Parameters:allowCompactArrays - - set true for RPC and internal or intra-cluster  usages.  Set false for inter-cluster, File, and other persisted output   usages, to preserve the ability to interchange files with other clusters   that may not be running the same version of software.  Sometime in ~2013   we can consider removing this parameter and always using the compact format. Throws: IOException readObject public static Object readObject(DataInput in,                 Configuration conf)                          throws IOException Read a Writable, String, primitive type, or an array of  the preceding. Throws: IOException readObject public static Object readObject(DataInput in,                 ObjectWritable objectWritable,                 Configuration conf)                          throws IOException Read a Writable, String, primitive type, or an array of  the preceding. Throws: IOException loadClass public static Class<?> loadClass(Configuration conf,                  String className) Find and load the class with given name className by first finding  it in the specified conf. If the specified conf is null,  try load it directly. setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Options (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Options (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class Options java.lang.Object org.apache.hadoop.fs.Options @InterfaceAudience.Public @InterfaceStability.Evolving public final class Options extends Object This class contains options related to file system operations. Constructor Summary Constructors  Constructor and Description Options()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Options public Options() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OracleDBRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OracleDBRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class OracleDBRecordReader<T extends DBWritable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<LongWritable,T> org.apache.hadoop.mapreduce.lib.db.DBRecordReader<T> org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader<T> All Implemented Interfaces: Closeable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Evolving public class OracleDBRecordReader<T extends DBWritable> extends DBRecordReader<T> A RecordReader that reads records from an Oracle SQL table. Field Summary Fields  Modifier and Type Field and Description static String SESSION_TIMEZONE_KEY Configuration key to set to a timezone string. Fields inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader statement Constructor Summary Constructors  Constructor and Description OracleDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                         Class<T> inputClass,                                         Configuration conf,                                         Connection conn,                                         DBConfiguration dbConfig,                                         String cond,                                         String[] fields,                                         String table)  Method Summary Methods  Modifier and Type Method and Description protected String getSelectQuery() Returns the query for selecting the records from an Oracle DB. static void setSessionTimeZone(Configuration conf,                                     Connection conn) Set session time zone Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader close, createValue, executeQuery, getConditions, getConnection, getCurrentKey, getCurrentValue, getDBConf, getFieldNames, getPos, getProgress, getSplit, getStatement, getTableName, initialize, next, nextKeyValue, setStatement Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail SESSION_TIMEZONE_KEY public static final String SESSION_TIMEZONE_KEY Configuration key to set to a timezone string. See Also:Constant Field Values Constructor Detail OracleDBRecordReader public OracleDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                     Class<T> inputClass,                     Configuration conf,                     Connection conn,                     DBConfiguration dbConfig,                     String cond,                     String[] fields,                     String table)                      throws SQLException Throws: SQLException Method Detail getSelectQuery protected String getSelectQuery() Returns the query for selecting the records from an Oracle DB. Overrides: getSelectQuery in class DBRecordReader<T extends DBWritable> setSessionTimeZone public static void setSessionTimeZone(Configuration conf,                       Connection conn)                                throws SQLException Set session time zone Parameters:conf - The current configuration.  We read the 'oracle.sessionTimeZone' property from here.conn - The connection to alter the timezone properties of. Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OracleDataDrivenDBInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OracleDataDrivenDBInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class OracleDataDrivenDBInputFormat<T extends DBWritable> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<LongWritable,T> org.apache.hadoop.mapreduce.lib.db.DBInputFormat<T> org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat<T> org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat<T> All Implemented Interfaces: Configurable @InterfaceAudience.Public @InterfaceStability.Evolving public class OracleDataDrivenDBInputFormat<T extends DBWritable> extends DataDrivenDBInputFormat<T> implements Configurable A InputFormat that reads input data from an SQL table in an Oracle db. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat SUBSTITUTE_TOKEN Fields inherited from class org.apache.hadoop.mapreduce.lib.db.DBInputFormat conditions, connection, dbConf, dbProductName, fieldNames, tableName Constructor Summary Constructors  Constructor and Description OracleDataDrivenDBInputFormat()  Method Summary Methods  Modifier and Type Method and Description protected RecordReader<LongWritable,T> createDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                         Configuration conf)  protected DBSplitter getSplitter(int sqlDataType)  Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat getBoundingValsQuery, getSplits, setBoundingQuery, setInput, setInput Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DBInputFormat closeConnection, createConnection, createRecordReader, getConf, getConnection, getCountQuery, getDBConf, getDBProductName, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Constructor Detail OracleDataDrivenDBInputFormat public OracleDataDrivenDBInputFormat() Method Detail getSplitter protected DBSplitter getSplitter(int sqlDataType) Overrides: getSplitter in class DataDrivenDBInputFormat<T extends DBWritable> Returns:the DBSplitter implementation to use to divide the table/query into InputSplits. createDBRecordReader protected RecordReader<LongWritable,T> createDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                                 Configuration conf)                                                                         throws IOException Overrides: createDBRecordReader in class DataDrivenDBInputFormat<T extends DBWritable> Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OracleDataDrivenDBRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OracleDataDrivenDBRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class OracleDataDrivenDBRecordReader<T extends DBWritable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<LongWritable,T> org.apache.hadoop.mapreduce.lib.db.DBRecordReader<T> org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader<T> org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBRecordReader<T> All Implemented Interfaces: Closeable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Evolving public class OracleDataDrivenDBRecordReader<T extends DBWritable> extends DataDrivenDBRecordReader<T> A RecordReader that reads records from a Oracle table via DataDrivenDBRecordReader Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader statement Constructor Summary Constructors  Constructor and Description OracleDataDrivenDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                                                             Class<T> inputClass,                                                             Configuration conf,                                                             Connection conn,                                                             DBConfiguration dbConfig,                                                             String cond,                                                             String[] fields,                                                             String table)  Method Summary Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader getSelectQuery Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DBRecordReader close, createValue, executeQuery, getConditions, getConnection, getCurrentKey, getCurrentValue, getDBConf, getFieldNames, getPos, getProgress, getSplit, getStatement, getTableName, initialize, next, nextKeyValue, setStatement Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail OracleDataDrivenDBRecordReader public OracleDataDrivenDBRecordReader(org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit split,                               Class<T> inputClass,                               Configuration conf,                               Connection conn,                               DBConfiguration dbConfig,                               String cond,                               String[] fields,                               String table)                                throws SQLException Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OracleDateSplitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OracleDateSplitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class OracleDateSplitter java.lang.Object org.apache.hadoop.mapreduce.lib.db.IntegerSplitter org.apache.hadoop.mapreduce.lib.db.DateSplitter org.apache.hadoop.mapreduce.lib.db.OracleDateSplitter All Implemented Interfaces: DBSplitter @InterfaceAudience.Public @InterfaceStability.Evolving public class OracleDateSplitter extends DateSplitter Implement DBSplitter over date/time values returned by an Oracle db.  Make use of logic from DateSplitter, since this just needs to use  some Oracle-specific functions on the formatting end when generating  InputSplits. Constructor Summary Constructors  Constructor and Description OracleDateSplitter()  Method Summary Methods  Modifier and Type Method and Description protected String dateToString(Date d) Given a Date 'd', format it as a string for use in a SQL date  comparison operation. Methods inherited from class org.apache.hadoop.mapreduce.lib.db.DateSplitter split Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail OracleDateSplitter public OracleDateSplitter() Method Detail dateToString protected String dateToString(Date d) Description copied from class: DateSplitter Given a Date 'd', format it as a string for use in a SQL date  comparison operation. Overrides: dateToString in class DateSplitter Parameters:d - the date to format. Returns:the string representing this date in SQL with any appropriate  quotation characters, etc. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OuterJoinRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OuterJoinRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class OuterJoinRecordReader<K extends WritableComparable<?>> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader<K,X> org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader<K,Writable,TupleWritable> org.apache.hadoop.mapreduce.lib.join.JoinRecordReader<K> org.apache.hadoop.mapreduce.lib.join.OuterJoinRecordReader<K> All Implemented Interfaces: Closeable, AutoCloseable, Comparable<ComposableRecordReader<K,?>>, Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class OuterJoinRecordReader<K extends WritableComparable<?>> extends JoinRecordReader<K> Full outer join. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader conf, jc, key, keyclass, kids, value Method Summary Methods  Modifier and Type Method and Description protected boolean combine(Object[] srcs,               TupleWritable dst) Emit everything from the collector. Methods inherited from class org.apache.hadoop.mapreduce.lib.join.JoinRecordReader createValue, getDelegate, nextKeyValue Methods inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader accept, add, close, compareTo, createKey, createTupleWritable, fillJoinCollector, getComparator, getConf, getCurrentKey, getCurrentValue, getProgress, getRecordReaderQueue, hasNext, id, initialize, key, key, setConf, skip Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail combine protected boolean combine(Object[] srcs,               TupleWritable dst) Emit everything from the collector. Specified by: combine in class CompositeRecordReader<K extends WritableComparable<?>,Writable,TupleWritable> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OutputCollector (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OutputCollector (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Interface OutputCollector<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public interface OutputCollector<K,V> Collects the <key, value> pairs output by Mappers  and Reducers.     OutputCollector is the generalization of the facility   provided by the Map-Reduce framework to collect data output by either the   Mapper or the Reducer i.e. intermediate outputs   or the output of the job. Method Summary Methods  Modifier and Type Method and Description void collect(K key,               V value) Adds a key/value pair to the output. Method Detail collect void collect(K key,            V value)              throws IOException Adds a key/value pair to the output. Parameters:key - the key to collect.value - to value to collect. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OutputCommitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OutputCommitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class OutputCommitter java.lang.Object org.apache.hadoop.mapreduce.OutputCommitter Direct Known Subclasses: FileOutputCommitter, OutputCommitter @InterfaceAudience.Public @InterfaceStability.Stable public abstract class OutputCommitter extends Object OutputCommitter describes the commit of task output for a   Map-Reduce job.  The Map-Reduce framework relies on the OutputCommitter of   the job to:          Setup the job during initialization. For example, create the temporary     output directory for the job during the initialization of the job.            Cleanup the job after the job completion. For example, remove the    temporary output directory after the job completion.             Setup the task temporary output.             Check whether a task needs a commit. This is to avoid the commit    procedure if a task does not need commit.            Commit of the task output.              Discard the task commit.        The methods in this class can be called from several different processes and  from several different contexts.  It is important to know which process and  which context each is called from.  Each method should be marked accordingly  in its documentation.  It is also important to note that not all methods are  guaranteed to be called once and only once.  If a method is not guaranteed to  have this property the output committer needs to handle this appropriately.   Also note it will only be in rare situations where they may be called   multiple times for the same task. See Also:FileOutputCommitter,  JobContext,  TaskAttemptContext Constructor Summary Constructors  Constructor and Description OutputCommitter()  Method Summary Methods  Modifier and Type Method and Description void abortJob(JobContext jobContext,                 org.apache.hadoop.mapreduce.JobStatus.State state) For aborting an unsuccessful job's output. abstract void abortTask(TaskAttemptContext taskContext) Discard the task output. void cleanupJob(JobContext jobContext) Deprecated.  Use commitJob(JobContext) and                  abortJob(JobContext, JobStatus.State) instead. void commitJob(JobContext jobContext) For committing job's output after successful job completion. abstract void commitTask(TaskAttemptContext taskContext) To promote the task's temporary output to final output location. boolean isRecoverySupported() Deprecated.  Use isRecoverySupported(JobContext) instead. boolean isRecoverySupported(JobContext jobContext) Is task output recovery supported for restarting jobs?    If task output recovery is supported, job restart can be done more  efficiently. abstract boolean needsTaskCommit(TaskAttemptContext taskContext) Check whether task needs a commit. void recoverTask(TaskAttemptContext taskContext) Recover the task output. abstract void setupJob(JobContext jobContext) For the framework to setup the job output during initialization. abstract void setupTask(TaskAttemptContext taskContext) Sets up output for the task. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail OutputCommitter public OutputCommitter() Method Detail setupJob public abstract void setupJob(JobContext jobContext)                        throws IOException For the framework to setup the job output during initialization.  This is  called from the application master process for the entire job. This will be  called multiple times, once per job attempt. Parameters:jobContext - Context of the job whose output is being written. Throws: IOException - if temporary output could not be created cleanupJob @Deprecated public void cleanupJob(JobContext jobContext)                 throws IOException Deprecated. Use commitJob(JobContext) and                  abortJob(JobContext, JobStatus.State) instead. For cleaning up the job's output after job completion.  This is called  from the application master process for the entire job. This may be called  multiple times. Parameters:jobContext - Context of the job whose output is being written. Throws: IOException commitJob public void commitJob(JobContext jobContext)                throws IOException For committing job's output after successful job completion. Note that this  is invoked for jobs with final runstate as SUCCESSFUL.  This is called  from the application master process for the entire job. This is guaranteed  to only be called once.  If it throws an exception the entire job will  fail. Parameters:jobContext - Context of the job whose output is being written. Throws: IOException abortJob public void abortJob(JobContext jobContext,             org.apache.hadoop.mapreduce.JobStatus.State state)               throws IOException For aborting an unsuccessful job's output. Note that this is invoked for   jobs with final runstate as JobStatus.State.FAILED or   JobStatus.State.KILLED.  This is called from the application  master process for the entire job. This may be called multiple times. Parameters:jobContext - Context of the job whose output is being written.state - final runstate of the job Throws: IOException setupTask public abstract void setupTask(TaskAttemptContext taskContext)                         throws IOException Sets up output for the task.  This is called from each individual task's  process that will output to HDFS, and it is called just for that task. This  may be called multiple times for the same task, but for different task  attempts. Parameters:taskContext - Context of the task whose output is being written. Throws: IOException needsTaskCommit public abstract boolean needsTaskCommit(TaskAttemptContext taskContext)                                  throws IOException Check whether task needs a commit.  This is called from each individual  task's process that will output to HDFS, and it is called just for that  task. Parameters:taskContext -  Returns:true/false Throws: IOException commitTask public abstract void commitTask(TaskAttemptContext taskContext)                          throws IOException To promote the task's temporary output to final output location.  If needsTaskCommit(TaskAttemptContext) returns true and this  task is the task that the AM determines finished first, this method  is called to commit an individual task's output.  This is to mark  that tasks output as complete, as commitJob(JobContext) will   also be called later on if the entire job finished successfully. This  is called from a task's process. This may be called multiple times for the  same task, but different task attempts.  It should be very rare for this to  be called multiple times and requires odd networking failures to make this  happen. In the future the Hadoop framework may eliminate this race. Parameters:taskContext - Context of the task whose output is being written. Throws: IOException - if commit is not successful. abortTask public abstract void abortTask(TaskAttemptContext taskContext)                         throws IOException Discard the task output. This is called from a task's process to clean   up a single task's output that can not yet been committed. This may be  called multiple times for the same task, but for different task attempts. Parameters:taskContext -  Throws: IOException isRecoverySupported @Deprecated public boolean isRecoverySupported() Deprecated. Use isRecoverySupported(JobContext) instead. Is task output recovery supported for restarting jobs?    If task output recovery is supported, job restart can be done more  efficiently. Returns:true if task output recovery is supported,          false otherwiseSee Also:recoverTask(TaskAttemptContext) isRecoverySupported public boolean isRecoverySupported(JobContext jobContext)                             throws IOException Is task output recovery supported for restarting jobs?    If task output recovery is supported, job restart can be done more  efficiently. Parameters:jobContext - Context of the job whose output is being written. Returns:true if task output recovery is supported,          false otherwise Throws: IOExceptionSee Also:recoverTask(TaskAttemptContext) recoverTask public void recoverTask(TaskAttemptContext taskContext)                  throws IOException Recover the task output.     The retry-count for the job will be passed via the   MRJobConfig.APPLICATION_ATTEMPT_ID key in    JobContext.getConfiguration() for the   OutputCommitter.  This is called from the application master  process, but it is called individually for each task.    If an exception is thrown the task will be attempted again.     This may be called multiple times for the same task.  But from different  application attempts. Parameters:taskContext - Context of the task whose output is being recovered Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class OutputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> Direct Known Subclasses: DBOutputFormat, FileOutputFormat, FilterOutputFormat, NullOutputFormat @InterfaceAudience.Public @InterfaceStability.Stable public abstract class OutputFormat<K,V> extends Object OutputFormat describes the output-specification for a   Map-Reduce job.  The Map-Reduce framework relies on the OutputFormat of the  job to:          Validate the output-specification of the job. For e.g. check that the     output directory doesn't already exist.         Provide the RecordWriter implementation to be used to write out    the output files of the job. Output files are stored in a     FileSystem.       See Also:RecordWriter Constructor Summary Constructors  Constructor and Description OutputFormat()  Method Summary Methods  Modifier and Type Method and Description abstract void checkOutputSpecs(JobContext context) Check for validity of the output-specification for the job. abstract OutputCommitter getOutputCommitter(TaskAttemptContext context) Get the output committer for this output format. abstract RecordWriter<K,V> getRecordWriter(TaskAttemptContext context) Get the RecordWriter for the given task. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail OutputFormat public OutputFormat() Method Detail getRecordWriter public abstract RecordWriter<K,V> getRecordWriter(TaskAttemptContext context)                                            throws IOException,                                                   InterruptedException Get the RecordWriter for the given task. Parameters:context - the information about the current task. Returns:a RecordWriter to write the output for the job. Throws: IOException InterruptedException checkOutputSpecs public abstract void checkOutputSpecs(JobContext context)                                throws IOException,                                       InterruptedException Check for validity of the output-specification for the job.     This is to validate the output specification for the job when it is  a job is submitted.  Typically checks that it does not already exist,  throwing an exception when it already exists, so that output is not  overwritten. Parameters:context - information about the job Throws: IOException - when output should not be attempted InterruptedException getOutputCommitter public abstract OutputCommitter getOutputCommitter(TaskAttemptContext context)                                             throws IOException,                                                    InterruptedException Get the output committer for this output format. This is responsible  for ensuring the output is committed correctly. Parameters:context - the task context Returns:an output committer Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OutputLogFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OutputLogFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class OutputLogFilter java.lang.Object org.apache.hadoop.mapred.OutputLogFilter All Implemented Interfaces: PathFilter @InterfaceAudience.Public @InterfaceStability.Stable public class OutputLogFilter extends Object implements PathFilter This class filters log files from directory given  It doesnt accept paths having _logs.  This can be used to list paths of output directory as follows:    Path[] fileList = FileUtil.stat2Paths(fs.listStatus(outDir,                                    new OutputLogFilter())); Constructor Summary Constructors  Constructor and Description OutputLogFilter()  Method Summary Methods  Modifier and Type Method and Description boolean accept(Path path) Tests whether or not the specified abstract pathname should be  included in a pathname list. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail OutputLogFilter public OutputLogFilter() Method Detail accept public boolean accept(Path path) Description copied from interface: PathFilter Tests whether or not the specified abstract pathname should be  included in a pathname list. Specified by: accept in interface PathFilter Parameters:path - The abstract pathname to be tested Returns:true if and only if pathname           should be included Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OutputRecord (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OutputRecord (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.spi Class OutputRecord java.lang.Object org.apache.hadoop.metrics.spi.OutputRecord @InterfaceAudience.Public @InterfaceStability.Evolving public class OutputRecord extends Object Represents a record of metric data to be sent to a metrics system. Method Summary Methods  Modifier and Type Method and Description Number getMetric(String name) Returns the metric object which can be a Float, Integer, Short or Byte. Set<String> getMetricNames() Returns the set of metric names. org.apache.hadoop.metrics.spi.AbstractMetricsContext.MetricMap getMetricsCopy() Returns a copy of this record's metrics. Object getTag(String name) Returns a tag object which is can be a String, Integer, Short or Byte. Set<String> getTagNames() Returns the set of tag names org.apache.hadoop.metrics.spi.AbstractMetricsContext.TagMap getTagsCopy() Returns a copy of this record's tags. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail getTagNames public Set<String> getTagNames() Returns the set of tag names getTag public Object getTag(String name) Returns a tag object which is can be a String, Integer, Short or Byte. Returns:the tag value, or null if there is no such tag getMetricNames public Set<String> getMetricNames() Returns the set of metric names. getMetric public Number getMetric(String name) Returns the metric object which can be a Float, Integer, Short or Byte. getTagsCopy public org.apache.hadoop.metrics.spi.AbstractMetricsContext.TagMap getTagsCopy() Returns a copy of this record's tags. getMetricsCopy public org.apache.hadoop.metrics.spi.AbstractMetricsContext.MetricMap getMetricsCopy() Returns a copy of this record's metrics. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  OverrideRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="OverrideRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class OverrideRecordReader<K extends WritableComparable<?>,V extends Writable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader<K,X> org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader<K,V,V> org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader<K,V> org.apache.hadoop.mapreduce.lib.join.OverrideRecordReader<K,V> All Implemented Interfaces: Closeable, AutoCloseable, Comparable<ComposableRecordReader<K,?>>, Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class OverrideRecordReader<K extends WritableComparable<?>,V extends Writable> extends MultiFilterRecordReader<K,V> Prefer the "rightmost" data source for this key.  For example, override(S1,S2,S3) will prefer values  from S3 over S2, and values from S2 over S1 for all keys  emitted from all sources. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader conf, jc, key, keyclass, kids, value Method Summary Methods  Modifier and Type Method and Description V createValue() Create instance of value. protected V emit(TupleWritable dst) Emit the value with the highest position in the tuple. protected void fillJoinCollector(K iterkey) Instead of filling the JoinCollector with iterators from all  data sources, fill only the rightmost for this key. Methods inherited from class org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader combine, getDelegate, initialize, nextKeyValue Methods inherited from class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader accept, add, close, compareTo, createKey, createTupleWritable, getComparator, getConf, getCurrentKey, getCurrentValue, getProgress, getRecordReaderQueue, hasNext, id, key, key, setConf, skip Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail emit protected V emit(TupleWritable dst) Emit the value with the highest position in the tuple. Specified by: emit in class MultiFilterRecordReader<K extends WritableComparable<?>,V extends Writable> createValue public V createValue() Description copied from class: ComposableRecordReader Create instance of value. fillJoinCollector protected void fillJoinCollector(K iterkey)                           throws IOException,                                  InterruptedException Instead of filling the JoinCollector with iterators from all  data sources, fill only the rightmost for this key.  This not only saves space by discarding the other sources, but  it also emits the number of key-value pairs in the preferred  RecordReader instead of repeating that stream n times, where  n is the cardinality of the cross product of the discarded  streams for the given key. Overrides: fillJoinCollector in class CompositeRecordReader<K extends WritableComparable<?>,V extends Writable,V extends Writable> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ParentNotDirectoryException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ParentNotDirectoryException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class ParentNotDirectoryException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.ParentNotDirectoryException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class ParentNotDirectoryException extends IOException Indicates that the parent of specified Path is not a directory  as expected. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ParentNotDirectoryException()  ParentNotDirectoryException(String msg)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ParentNotDirectoryException public ParentNotDirectoryException() ParentNotDirectoryException public ParentNotDirectoryException(String msg) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ParseException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ParseException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler.generated Class ParseException java.lang.Object java.lang.Throwable java.lang.Exception org.apache.hadoop.record.compiler.generated.ParseException All Implemented Interfaces: Serializable Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class ParseException extends Exception This exception is thrown when parse errors are encountered.  You can explicitly create objects of this exception type by  calling the method generateParseException in the generated  parser.  You can modify this class to customize your error reporting  mechanisms so long as you retain the public fields. See Also:Serialized Form Field Summary Fields  Modifier and Type Field and Description Token currentToken Deprecated.  This is the last token that has been consumed successfully. protected String eol Deprecated.  The end of line string for this machine. int[][] expectedTokenSequences Deprecated.  Each entry in this array is an array of integers. protected boolean specialConstructor Deprecated.  This variable determines which constructor was used to create  this object and thereby affects the semantics of the  "getMessage" method (see below). String[] tokenImage Deprecated.  This is a reference to the "tokenImage" array of the generated  parser within which the parse error occurred. Constructor Summary Constructors  Constructor and Description ParseException() Deprecated.  The following constructors are for use by you for whatever  purpose you can think of. ParseException(String message) Deprecated.    ParseException(Token currentTokenVal,                             int[][] expectedTokenSequencesVal,                             String[] tokenImageVal) Deprecated.  This constructor is used by the method "generateParseException"  in the generated parser. Method Summary Methods  Modifier and Type Method and Description protected String add_escapes(String str) Deprecated.  Used to convert raw characters to their escaped version  when these raw version cannot be used as part of an ASCII  string literal. String getMessage() Deprecated.  This method has the standard behavior when this object has been  created using the standard constructors. Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail specialConstructor protected boolean specialConstructor Deprecated.  This variable determines which constructor was used to create  this object and thereby affects the semantics of the  "getMessage" method (see below). currentToken public Token currentToken Deprecated.  This is the last token that has been consumed successfully.  If  this object has been created due to a parse error, the token  followng this token will (therefore) be the first error token. expectedTokenSequences public int[][] expectedTokenSequences Deprecated.  Each entry in this array is an array of integers.  Each array  of integers represents a sequence of tokens (by their ordinal  values) that is expected at this point of the parse. tokenImage public String[] tokenImage Deprecated.  This is a reference to the "tokenImage" array of the generated  parser within which the parse error occurred.  This array is  defined in the generated ...Constants interface. eol protected String eol Deprecated.  The end of line string for this machine. Constructor Detail ParseException public ParseException(Token currentTokenVal,               int[][] expectedTokenSequencesVal,               String[] tokenImageVal) Deprecated.  This constructor is used by the method "generateParseException"  in the generated parser.  Calling this constructor generates  a new object of this type with the fields "currentToken",  "expectedTokenSequences", and "tokenImage" set.  The boolean  flag "specialConstructor" is also set to true to indicate that  this constructor was used to create this object.  This constructor calls its super class with the empty string  to force the "toString" method of parent class "Throwable" to  print the error message in the form:      ParseException:  ParseException public ParseException() Deprecated.  The following constructors are for use by you for whatever  purpose you can think of.  Constructing the exception in this  manner makes the exception behave in the normal way - i.e., as  documented in the class "Throwable".  The fields "errorToken",  "expectedTokenSequences", and "tokenImage" do not contain  relevant information.  The JavaCC generated code does not use  these constructors. ParseException public ParseException(String message) Deprecated.  Method Detail getMessage public String getMessage() Deprecated.  This method has the standard behavior when this object has been  created using the standard constructors.  Otherwise, it uses  "currentToken" and "expectedTokenSequences" to generate a parse  error message and returns it.  If this object has been created  due to a parse error, and you do not catch it (it gets thrown  from the parser), then this method is called during the printing  of the final stack trace, and hence the correct error message  gets displayed. Overrides: getMessage in class Throwable add_escapes protected String add_escapes(String str) Deprecated.  Used to convert raw characters to their escaped version  when these raw version cannot be used as part of an ASCII  string literal. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Parser.Node (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Parser.Node (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class Parser.Node java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableInputFormat org.apache.hadoop.mapreduce.lib.join.Parser.Node Enclosing class: Parser @InterfaceAudience.Public @InterfaceStability.Evolving public abstract static class Parser.Node extends ComposableInputFormat Field Summary Fields  Modifier and Type Field and Description protected Class<? extends WritableComparator> cmpcl  protected int id  protected String ident  protected static Map<String,Constructor<? extends ComposableRecordReader>> rrCstrMap  Constructor Summary Constructors  Modifier Constructor and Description protected  Parser.Node(String ident)  Method Summary Methods  Modifier and Type Method and Description protected static void addIdentifier(String ident,                           Class<?>[] mcstrSig,                           Class<? extends Parser.Node> nodetype,                           Class<? extends ComposableRecordReader> cl) For a given identifier, add a mapping to the nodetype for the parse  tree and to the ComposableRecordReader to be created, including the  formals required to invoke the constructor. protected void setID(int id)  protected void setKeyComparator(Class<? extends WritableComparator> cmpcl)  Methods inherited from class org.apache.hadoop.mapreduce.lib.join.ComposableInputFormat createRecordReader Methods inherited from class org.apache.hadoop.mapreduce.InputFormat getSplits Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail rrCstrMap protected static final Map<String,Constructor<? extends ComposableRecordReader>> rrCstrMap id protected int id ident protected String ident cmpcl protected Class<? extends WritableComparator> cmpcl Constructor Detail Parser.Node protected Parser.Node(String ident) Method Detail addIdentifier protected static void addIdentifier(String ident,                  Class<?>[] mcstrSig,                  Class<? extends Parser.Node> nodetype,                  Class<? extends ComposableRecordReader> cl)                              throws NoSuchMethodException For a given identifier, add a mapping to the nodetype for the parse  tree and to the ComposableRecordReader to be created, including the  formals required to invoke the constructor.  The nodetype and constructor signature should be filled in from the  child node. Throws: NoSuchMethodException setID protected void setID(int id) setKeyComparator protected void setKeyComparator(Class<? extends WritableComparator> cmpcl) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Parser.NodeToken (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Parser.NodeToken (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class Parser.NodeToken java.lang.Object org.apache.hadoop.mapreduce.lib.join.Parser.Token org.apache.hadoop.mapreduce.lib.join.Parser.NodeToken Enclosing class: Parser @InterfaceAudience.Public @InterfaceStability.Evolving public static class Parser.NodeToken extends Parser.Token Method Summary Methods  Modifier and Type Method and Description Parser.Node getNode()  Methods inherited from class org.apache.hadoop.mapreduce.lib.join.Parser.Token getNum, getStr, getType Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail getNode public Parser.Node getNode() Overrides: getNode in class Parser.Token Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Parser.NumToken (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Parser.NumToken (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class Parser.NumToken java.lang.Object org.apache.hadoop.mapreduce.lib.join.Parser.Token org.apache.hadoop.mapreduce.lib.join.Parser.NumToken Enclosing class: Parser @InterfaceAudience.Public @InterfaceStability.Evolving public static class Parser.NumToken extends Parser.Token Constructor Summary Constructors  Constructor and Description Parser.NumToken(double num)  Method Summary Methods  Modifier and Type Method and Description double getNum()  Methods inherited from class org.apache.hadoop.mapreduce.lib.join.Parser.Token getNode, getStr, getType Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Parser.NumToken public Parser.NumToken(double num) Method Detail getNum public double getNum() Overrides: getNum in class Parser.Token Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Parser.StrToken (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Parser.StrToken (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class Parser.StrToken java.lang.Object org.apache.hadoop.mapreduce.lib.join.Parser.Token org.apache.hadoop.mapreduce.lib.join.Parser.StrToken Enclosing class: Parser @InterfaceAudience.Public @InterfaceStability.Evolving public static class Parser.StrToken extends Parser.Token Constructor Summary Constructors  Constructor and Description Parser.StrToken(Parser.TType type,                               String str)  Method Summary Methods  Modifier and Type Method and Description String getStr()  Methods inherited from class org.apache.hadoop.mapreduce.lib.join.Parser.Token getNode, getNum, getType Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Parser.StrToken public Parser.StrToken(Parser.TType type,                String str) Method Detail getStr public String getStr() Overrides: getStr in class Parser.Token Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Parser.TType (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Parser.TType (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.mapreduce.lib.join Enum Parser.TType java.lang.Object java.lang.Enum<Parser.TType> org.apache.hadoop.mapreduce.lib.join.Parser.TType All Implemented Interfaces: Serializable, Comparable<Parser.TType> Enclosing class: Parser @InterfaceAudience.Public @InterfaceStability.Evolving public static enum Parser.TType extends Enum<Parser.TType> Enum Constant Summary Enum Constants  Enum Constant and Description CIF  COMMA  IDENT  LPAREN  NUM  QUOT  RPAREN  Method Summary Methods  Modifier and Type Method and Description static Parser.TType valueOf(String name) Returns the enum constant of this type with the specified name. static Parser.TType[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail CIF public static final Parser.TType CIF IDENT public static final Parser.TType IDENT COMMA public static final Parser.TType COMMA LPAREN public static final Parser.TType LPAREN RPAREN public static final Parser.TType RPAREN QUOT public static final Parser.TType QUOT NUM public static final Parser.TType NUM Method Detail values public static Parser.TType[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (Parser.TType c : Parser.TType.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static Parser.TType valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Parser.Token (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Parser.Token (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class Parser.Token java.lang.Object org.apache.hadoop.mapreduce.lib.join.Parser.Token Direct Known Subclasses: Parser.NodeToken, Parser.NumToken, Parser.StrToken Enclosing class: Parser @InterfaceAudience.Public @InterfaceStability.Evolving public static class Parser.Token extends Object Tagged-union type for tokens from the join expression. See Also:Parser.TType Method Summary Methods  Modifier and Type Method and Description Parser.Node getNode()  double getNum()  String getStr()  Parser.TType getType()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail getType public Parser.TType getType() getNode public Parser.Node getNode()                     throws IOException Throws: IOException getNum public double getNum()               throws IOException Throws: IOException getStr public String getStr()               throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Parser (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Parser (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class Parser java.lang.Object org.apache.hadoop.mapreduce.lib.join.Parser @InterfaceAudience.Public @InterfaceStability.Evolving public class Parser extends Object Very simple shift-reduce parser for join expressions.  This should be sufficient for the user extension permitted now, but ought to  be replaced with a parser generator if more complex grammars are supported.  In particular, this "shift-reduce" parser has no states. Each set  of formals requires a different internal node type, which is responsible for  interpreting the list of tokens it receives. This is sufficient for the  current grammar, but it has several annoying properties that might inhibit  extension. In particular, parenthesis are always function calls; an  algebraic or filter grammar would not only require a node type, but must  also work around the internals of this parser.  For most other cases, adding classes to the hierarchy- particularly by  extending JoinRecordReader and MultiFilterRecordReader- is fairly  straightforward. One need only override the relevant method(s) (usually only  CompositeRecordReader.combine(java.lang.Object[], org.apache.hadoop.mapreduce.lib.join.TupleWritable)) and include a property to map its  value to an identifier in the parser. Nested Class Summary Nested Classes  Modifier and Type Class and Description static class  Parser.Node  static class  Parser.NodeToken  static class  Parser.NumToken  static class  Parser.StrToken  static class  Parser.Token Tagged-union type for tokens from the join expression. static class  Parser.TType  Constructor Summary Constructors  Constructor and Description Parser()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Parser public Parser() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PartialFileOutputCommitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PartialFileOutputCommitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class PartialFileOutputCommitter java.lang.Object org.apache.hadoop.mapreduce.OutputCommitter org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter All Implemented Interfaces: PartialOutputCommitter @Checkpointable @InterfaceAudience.Public @InterfaceStability.Evolving public class PartialFileOutputCommitter extends FileOutputCommitter implements PartialOutputCommitter An OutputCommitter that commits files specified  in job output directory i.e. ${mapreduce.output.fileoutputformat.outputdir}. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter FILEOUTPUTCOMMITTER_ALGORITHM_VERSION, FILEOUTPUTCOMMITTER_ALGORITHM_VERSION_DEFAULT, PENDING_DIR_NAME, SUCCEEDED_FILE_NAME, SUCCESSFUL_JOB_OUTPUT_DIR_MARKER, TEMP_DIR_NAME Constructor Summary Constructors  Constructor and Description PartialFileOutputCommitter(Path outputPath,                                                     JobContext context)  PartialFileOutputCommitter(Path outputPath,                                                     TaskAttemptContext context)  Method Summary Methods  Modifier and Type Method and Description void cleanUpPartialOutputForTask(TaskAttemptContext context) Remove all previously committed outputs from prior executions of this task. Path getCommittedTaskPath(int appAttemptId,                                         TaskAttemptContext context) Compute the path where the output of a committed task is stored until the  entire job is committed for a specific application attempt. Methods inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter abortJob, abortTask, cleanupJob, commitJob, commitTask, getCommittedTaskPath, getCommittedTaskPath, getJobAttemptPath, getJobAttemptPath, getJobAttemptPath, getTaskAttemptPath, getTaskAttemptPath, getWorkPath, isRecoverySupported, needsTaskCommit, recoverTask, setupJob, setupTask Methods inherited from class org.apache.hadoop.mapreduce.OutputCommitter isRecoverySupported Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail PartialFileOutputCommitter public PartialFileOutputCommitter(Path outputPath,                           TaskAttemptContext context)                            throws IOException Throws: IOException PartialFileOutputCommitter public PartialFileOutputCommitter(Path outputPath,                           JobContext context)                            throws IOException Throws: IOException Method Detail getCommittedTaskPath public Path getCommittedTaskPath(int appAttemptId,                         TaskAttemptContext context) Description copied from class: FileOutputCommitter Compute the path where the output of a committed task is stored until the  entire job is committed for a specific application attempt. Overrides: getCommittedTaskPath in class FileOutputCommitter Parameters:appAttemptId - the id of the application attempt to usecontext - the context of any task. Returns:the path where the output of a committed task is stored. cleanUpPartialOutputForTask public void cleanUpPartialOutputForTask(TaskAttemptContext context)                                  throws IOException Description copied from interface: PartialOutputCommitter Remove all previously committed outputs from prior executions of this task. Specified by: cleanUpPartialOutputForTask in interface PartialOutputCommitter Parameters:context - Context for cleaning up previously promoted output. Throws: IOException - If cleanup fails, then the state of the task my not be                      well defined. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PartialOutputCommitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PartialOutputCommitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Interface PartialOutputCommitter All Known Implementing Classes: PartialFileOutputCommitter @InterfaceAudience.Public @InterfaceStability.Evolving public interface PartialOutputCommitter Interface for an OutputCommitter  implementing partial commit of task output, as during preemption. Method Summary Methods  Modifier and Type Method and Description void cleanUpPartialOutputForTask(TaskAttemptContext context) Remove all previously committed outputs from prior executions of this task. Method Detail cleanUpPartialOutputForTask void cleanUpPartialOutputForTask(TaskAttemptContext context)                                  throws IOException Remove all previously committed outputs from prior executions of this task. Parameters:context - Context for cleaning up previously promoted output. Throws: IOException - If cleanup fails, then the state of the task my not be                      well defined. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Partitioner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Partitioner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class Partitioner<KEY,VALUE> java.lang.Object org.apache.hadoop.mapreduce.Partitioner<KEY,VALUE> Direct Known Subclasses: BinaryPartitioner, HashPartitioner, KeyFieldBasedPartitioner, TotalOrderPartitioner @InterfaceAudience.Public @InterfaceStability.Stable public abstract class Partitioner<KEY,VALUE> extends Object Partitions the key space.    Partitioner controls the partitioning of the keys of the   intermediate map-outputs. The key (or a subset of the key) is used to derive  the partition, typically by a hash function. The total number of partitions  is the same as the number of reduce tasks for the job. Hence this controls  which of the m reduce tasks the intermediate key (and hence the   record) is sent for reduction.    Note: If you require your Partitioner class to obtain the Job's configuration  object, implement the Configurable interface. See Also:Reducer Constructor Summary Constructors  Constructor and Description Partitioner()  Method Summary Methods  Modifier and Type Method and Description abstract int getPartition(KEY key,                         VALUE value,                         int numPartitions) Get the partition number for a given key (hence record) given the total   number of partitions i.e. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Partitioner public Partitioner() Method Detail getPartition public abstract int getPartition(KEY key,                VALUE value,                int numPartitions) Get the partition number for a given key (hence record) given the total   number of partitions i.e. number of reduce-tasks for the job.      Typically a hash function on a all or a subset of the key. Parameters:key - the key to be partioned.value - the entry value.numPartitions - the total number of partitions. Returns:the partition number for the key. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Path (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Path (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class Path java.lang.Object org.apache.hadoop.fs.Path All Implemented Interfaces: Comparable @Stringable @InterfaceAudience.Public @InterfaceStability.Stable public class Path extends Object implements Comparable Names a file or directory in a FileSystem.  Path strings use slash as the directory separator.  A path string is  absolute if it begins with a slash. Field Summary Fields  Modifier and Type Field and Description static String CUR_DIR  static String SEPARATOR The directory separator, a slash. static char SEPARATOR_CHAR  static boolean WINDOWS  Constructor Summary Constructors  Constructor and Description Path(Path parent,         Path child) Resolve a child path against a parent path. Path(Path parent,         String child) Resolve a child path against a parent path. Path(String pathString) Construct a path from a String. Path(String parent,         Path child) Resolve a child path against a parent path. Path(String parent,         String child) Resolve a child path against a parent path. Path(String scheme,         String authority,         String path) Construct a Path from components. Path(URI aUri) Construct a path from a URI Method Summary Methods  Modifier and Type Method and Description int compareTo(Object o)  int depth() Return the number of elements in this path. boolean equals(Object o)  FileSystem getFileSystem(Configuration conf) Return the FileSystem that owns this Path. String getName() Returns the final component of this path. Path getParent() Returns the parent of a path or null if at root. static Path getPathWithoutSchemeAndAuthority(Path path)  int hashCode()  boolean isAbsolute() There is some ambiguity here. boolean isAbsoluteAndSchemeAuthorityNull() Is an absolute path (ie a slash relative path part)   AND  a scheme is null AND  authority is null. boolean isRoot()  boolean isUriPathAbsolute() True if the path component (i.e. static boolean isWindowsAbsolutePath(String pathString,                                           boolean slashed) Determine whether a given path string represents an absolute path on  Windows. Path makeQualified(FileSystem fs) Deprecated.  static Path mergePaths(Path path1,                     Path path2) Merge 2 paths such that the second path is appended relative to the first. Path suffix(String suffix) Adds a suffix to the final name in the path. String toString()  URI toUri() Convert this to a URI. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail SEPARATOR public static final String SEPARATOR The directory separator, a slash. See Also:Constant Field Values SEPARATOR_CHAR public static final char SEPARATOR_CHAR See Also:Constant Field Values CUR_DIR public static final String CUR_DIR See Also:Constant Field Values WINDOWS public static final boolean WINDOWS Constructor Detail Path public Path(String parent,     String child) Resolve a child path against a parent path. Path public Path(Path parent,     String child) Resolve a child path against a parent path. Path public Path(String parent,     Path child) Resolve a child path against a parent path. Path public Path(Path parent,     Path child) Resolve a child path against a parent path. Path public Path(String pathString)      throws IllegalArgumentException Construct a path from a String.  Path strings are URIs, but with  unescaped elements and some additional normalization. Throws: IllegalArgumentException Path public Path(URI aUri) Construct a path from a URI Path public Path(String scheme,     String authority,     String path) Construct a Path from components. Method Detail getPathWithoutSchemeAndAuthority public static Path getPathWithoutSchemeAndAuthority(Path path) mergePaths public static Path mergePaths(Path path1,               Path path2) Merge 2 paths such that the second path is appended relative to the first.  The returned path has the scheme and authority of the first path.  On  Windows, the drive specification in the second path is discarded. Parameters:path1 - Path first pathpath2 - Path second path, to be appended relative to path1 Returns:Path merged path isWindowsAbsolutePath public static boolean isWindowsAbsolutePath(String pathString,                             boolean slashed) Determine whether a given path string represents an absolute path on  Windows. e.g. "C:/a/b" is an absolute path. "C:a/b" is not. Parameters:pathString - Supplies the path string to evaluate.slashed - true if the given path is prefixed with "/". Returns:true if the supplied path looks like an absolute path with a Windows  drive-specifier. toUri public URI toUri() Convert this to a URI. getFileSystem public FileSystem getFileSystem(Configuration conf)                          throws IOException Return the FileSystem that owns this Path. Throws: IOException isAbsoluteAndSchemeAuthorityNull public boolean isAbsoluteAndSchemeAuthorityNull() Is an absolute path (ie a slash relative path part)   AND  a scheme is null AND  authority is null. isUriPathAbsolute public boolean isUriPathAbsolute() True if the path component (i.e. directory) of this URI is absolute. isAbsolute public boolean isAbsolute() There is some ambiguity here. An absolute path is a slash  relative name without a scheme or an authority.  So either this method was incorrectly named or its  implementation is incorrect. This method returns true  even if there is a scheme and authority. isRoot public boolean isRoot() Returns:true if and only if this path represents the root of a file system getName public String getName() Returns the final component of this path. getParent public Path getParent() Returns the parent of a path or null if at root. suffix public Path suffix(String suffix) Adds a suffix to the final name in the path. toString public String toString() Overrides: toString in class Object equals public boolean equals(Object o) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(Object o) Specified by: compareTo in interface Comparable depth public int depth() Return the number of elements in this path. makeQualified @Deprecated public Path makeQualified(FileSystem fs) Deprecated.  Returns a qualified path object.      Deprecated - use makeQualified(URI, Path) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PathFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PathFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Interface PathFilter All Known Implementing Classes: GlobFilter, OutputLogFilter @InterfaceAudience.Public @InterfaceStability.Stable public interface PathFilter Method Summary Methods  Modifier and Type Method and Description boolean accept(Path path) Tests whether or not the specified abstract pathname should be  included in a pathname list. Method Detail accept boolean accept(Path path) Tests whether or not the specified abstract pathname should be  included in a pathname list. Parameters:path - The abstract pathname to be tested Returns:true if and only if pathname           should be included Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PositionedReadable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PositionedReadable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Interface PositionedReadable All Known Implementing Classes: FSDataInputStream @InterfaceAudience.Public @InterfaceStability.Evolving public interface PositionedReadable Stream that permits positional reading. Method Summary Methods  Modifier and Type Method and Description int read(long position,         byte[] buffer,         int offset,         int length) Read upto the specified number of bytes, from a given  position within a file, and return the number of bytes read. void readFully(long position,                   byte[] buffer) Read number of bytes equal to the length of the buffer, from a given  position within a file. void readFully(long position,                   byte[] buffer,                   int offset,                   int length) Read the specified number of bytes, from a given  position within a file. Method Detail read int read(long position,        byte[] buffer,        int offset,        int length)          throws IOException Read upto the specified number of bytes, from a given  position within a file, and return the number of bytes read. This does not  change the current offset of a file, and is thread-safe. Throws: IOException readFully void readFully(long position,              byte[] buffer,              int offset,              int length)                throws IOException Read the specified number of bytes, from a given  position within a file. This does not  change the current offset of a file, and is thread-safe. Throws: IOException readFully void readFully(long position,              byte[] buffer)                throws IOException Read number of bytes equal to the length of the buffer, from a given  position within a file. This does not  change the current offset of a file, and is thread-safe. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PreemptionContainer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PreemptionContainer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class PreemptionContainer java.lang.Object org.apache.hadoop.yarn.api.records.PreemptionContainer @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class PreemptionContainer extends Object Specific container requested back by the ResourceManager. See Also:PreemptionContract,  StrictPreemptionContract Constructor Summary Constructors  Constructor and Description PreemptionContainer()  Method Summary Methods  Modifier and Type Method and Description abstract ContainerId getId()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail PreemptionContainer public PreemptionContainer() Method Detail getId @InterfaceAudience.Public @InterfaceStability.Evolving public abstract ContainerId getId() Returns:Container referenced by this handle. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PreemptionContract (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PreemptionContract (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class PreemptionContract java.lang.Object org.apache.hadoop.yarn.api.records.PreemptionContract @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class PreemptionContract extends Object Description of resources requested back by the ResourceManager.  The ApplicationMaster (AM) can satisfy this request according  to its own priorities to prevent containers from being forcibly killed by  the platform. See Also:PreemptionMessage Constructor Summary Constructors  Constructor and Description PreemptionContract()  Method Summary Methods  Modifier and Type Method and Description abstract Set<PreemptionContainer> getContainers() Assign the set of PreemptionContainer specifying which containers  owned by the ApplicationMaster that may be reclaimed by the  ResourceManager. abstract List<PreemptionResourceRequest> getResourceRequest() If the AM releases resources matching these requests, then the PreemptionContainers enumerated in getContainers() should not be  evicted from the cluster. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail PreemptionContract public PreemptionContract() Method Detail getResourceRequest @InterfaceAudience.Public @InterfaceStability.Evolving public abstract List<PreemptionResourceRequest> getResourceRequest() If the AM releases resources matching these requests, then the PreemptionContainers enumerated in getContainers() should not be  evicted from the cluster. Due to delays in propagating cluster state and  sending these messages, there are conditions where satisfied contracts may  not prevent the platform from killing containers. Returns:List of PreemptionResourceRequest to update the  ApplicationMaster about resources requested back by the  ResourceManager.See Also:AllocateRequest.setAskList(List) getContainers @InterfaceAudience.Public @InterfaceStability.Evolving public abstract Set<PreemptionContainer> getContainers() Assign the set of PreemptionContainer specifying which containers  owned by the ApplicationMaster that may be reclaimed by the  ResourceManager. If the AM prefers a different set of  containers, then it may checkpoint or kill containers matching the  description in getResourceRequest(). Returns:Set of containers at risk if the contract is not met. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PreemptionMessage (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PreemptionMessage (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class PreemptionMessage java.lang.Object org.apache.hadoop.yarn.api.records.PreemptionMessage @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class PreemptionMessage extends Object A PreemptionMessage is part of the RM-AM protocol, and it is used by  the RM to specify resources that the RM wants to reclaim from this  ApplicationMaster (AM). The AM receives a StrictPreemptionContract message encoding which containers the platform may  forcibly kill, granting it an opportunity to checkpoint state or adjust its  execution plan. The message may also include a PreemptionContract  granting the AM more latitude in selecting which resources to return to the  cluster.    The AM should decode both parts of the message. The StrictPreemptionContract specifies particular allocations that the RM  requires back. The AM can checkpoint containers' state, adjust its execution  plan to move the computation, or take no action and hope that conditions that  caused the RM to ask for the container will change.    In contrast, the PreemptionContract also includes a description of  resources with a set of containers. If the AM releases containers matching  that profile, then the containers enumerated in PreemptionContract.getContainers() may not be killed.    Each preemption message reflects the RM's current understanding of the  cluster state, so a request to return N containers may not  reflect containers the AM is releasing, recently exited containers the RM has  yet to learn about, or new containers allocated before the message was  generated. Conversely, an RM may request a different profile of containers in  subsequent requests.    The policy enforced by the RM is part of the scheduler. Generally, only  containers that have been requested consistently should be killed, but the  details are not specified. Constructor Summary Constructors  Constructor and Description PreemptionMessage()  Method Summary Methods  Modifier and Type Method and Description abstract PreemptionContract getContract()  abstract StrictPreemptionContract getStrictContract()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail PreemptionMessage public PreemptionMessage() Method Detail getStrictContract @InterfaceAudience.Public @InterfaceStability.Evolving public abstract StrictPreemptionContract getStrictContract() Returns:Specific resources that may be killed by the  ResourceManager getContract @InterfaceAudience.Public @InterfaceStability.Evolving public abstract PreemptionContract getContract() Returns:Contract describing resources to return to the cluster. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PreemptionResourceRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PreemptionResourceRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class PreemptionResourceRequest java.lang.Object org.apache.hadoop.yarn.api.records.PreemptionResourceRequest @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class PreemptionResourceRequest extends Object Description of resources requested back by the cluster. See Also:PreemptionContract,  AllocateRequest.setAskList(java.util.List) Constructor Summary Constructors  Constructor and Description PreemptionResourceRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ResourceRequest getResourceRequest()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail PreemptionResourceRequest public PreemptionResourceRequest() Method Detail getResourceRequest @InterfaceAudience.Public @InterfaceStability.Evolving public abstract ResourceRequest getResourceRequest() Returns:Resource described in this request, to be matched against running  containers. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Priority (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Priority (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class Priority java.lang.Object org.apache.hadoop.yarn.api.records.Priority All Implemented Interfaces: Comparable<Priority> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class Priority extends Object implements Comparable<Priority> The priority assigned to a ResourceRequest or Application or Container   allocation Field Summary Fields  Modifier and Type Field and Description static Priority UNDEFINED  Constructor Summary Constructors  Constructor and Description Priority()  Method Summary Methods  Modifier and Type Method and Description int compareTo(Priority other)  boolean equals(Object obj)  abstract int getPriority() Get the assigned priority int hashCode()  static Priority newInstance(int p)  abstract void setPriority(int priority) Set the assigned priority String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail UNDEFINED public static final Priority UNDEFINED Constructor Detail Priority public Priority() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static Priority newInstance(int p) getPriority @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getPriority() Get the assigned priority Returns:the assigned priority setPriority @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setPriority(int priority) Set the assigned priority Parameters:priority - the assigned priority hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object compareTo public int compareTo(Priority other) Specified by: compareTo in interface Comparable<Priority> toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Progressable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Progressable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util Interface Progressable All Known Subinterfaces: MapContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT>, ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT>, Reporter, TaskAttemptContext, TaskAttemptContext, TaskInputOutputContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Stable public interface Progressable A facility for reporting progress.    Clients and/or applications can use the provided Progressable  to explicitly report progress to the Hadoop framework. This is especially  important for operations which take significant amount of time since,  in-lieu of the reported progress, the framework has to assume that an error  has occured and time-out the operation. Method Summary Methods  Modifier and Type Method and Description void progress() Report progress to the Hadoop framework. Method Detail progress void progress() Report progress to the Hadoop framework. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ProtocolTypes (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ProtocolTypes (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.types Interface ProtocolTypes @InterfaceAudience.Public @InterfaceStability.Evolving public interface ProtocolTypes some common protocol types Field Summary Fields  Modifier and Type Field and Description static String PROTOCOL_FILESYSTEM Addresses are URIs of Hadoop Filesystem paths: "hadoop/filesystem". static String PROTOCOL_HADOOP_IPC Hadoop IPC,  "classic" or protobuf : "hadoop/IPC". static String PROTOCOL_IIOP Corba IIOP: "IIOP". static String PROTOCOL_REST REST: "REST". static String PROTOCOL_RMI Java RMI: "RMI". static String PROTOCOL_SUN_RPC SunOS RPC, as used by NFS and similar: "sunrpc". static String PROTOCOL_TCP Custom TCP protocol: "tcp". static String PROTOCOL_THRIFT Thrift-based protocols: "thrift". static String PROTOCOL_UDP Custom UPC-based protocol : "udp". static String PROTOCOL_UNKNOWN Default value —the protocol is unknown : """" static String PROTOCOL_WEBUI Web page: "webui". static String PROTOCOL_WSAPI Web Services: "WS-*". static String PROTOCOL_ZOOKEEPER_BINDING A zookeeper binding: "zookeeper". Field Detail PROTOCOL_FILESYSTEM static final String PROTOCOL_FILESYSTEM Addresses are URIs of Hadoop Filesystem paths: "hadoop/filesystem". See Also:Constant Field Values PROTOCOL_HADOOP_IPC static final String PROTOCOL_HADOOP_IPC Hadoop IPC,  "classic" or protobuf : "hadoop/IPC". See Also:Constant Field Values PROTOCOL_IIOP static final String PROTOCOL_IIOP Corba IIOP: "IIOP". See Also:Constant Field Values PROTOCOL_REST static final String PROTOCOL_REST REST: "REST". See Also:Constant Field Values PROTOCOL_RMI static final String PROTOCOL_RMI Java RMI: "RMI". See Also:Constant Field Values PROTOCOL_SUN_RPC static final String PROTOCOL_SUN_RPC SunOS RPC, as used by NFS and similar: "sunrpc". See Also:Constant Field Values PROTOCOL_THRIFT static final String PROTOCOL_THRIFT Thrift-based protocols: "thrift". See Also:Constant Field Values PROTOCOL_TCP static final String PROTOCOL_TCP Custom TCP protocol: "tcp". See Also:Constant Field Values PROTOCOL_UDP static final String PROTOCOL_UDP Custom UPC-based protocol : "udp". See Also:Constant Field Values PROTOCOL_UNKNOWN static final String PROTOCOL_UNKNOWN Default value —the protocol is unknown : """" See Also:Constant Field Values PROTOCOL_WEBUI static final String PROTOCOL_WEBUI Web page: "webui".  This protocol implies that the URLs are designed for  people to view via web browsers. See Also:Constant Field Values PROTOCOL_WSAPI static final String PROTOCOL_WSAPI Web Services: "WS-*". See Also:Constant Field Values PROTOCOL_ZOOKEEPER_BINDING static final String PROTOCOL_ZOOKEEPER_BINDING A zookeeper binding: "zookeeper". See Also:Constant Field Values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PseudoDelegationTokenAuthenticator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PseudoDelegationTokenAuthenticator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.security.token.delegation.web Class PseudoDelegationTokenAuthenticator java.lang.Object org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator org.apache.hadoop.security.token.delegation.web.PseudoDelegationTokenAuthenticator All Implemented Interfaces: org.apache.hadoop.security.authentication.client.Authenticator @InterfaceAudience.Public @InterfaceStability.Evolving public class PseudoDelegationTokenAuthenticator extends DelegationTokenAuthenticator The PseudoDelegationTokenAuthenticator provides support for  Hadoop's pseudo authentication mechanism that accepts  the user name specified as a query string parameter and support for Hadoop  Delegation Token operations.    This mimics the model of Hadoop Simple authentication trusting the  UserGroupInformation.getCurrentUser() value. Field Summary Fields inherited from class org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator DELEGATION_PARAM, DELEGATION_TOKEN_HEADER, DELEGATION_TOKEN_JSON, DELEGATION_TOKEN_URL_STRING_JSON, OP_PARAM, RENEW_DELEGATION_TOKEN_JSON, RENEWER_PARAM, TOKEN_PARAM Constructor Summary Constructors  Constructor and Description PseudoDelegationTokenAuthenticator()  Method Summary Methods inherited from class org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator authenticate, cancelDelegationToken, cancelDelegationToken, getDelegationToken, getDelegationToken, renewDelegationToken, renewDelegationToken, setConnectionConfigurator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail PseudoDelegationTokenAuthenticator public PseudoDelegationTokenAuthenticator() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PureJavaCrc32 (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PureJavaCrc32 (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util Class PureJavaCrc32 java.lang.Object org.apache.hadoop.util.PureJavaCrc32 All Implemented Interfaces: Checksum @InterfaceAudience.Public @InterfaceStability.Stable public class PureJavaCrc32 extends Object implements Checksum A pure-java implementation of the CRC32 checksum that uses  the same polynomial as the built-in native CRC32.  This is to avoid the JNI overhead for certain uses of Checksumming  where many small pieces of data are checksummed in succession.  The current version is ~10x to 1.8x as fast as Sun's native  java.util.zip.CRC32 in Java 1.6 See Also:CRC32 Constructor Summary Constructors  Constructor and Description PureJavaCrc32() Create a new PureJavaCrc32 object. Method Summary Methods  Modifier and Type Method and Description long getValue()  void reset()  void update(byte[] b,             int offset,             int len)  void update(int b)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail PureJavaCrc32 public PureJavaCrc32() Create a new PureJavaCrc32 object. Method Detail getValue public long getValue() Specified by: getValue in interface Checksum reset public void reset() Specified by: reset in interface Checksum update public void update(byte[] b,           int offset,           int len) Specified by: update in interface Checksum update public final void update(int b) Specified by: update in interface Checksum Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  PureJavaCrc32C (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="PureJavaCrc32C (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util Class PureJavaCrc32C java.lang.Object org.apache.hadoop.util.PureJavaCrc32C All Implemented Interfaces: Checksum @InterfaceAudience.Public @InterfaceStability.Stable public class PureJavaCrc32C extends Object implements Checksum A pure-java implementation of the CRC32 checksum that uses  the CRC32-C polynomial, the same polynomial used by iSCSI  and implemented on many Intel chipsets supporting SSE4.2. Constructor Summary Constructors  Constructor and Description PureJavaCrc32C() Create a new PureJavaCrc32 object. Method Summary Methods  Modifier and Type Method and Description long getValue()  void reset()  void update(byte[] b,             int off,             int len)  void update(int b)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail PureJavaCrc32C public PureJavaCrc32C() Create a new PureJavaCrc32 object. Method Detail getValue public long getValue() Specified by: getValue in interface Checksum reset public void reset() Specified by: reset in interface Checksum update public void update(byte[] b,           int off,           int len) Specified by: update in interface Checksum update public final void update(int b) Specified by: update in interface Checksum Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  QueueACL (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="QueueACL (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum QueueACL java.lang.Object java.lang.Enum<QueueACL> org.apache.hadoop.yarn.api.records.QueueACL All Implemented Interfaces: Serializable, Comparable<QueueACL> @InterfaceAudience.Public @InterfaceStability.Stable public enum QueueACL extends Enum<QueueACL> QueueACL enumerates the various ACLs for queues.    The ACL is one of:            SUBMIT_APPLICATIONS - ACL to submit applications to the queue.        ADMINISTER_QUEUE - ACL to administer the queue.   See Also:QueueInfo,  ApplicationClientProtocol.getQueueUserAcls(org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest) Enum Constant Summary Enum Constants  Enum Constant and Description ADMINISTER_QUEUE ACL to administer the queue. SUBMIT_APPLICATIONS ACL to submit applications to the queue. Method Summary Methods  Modifier and Type Method and Description static QueueACL valueOf(String name) Returns the enum constant of this type with the specified name. static QueueACL[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail SUBMIT_APPLICATIONS public static final QueueACL SUBMIT_APPLICATIONS ACL to submit applications to the queue. ADMINISTER_QUEUE public static final QueueACL ADMINISTER_QUEUE ACL to administer the queue. Method Detail values public static QueueACL[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (QueueACL c : QueueACL.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static QueueACL valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  QueueAclsInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="QueueAclsInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class QueueAclsInfo java.lang.Object org.apache.hadoop.mapreduce.QueueAclsInfo All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class QueueAclsInfo extends Object implements Writable Class to encapsulate Queue ACLs for a particular   user. Constructor Summary Constructors  Constructor and Description QueueAclsInfo() Default constructor for QueueAclsInfo. QueueAclsInfo(String queueName,                           String[] operations) Construct a new QueueAclsInfo object using the queue name and the  queue operations array Method Summary Methods  Modifier and Type Method and Description String[] getOperations() Get opearations allowed on queue. String getQueueName() Get queue name. void readFields(DataInput in) Deserialize the fields of this object from in. protected void setQueueName(String queueName)  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail QueueAclsInfo public QueueAclsInfo() Default constructor for QueueAclsInfo. QueueAclsInfo public QueueAclsInfo(String queueName,              String[] operations) Construct a new QueueAclsInfo object using the queue name and the  queue operations array Parameters:queueName - Name of the job queueoperations -  Method Detail getQueueName public String getQueueName() Get queue name. Returns:name setQueueName protected void setQueueName(String queueName) getOperations public String[] getOperations() Get opearations allowed on queue. Returns:array of String readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  QueueInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="QueueInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class QueueInfo java.lang.Object org.apache.hadoop.yarn.api.records.QueueInfo @InterfaceAudience.Public @InterfaceStability.Stable public abstract class QueueInfo extends Object QueueInfo is a report of the runtime information of the queue.    It includes information such as:      Queue name.    Capacity of the queue.    Maximum capacity of the queue.    Current capacity of the queue.    Child queues.    Running applications.    QueueState of the queue.   See Also:QueueState,  ApplicationClientProtocol.getQueueInfo(org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest) Constructor Summary Constructors  Constructor and Description QueueInfo()  Method Summary Methods  Modifier and Type Method and Description abstract Set<String> getAccessibleNodeLabels() Get the accessible node labels of the queue. abstract List<ApplicationReport> getApplications() Get the running applications of the queue. abstract float getCapacity() Get the configured capacity of the queue. abstract List<QueueInfo> getChildQueues() Get the child queues of the queue. abstract float getCurrentCapacity() Get the current capacity of the queue. abstract String getDefaultNodeLabelExpression() Get the default node label expression of the queue, this takes  affect only when the ApplicationSubmissionContext and  ResourceRequest don't specify their  NodeLabelExpression. abstract float getMaximumCapacity() Get the maximum capacity of the queue. abstract String getQueueName() Get the name of the queue. abstract QueueState getQueueState() Get the QueueState of the queue. abstract void setDefaultNodeLabelExpression(String defaultLabelExpression)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail QueueInfo public QueueInfo() Method Detail getQueueName @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getQueueName() Get the name of the queue. Returns:name of the queue getCapacity @InterfaceAudience.Public @InterfaceStability.Stable public abstract float getCapacity() Get the configured capacity of the queue. Returns:configured capacity of the queue getMaximumCapacity @InterfaceAudience.Public @InterfaceStability.Stable public abstract float getMaximumCapacity() Get the maximum capacity of the queue. Returns:maximum capacity of the queue getCurrentCapacity @InterfaceAudience.Public @InterfaceStability.Stable public abstract float getCurrentCapacity() Get the current capacity of the queue. Returns:current capacity of the queue getChildQueues @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<QueueInfo> getChildQueues() Get the child queues of the queue. Returns:child queues of the queue getApplications @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ApplicationReport> getApplications() Get the running applications of the queue. Returns:running applications of the queue getQueueState @InterfaceAudience.Public @InterfaceStability.Stable public abstract QueueState getQueueState() Get the QueueState of the queue. Returns:QueueState of the queue getAccessibleNodeLabels @InterfaceAudience.Public @InterfaceStability.Stable public abstract Set<String> getAccessibleNodeLabels() Get the accessible node labels of the queue. Returns:accessible node labels of the queue getDefaultNodeLabelExpression @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getDefaultNodeLabelExpression() Get the default node label expression of the queue, this takes  affect only when the ApplicationSubmissionContext and  ResourceRequest don't specify their  NodeLabelExpression. Returns:default node label expression of the queue setDefaultNodeLabelExpression @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setDefaultNodeLabelExpression(String defaultLabelExpression) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  QueueState (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="QueueState (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum QueueState java.lang.Object java.lang.Enum<QueueState> org.apache.hadoop.yarn.api.records.QueueState All Implemented Interfaces: Serializable, Comparable<QueueState> @InterfaceAudience.Public @InterfaceStability.Stable public enum QueueState extends Enum<QueueState> State of a Queue.    A queue is in one of:      RUNNING - normal state.    STOPPED - not accepting new application submissions.   See Also:QueueInfo,  ApplicationClientProtocol.getQueueInfo(org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest) Enum Constant Summary Enum Constants  Enum Constant and Description RUNNING Running - normal operation. STOPPED Stopped - Not accepting submissions of new applications. Method Summary Methods  Modifier and Type Method and Description static QueueState valueOf(String name) Returns the enum constant of this type with the specified name. static QueueState[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail STOPPED public static final QueueState STOPPED Stopped - Not accepting submissions of new applications. RUNNING public static final QueueState RUNNING Running - normal operation. Method Detail values public static QueueState[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (QueueState c : QueueState.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static QueueState valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  QueueUserACLInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="QueueUserACLInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class QueueUserACLInfo java.lang.Object org.apache.hadoop.yarn.api.records.QueueUserACLInfo @InterfaceAudience.Public @InterfaceStability.Stable public abstract class QueueUserACLInfo extends Object QueueUserACLInfo provides information QueueACL for  the given user. See Also:QueueACL,  ApplicationClientProtocol.getQueueUserAcls(org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest) Constructor Summary Constructors  Constructor and Description QueueUserACLInfo()  Method Summary Methods  Modifier and Type Method and Description abstract String getQueueName() Get the queue name of the queue. abstract List<QueueACL> getUserAcls() Get the list of QueueACL for the given user. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail QueueUserACLInfo public QueueUserACLInfo() Method Detail getQueueName @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getQueueName() Get the queue name of the queue. Returns:queue name of the queue getUserAcls @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<QueueACL> getUserAcls() Get the list of QueueACL for the given user. Returns:list of QueueACL for the given user Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RMDelegationTokenIdentifier (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RMDelegationTokenIdentifier (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.client Class RMDelegationTokenIdentifier java.lang.Object org.apache.hadoop.security.token.TokenIdentifier org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class RMDelegationTokenIdentifier extends org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier Delegation Token Identifier that identifies the delegation tokens from the   Resource Manager. Field Summary Fields  Modifier and Type Field and Description static Text KIND_NAME  Constructor Summary Constructors  Constructor and Description RMDelegationTokenIdentifier()  RMDelegationTokenIdentifier(Text owner,                                                       Text renewer,                                                       Text realUser) Create a new delegation token identifier Method Summary Methods  Modifier and Type Method and Description Text getKind() Get the token kind Methods inherited from class org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier getProto, readFields, write Methods inherited from class org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier equals, getIssueDate, getMasterKeyId, getMaxDate, getOwner, getRealUser, getRenewer, getSequenceNumber, getUser, hashCode, isEqual, setIssueDate, setMasterKeyId, setMaxDate, setOwner, setRealUser, setRenewer, setSequenceNumber, toString Methods inherited from class org.apache.hadoop.security.token.TokenIdentifier getBytes, getTrackingId Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail KIND_NAME public static final Text KIND_NAME Constructor Detail RMDelegationTokenIdentifier public RMDelegationTokenIdentifier() RMDelegationTokenIdentifier public RMDelegationTokenIdentifier(Text owner,                            Text renewer,                            Text realUser) Create a new delegation token identifier Parameters:owner - the effective username of the token ownerrenewer - the username of the renewerrealUser - the real username of the token owner Method Detail getKind public Text getKind() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the token kind Specified by: getKind in class org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier Returns:the kind of the token Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RMDelegationTokenSelector (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RMDelegationTokenSelector (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.client Class RMDelegationTokenSelector java.lang.Object org.apache.hadoop.yarn.security.client.RMDelegationTokenSelector All Implemented Interfaces: org.apache.hadoop.security.token.TokenSelector<RMDelegationTokenIdentifier> @InterfaceAudience.Public @InterfaceStability.Stable public class RMDelegationTokenSelector extends Object implements org.apache.hadoop.security.token.TokenSelector<RMDelegationTokenIdentifier> Constructor Summary Constructors  Constructor and Description RMDelegationTokenSelector()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.token.Token<RMDelegationTokenIdentifier> selectToken(Text service,                       Collection<org.apache.hadoop.security.token.Token<? extends org.apache.hadoop.security.token.TokenIdentifier>> tokens)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RMDelegationTokenSelector public RMDelegationTokenSelector() Method Detail selectToken public org.apache.hadoop.security.token.Token<RMDelegationTokenIdentifier> selectToken(Text service,                                                                               Collection<org.apache.hadoop.security.token.Token<? extends org.apache.hadoop.security.token.TokenIdentifier>> tokens) Specified by: selectToken in interface org.apache.hadoop.security.token.TokenSelector<RMDelegationTokenIdentifier> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RMProxy (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RMProxy (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client Class RMProxy<T> java.lang.Object org.apache.hadoop.yarn.client.RMProxy<T> Direct Known Subclasses: ClientRMProxy @InterfaceAudience.Public @InterfaceStability.Evolving public class RMProxy<T> extends Object Constructor Summary Constructors  Modifier Constructor and Description protected  RMProxy()  Method Summary Methods  Modifier and Type Method and Description static <T> T createRMProxy(Configuration conf,                           Class<T> protocol,                           InetSocketAddress rmAddress) Deprecated.  This method is deprecated and is not used by YARN internally any more.  To create a proxy to the RM, use ClientRMProxy#createRMProxy or  ServerRMProxy#createRMProxy.  Create a proxy to the ResourceManager at the specified address. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RMProxy protected RMProxy() Method Detail createRMProxy @Deprecated public static <T> T createRMProxy(Configuration conf,                              Class<T> protocol,                              InetSocketAddress rmAddress)                        throws IOException Deprecated. This method is deprecated and is not used by YARN internally any more.  To create a proxy to the RM, use ClientRMProxy#createRMProxy or  ServerRMProxy#createRMProxy.  Create a proxy to the ResourceManager at the specified address. Type Parameters:T - Type information of the proxyParameters:conf - Configuration to generate retry policyprotocol - Protocol for the proxyrmAddress - Address of the ResourceManager Returns:Proxy to the RM Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RawComparable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RawComparable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.file.tfile Interface RawComparable @InterfaceAudience.Public @InterfaceStability.Evolving public interface RawComparable Interface for objects that can be compared through RawComparator.  This is useful in places where we need a single object reference to specify a  range of bytes in a byte array, such as Comparable or  Collections.binarySearch(java.util.List, Object, Comparator)    The actual comparison among RawComparable's requires an external  RawComparator and it is applications' responsibility to ensure two  RawComparable are supposed to be semantically comparable with the same  RawComparator. Method Summary Methods  Modifier and Type Method and Description byte[] buffer() Get the underlying byte array. int offset() Get the offset of the first byte in the byte array. int size() Get the size of the byte range in the byte array. Method Detail buffer byte[] buffer() Get the underlying byte array. Returns:The underlying byte array. offset int offset() Get the offset of the first byte in the byte array. Returns:The offset of the first byte in the byte array. size int size() Get the size of the byte range in the byte array. Returns:The size of the byte range in the byte array. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RawComparator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RawComparator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Interface RawComparator<T> Type Parameters:T -  All Superinterfaces: Comparator<T> All Known Implementing Classes: org.apache.hadoop.io.serializer.DeserializerComparator, JavaSerializationComparator, KeyFieldBasedComparator, KeyFieldBasedComparator, RecordComparator, WritableComparator @InterfaceAudience.Public @InterfaceStability.Stable public interface RawComparator<T> extends Comparator<T>  A Comparator that operates directly on byte representations of  objects.   See Also:DeserializerComparator Method Summary Methods  Modifier and Type Method and Description int compare(byte[] b1,               int s1,               int l1,               byte[] b2,               int s2,               int l2) Compare two objects in binary. Methods inherited from interface java.util.Comparator compare, equals Method Detail compare int compare(byte[] b1,           int s1,           int l1,           byte[] b2,           int s2,           int l2) Compare two objects in binary.  b1[s1:l1] is the first object, and b2[s2:l2] is the second object. Parameters:b1 - The first byte array.s1 - The position index in b1. The object under comparison's starting index.l1 - The length of the object in b1.b2 - The second byte array.s2 - The position index in b2. The object under comparison's starting index.l2 - The length of the object under comparison in b2. Returns:An integer result of the comparison. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RawLocalFileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RawLocalFileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class RawLocalFileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem org.apache.hadoop.fs.RawLocalFileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class RawLocalFileSystem extends FileSystem Implement the FileSystem API for the raw local filesystem. Field Summary Fields inherited from class org.apache.hadoop.fs.FileSystem DEFAULT_FS, FS_DEFAULT_NAME_KEY, LOG, SHUTDOWN_HOOK_PRIORITY, statistics Constructor Summary Constructors  Constructor and Description RawLocalFileSystem()  Method Summary Methods  Modifier and Type Method and Description FSDataOutputStream append(Path f,             int bufferSize,             Progressable progress) Append to an existing file (optional operation). void close() No more filesystem operations are needed. void completeLocalOutput(Path fsWorkingFile,                                       Path tmpLocalFile) Called when we're all done writing to the target. FSDataOutputStream create(Path f,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream create(Path f,             FsPermission permission,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     EnumSet<CreateFlag> flags,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Deprecated.  protected OutputStream createOutputStream(Path f,                                     boolean append)  protected OutputStream createOutputStreamWithMode(Path f,                                                     boolean append,                                                     FsPermission permission)  void createSymlink(Path target,                           Path link,                           boolean createParent) See FileContext.createSymlink(Path, Path, boolean) boolean delete(Path p,             boolean recursive) Delete the given path to a file or directory. FileStatus getFileLinkStatus(Path f) Return a FileStatus representing the given path. FileStatus getFileStatus(Path f) Return a file status object that represents the path. Path getHomeDirectory() Return the current user's home directory in this filesystem. protected Path getInitialWorkingDirectory() Note: with the new FilesContext class, getWorkingDirectory()  will be removed. Path getLinkTarget(Path f) See FileContext.getLinkTarget(Path) FsStatus getStatus(Path p) Returns a status object describing the use and capacity of the  file system. URI getUri() Returns a URI whose scheme and authority identify this FileSystem. Path getWorkingDirectory() Get the current working directory for the given file system void initialize(URI uri,                     Configuration conf) Called after a new FileSystem instance is constructed. FileStatus[] listStatus(Path f) List the statuses of the files/directories in the given path if the path is  a directory. boolean mkdirs(Path f) Creates the specified directory hierarchy. boolean mkdirs(Path f,             FsPermission permission) Make the given file and all non-existent parents into  directories. protected boolean mkOneDir(File p2f)  protected boolean mkOneDirWithMode(Path p,                                 File p2f,                                 FsPermission permission)  void moveFromLocalFile(Path src,                                   Path dst) The src file is on the local disk. FSDataInputStream open(Path f,         int bufferSize) Opens an FSDataInputStream at the indicated Path. File pathToFile(Path path) Convert a path to a File. boolean rename(Path src,             Path dst) Renames Path src to Path dst. void setOwner(Path p,                 String username,                 String groupname) Use the command chown to set owner. void setPermission(Path p,                           FsPermission permission) Use the command chmod to set permission. void setTimes(Path p,                 long mtime,                 long atime) Sets the Path's last modified time only to the given  valid time. void setWorkingDirectory(Path newDir) Set the working directory to the given directory. Path startLocalOutput(Path fsOutputFile,                                 Path tmpLocalFile) Returns a local File that the user can write output to. boolean supportsSymlinks() See AbstractFileSystem.supportsSymlinks() String toString()  boolean truncate(Path f,                 long newLength) Truncate the file in the indicated path to the indicated size. static void useStatIfAvailable()  Methods inherited from class org.apache.hadoop.fs.FileSystem append, append, areSymlinksEnabled, cancelDeleteOnExit, canonicalizeUri, checkPath, clearStatistics, closeAll, closeAllForUGI, concat, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyToLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, create, createNewFile, createNonRecursive, createSnapshot, createSnapshot, delete, deleteOnExit, deleteSnapshot, enableSymlinks, exists, fixRelativePart, get, get, get, getAclStatus, getAllStatistics, getBlockSize, getCanonicalUri, getContentSummary, getDefaultBlockSize, getDefaultBlockSize, getDefaultPort, getDefaultReplication, getDefaultReplication, getDefaultUri, getFileBlockLocations, getFileBlockLocations, getFileChecksum, getFileChecksum, getFileSystemClass, getFSofPath, getLength, getLocal, getName, getNamed, getReplication, getScheme, getServerDefaults, getServerDefaults, getStatistics, getStatistics, getStatus, getUsed, getXAttr, getXAttrs, getXAttrs, globStatus, globStatus, isDirectory, isFile, listCorruptFileBlocks, listFiles, listLocatedStatus, listLocatedStatus, listStatus, listStatus, listStatus, listStatusIterator, listXAttrs, makeQualified, mkdirs, modifyAclEntries, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveCreate, primitiveMkdir, primitiveMkdir, printStatistics, processDeleteOnExit, removeAcl, removeAclEntries, removeDefaultAcl, removeXAttr, rename, renameSnapshot, resolveLink, resolvePath, setAcl, setDefaultUri, setDefaultUri, setReplication, setVerifyChecksum, setWriteChecksum, setXAttr, setXAttr Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail RawLocalFileSystem public RawLocalFileSystem() Method Detail useStatIfAvailable public static void useStatIfAvailable() pathToFile public File pathToFile(Path path) Convert a path to a File. getUri public URI getUri() Description copied from class: FileSystem Returns a URI whose scheme and authority identify this FileSystem. Specified by: getUri in class FileSystem initialize public void initialize(URI uri,               Configuration conf)                 throws IOException Description copied from class: FileSystem Called after a new FileSystem instance is constructed. Overrides: initialize in class FileSystem Parameters:uri - a uri whose authority section names the host, port, etc.    for this FileSystemconf - the configuration Throws: IOException open public FSDataInputStream open(Path f,                      int bufferSize)                        throws IOException Description copied from class: FileSystem Opens an FSDataInputStream at the indicated Path. Specified by: open in class FileSystem Parameters:f - the file name to openbufferSize - the size of the buffer to be used. Throws: IOException append public FSDataOutputStream append(Path f,                         int bufferSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Append to an existing file (optional operation). Specified by: append in class FileSystem Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used.progress - for reporting progress if it is not null. Throws: IOException create public FSDataOutputStream create(Path f,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Overrides: create in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOException createOutputStream protected OutputStream createOutputStream(Path f,                               boolean append)                                    throws IOException Throws: IOException createOutputStreamWithMode protected OutputStream createOutputStreamWithMode(Path f,                                       boolean append,                                       FsPermission permission)                                            throws IOException Throws: IOException createNonRecursive @Deprecated public FSDataOutputStream createNonRecursive(Path f,                                                FsPermission permission,                                                EnumSet<CreateFlag> flags,                                                int bufferSize,                                                short replication,                                                long blockSize,                                                Progressable progress)                                       throws IOException Deprecated.  Description copied from class: FileSystem Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Overrides: createNonRecursive in class FileSystem Parameters:f - the file name to openflags - CreateFlags to use for this stream.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) create public FSDataOutputStream create(Path f,                         FsPermission permission,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Specified by: create in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) createNonRecursive public FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     boolean overwrite,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress)                                       throws IOException Description copied from class: FileSystem Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Overrides: createNonRecursive in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,  the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) rename public boolean rename(Path src,              Path dst)                throws IOException Description copied from class: FileSystem Renames Path src to Path dst.  Can take place on local fs  or remote DFS. Specified by: rename in class FileSystem Parameters:src - path to be renameddst - new path after rename Returns:true if rename is successful Throws: IOException - on failure truncate public boolean truncate(Path f,                long newLength)                  throws IOException Description copied from class: FileSystem Truncate the file in the indicated path to the indicated size.    Fails if path is a directory.  Fails if path does not exist.  Fails if path is not closed.  Fails if new size is greater than current size.   Overrides: truncate in class FileSystem Parameters:f - The path to the file to be truncatednewLength - The size the file is to be truncated to Returns:true if the file has been truncated to the desired  newLength and is immediately available to be reused for  write operations such as append, or  false if a background process of adjusting the length of  the last block has been started, and clients should wait for it to  complete before proceeding with further file updates. Throws: IOException delete public boolean delete(Path p,              boolean recursive)                throws IOException Delete the given path to a file or directory. Specified by: delete in class FileSystem Parameters:p - the path to deleterecursive - to delete sub-directories Returns:true if the file or directory and all its contents were deleted Throws: IOException - if p is non-empty and recursive is false listStatus public FileStatus[] listStatus(Path f)                         throws IOException Description copied from class: FileSystem List the statuses of the files/directories in the given path if the path is  a directory. Specified by: listStatus in class FileSystem Parameters:f - given path Returns:the statuses of the files/directories in the given patch Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException mkOneDir protected boolean mkOneDir(File p2f)                     throws IOException Throws: IOException mkOneDirWithMode protected boolean mkOneDirWithMode(Path p,                        File p2f,                        FsPermission permission)                             throws IOException Throws: IOException mkdirs public boolean mkdirs(Path f)                throws IOException Creates the specified directory hierarchy. Does not  treat existence as an error. Overrides: mkdirs in class FileSystem Throws: IOException mkdirs public boolean mkdirs(Path f,              FsPermission permission)                throws IOException Description copied from class: FileSystem Make the given file and all non-existent parents into  directories. Has the semantics of Unix 'mkdir -p'.  Existence of the directory hierarchy is not an error. Specified by: mkdirs in class FileSystem Parameters:f - path to createpermission - to apply to f Throws: IOException getHomeDirectory public Path getHomeDirectory() Description copied from class: FileSystem Return the current user's home directory in this filesystem.  The default implementation returns "/user/$USER/". Overrides: getHomeDirectory in class FileSystem setWorkingDirectory public void setWorkingDirectory(Path newDir) Set the working directory to the given directory. Specified by: setWorkingDirectory in class FileSystem getWorkingDirectory public Path getWorkingDirectory() Description copied from class: FileSystem Get the current working directory for the given file system Specified by: getWorkingDirectory in class FileSystem Returns:the directory pathname getInitialWorkingDirectory protected Path getInitialWorkingDirectory() Description copied from class: FileSystem Note: with the new FilesContext class, getWorkingDirectory()  will be removed.   The working directory is implemented in FilesContext.    Some file systems like LocalFileSystem have an initial workingDir  that we use as the starting workingDir. For other file systems  like HDFS there is no built in notion of an initial workingDir. Overrides: getInitialWorkingDirectory in class FileSystem Returns:if there is built in notion of workingDir then it  is returned; else a null is returned. getStatus public FsStatus getStatus(Path p)                    throws IOException Description copied from class: FileSystem Returns a status object describing the use and capacity of the  file system. If the file system has multiple partitions, the  use and capacity of the partition pointed to by the specified  path is reflected. Overrides: getStatus in class FileSystem Parameters:p - Path for which status should be obtained. null means  the default partition. Returns:a FsStatus object Throws: IOException - see specific implementation moveFromLocalFile public void moveFromLocalFile(Path src,                      Path dst)                        throws IOException Description copied from class: FileSystem The src file is on the local disk.  Add it to FS at  the given dst name, removing the source afterwards. Overrides: moveFromLocalFile in class FileSystem Parameters:src - pathdst - path Throws: IOException startLocalOutput public Path startLocalOutput(Path fsOutputFile,                     Path tmpLocalFile)                       throws IOException Description copied from class: FileSystem Returns a local File that the user can write output to.  The caller  provides both the eventual FS target name and the local working  file.  If the FS is local, we write directly into the target.  If  the FS is remote, we write into the tmp local area. Overrides: startLocalOutput in class FileSystem Parameters:fsOutputFile - path of output filetmpLocalFile - path of local tmp file Throws: IOException completeLocalOutput public void completeLocalOutput(Path fsWorkingFile,                        Path tmpLocalFile)                          throws IOException Description copied from class: FileSystem Called when we're all done writing to the target.  A local FS will  do nothing, because we've written to exactly the right place.  A remote  FS will copy the contents of tmpLocalFile to the correct target at  fsOutputFile. Overrides: completeLocalOutput in class FileSystem Parameters:fsWorkingFile - path of output filetmpLocalFile - path to local tmp file Throws: IOException close public void close()            throws IOException Description copied from class: FileSystem No more filesystem operations are needed.  Will  release any held locks. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Overrides: close in class FileSystem Throws: IOException toString public String toString() Overrides: toString in class Object getFileStatus public FileStatus getFileStatus(Path f)                          throws IOException Description copied from class: FileSystem Return a file status object that represents the path. Specified by: getFileStatus in class FileSystem Parameters:f - The path we want information from Returns:a FileStatus object Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException setOwner public void setOwner(Path p,             String username,             String groupname)               throws IOException Use the command chown to set owner. Overrides: setOwner in class FileSystem Parameters:p - The pathusername - If it is null, the original username remains unchanged.groupname - If it is null, the original groupname remains unchanged. Throws: IOException setPermission public void setPermission(Path p,                  FsPermission permission)                    throws IOException Use the command chmod to set permission. Overrides: setPermission in class FileSystem Throws: IOException setTimes public void setTimes(Path p,             long mtime,             long atime)               throws IOException Sets the Path's last modified time only to the given  valid time. Overrides: setTimes in class FileSystem Parameters:mtime - the modification time to set (only if greater than zero).atime - currently ignored.p - The path Throws: IOException - if setting the last modified time fails. supportsSymlinks public boolean supportsSymlinks() Description copied from class: FileSystem See AbstractFileSystem.supportsSymlinks() Overrides: supportsSymlinks in class FileSystem createSymlink public void createSymlink(Path target,                  Path link,                  boolean createParent)                    throws IOException Description copied from class: FileSystem See FileContext.createSymlink(Path, Path, boolean) Overrides: createSymlink in class FileSystem Throws: IOException getFileLinkStatus public FileStatus getFileLinkStatus(Path f)                              throws IOException Return a FileStatus representing the given path. If the path refers  to a symlink return a FileStatus representing the link rather than  the object the link refers to. Overrides: getFileLinkStatus in class FileSystem Throws: IOException getLinkTarget public Path getLinkTarget(Path f)                    throws IOException Description copied from class: FileSystem See FileContext.getLinkTarget(Path) Overrides: getLinkTarget in class FileSystem Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Rcc (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Rcc (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler.generated Class Rcc java.lang.Object org.apache.hadoop.record.compiler.generated.Rcc All Implemented Interfaces: RccConstants Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class Rcc extends Object implements RccConstants Field Summary Fields  Modifier and Type Field and Description Token jj_nt Deprecated.    Token token Deprecated.    RccTokenManager token_source Deprecated.    Fields inherited from interface org.apache.hadoop.record.compiler.generated.RccConstants BOOLEAN_TKN, BUFFER_TKN, BYTE_TKN, COMMA_TKN, CSTRING_TKN, DEFAULT, DOT_TKN, DOUBLE_TKN, EOF, FLOAT_TKN, GT_TKN, IDENT_TKN, INCLUDE_TKN, INT_TKN, LBRACE_TKN, LONG_TKN, LT_TKN, MAP_TKN, MODULE_TKN, RBRACE_TKN, RECORD_TKN, SEMICOLON_TKN, tokenImage, USTRING_TKN, VECTOR_TKN, WithinMultiLineComment, WithinOneLineComment Constructor Summary Constructors  Constructor and Description Rcc(InputStream stream) Deprecated.    Rcc(InputStream stream,       String encoding) Deprecated.    Rcc(RccTokenManager tm) Deprecated.    Rcc(Reader stream) Deprecated.    Method Summary Methods  Modifier and Type Method and Description void disable_tracing() Deprecated.    static int driver(String[] args) Deprecated.    void enable_tracing() Deprecated.    JField<JType> Field() Deprecated.    ParseException generateParseException() Deprecated.    Token getNextToken() Deprecated.    Token getToken(int index) Deprecated.    JFile Include() Deprecated.    JFile Input() Deprecated.    static void main(String[] args) Deprecated.    JMap Map() Deprecated.    ArrayList<JRecord> Module() Deprecated.    String ModuleName() Deprecated.    JRecord Record() Deprecated.    ArrayList<JRecord> RecordList() Deprecated.    void ReInit(InputStream stream) Deprecated.    void ReInit(InputStream stream,             String encoding) Deprecated.    void ReInit(RccTokenManager tm) Deprecated.    void ReInit(Reader stream) Deprecated.    JType Type() Deprecated.    static void usage() Deprecated.    JVector Vector() Deprecated.    Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail token_source public RccTokenManager token_source Deprecated.  token public Token token Deprecated.  jj_nt public Token jj_nt Deprecated.  Constructor Detail Rcc public Rcc(InputStream stream) Deprecated.  Rcc public Rcc(InputStream stream,    String encoding) Deprecated.  Rcc public Rcc(Reader stream) Deprecated.  Rcc public Rcc(RccTokenManager tm) Deprecated.  Method Detail main public static void main(String[] args) Deprecated.  usage public static void usage() Deprecated.  driver public static int driver(String[] args) Deprecated.  Input public final JFile Input()                   throws ParseException Deprecated.  Throws: ParseException Include public final JFile Include()                     throws ParseException Deprecated.  Throws: ParseException Module public final ArrayList<JRecord> Module()                                 throws ParseException Deprecated.  Throws: ParseException ModuleName public final String ModuleName()                         throws ParseException Deprecated.  Throws: ParseException RecordList public final ArrayList<JRecord> RecordList()                                     throws ParseException Deprecated.  Throws: ParseException Record public final JRecord Record()                      throws ParseException Deprecated.  Throws: ParseException Field public final JField<JType> Field()                           throws ParseException Deprecated.  Throws: ParseException Type public final JType Type()                  throws ParseException Deprecated.  Throws: ParseException Map public final JMap Map()                throws ParseException Deprecated.  Throws: ParseException Vector public final JVector Vector()                      throws ParseException Deprecated.  Throws: ParseException ReInit public void ReInit(InputStream stream) Deprecated.  ReInit public void ReInit(InputStream stream,           String encoding) Deprecated.  ReInit public void ReInit(Reader stream) Deprecated.  ReInit public void ReInit(RccTokenManager tm) Deprecated.  getNextToken public final Token getNextToken() Deprecated.  getToken public final Token getToken(int index) Deprecated.  generateParseException public ParseException generateParseException() Deprecated.  enable_tracing public final void enable_tracing() Deprecated.  disable_tracing public final void disable_tracing() Deprecated.  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RccConstants (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RccConstants (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler.generated Interface RccConstants All Known Implementing Classes: Rcc, RccTokenManager Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public interface RccConstants Field Summary Fields  Modifier and Type Field and Description static int BOOLEAN_TKN Deprecated.    static int BUFFER_TKN Deprecated.    static int BYTE_TKN Deprecated.    static int COMMA_TKN Deprecated.    static int CSTRING_TKN Deprecated.    static int DEFAULT Deprecated.    static int DOT_TKN Deprecated.    static int DOUBLE_TKN Deprecated.    static int EOF Deprecated.    static int FLOAT_TKN Deprecated.    static int GT_TKN Deprecated.    static int IDENT_TKN Deprecated.    static int INCLUDE_TKN Deprecated.    static int INT_TKN Deprecated.    static int LBRACE_TKN Deprecated.    static int LONG_TKN Deprecated.    static int LT_TKN Deprecated.    static int MAP_TKN Deprecated.    static int MODULE_TKN Deprecated.    static int RBRACE_TKN Deprecated.    static int RECORD_TKN Deprecated.    static int SEMICOLON_TKN Deprecated.    static String[] tokenImage Deprecated.    static int USTRING_TKN Deprecated.    static int VECTOR_TKN Deprecated.    static int WithinMultiLineComment Deprecated.    static int WithinOneLineComment Deprecated.    Field Detail EOF static final int EOF Deprecated.  See Also:Constant Field Values MODULE_TKN static final int MODULE_TKN Deprecated.  See Also:Constant Field Values RECORD_TKN static final int RECORD_TKN Deprecated.  See Also:Constant Field Values INCLUDE_TKN static final int INCLUDE_TKN Deprecated.  See Also:Constant Field Values BYTE_TKN static final int BYTE_TKN Deprecated.  See Also:Constant Field Values BOOLEAN_TKN static final int BOOLEAN_TKN Deprecated.  See Also:Constant Field Values INT_TKN static final int INT_TKN Deprecated.  See Also:Constant Field Values LONG_TKN static final int LONG_TKN Deprecated.  See Also:Constant Field Values FLOAT_TKN static final int FLOAT_TKN Deprecated.  See Also:Constant Field Values DOUBLE_TKN static final int DOUBLE_TKN Deprecated.  See Also:Constant Field Values USTRING_TKN static final int USTRING_TKN Deprecated.  See Also:Constant Field Values BUFFER_TKN static final int BUFFER_TKN Deprecated.  See Also:Constant Field Values VECTOR_TKN static final int VECTOR_TKN Deprecated.  See Also:Constant Field Values MAP_TKN static final int MAP_TKN Deprecated.  See Also:Constant Field Values LBRACE_TKN static final int LBRACE_TKN Deprecated.  See Also:Constant Field Values RBRACE_TKN static final int RBRACE_TKN Deprecated.  See Also:Constant Field Values LT_TKN static final int LT_TKN Deprecated.  See Also:Constant Field Values GT_TKN static final int GT_TKN Deprecated.  See Also:Constant Field Values SEMICOLON_TKN static final int SEMICOLON_TKN Deprecated.  See Also:Constant Field Values COMMA_TKN static final int COMMA_TKN Deprecated.  See Also:Constant Field Values DOT_TKN static final int DOT_TKN Deprecated.  See Also:Constant Field Values CSTRING_TKN static final int CSTRING_TKN Deprecated.  See Also:Constant Field Values IDENT_TKN static final int IDENT_TKN Deprecated.  See Also:Constant Field Values DEFAULT static final int DEFAULT Deprecated.  See Also:Constant Field Values WithinOneLineComment static final int WithinOneLineComment Deprecated.  See Also:Constant Field Values WithinMultiLineComment static final int WithinMultiLineComment Deprecated.  See Also:Constant Field Values tokenImage static final String[] tokenImage Deprecated.  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RccTask (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RccTask (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler.ant Class RccTask java.lang.Object org.apache.tools.ant.ProjectComponent org.apache.tools.ant.Task org.apache.hadoop.record.compiler.ant.RccTask All Implemented Interfaces: Cloneable Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class RccTask extends org.apache.tools.ant.Task Hadoop record compiler ant Task  This task takes the given record definition files and compiles them into  java or c++  files. It is then up to the user to compile the generated files.   The task requires the file or the nested fileset element to be  specified. Optional attributes are language (set the output  language, default is "java"),  destdir (name of the destination directory for generated java/c++  code, default is ".") and failonerror (specifies error handling  behavior. default is true).  Usage    <recordcc        destdir="${basedir}/gensrc"        language="java">    <fileset include="**\/*.jr" />  </recordcc>   Field Summary Fields inherited from class org.apache.tools.ant.Task target, taskName, taskType, wrapper Fields inherited from class org.apache.tools.ant.ProjectComponent description, location, project Constructor Summary Constructors  Constructor and Description RccTask() Deprecated.  Creates a new instance of RccTask Method Summary Methods  Modifier and Type Method and Description void addFileset(org.apache.tools.ant.types.FileSet set) Deprecated.  Adds a fileset that can consist of one or more files void execute() Deprecated.  Invoke the Hadoop record compiler on each record definition file void setDestdir(File dir) Deprecated.  Sets directory where output files will be generated void setFailonerror(boolean flag) Deprecated.  Given multiple files (via fileset), set the error handling behavior void setFile(File file) Deprecated.  Sets the record definition file attribute void setLanguage(String language) Deprecated.  Sets the output language option Methods inherited from class org.apache.tools.ant.Task bindToOwner, getOwningTarget, getRuntimeConfigurableWrapper, getTaskName, getTaskType, getWrapper, handleErrorFlush, handleErrorOutput, handleFlush, handleInput, handleOutput, init, isInvalid, log, log, log, log, maybeConfigure, perform, reconfigure, setOwningTarget, setRuntimeConfigurableWrapper, setTaskName, setTaskType Methods inherited from class org.apache.tools.ant.ProjectComponent clone, getDescription, getLocation, getProject, setDescription, setLocation, setProject Methods inherited from class java.lang.Object equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RccTask public RccTask() Deprecated.  Creates a new instance of RccTask Method Detail setLanguage public void setLanguage(String language) Deprecated.  Sets the output language option Parameters:language - "java"/"c++" setFile public void setFile(File file) Deprecated.  Sets the record definition file attribute Parameters:file - record definition file setFailonerror public void setFailonerror(boolean flag) Deprecated.  Given multiple files (via fileset), set the error handling behavior Parameters:flag - true will throw build exception in case of failure (default) setDestdir public void setDestdir(File dir) Deprecated.  Sets directory where output files will be generated Parameters:dir - output directory addFileset public void addFileset(org.apache.tools.ant.types.FileSet set) Deprecated.  Adds a fileset that can consist of one or more files Parameters:set - Set of record definition files execute public void execute()              throws org.apache.tools.ant.BuildException Deprecated.  Invoke the Hadoop record compiler on each record definition file Overrides: execute in class org.apache.tools.ant.Task Throws: org.apache.tools.ant.BuildException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RccTokenManager (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RccTokenManager (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler.generated Class RccTokenManager java.lang.Object org.apache.hadoop.record.compiler.generated.RccTokenManager All Implemented Interfaces: RccConstants Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class RccTokenManager extends Object implements RccConstants Field Summary Fields  Modifier and Type Field and Description protected char curChar Deprecated.    PrintStream debugStream Deprecated.    protected SimpleCharStream input_stream Deprecated.    static int[] jjnewLexState Deprecated.    static String[] jjstrLiteralImages Deprecated.    static String[] lexStateNames Deprecated.    Fields inherited from interface org.apache.hadoop.record.compiler.generated.RccConstants BOOLEAN_TKN, BUFFER_TKN, BYTE_TKN, COMMA_TKN, CSTRING_TKN, DEFAULT, DOT_TKN, DOUBLE_TKN, EOF, FLOAT_TKN, GT_TKN, IDENT_TKN, INCLUDE_TKN, INT_TKN, LBRACE_TKN, LONG_TKN, LT_TKN, MAP_TKN, MODULE_TKN, RBRACE_TKN, RECORD_TKN, SEMICOLON_TKN, tokenImage, USTRING_TKN, VECTOR_TKN, WithinMultiLineComment, WithinOneLineComment Constructor Summary Constructors  Constructor and Description RccTokenManager(SimpleCharStream stream) Deprecated.    RccTokenManager(SimpleCharStream stream,                               int lexState) Deprecated.    Method Summary Methods  Modifier and Type Method and Description Token getNextToken() Deprecated.    protected Token jjFillToken() Deprecated.    void ReInit(SimpleCharStream stream) Deprecated.    void ReInit(SimpleCharStream stream,             int lexState) Deprecated.    void setDebugStream(PrintStream ds) Deprecated.    void SwitchTo(int lexState) Deprecated.    Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail debugStream public PrintStream debugStream Deprecated.  jjstrLiteralImages public static final String[] jjstrLiteralImages Deprecated.  lexStateNames public static final String[] lexStateNames Deprecated.  jjnewLexState public static final int[] jjnewLexState Deprecated.  input_stream protected SimpleCharStream input_stream Deprecated.  curChar protected char curChar Deprecated.  Constructor Detail RccTokenManager public RccTokenManager(SimpleCharStream stream) Deprecated.  RccTokenManager public RccTokenManager(SimpleCharStream stream,                int lexState) Deprecated.  Method Detail setDebugStream public void setDebugStream(PrintStream ds) Deprecated.  ReInit public void ReInit(SimpleCharStream stream) Deprecated.  ReInit public void ReInit(SimpleCharStream stream,           int lexState) Deprecated.  SwitchTo public void SwitchTo(int lexState) Deprecated.  jjFillToken protected Token jjFillToken() Deprecated.  getNextToken public Token getNextToken() Deprecated.  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReadOption (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReadOption (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.fs Enum ReadOption java.lang.Object java.lang.Enum<ReadOption> org.apache.hadoop.fs.ReadOption All Implemented Interfaces: Serializable, Comparable<ReadOption> @InterfaceAudience.Public @InterfaceStability.Stable public enum ReadOption extends Enum<ReadOption> Options that can be used when reading from a FileSystem. Enum Constant Summary Enum Constants  Enum Constant and Description SKIP_CHECKSUMS Skip checksums when reading. Method Summary Methods  Modifier and Type Method and Description static ReadOption valueOf(String name) Returns the enum constant of this type with the specified name. static ReadOption[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail SKIP_CHECKSUMS public static final ReadOption SKIP_CHECKSUMS Skip checksums when reading.  This option may be useful when reading a file  format that has built-in checksums, or for testing purposes. Method Detail values public static ReadOption[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (ReadOption c : ReadOption.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static ReadOption valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReconfigurationTaskStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReconfigurationTaskStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.conf Class ReconfigurationTaskStatus java.lang.Object org.apache.hadoop.conf.ReconfigurationTaskStatus @InterfaceAudience.Public @InterfaceStability.Stable public class ReconfigurationTaskStatus extends Object Constructor Summary Constructors  Constructor and Description ReconfigurationTaskStatus(long startTime,                                                   long endTime,                                                   Map<org.apache.hadoop.conf.ReconfigurationUtil.PropertyChange,com.google.common.base.Optional<String>> status)  Method Summary Methods  Modifier and Type Method and Description long getEndTime()  long getStartTime()  Map<org.apache.hadoop.conf.ReconfigurationUtil.PropertyChange,com.google.common.base.Optional<String>> getStatus()  boolean hasTask() Return true if    - A reconfiguration task has finished or    - an active reconfiguration task is running boolean stopped() Return true if the latest reconfiguration task has finished and there is  no another active task running. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReconfigurationTaskStatus public ReconfigurationTaskStatus(long startTime,                          long endTime,                          Map<org.apache.hadoop.conf.ReconfigurationUtil.PropertyChange,com.google.common.base.Optional<String>> status) Method Detail hasTask public boolean hasTask() Return true if    - A reconfiguration task has finished or    - an active reconfiguration task is running stopped public boolean stopped() Return true if the latest reconfiguration task has finished and there is  no another active task running. getStartTime public long getStartTime() getEndTime public long getEndTime() getStatus public final Map<org.apache.hadoop.conf.ReconfigurationUtil.PropertyChange,com.google.common.base.Optional<String>> getStatus() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Record (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Record (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class Record java.lang.Object org.apache.hadoop.record.Record All Implemented Interfaces: Cloneable, Comparable, Writable, WritableComparable Direct Known Subclasses: RecordTypeInfo Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public abstract class Record extends Object implements WritableComparable, Cloneable Abstract class that is extended by generated classes. Constructor Summary Constructors  Constructor and Description Record() Deprecated.    Method Summary Methods  Modifier and Type Method and Description abstract int compareTo(Object peer) Deprecated.    void deserialize(RecordInput rin) Deprecated.  Deserialize a record without a tag abstract void deserialize(RecordInput rin,                       String tag) Deprecated.  Deserialize a record with a tag (usually field name) void readFields(DataInput din) Deprecated.  Deserialize the fields of this object from in. void serialize(RecordOutput rout) Deprecated.  Serialize a record without a tag abstract void serialize(RecordOutput rout,                   String tag) Deprecated.  Serialize a record with tag (ususally field name) String toString() Deprecated.    void write(DataOutput out) Deprecated.  Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail Record public Record() Deprecated.  Method Detail serialize public abstract void serialize(RecordOutput rout,              String tag)                         throws IOException Deprecated.  Serialize a record with tag (ususally field name) Parameters:rout - Record output destinationtag - record tag (Used only in tagged serialization e.g. XML) Throws: IOException deserialize public abstract void deserialize(RecordInput rin,                String tag)                           throws IOException Deprecated.  Deserialize a record with a tag (usually field name) Parameters:rin - Record input sourcetag - Record tag (Used only in tagged serialization e.g. XML) Throws: IOException compareTo public abstract int compareTo(Object peer)                        throws ClassCastException Deprecated.  Specified by: compareTo in interface Comparable Throws: ClassCastException serialize public void serialize(RecordOutput rout)                throws IOException Deprecated.  Serialize a record without a tag Parameters:rout - Record output destination Throws: IOException deserialize public void deserialize(RecordInput rin)                  throws IOException Deprecated.  Deserialize a record without a tag Parameters:rin - Record input source Throws: IOException write public void write(DataOutput out)            throws IOException Deprecated.  Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput din)                 throws IOException Deprecated.  Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:din - DataInput to deseriablize this object from. Throws: IOException toString public String toString() Deprecated.  Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RecordComparator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RecordComparator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class RecordComparator java.lang.Object org.apache.hadoop.io.WritableComparator org.apache.hadoop.record.RecordComparator All Implemented Interfaces: Comparator, Configurable, RawComparator Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public abstract class RecordComparator extends WritableComparator A raw record comparator base class Constructor Summary Constructors  Modifier Constructor and Description protected  RecordComparator(Class<? extends WritableComparable> recordClass) Deprecated.  Construct a raw Record comparison implementation. Method Summary Methods  Modifier and Type Method and Description abstract int compare(byte[] b1,               int s1,               int l1,               byte[] b2,               int s2,               int l2) Deprecated.  Optimization hook. static void define(Class c,             RecordComparator comparator) Deprecated.  Register an optimized comparator for a Record implementation. Methods inherited from class org.apache.hadoop.io.WritableComparator compare, compare, compareBytes, define, get, get, getConf, getKeyClass, hashBytes, hashBytes, newKey, readDouble, readFloat, readInt, readLong, readUnsignedShort, readVInt, readVLong, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface java.util.Comparator equals Constructor Detail RecordComparator protected RecordComparator(Class<? extends WritableComparable> recordClass) Deprecated.  Construct a raw Record comparison implementation. Method Detail compare public abstract int compare(byte[] b1,           int s1,           int l1,           byte[] b2,           int s2,           int l2) Deprecated.  Description copied from class: WritableComparator Optimization hook.  Override this to make SequenceFile.Sorter's scream.  The default implementation reads the data into two WritableComparables (using Writable.readFields(DataInput), then calls WritableComparator.compare(WritableComparable,WritableComparable). Specified by: compare in interface RawComparator Overrides: compare in class WritableComparator Parameters:b1 - The first byte array.s1 - The position index in b1. The object under comparison's starting index.l1 - The length of the object in b1.b2 - The second byte array.s2 - The position index in b2. The object under comparison's starting index.l2 - The length of the object under comparison in b2. Returns:An integer result of the comparison. define public static void define(Class c,           RecordComparator comparator) Deprecated.  Register an optimized comparator for a Record implementation. Parameters:c - record classs for which a raw comparator is providedcomparator - Raw comparator instance for class c Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RecordInput (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RecordInput (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Interface RecordInput All Known Implementing Classes: BinaryRecordInput, CsvRecordInput, XmlRecordInput Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public interface RecordInput Interface that all the Deserializers have to implement. Method Summary Methods  Modifier and Type Method and Description void endMap(String tag) Deprecated.  Check the mark for end of the serialized map. void endRecord(String tag) Deprecated.  Check the mark for end of the serialized record. void endVector(String tag) Deprecated.  Check the mark for end of the serialized vector. boolean readBool(String tag) Deprecated.  Read a boolean from serialized record. Buffer readBuffer(String tag) Deprecated.  Read byte array from serialized record. byte readByte(String tag) Deprecated.  Read a byte from serialized record. double readDouble(String tag) Deprecated.  Read a double-precision number from serialized record. float readFloat(String tag) Deprecated.  Read a single-precision float from serialized record. int readInt(String tag) Deprecated.  Read an integer from serialized record. long readLong(String tag) Deprecated.  Read a long integer from serialized record. String readString(String tag) Deprecated.  Read a UTF-8 encoded string from serialized record. Index startMap(String tag) Deprecated.  Check the mark for start of the serialized map. void startRecord(String tag) Deprecated.  Check the mark for start of the serialized record. Index startVector(String tag) Deprecated.  Check the mark for start of the serialized vector. Method Detail readByte byte readByte(String tag)               throws IOException Deprecated.  Read a byte from serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readBool boolean readBool(String tag)                  throws IOException Deprecated.  Read a boolean from serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readInt int readInt(String tag)             throws IOException Deprecated.  Read an integer from serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readLong long readLong(String tag)               throws IOException Deprecated.  Read a long integer from serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readFloat float readFloat(String tag)                 throws IOException Deprecated.  Read a single-precision float from serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readDouble double readDouble(String tag)                   throws IOException Deprecated.  Read a double-precision number from serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readString String readString(String tag)                   throws IOException Deprecated.  Read a UTF-8 encoded string from serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readBuffer Buffer readBuffer(String tag)                   throws IOException Deprecated.  Read byte array from serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException startRecord void startRecord(String tag)                  throws IOException Deprecated.  Check the mark for start of the serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException endRecord void endRecord(String tag)                throws IOException Deprecated.  Check the mark for end of the serialized record. Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException startVector Index startVector(String tag)                   throws IOException Deprecated.  Check the mark for start of the serialized vector. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:Index that is used to count the number of elements. Throws: IOException endVector void endVector(String tag)                throws IOException Deprecated.  Check the mark for end of the serialized vector. Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException startMap Index startMap(String tag)                throws IOException Deprecated.  Check the mark for start of the serialized map. Parameters:tag - Used by tagged serialization formats (such as XML) Returns:Index that is used to count the number of map entries. Throws: IOException endMap void endMap(String tag)             throws IOException Deprecated.  Check the mark for end of the serialized map. Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RecordOutput (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RecordOutput (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Interface RecordOutput All Known Implementing Classes: BinaryRecordOutput, CsvRecordOutput, XmlRecordOutput Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public interface RecordOutput Interface that all the serializers have to implement. Method Summary Methods  Modifier and Type Method and Description void endMap(TreeMap m,             String tag) Deprecated.  Mark the end of a serialized map. void endRecord(Record r,                   String tag) Deprecated.  Mark the end of a serialized record. void endVector(ArrayList v,                   String tag) Deprecated.  Mark the end of a serialized vector. void startMap(TreeMap m,                 String tag) Deprecated.  Mark the start of a map to be serialized. void startRecord(Record r,                       String tag) Deprecated.  Mark the start of a record to be serialized. void startVector(ArrayList v,                       String tag) Deprecated.  Mark the start of a vector to be serialized. void writeBool(boolean b,                   String tag) Deprecated.  Write a boolean to serialized record. void writeBuffer(Buffer buf,                       String tag) Deprecated.  Write a buffer to serialized record. void writeByte(byte b,                   String tag) Deprecated.  Write a byte to serialized record. void writeDouble(double d,                       String tag) Deprecated.  Write a double precision floating point number to serialized record. void writeFloat(float f,                     String tag) Deprecated.  Write a single-precision float to serialized record. void writeInt(int i,                 String tag) Deprecated.  Write an integer to serialized record. void writeLong(long l,                   String tag) Deprecated.  Write a long integer to serialized record. void writeString(String s,                       String tag) Deprecated.  Write a unicode string to serialized record. Method Detail writeByte void writeByte(byte b,              String tag)                throws IOException Deprecated.  Write a byte to serialized record. Parameters:b - Byte to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeBool void writeBool(boolean b,              String tag)                throws IOException Deprecated.  Write a boolean to serialized record. Parameters:b - Boolean to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeInt void writeInt(int i,             String tag)               throws IOException Deprecated.  Write an integer to serialized record. Parameters:i - Integer to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeLong void writeLong(long l,              String tag)                throws IOException Deprecated.  Write a long integer to serialized record. Parameters:l - Long to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeFloat void writeFloat(float f,               String tag)                 throws IOException Deprecated.  Write a single-precision float to serialized record. Parameters:f - Float to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeDouble void writeDouble(double d,                String tag)                  throws IOException Deprecated.  Write a double precision floating point number to serialized record. Parameters:d - Double to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeString void writeString(String s,                String tag)                  throws IOException Deprecated.  Write a unicode string to serialized record. Parameters:s - String to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeBuffer void writeBuffer(Buffer buf,                String tag)                  throws IOException Deprecated.  Write a buffer to serialized record. Parameters:buf - Buffer to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startRecord void startRecord(Record r,                String tag)                  throws IOException Deprecated.  Mark the start of a record to be serialized. Parameters:r - Record to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endRecord void endRecord(Record r,              String tag)                throws IOException Deprecated.  Mark the end of a serialized record. Parameters:r - Record to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startVector void startVector(ArrayList v,                String tag)                  throws IOException Deprecated.  Mark the start of a vector to be serialized. Parameters:v - Vector to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endVector void endVector(ArrayList v,              String tag)                throws IOException Deprecated.  Mark the end of a serialized vector. Parameters:v - Vector to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startMap void startMap(TreeMap m,             String tag)               throws IOException Deprecated.  Mark the start of a map to be serialized. Parameters:m - Map to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endMap void endMap(TreeMap m,           String tag)             throws IOException Deprecated.  Mark the end of a serialized map. Parameters:m - Map to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class RecordReader<KEYIN,VALUEIN> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<KEYIN,VALUEIN> Type Parameters:KEYIN - VALUEIN -  All Implemented Interfaces: Closeable, AutoCloseable Direct Known Subclasses: CombineFileRecordReader, CombineFileRecordReaderWrapper, ComposableRecordReader, DBRecordReader, KeyValueLineRecordReader, SequenceFileAsTextRecordReader, SequenceFileRecordReader @InterfaceAudience.Public @InterfaceStability.Stable public abstract class RecordReader<KEYIN,VALUEIN> extends Object implements Closeable The record reader breaks the data into key/value pairs for input to the  Mapper. Constructor Summary Constructors  Constructor and Description RecordReader()  Method Summary Methods  Modifier and Type Method and Description abstract void close() Close the record reader. abstract KEYIN getCurrentKey() Get the current key abstract VALUEIN getCurrentValue() Get the current value. abstract float getProgress() The current progress of the record reader through its data. abstract void initialize(InputSplit split,                     TaskAttemptContext context) Called once at initialization. abstract boolean nextKeyValue() Read the next key, value pair. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RecordReader public RecordReader() Method Detail initialize public abstract void initialize(InputSplit split,               TaskAttemptContext context)                          throws IOException,                                 InterruptedException Called once at initialization. Parameters:split - the split that defines the range of records to readcontext - the information about the task Throws: IOException InterruptedException nextKeyValue public abstract boolean nextKeyValue()                               throws IOException,                                      InterruptedException Read the next key, value pair. Returns:true if a key/value pair was read Throws: IOException InterruptedException getCurrentKey public abstract KEYIN getCurrentKey()                              throws IOException,                                     InterruptedException Get the current key Returns:the current key or null if there is no current key Throws: IOException InterruptedException getCurrentValue public abstract VALUEIN getCurrentValue()                                  throws IOException,                                         InterruptedException Get the current value. Returns:the object that was read Throws: IOException InterruptedException getProgress public abstract float getProgress()                            throws IOException,                                   InterruptedException The current progress of the record reader through its data. Returns:a number between 0.0 and 1.0 that is the fraction of the data read Throws: IOException InterruptedException close public abstract void close()                     throws IOException Close the record reader. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RecordTypeInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RecordTypeInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.meta Class RecordTypeInfo java.lang.Object org.apache.hadoop.record.Record org.apache.hadoop.record.meta.RecordTypeInfo All Implemented Interfaces: Cloneable, Comparable, Writable, WritableComparable Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class RecordTypeInfo extends Record A record's Type Information object which can read/write itself.     Type information for a record comprises metadata about the record,   as well as a collection of type information for each field in the record. Constructor Summary Constructors  Constructor and Description RecordTypeInfo() Deprecated.  Create an empty RecordTypeInfo object. RecordTypeInfo(String name) Deprecated.  Create a RecordTypeInfo object representing a record with the given name Method Summary Methods  Modifier and Type Method and Description void addField(String fieldName,                 TypeID tid) Deprecated.  Add a field. int compareTo(Object peer_) Deprecated.  This class doesn't implement Comparable as it's not meant to be used   for anything besides de/serializing. void deserialize(RecordInput rin,                       String tag) Deprecated.  Deserialize the type information for a record Collection<FieldTypeInfo> getFieldTypeInfos() Deprecated.  Return a collection of field type infos String getName() Deprecated.  return the name of the record RecordTypeInfo getNestedStructTypeInfo(String name) Deprecated.  Return the type info of a nested record. void serialize(RecordOutput rout,                   String tag) Deprecated.  Serialize the type information for a record void setName(String name) Deprecated.  set the name of the record Methods inherited from class org.apache.hadoop.record.Record deserialize, readFields, serialize, toString, write Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail RecordTypeInfo public RecordTypeInfo() Deprecated.  Create an empty RecordTypeInfo object. RecordTypeInfo public RecordTypeInfo(String name) Deprecated.  Create a RecordTypeInfo object representing a record with the given name Parameters:name - Name of the record Method Detail getName public String getName() Deprecated.  return the name of the record setName public void setName(String name) Deprecated.  set the name of the record addField public void addField(String fieldName,             TypeID tid) Deprecated.  Add a field. Parameters:fieldName - Name of the fieldtid - Type ID of the field getFieldTypeInfos public Collection<FieldTypeInfo> getFieldTypeInfos() Deprecated.  Return a collection of field type infos getNestedStructTypeInfo public RecordTypeInfo getNestedStructTypeInfo(String name) Deprecated.  Return the type info of a nested record. We only consider nesting   to one level. Parameters:name - Name of the nested record serialize public void serialize(RecordOutput rout,              String tag)                throws IOException Deprecated.  Serialize the type information for a record Specified by: serialize in class Record Parameters:rout - Record output destinationtag - record tag (Used only in tagged serialization e.g. XML) Throws: IOException deserialize public void deserialize(RecordInput rin,                String tag)                  throws IOException Deprecated.  Deserialize the type information for a record Specified by: deserialize in class Record Parameters:rin - Record input sourcetag - Record tag (Used only in tagged serialization e.g. XML) Throws: IOException compareTo public int compareTo(Object peer_)               throws ClassCastException Deprecated.  This class doesn't implement Comparable as it's not meant to be used   for anything besides de/serializing.  So we always throw an exception.  Not implemented. Always returns 0 if another RecordTypeInfo is passed in. Specified by: compareTo in interface Comparable Specified by: compareTo in class Record Throws: ClassCastException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RecordWriter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RecordWriter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class RecordWriter<K,V> java.lang.Object org.apache.hadoop.mapreduce.RecordWriter<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class RecordWriter<K,V> extends Object RecordWriter writes the output <key, value> pairs   to an output file.  RecordWriter implementations write the job outputs to the  FileSystem. See Also:OutputFormat Constructor Summary Constructors  Constructor and Description RecordWriter()  Method Summary Methods  Modifier and Type Method and Description abstract void close(TaskAttemptContext context) Close this RecordWriter to future operations. abstract void write(K key,           V value) Writes a key/value pair. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RecordWriter public RecordWriter() Method Detail write public abstract void write(K key,          V value)                     throws IOException,                            InterruptedException Writes a key/value pair. Parameters:key - the key to write.value - the value to write. Throws: IOException InterruptedException close public abstract void close(TaskAttemptContext context)                     throws IOException,                            InterruptedException Close this RecordWriter to future operations. Parameters:context - the context of the task Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReduceContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReduceContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Interface ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> Type Parameters:KEYIN - the class of the input keysVALUEIN - the class of the input valuesKEYOUT - the class of the output keysVALUEOUT - the class of the output values All Superinterfaces: JobContext, org.apache.hadoop.mapreduce.MRJobConfig, Progressable, TaskAttemptContext, TaskInputOutputContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Evolving public interface ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends TaskInputOutputContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> The context passed to the Reducer. Field Summary Fields inherited from interface org.apache.hadoop.mapreduce.MRJobConfig APPLICATION_ATTEMPT_ID, APPLICATION_MASTER_CLASS, CACHE_ARCHIVES, CACHE_ARCHIVES_SIZES, CACHE_ARCHIVES_TIMESTAMPS, CACHE_ARCHIVES_VISIBILITIES, CACHE_FILE_TIMESTAMPS, CACHE_FILE_VISIBILITIES, CACHE_FILES, CACHE_FILES_SIZES, CACHE_LOCALARCHIVES, CACHE_LOCALFILES, CACHE_SYMLINK, CLASSPATH_ARCHIVES, CLASSPATH_FILES, COMBINE_CLASS_ATTR, COMBINE_RECORDS_BEFORE_PROGRESS, COMBINER_GROUP_COMPARATOR_CLASS, COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, COUNTER_GROUP_NAME_MAX_DEFAULT, COUNTER_GROUP_NAME_MAX_KEY, COUNTER_GROUPS_MAX_DEFAULT, COUNTER_GROUPS_MAX_KEY, COUNTER_NAME_MAX_DEFAULT, COUNTER_NAME_MAX_KEY, COUNTERS_MAX_DEFAULT, COUNTERS_MAX_KEY, DEFAULT_JOB_ACL_MODIFY_JOB, DEFAULT_JOB_ACL_VIEW_JOB, DEFAULT_JOB_AM_ACCESS_DISABLED, DEFAULT_JOB_RUNNING_MAP_LIMIT, DEFAULT_JOB_RUNNING_REDUCE_LIMIT, DEFAULT_JOB_TOKEN_TRACKING_IDS_ENABLED, DEFAULT_LOG_LEVEL, DEFAULT_MAP_CPU_VCORES, DEFAULT_MAP_MEMORY_MB, DEFAULT_MAPRED_ADMIN_JAVA_OPTS, DEFAULT_MAPRED_ADMIN_USER_ENV, DEFAULT_MAPREDUCE_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_CROSS_PLATFORM_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA, DEFAULT_MAX_ALLOWED_FETCH_FAILURES_FRACTION, DEFAULT_MAX_FETCH_FAILURES_NOTIFICATIONS, DEFAULT_MAX_SHUFFLE_FETCH_HOST_FAILURES, DEFAULT_MAX_SHUFFLE_FETCH_RETRY_DELAY, DEFAULT_MR_AM_ADMIN_COMMAND_OPTS, DEFAULT_MR_AM_COMMAND_OPTS, DEFAULT_MR_AM_COMMIT_WINDOW_MS, DEFAULT_MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, DEFAULT_MR_AM_CPU_VCORES, DEFAULT_MR_AM_HARD_KILL_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, DEFAULT_MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERCENT, DEFAULT_MR_AM_JOB_CLIENT_THREAD_COUNT, DEFAULT_MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, DEFAULT_MR_AM_JOB_REDUCE_RAMP_UP_LIMIT, DEFAULT_MR_AM_LOG_BACKUPS, DEFAULT_MR_AM_LOG_KB, DEFAULT_MR_AM_LOG_LEVEL, DEFAULT_MR_AM_MAX_ATTEMPTS, DEFAULT_MR_AM_NUM_PROGRESS_SPLITS, DEFAULT_MR_AM_PROFILE, DEFAULT_MR_AM_STAGING_DIR, DEFAULT_MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, DEFAULT_MR_AM_TASK_LISTENER_THREAD_COUNT, DEFAULT_MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, DEFAULT_MR_AM_TO_RM_WAIT_INTERVAL_MS, DEFAULT_MR_AM_VMEM_MB, DEFAULT_MR_CLIENT_JOB_MAX_RETRIES, DEFAULT_MR_CLIENT_JOB_RETRY_INTERVAL, DEFAULT_MR_CLIENT_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, DEFAULT_MR_JOB_END_NOTIFICATION_TIMEOUT, DEFAULT_MR_JOB_REDUCER_PREEMPT_DELAY_SEC, DEFAULT_REDUCE_CPU_VCORES, DEFAULT_REDUCE_MEMORY_MB, DEFAULT_REDUCE_SEPARATE_SHUFFLE_LOG, DEFAULT_SHELL, DEFAULT_SHUFFLE_FETCH_RETRY_INTERVAL_MS, DEFAULT_SHUFFLE_INPUT_BUFFER_PERCENT, DEFAULT_SHUFFLE_LOG_BACKUPS, DEFAULT_SHUFFLE_LOG_KB, DEFAULT_SPECULATIVE_MINIMUM_ALLOWED_TASKS, DEFAULT_SPECULATIVE_RETRY_AFTER_NO_SPECULATE, DEFAULT_SPECULATIVE_RETRY_AFTER_SPECULATE, DEFAULT_SPECULATIVECAP_RUNNING_TASKS, DEFAULT_SPECULATIVECAP_TOTAL_TASKS, DEFAULT_SPLIT_METAINFO_MAXSIZE, DEFAULT_TASK_ISMAP, DEFAULT_TASK_LOG_BACKUPS, DEFAULT_TASK_PROFILE_PARAMS, GROUP_COMPARATOR_CLASS, HADOOP_WORK_DIR, ID, INDEX_CACHE_MEMORY_LIMIT, INPUT_FORMAT_CLASS_ATTR, IO_SORT_FACTOR, IO_SORT_MB, JAR, JAR_UNPACK_PATTERN, JOB_ACL_MODIFY_JOB, JOB_ACL_VIEW_JOB, JOB_AM_ACCESS_DISABLED, JOB_CANCEL_DELEGATION_TOKEN, JOB_CONF_FILE, JOB_JAR, JOB_JOBTRACKER_ID, JOB_LOCAL_DIR, JOB_NAME, JOB_NAMENODES, JOB_RUNNING_MAP_LIMIT, JOB_RUNNING_REDUCE_LIMIT, JOB_SPLIT, JOB_SPLIT_METAINFO, JOB_SUBMIT_DIR, JOB_SUBMITHOST, JOB_SUBMITHOSTADDR, JOB_TAGS, JOB_TOKEN_TRACKING_IDS, JOB_TOKEN_TRACKING_IDS_ENABLED, JOB_UBERTASK_ENABLE, JOB_UBERTASK_MAXBYTES, JOB_UBERTASK_MAXMAPS, JOB_UBERTASK_MAXREDUCES, JVM_NUMTASKS_TORUN, KEY_COMPARATOR, MAP_CLASS_ATTR, MAP_COMBINE_MIN_SPILLS, MAP_CPU_VCORES, MAP_DEBUG_SCRIPT, MAP_ENV, MAP_FAILURES_MAX_PERCENT, MAP_INPUT_FILE, MAP_INPUT_PATH, MAP_INPUT_START, MAP_JAVA_OPTS, MAP_LOG_LEVEL, MAP_MAX_ATTEMPTS, MAP_MEMORY_MB, MAP_OUTPUT_COLLECTOR_CLASS_ATTR, MAP_OUTPUT_COMPRESS, MAP_OUTPUT_COMPRESS_CODEC, MAP_OUTPUT_KEY_CLASS, MAP_OUTPUT_KEY_FIELD_SEPERATOR, MAP_OUTPUT_VALUE_CLASS, MAP_SKIP_INCR_PROC_COUNT, MAP_SKIP_MAX_RECORDS, MAP_SORT_SPILL_PERCENT, MAP_SPECULATIVE, MAPRED_ADMIN_USER_ENV, MAPRED_ADMIN_USER_SHELL, MAPRED_MAP_ADMIN_JAVA_OPTS, MAPRED_REDUCE_ADMIN_JAVA_OPTS, MAPREDUCE_APPLICATION_CLASSPATH, MAPREDUCE_APPLICATION_FRAMEWORK_PATH, MAPREDUCE_JOB_CLASSLOADER, MAPREDUCE_JOB_CLASSLOADER_SYSTEM_CLASSES, MAPREDUCE_JOB_CREDENTIALS_BINARY, MAPREDUCE_JOB_DIR, MAPREDUCE_JOB_EMIT_TIMELINE_DATA, MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE, MAPREDUCE_JOB_SHUFFLE_PROVIDER_SERVICES, MAPREDUCE_JOB_USER_CLASSPATH_FIRST, MAPREDUCE_V2_CHILD_CLASS, MAX_ALLOWED_FETCH_FAILURES_FRACTION, MAX_FETCH_FAILURES_NOTIFICATIONS, MAX_SHUFFLE_FETCH_HOST_FAILURES, MAX_SHUFFLE_FETCH_RETRY_DELAY, MAX_TASK_FAILURES_PER_TRACKER, MR_AM_ADMIN_COMMAND_OPTS, MR_AM_ADMIN_USER_ENV, MR_AM_COMMAND_OPTS, MR_AM_COMMIT_WINDOW_MS, MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, MR_AM_CPU_VCORES, MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR, MR_AM_ENV, MR_AM_HARD_KILL_TIMEOUT_MS, MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERECENT, MR_AM_JOB_CLIENT_PORT_RANGE, MR_AM_JOB_CLIENT_THREAD_COUNT, MR_AM_JOB_NODE_BLACKLISTING_ENABLE, MR_AM_JOB_RECOVERY_ENABLE, MR_AM_JOB_RECOVERY_ENABLE_DEFAULT, MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, MR_AM_JOB_REDUCE_RAMPUP_UP_LIMIT, MR_AM_JOB_SPECULATOR, MR_AM_LOG_BACKUPS, MR_AM_LOG_KB, MR_AM_LOG_LEVEL, MR_AM_MAX_ATTEMPTS, MR_AM_NUM_PROGRESS_SPLITS, MR_AM_PREFIX, MR_AM_PROFILE, MR_AM_PROFILE_PARAMS, MR_AM_SECURITY_SERVICE_AUTHORIZATION_CLIENT, MR_AM_SECURITY_SERVICE_AUTHORIZATION_TASK_UMBILICAL, MR_AM_STAGING_DIR, MR_AM_TASK_ESTIMATOR, MR_AM_TASK_ESTIMATOR_EXPONENTIAL_RATE_ENABLE, MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, MR_AM_TASK_LISTENER_THREAD_COUNT, MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, MR_AM_TO_RM_WAIT_INTERVAL_MS, MR_AM_VMEM_MB, MR_APPLICATION_TYPE, MR_CLIENT_JOB_MAX_RETRIES, MR_CLIENT_JOB_RETRY_INTERVAL, MR_CLIENT_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, MR_ENCRYPTED_INTERMEDIATE_DATA, MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, MR_JOB_END_NOTIFICATION_MAX_ATTEMPTS, MR_JOB_END_NOTIFICATION_MAX_RETRY_INTERVAL, MR_JOB_END_NOTIFICATION_PROXY, MR_JOB_END_NOTIFICATION_TIMEOUT, MR_JOB_END_NOTIFICATION_URL, MR_JOB_END_RETRY_ATTEMPTS, MR_JOB_END_RETRY_INTERVAL, MR_JOB_REDUCER_PREEMPT_DELAY_SEC, MR_PREFIX, NUM_MAP_PROFILES, NUM_MAPS, NUM_REDUCE_PROFILES, NUM_REDUCES, OUTPUT, OUTPUT_FORMAT_CLASS_ATTR, OUTPUT_KEY_CLASS, OUTPUT_VALUE_CLASS, PARTITIONER_CLASS_ATTR, PRESERVE_FAILED_TASK_FILES, PRESERVE_FILES_PATTERN, PRIORITY, QUEUE_NAME, RECORDS_BEFORE_PROGRESS, REDUCE_CLASS_ATTR, REDUCE_CPU_VCORES, REDUCE_DEBUG_SCRIPT, REDUCE_ENV, REDUCE_FAILURES_MAXPERCENT, REDUCE_INPUT_BUFFER_PERCENT, REDUCE_JAVA_OPTS, REDUCE_LOG_LEVEL, REDUCE_MARKRESET_BUFFER_PERCENT, REDUCE_MARKRESET_BUFFER_SIZE, REDUCE_MAX_ATTEMPTS, REDUCE_MEMORY_MB, REDUCE_MEMORY_TOTAL_BYTES, REDUCE_MEMTOMEM_ENABLED, REDUCE_MEMTOMEM_THRESHOLD, REDUCE_MERGE_INMEM_THRESHOLD, REDUCE_SEPARATE_SHUFFLE_LOG, REDUCE_SKIP_INCR_PROC_COUNT, REDUCE_SKIP_MAXGROUPS, REDUCE_SPECULATIVE, RESERVATION_ID, SETUP_CLEANUP_NEEDED, SHUFFLE_CONNECT_TIMEOUT, SHUFFLE_FETCH_FAILURES, SHUFFLE_FETCH_RETRY_ENABLED, SHUFFLE_FETCH_RETRY_INTERVAL_MS, SHUFFLE_FETCH_RETRY_TIMEOUT_MS, SHUFFLE_INPUT_BUFFER_PERCENT, SHUFFLE_LOG_BACKUPS, SHUFFLE_LOG_KB, SHUFFLE_MEMORY_LIMIT_PERCENT, SHUFFLE_MERGE_PERCENT, SHUFFLE_NOTIFY_READERROR, SHUFFLE_PARALLEL_COPIES, SHUFFLE_READ_TIMEOUT, SKIP_OUTDIR, SKIP_RECORDS, SKIP_START_ATTEMPTS, SPECULATIVE_MINIMUM_ALLOWED_TASKS, SPECULATIVE_RETRY_AFTER_NO_SPECULATE, SPECULATIVE_RETRY_AFTER_SPECULATE, SPECULATIVE_SLOWNODE_THRESHOLD, SPECULATIVE_SLOWTASK_THRESHOLD, SPECULATIVECAP, SPECULATIVECAP_RUNNING_TASKS, SPECULATIVECAP_TOTAL_TASKS, SPLIT_FILE, SPLIT_METAINFO_MAXSIZE, STDERR_LOGFILE_ENV, STDOUT_LOGFILE_ENV, TASK_ATTEMPT_ID, TASK_CLEANUP_NEEDED, TASK_DEBUGOUT_LINES, TASK_ID, TASK_ISMAP, TASK_LOG_BACKUPS, TASK_MAP_PROFILE_PARAMS, TASK_OUTPUT_DIR, TASK_PARTITION, TASK_PROFILE, TASK_PROFILE_PARAMS, TASK_REDUCE_PROFILE_PARAMS, TASK_TIMEOUT, TASK_TIMEOUT_CHECK_INTERVAL_MS, TASK_USERLOG_LIMIT, USER_LOG_RETAIN_HOURS, USER_NAME, WORKDIR, WORKFLOW_ADJACENCY_PREFIX_PATTERN, WORKFLOW_ADJACENCY_PREFIX_STRING, WORKFLOW_ID, WORKFLOW_NAME, WORKFLOW_NODE_NAME, WORKFLOW_TAGS, WORKING_DIR Method Summary Methods  Modifier and Type Method and Description Iterable<VALUEIN> getValues() Iterate through the values for the current key, reusing the same value   object, which is stored in the context. boolean nextKey() Start processing next unique key. Methods inherited from interface org.apache.hadoop.mapreduce.TaskInputOutputContext getCurrentKey, getCurrentValue, getOutputCommitter, nextKeyValue, write Methods inherited from interface org.apache.hadoop.mapreduce.TaskAttemptContext getCounter, getCounter, getProgress, getStatus, getTaskAttemptID, setStatus Methods inherited from interface org.apache.hadoop.mapreduce.JobContext getArchiveClassPaths, getArchiveTimestamps, getCacheArchives, getCacheFiles, getCombinerClass, getCombinerKeyGroupingComparator, getConfiguration, getCredentials, getFileClassPaths, getFileTimestamps, getGroupingComparator, getInputFormatClass, getJar, getJobID, getJobName, getJobSetupCleanupNeeded, getLocalCacheArchives, getLocalCacheFiles, getMapOutputKeyClass, getMapOutputValueClass, getMapperClass, getMaxMapAttempts, getMaxReduceAttempts, getNumReduceTasks, getOutputFormatClass, getOutputKeyClass, getOutputValueClass, getPartitionerClass, getProfileEnabled, getProfileParams, getProfileTaskRange, getReducerClass, getSortComparator, getSymlink, getTaskCleanupNeeded, getUser, getWorkingDirectory Methods inherited from interface org.apache.hadoop.util.Progressable progress Method Detail nextKey boolean nextKey()                 throws IOException,                        InterruptedException Start processing next unique key. Throws: IOException InterruptedException getValues Iterable<VALUEIN> getValues()                             throws IOException,                                    InterruptedException Iterate through the values for the current key, reusing the same value   object, which is stored in the context. Returns:the series of values associated with the current key. All of the   objects returned directly and indirectly from this method are reused. Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Reducer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Reducer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> java.lang.Object org.apache.hadoop.mapreduce.Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> Direct Known Subclasses: ChainReducer, FieldSelectionReducer, IntSumReducer, LongSumReducer, ValueAggregatorCombiner, ValueAggregatorReducer, WrappedReducer @Checkpointable @InterfaceAudience.Public @InterfaceStability.Stable public class Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends Object Reduces a set of intermediate values which share a key to a smaller set of  values.      Reducer implementations   can access the Configuration for the job via the   JobContext.getConfiguration() method.  Reducer has 3 primary phases:              Shuffle        The Reducer copies the sorted output from each     Mapper using HTTP across the network.                Sort        The framework merge sorts Reducer inputs by     keys     (since different Mappers may have output the same key).        The shuffle and sort phases occur simultaneously i.e. while outputs are    being fetched they are merged.           SecondarySort        To achieve a secondary sort on the values returned by the value     iterator, the application should extend the key with the secondary    key and define a grouping comparator. The keys will be sorted using the    entire key, but will be grouped using the grouping comparator to decide    which keys and values are sent in the same call to reduce.The grouping     comparator is specified via     Job.setGroupingComparatorClass(Class). The sort order is    controlled by     Job.setSortComparatorClass(Class).            For example, say that you want to find duplicate web pages and tag them     all with the url of the "best" known example. You would set up the job     like:          Map Input Key: url      Map Input Value: document      Map Output Key: document checksum, url pagerank      Map Output Value: url      Partitioner: by checksum      OutputKeyComparator: by checksum and then decreasing pagerank      OutputValueGroupingComparator: by checksum                       Reduce        In this phase the     reduce(Object, Iterable, org.apache.hadoop.mapreduce.Reducer.Context)    method is called for each <key, (collection of values)> in    the sorted inputs.    The output of the reduce task is typically written to a     RecordWriter via     TaskInputOutputContext.write(Object, Object).          The output of the Reducer is not re-sorted.    Example:    public class IntSumReducer<Key> extends Reducer<Key,IntWritable,                                                  Key,IntWritable> {    private IntWritable result = new IntWritable();      public void reduce(Key key, Iterable<IntWritable> values,                       Context context) throws IOException, InterruptedException {      int sum = 0;      for (IntWritable val : values) {        sum += val.get();      }      result.set(sum);      context.write(key, result);    }  }   See Also:Mapper,  Partitioner Constructor Summary Constructors  Constructor and Description Reducer()  Method Summary Methods  Modifier and Type Method and Description protected void cleanup(org.apache.hadoop.mapreduce.Reducer.Context context) Called once at the end of the task. protected void reduce(KEYIN key,             Iterable<VALUEIN> values,             org.apache.hadoop.mapreduce.Reducer.Context context) This method is called once for each key. void run(org.apache.hadoop.mapreduce.Reducer.Context context) Advanced application writers can use the   run(org.apache.hadoop.mapreduce.Reducer.Context) method to  control how the reduce task works. protected void setup(org.apache.hadoop.mapreduce.Reducer.Context context) Called once at the start of the task. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Reducer public Reducer() Method Detail setup protected void setup(org.apache.hadoop.mapreduce.Reducer.Context context)               throws IOException,                      InterruptedException Called once at the start of the task. Throws: IOException InterruptedException reduce protected void reduce(KEYIN key,           Iterable<VALUEIN> values,           org.apache.hadoop.mapreduce.Reducer.Context context)                throws IOException,                       InterruptedException This method is called once for each key. Most applications will define  their reduce class by overriding this method. The default implementation  is an identity function. Throws: IOException InterruptedException cleanup protected void cleanup(org.apache.hadoop.mapreduce.Reducer.Context context)                 throws IOException,                        InterruptedException Called once at the end of the task. Throws: IOException InterruptedException run public void run(org.apache.hadoop.mapreduce.Reducer.Context context)          throws IOException,                 InterruptedException Advanced application writers can use the   run(org.apache.hadoop.mapreduce.Reducer.Context) method to  control how the reduce task works. Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReflectionUtils (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReflectionUtils (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util Class ReflectionUtils java.lang.Object org.apache.hadoop.util.ReflectionUtils @InterfaceAudience.Public @InterfaceStability.Evolving public class ReflectionUtils extends Object General reflection utils Constructor Summary Constructors  Constructor and Description ReflectionUtils()  Method Summary Methods  Modifier and Type Method and Description static void cloneWritableInto(Writable dst,                                   Writable src) Deprecated.  static <T> T copy(Configuration conf,         T src,         T dst) Make a copy of the writable object using serialization to a buffer static <T> Class<T> getClass(T o) Return the correctly-typed Class of the given object. static List<Field> getDeclaredFieldsIncludingInherited(Class<?> clazz) Gets all the declared fields of a class including fields declared in  superclasses. static List<Method> getDeclaredMethodsIncludingInherited(Class<?> clazz) Gets all the declared methods of a class including methods declared in  superclasses. static void logThreadInfo(org.apache.commons.logging.Log log,                           String title,                           long minInterval) Log the current thread stacks at INFO level. static <T> T newInstance(Class<T> theClass,                       Configuration conf) Create an object for the given class and initialize it from conf static void printThreadInfo(PrintStream stream,                               String title) Print all of the thread's information and stack traces. static void setConf(Object theObject,               Configuration conf) Check and set 'configuration' if necessary. static void setContentionTracing(boolean val)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReflectionUtils public ReflectionUtils() Method Detail setConf public static void setConf(Object theObject,            Configuration conf) Check and set 'configuration' if necessary. Parameters:theObject - object for which to set configurationconf - Configuration newInstance public static <T> T newInstance(Class<T> theClass,                 Configuration conf) Create an object for the given class and initialize it from conf Parameters:theClass - class of which an object is createdconf - Configuration Returns:a new object setContentionTracing public static void setContentionTracing(boolean val) printThreadInfo public static void printThreadInfo(PrintStream stream,                    String title) Print all of the thread's information and stack traces. Parameters:stream - the stream totitle - a string title for the stack trace logThreadInfo public static void logThreadInfo(org.apache.commons.logging.Log log,                  String title,                  long minInterval) Log the current thread stacks at INFO level. Parameters:log - the logger that logs the stack tracetitle - a descriptive title for the call stacksminInterval - the minimum time from the last getClass public static <T> Class<T> getClass(T o) Return the correctly-typed Class of the given object. Parameters:o - object whose correctly-typed Class is to be obtained Returns:the correctly typed Class of the given object. copy public static <T> T copy(Configuration conf,          T src,          T dst)               throws IOException Make a copy of the writable object using serialization to a buffer Parameters:src - the object to copy fromdst - the object to copy into, which is destroyed Returns:dst param (the copy) Throws: IOException cloneWritableInto @Deprecated public static void cloneWritableInto(Writable dst,                                 Writable src)                               throws IOException Deprecated.  Throws: IOException getDeclaredFieldsIncludingInherited public static List<Field> getDeclaredFieldsIncludingInherited(Class<?> clazz) Gets all the declared fields of a class including fields declared in  superclasses. getDeclaredMethodsIncludingInherited public static List<Method> getDeclaredMethodsIncludingInherited(Class<?> clazz) Gets all the declared methods of a class including methods declared in  superclasses. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegexFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegexFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.filter Class RegexFilter java.lang.Object org.apache.hadoop.metrics2.MetricsFilter org.apache.hadoop.metrics2.filter.AbstractPatternFilter org.apache.hadoop.metrics2.filter.RegexFilter All Implemented Interfaces: MetricsPlugin @InterfaceAudience.Public @InterfaceStability.Evolving public class RegexFilter extends org.apache.hadoop.metrics2.filter.AbstractPatternFilter A regex pattern filter for metrics Field Summary Fields inherited from class org.apache.hadoop.metrics2.filter.AbstractPatternFilter EXCLUDE_KEY, EXCLUDE_TAGS_KEY, INCLUDE_KEY, INCLUDE_TAGS_KEY Constructor Summary Constructors  Constructor and Description RegexFilter()  Method Summary Methods  Modifier and Type Method and Description protected Pattern compile(String s) Compile a string pattern in to a pattern object Methods inherited from class org.apache.hadoop.metrics2.filter.AbstractPatternFilter accepts, accepts, accepts, init Methods inherited from class org.apache.hadoop.metrics2.MetricsFilter accepts Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RegexFilter public RegexFilter() Method Detail compile protected Pattern compile(String s) Description copied from class: org.apache.hadoop.metrics2.filter.AbstractPatternFilter Compile a string pattern in to a pattern object Specified by: compile in class org.apache.hadoop.metrics2.filter.AbstractPatternFilter Parameters:s - the string pattern to compile Returns:the compiled pattern object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegexMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegexMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.map Class RegexMapper<K> java.lang.Object org.apache.hadoop.mapreduce.Mapper<K,Text,Text,LongWritable> org.apache.hadoop.mapreduce.lib.map.RegexMapper<K> @InterfaceAudience.Public @InterfaceStability.Stable public class RegexMapper<K> extends Mapper<K,Text,Text,LongWritable> A Mapper that extracts text matching a regular expression. Field Summary Fields  Modifier and Type Field and Description static String GROUP  static String PATTERN  Constructor Summary Constructors  Constructor and Description RegexMapper()  Method Summary Methods  Modifier and Type Method and Description void map(K key,       Text value,       org.apache.hadoop.mapreduce.Mapper.Context context) Called once for each key/value pair in the input split. void setup(org.apache.hadoop.mapreduce.Mapper.Context context) Called once at the beginning of the task. Methods inherited from class org.apache.hadoop.mapreduce.Mapper cleanup, run Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail PATTERN public static String PATTERN GROUP public static String GROUP Constructor Detail RegexMapper public RegexMapper() Method Detail setup public void setup(org.apache.hadoop.mapreduce.Mapper.Context context) Description copied from class: Mapper Called once at the beginning of the task. Overrides: setup in class Mapper<K,Text,Text,LongWritable> map public void map(K key,        Text value,        org.apache.hadoop.mapreduce.Mapper.Context context)          throws IOException,                 InterruptedException Description copied from class: Mapper Called once for each key/value pair in the input split. Most applications  should override this, but the default is the identity function. Overrides: map in class Mapper<K,Text,Text,LongWritable> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegisterApplicationMasterRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegisterApplicationMasterRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class RegisterApplicationMasterRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class RegisterApplicationMasterRequest extends Object The request sent by the ApplicationMaster to ResourceManager  on registration.    The registration includes details such as:      Hostname on which the AM is running.    RPC Port    Tracking URL   See Also:ApplicationMasterProtocol.registerApplicationMaster(RegisterApplicationMasterRequest) Constructor Summary Constructors  Constructor and Description RegisterApplicationMasterRequest()  Method Summary Methods  Modifier and Type Method and Description abstract String getHost() Get the host on which the ApplicationMaster is   running. abstract int getRpcPort() Get the RPC port on which the ApplicationMaster is  responding. abstract String getTrackingUrl() Get the tracking URL for the ApplicationMaster. static RegisterApplicationMasterRequest newInstance(String host,                       int port,                       String trackingUrl) Create a new instance of RegisterApplicationMasterRequest. abstract void setHost(String host) Set the host on which the ApplicationMaster is   running. abstract void setRpcPort(int port) Set the RPC port on which the ApplicationMaster is  responding. abstract void setTrackingUrl(String trackingUrl) Set the tracking URLfor the ApplicationMaster while  it is running. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RegisterApplicationMasterRequest public RegisterApplicationMasterRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static RegisterApplicationMasterRequest newInstance(String host,                                                                                               int port,                                                                                               String trackingUrl) Create a new instance of RegisterApplicationMasterRequest.  If port, trackingUrl is not used, use the following default value:     port: -1   trackingUrl: null    The port is allowed to be any integer larger than or equal to -1. Returns:the new instance of RegisterApplicationMasterRequest getHost @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getHost() Get the host on which the ApplicationMaster is   running. Returns:host on which the ApplicationMaster is running setHost @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setHost(String host) Set the host on which the ApplicationMaster is   running. Parameters:host - host on which the ApplicationMaster               is running getRpcPort @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getRpcPort() Get the RPC port on which the ApplicationMaster is  responding. Returns:the RPC port on which the ApplicationMaster          is responding setRpcPort @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setRpcPort(int port) Set the RPC port on which the ApplicationMaster is  responding. Parameters:port - RPC port on which the ApplicationMaster              is responding getTrackingUrl @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getTrackingUrl() Get the tracking URL for the ApplicationMaster.  This url if contains scheme then that will be used by resource manager  web application proxy otherwise it will default to http. Returns:tracking URL for the ApplicationMaster setTrackingUrl @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setTrackingUrl(String trackingUrl) Set the tracking URLfor the ApplicationMaster while  it is running. This is the web-URL to which ResourceManager or  web-application proxy will redirect client/users while the application and  the ApplicationMaster are still running.    If the passed url has a scheme then that will be used by the  ResourceManager and web-application proxy, otherwise the scheme will  default to http.      Empty, null, "N/A" strings are all valid besides a real URL. In case an url  isn't explicitly passed, it defaults to "N/A" on the ResourceManager.   Parameters:trackingUrl - tracking URLfor the ApplicationMaster Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegisterApplicationMasterResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegisterApplicationMasterResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class RegisterApplicationMasterResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class RegisterApplicationMasterResponse extends Object The response sent by the ResourceManager to a new  ApplicationMaster on registration.    The response contains critical details such as:      Maximum capability for allocated resources in the cluster.    ApplicationACLs for the application.    ClientToAMToken master key.   See Also:ApplicationMasterProtocol.registerApplicationMaster(RegisterApplicationMasterRequest) Constructor Summary Constructors  Constructor and Description RegisterApplicationMasterResponse()  Method Summary Methods  Modifier and Type Method and Description abstract Map<ApplicationAccessType,String> getApplicationACLs() Get the ApplicationACLs for the application. abstract ByteBuffer getClientToAMTokenMasterKey() Get ClientToAMToken master key. abstract List<Container> getContainersFromPreviousAttempts()  Get the list of running containers as viewed by  ResourceManager from previous application attempts. abstract Resource getMaximumResourceCapability() Get the maximum capability for any Resource allocated by the   ResourceManager in the cluster. abstract List<NMToken> getNMTokensFromPreviousAttempts() Get the list of NMTokens for communicating with the NMs where the  containers of previous application attempts are running. abstract String getQueue() Get the queue that the application was placed in. abstract EnumSet<org.apache.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes> getSchedulerResourceTypes() Get a set of the resource types considered by the scheduler. abstract void setClientToAMTokenMasterKey(ByteBuffer key) Set ClientToAMToken master key. abstract void setQueue(String queue) Set the queue that the application was placed in. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RegisterApplicationMasterResponse public RegisterApplicationMasterResponse() Method Detail getMaximumResourceCapability @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getMaximumResourceCapability() Get the maximum capability for any Resource allocated by the   ResourceManager in the cluster. Returns:maximum capability of allocated resources in the cluster getApplicationACLs @InterfaceAudience.Public @InterfaceStability.Stable public abstract Map<ApplicationAccessType,String> getApplicationACLs() Get the ApplicationACLs for the application. Returns:all the ApplicationACLs getClientToAMTokenMasterKey @InterfaceAudience.Public @InterfaceStability.Stable public abstract ByteBuffer getClientToAMTokenMasterKey() Get ClientToAMToken master key.  The ClientToAMToken master key is sent to ApplicationMaster  by ResourceManager via RegisterApplicationMasterResponse  , used to verify corresponding ClientToAMToken. setClientToAMTokenMasterKey @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setClientToAMTokenMasterKey(ByteBuffer key) Set ClientToAMToken master key. getQueue @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getQueue() Get the queue that the application was placed in. setQueue @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setQueue(String queue) Set the queue that the application was placed in. getContainersFromPreviousAttempts @InterfaceAudience.Public @InterfaceStability.Unstable public abstract List<Container> getContainersFromPreviousAttempts()  Get the list of running containers as viewed by  ResourceManager from previous application attempts.   Returns:the list of running containers as viewed by          ResourceManager from previous application attemptsSee Also:getNMTokensFromPreviousAttempts() getNMTokensFromPreviousAttempts @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<NMToken> getNMTokensFromPreviousAttempts() Get the list of NMTokens for communicating with the NMs where the  containers of previous application attempts are running. Returns:the list of NMTokens for communicating with the NMs where the          containers of previous application attempts are running.See Also:getContainersFromPreviousAttempts() getSchedulerResourceTypes @InterfaceAudience.Public @InterfaceStability.Unstable public abstract EnumSet<org.apache.hadoop.yarn.proto.YarnServiceProtos.SchedulerResourceTypes> getSchedulerResourceTypes() Get a set of the resource types considered by the scheduler. Returns:a Map of RM settings Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegistryBindingSource (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegistryBindingSource (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.impl.zk Interface RegistryBindingSource All Known Implementing Classes: org.apache.hadoop.registry.client.impl.zk.CuratorService, RegistryOperationsClient, RegistryOperationsService @InterfaceAudience.Public @InterfaceStability.Evolving public interface RegistryBindingSource Interface which can be implemented by a registry binding source Method Summary Methods  Modifier and Type Method and Description BindingInformation supplyBindingInformation() Supply the binding information for this registry Method Detail supplyBindingInformation BindingInformation supplyBindingInformation() Supply the binding information for this registry Returns:the binding information data Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegistryConstants (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegistryConstants (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.api Interface RegistryConstants All Known Implementing Classes: org.apache.hadoop.registry.client.impl.zk.CuratorService, RegistryOperationsClient, RegistryOperationsService @InterfaceAudience.Public @InterfaceStability.Evolving public interface RegistryConstants Constants for the registry, including configuration keys and default  values. Field Summary Fields  Modifier and Type Field and Description static String DEFAULT_REGISTRY_CLIENT_JAAS_CONTEXT default client-side registry JAAS context: "Client" static boolean DEFAULT_REGISTRY_ENABLED Defaut value for enabling the registry in the RM: false static boolean DEFAULT_REGISTRY_SECURE Default registry security policy: false. static String DEFAULT_REGISTRY_SYSTEM_ACCOUNTS Default system accounts given global access to the registry: "sasl:yarn@, sasl:mapred@, sasl:hdfs@, sasl:hadoop@". static String DEFAULT_REGISTRY_USER_ACCOUNTS Default system acls: "". static String DEFAULT_REGISTRY_ZK_QUORUM The default zookeeper quorum binding for the registry: "localhost:2181" static int DEFAULT_ZK_CONNECTION_TIMEOUT The default ZK connection timeout: 15000. static String DEFAULT_ZK_REGISTRY_ROOT Default root of the yarn registry: "/registry" static int DEFAULT_ZK_RETRY_CEILING Default limit on retries: 60000. static int DEFAULT_ZK_RETRY_INTERVAL The default interval between connection retries: 1000. static int DEFAULT_ZK_RETRY_TIMES The default # of times to retry a ZK connection: 5. static int DEFAULT_ZK_SESSION_TIMEOUT The default ZK session timeout: 60000. static String KEY_REGISTRY_CLIENT_AUTH Registry client authentication policy. static String KEY_REGISTRY_CLIENT_AUTHENTICATION_ID Registry client authentication ID static String KEY_REGISTRY_CLIENT_AUTHENTICATION_PASSWORD Registry client authentication password. static String KEY_REGISTRY_CLIENT_JAAS_CONTEXT Key to define the JAAS context. static String KEY_REGISTRY_ENABLED flag to indicate whether or not the registry should  be enabled in the RM: "hadoop.registry.rm.enabled" static String KEY_REGISTRY_KERBEROS_REALM The kerberos realm: "hadoop.registry.kerberos.realm". static String KEY_REGISTRY_SECURE Key to set if the registry is secure: "hadoop.registry.secure". static String KEY_REGISTRY_SYSTEM_ACCOUNTS A comma separated list of Zookeeper ACL identifiers with  system access to the registry in a secure cluster: "hadoop.registry.system.accounts". static String KEY_REGISTRY_USER_ACCOUNTS A comma separated list of Zookeeper ACL identifiers with  system access to the registry in a secure cluster: "hadoop.registry.user.accounts". static String KEY_REGISTRY_ZK_CONNECTION_TIMEOUT Zookeeper connection timeout in milliseconds: "hadoop.registry.zk.connection.timeout.ms". static String KEY_REGISTRY_ZK_QUORUM List of hostname:port pairs defining the  zookeeper quorum binding for the registry "hadoop.registry.zk.quorum" static String KEY_REGISTRY_ZK_RETRY_CEILING Zookeeper retry limit in milliseconds, during  exponential backoff: "hadoop.registry.zk.retry.ceiling.ms". static String KEY_REGISTRY_ZK_RETRY_INTERVAL Zookeeper connect interval in milliseconds: "hadoop.registry.zk.retry.interval.ms". static String KEY_REGISTRY_ZK_RETRY_TIMES Zookeeper connection retry count before failing: "hadoop.registry.zk.retry.times". static String KEY_REGISTRY_ZK_ROOT Root path in the ZK tree for the registry: "hadoop.registry.zk.root" static String KEY_REGISTRY_ZK_SESSION_TIMEOUT Zookeeper session timeout in milliseconds: "hadoop.registry.zk.session.timeout.ms" static String PATH_SYSTEM_SERVICES path to system services off the root : "/services/". static String PATH_USER_SERVICES path to system services under a user's home path : "/services/". static String PATH_USERS path to users off the root: "/users/". static String REGISTRY_CLIENT_AUTH_ANONYMOUS No authentication; client is anonymous static String REGISTRY_CLIENT_AUTH_DIGEST Username/password is the authentication mechanism. static String REGISTRY_CLIENT_AUTH_KERBEROS Registry client uses Kerberos: authentication is automatic from  logged in user static String REGISTRY_PREFIX prefix for registry configuration options: "hadoop.registry.". static String SUBPATH_COMPONENTS path under a service record to point to components of that service:   "/components/". static String ZK_PREFIX Prefix for zookeeper-specific options: "hadoop.registry.zk." Field Detail REGISTRY_PREFIX static final String REGISTRY_PREFIX prefix for registry configuration options: "hadoop.registry.".  Why hadoop. and not YARN? It can  live outside YARN See Also:Constant Field Values ZK_PREFIX static final String ZK_PREFIX Prefix for zookeeper-specific options: "hadoop.registry.zk."     For clients using other protocols, these options are not supported. See Also:Constant Field Values KEY_REGISTRY_ENABLED static final String KEY_REGISTRY_ENABLED flag to indicate whether or not the registry should  be enabled in the RM: "hadoop.registry.rm.enabled" See Also:Constant Field Values DEFAULT_REGISTRY_ENABLED static final boolean DEFAULT_REGISTRY_ENABLED Defaut value for enabling the registry in the RM: false See Also:Constant Field Values KEY_REGISTRY_SECURE static final String KEY_REGISTRY_SECURE Key to set if the registry is secure: "hadoop.registry.secure".  Turning it on changes the permissions policy from "open access"  to restrictions on kerberos with the option of  a user adding one or more auth key pairs down their  own tree. See Also:Constant Field Values DEFAULT_REGISTRY_SECURE static final boolean DEFAULT_REGISTRY_SECURE Default registry security policy: false. See Also:Constant Field Values KEY_REGISTRY_ZK_ROOT static final String KEY_REGISTRY_ZK_ROOT Root path in the ZK tree for the registry: "hadoop.registry.zk.root" See Also:Constant Field Values DEFAULT_ZK_REGISTRY_ROOT static final String DEFAULT_ZK_REGISTRY_ROOT Default root of the yarn registry: "/registry" See Also:Constant Field Values KEY_REGISTRY_CLIENT_AUTH static final String KEY_REGISTRY_CLIENT_AUTH Registry client authentication policy.     This is only used in secure clusters.     If the Factory methods of RegistryOperationsFactory  are used, this key does not need to be set: it is set  up based on the factory method used. See Also:Constant Field Values REGISTRY_CLIENT_AUTH_KERBEROS static final String REGISTRY_CLIENT_AUTH_KERBEROS Registry client uses Kerberos: authentication is automatic from  logged in user See Also:Constant Field Values REGISTRY_CLIENT_AUTH_DIGEST static final String REGISTRY_CLIENT_AUTH_DIGEST Username/password is the authentication mechanism.  If set then both KEY_REGISTRY_CLIENT_AUTHENTICATION_ID  and KEY_REGISTRY_CLIENT_AUTHENTICATION_PASSWORD must be set. See Also:Constant Field Values REGISTRY_CLIENT_AUTH_ANONYMOUS static final String REGISTRY_CLIENT_AUTH_ANONYMOUS No authentication; client is anonymous See Also:Constant Field Values KEY_REGISTRY_CLIENT_AUTHENTICATION_ID static final String KEY_REGISTRY_CLIENT_AUTHENTICATION_ID Registry client authentication ID    This is only used in secure clusters with  KEY_REGISTRY_CLIENT_AUTH set to  REGISTRY_CLIENT_AUTH_DIGEST See Also:Constant Field Values KEY_REGISTRY_CLIENT_AUTHENTICATION_PASSWORD static final String KEY_REGISTRY_CLIENT_AUTHENTICATION_PASSWORD Registry client authentication password.    This is only used in secure clusters with the client set to  use digest (not SASL or anonymouse) authentication.     Specifically, KEY_REGISTRY_CLIENT_AUTH set to  REGISTRY_CLIENT_AUTH_DIGEST See Also:Constant Field Values KEY_REGISTRY_ZK_QUORUM static final String KEY_REGISTRY_ZK_QUORUM List of hostname:port pairs defining the  zookeeper quorum binding for the registry "hadoop.registry.zk.quorum" See Also:Constant Field Values DEFAULT_REGISTRY_ZK_QUORUM static final String DEFAULT_REGISTRY_ZK_QUORUM The default zookeeper quorum binding for the registry: "localhost:2181" See Also:Constant Field Values KEY_REGISTRY_ZK_SESSION_TIMEOUT static final String KEY_REGISTRY_ZK_SESSION_TIMEOUT Zookeeper session timeout in milliseconds: "hadoop.registry.zk.session.timeout.ms" See Also:Constant Field Values DEFAULT_ZK_SESSION_TIMEOUT static final int DEFAULT_ZK_SESSION_TIMEOUT The default ZK session timeout: 60000. See Also:Constant Field Values KEY_REGISTRY_ZK_CONNECTION_TIMEOUT static final String KEY_REGISTRY_ZK_CONNECTION_TIMEOUT Zookeeper connection timeout in milliseconds: "hadoop.registry.zk.connection.timeout.ms". See Also:Constant Field Values DEFAULT_ZK_CONNECTION_TIMEOUT static final int DEFAULT_ZK_CONNECTION_TIMEOUT The default ZK connection timeout: 15000. See Also:Constant Field Values KEY_REGISTRY_ZK_RETRY_TIMES static final String KEY_REGISTRY_ZK_RETRY_TIMES Zookeeper connection retry count before failing: "hadoop.registry.zk.retry.times". See Also:Constant Field Values DEFAULT_ZK_RETRY_TIMES static final int DEFAULT_ZK_RETRY_TIMES The default # of times to retry a ZK connection: 5. See Also:Constant Field Values KEY_REGISTRY_ZK_RETRY_INTERVAL static final String KEY_REGISTRY_ZK_RETRY_INTERVAL Zookeeper connect interval in milliseconds: "hadoop.registry.zk.retry.interval.ms". See Also:Constant Field Values DEFAULT_ZK_RETRY_INTERVAL static final int DEFAULT_ZK_RETRY_INTERVAL The default interval between connection retries: 1000. See Also:Constant Field Values KEY_REGISTRY_ZK_RETRY_CEILING static final String KEY_REGISTRY_ZK_RETRY_CEILING Zookeeper retry limit in milliseconds, during  exponential backoff: "hadoop.registry.zk.retry.ceiling.ms".  This places a limit even  if the retry times and interval limit, combined  with the backoff policy, result in a long retry  period See Also:Constant Field Values DEFAULT_ZK_RETRY_CEILING static final int DEFAULT_ZK_RETRY_CEILING Default limit on retries: 60000. See Also:Constant Field Values KEY_REGISTRY_SYSTEM_ACCOUNTS static final String KEY_REGISTRY_SYSTEM_ACCOUNTS A comma separated list of Zookeeper ACL identifiers with  system access to the registry in a secure cluster: "hadoop.registry.system.accounts".  These are given full access to all entries.  If there is an "@" at the end of an entry it  instructs the registry client to append the kerberos realm as  derived from the login and KEY_REGISTRY_KERBEROS_REALM. See Also:Constant Field Values DEFAULT_REGISTRY_SYSTEM_ACCOUNTS static final String DEFAULT_REGISTRY_SYSTEM_ACCOUNTS Default system accounts given global access to the registry: "sasl:yarn@, sasl:mapred@, sasl:hdfs@, sasl:hadoop@". See Also:Constant Field Values KEY_REGISTRY_USER_ACCOUNTS static final String KEY_REGISTRY_USER_ACCOUNTS A comma separated list of Zookeeper ACL identifiers with  system access to the registry in a secure cluster: "hadoop.registry.user.accounts".  These are given full access to all entries.  If there is an "@" at the end of an entry it  instructs the registry client to append the default kerberos domain. See Also:Constant Field Values DEFAULT_REGISTRY_USER_ACCOUNTS static final String DEFAULT_REGISTRY_USER_ACCOUNTS Default system acls: "". See Also:Constant Field Values KEY_REGISTRY_KERBEROS_REALM static final String KEY_REGISTRY_KERBEROS_REALM The kerberos realm: "hadoop.registry.kerberos.realm".  This is used to set the realm of  system principals which do not declare their realm,  and any other accounts that need the value.  If empty, the default realm of the running process  is used.  If neither are known and the realm is needed, then the registry  service/client will fail. See Also:Constant Field Values KEY_REGISTRY_CLIENT_JAAS_CONTEXT static final String KEY_REGISTRY_CLIENT_JAAS_CONTEXT Key to define the JAAS context. Used in secure registries: "hadoop.registry.jaas.context". See Also:Constant Field Values DEFAULT_REGISTRY_CLIENT_JAAS_CONTEXT static final String DEFAULT_REGISTRY_CLIENT_JAAS_CONTEXT default client-side registry JAAS context: "Client" See Also:Constant Field Values PATH_USERS static final String PATH_USERS path to users off the root: "/users/". See Also:Constant Field Values PATH_SYSTEM_SERVICES static final String PATH_SYSTEM_SERVICES path to system services off the root : "/services/". See Also:Constant Field Values PATH_USER_SERVICES static final String PATH_USER_SERVICES path to system services under a user's home path : "/services/". See Also:Constant Field Values SUBPATH_COMPONENTS static final String SUBPATH_COMPONENTS path under a service record to point to components of that service:   "/components/". See Also:Constant Field Values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegistryIOException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegistryIOException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.exceptions Class RegistryIOException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.PathIOException org.apache.hadoop.registry.client.exceptions.RegistryIOException All Implemented Interfaces: Serializable Direct Known Subclasses: InvalidPathnameException, InvalidRecordException, NoChildrenForEphemeralsException, NoRecordException @InterfaceAudience.Public @InterfaceStability.Evolving public class RegistryIOException extends org.apache.hadoop.fs.PathIOException Base exception for registry operations.    These exceptions include the path of the failing operation wherever possible;  this can be retrieved via PathIOException.getPath(). See Also:Serialized Form Constructor Summary Constructors  Constructor and Description RegistryIOException(String message,                                       org.apache.hadoop.fs.PathIOException cause) Build an exception from any other Path IO Exception. RegistryIOException(String path,                                       String error)  RegistryIOException(String path,                                       String error,                                       Throwable cause)  RegistryIOException(String path,                                       Throwable cause)  Method Summary Methods inherited from class org.apache.hadoop.fs.PathIOException getMessage, getPath, getTargetPath, setOperation, setTargetPath Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail RegistryIOException public RegistryIOException(String message,                    org.apache.hadoop.fs.PathIOException cause) Build an exception from any other Path IO Exception.  This propagates the path of the original exception Parameters:message - more specific textcause - cause RegistryIOException public RegistryIOException(String path,                    Throwable cause) RegistryIOException public RegistryIOException(String path,                    String error) RegistryIOException public RegistryIOException(String path,                    String error,                    Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegistryOperations (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegistryOperations (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.api Interface RegistryOperations All Superinterfaces: AutoCloseable, Closeable, Service All Known Implementing Classes: RegistryOperationsClient, RegistryOperationsService @InterfaceAudience.Public @InterfaceStability.Evolving public interface RegistryOperations extends Service Registry Operations Method Summary Methods  Modifier and Type Method and Description boolean addWriteAccessor(String id,                                 String pass) Add a new write access entry to be added to node permissions in all  future write operations of a session connected to a secure registry. void bind(String path,         ServiceRecord record,         int flags) Bind a path in the registry to a service record void clearWriteAccessors() Clear all write accessors. void delete(String path,             boolean recursive) Delete a path. boolean exists(String path) Probe for a path existing. List<String> list(String path) List all entries under a registry path, returning the relative names  of the entries. boolean mknode(String path,             boolean createParents) Create a path. ServiceRecord resolve(String path) Resolve the record at a path RegistryPathStatus stat(String path) Get the status of a path Methods inherited from interface org.apache.hadoop.service.Service close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, registerServiceListener, start, stop, unregisterServiceListener, waitForServiceToStop Method Detail mknode boolean mknode(String path,              boolean createParents)                throws org.apache.hadoop.fs.PathNotFoundException,                       InvalidPathnameException,                       IOException Create a path.  It is not an error if the path exists already, be it empty or not.  The createParents flag also requests creating the parents.  As entries in the registry can hold data while still having  child entries, it is not an error if any of the parent path  elements have service records. Parameters:path - path to createcreateParents - also create the parents. Returns:true if the path was created, false if it existed. Throws: org.apache.hadoop.fs.PathNotFoundException - parent path is not in the registry. InvalidPathnameException - path name is invalid. IOException - Any other IO Exception. bind void bind(String path,         ServiceRecord record,         int flags)           throws org.apache.hadoop.fs.PathNotFoundException,                  FileAlreadyExistsException,                  InvalidPathnameException,                  IOException Bind a path in the registry to a service record Parameters:path - path to service recordrecord - service record service record to create/updateflags - bind flags Throws: org.apache.hadoop.fs.PathNotFoundException - the parent path does not exist FileAlreadyExistsException - path exists but create flags  do not include "overwrite" InvalidPathnameException - path name is invalid. IOException - Any other IO Exception. resolve ServiceRecord resolve(String path)                       throws org.apache.hadoop.fs.PathNotFoundException,                              NoRecordException,                              InvalidRecordException,                              IOException Resolve the record at a path Parameters:path - path to an entry containing a ServiceRecord Returns:the record Throws: org.apache.hadoop.fs.PathNotFoundException - path is not in the registry. NoRecordException - if there is not a service record InvalidRecordException - if there was a service record but it could  not be parsed. IOException - Any other IO Exception stat RegistryPathStatus stat(String path)                         throws org.apache.hadoop.fs.PathNotFoundException,                                InvalidPathnameException,                                IOException Get the status of a path Parameters:path - path to query Returns:the status of the path Throws: org.apache.hadoop.fs.PathNotFoundException - path is not in the registry. InvalidPathnameException - the path is invalid. IOException - Any other IO Exception exists boolean exists(String path)                throws IOException Probe for a path existing.  This is equivalent to stat(String) with  any failure downgraded to a Parameters:path - path to query Returns:true if the path was found Throws: IOException list List<String> list(String path)                   throws org.apache.hadoop.fs.PathNotFoundException,                          InvalidPathnameException,                          IOException List all entries under a registry path, returning the relative names  of the entries. Parameters:path - path to query Returns:a possibly empty list of the short path names of  child entries. Throws: org.apache.hadoop.fs.PathNotFoundException InvalidPathnameException IOException delete void delete(String path,           boolean recursive)             throws org.apache.hadoop.fs.PathNotFoundException,                    org.apache.hadoop.fs.PathIsNotEmptyDirectoryException,                    InvalidPathnameException,                    IOException Delete a path.  If the operation returns without an error then the entry has been  deleted. Parameters:path - path delete recursivelyrecursive - recursive flag Throws: org.apache.hadoop.fs.PathNotFoundException - path is not in the registry. InvalidPathnameException - the path is invalid. org.apache.hadoop.fs.PathIsNotEmptyDirectoryException - path has child entries, but  recursive is false. IOException - Any other IO Exception addWriteAccessor boolean addWriteAccessor(String id,                        String pass)                          throws IOException Add a new write access entry to be added to node permissions in all  future write operations of a session connected to a secure registry.  This does not grant the session any more rights: if it lacked any write  access, it will still be unable to manipulate the registry.  In an insecure cluster, this operation has no effect. Parameters:id - ID to usepass - password Returns:true if the accessor was added: that is, the registry connection  uses permissions to manage access Throws: IOException - on any failure to build the digest clearWriteAccessors void clearWriteAccessors() Clear all write accessors.  At this point all standard permissions/ACLs are retained,  including any set on behalf of the user  Only  accessors added via addWriteAccessor(String, String)  are removed. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegistryOperationsClient (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegistryOperationsClient (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.impl Class RegistryOperationsClient java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.service.CompositeService org.apache.hadoop.registry.client.impl.zk.CuratorService org.apache.hadoop.registry.client.impl.zk.RegistryOperationsService org.apache.hadoop.registry.client.impl.RegistryOperationsClient All Implemented Interfaces: Closeable, AutoCloseable, RegistryConstants, RegistryOperations, RegistryBindingSource, Service @InterfaceAudience.Public @InterfaceStability.Evolving public class RegistryOperationsClient extends RegistryOperationsService This is the client service for applications to work with the registry.  It does not set up the root paths for the registry, is bonded  to a user, and can be set to use SASL, anonymous or id:pass auth.  For SASL, the client must be operating in the context of an authed user.  For id:pass the client must have the relevant id and password, SASL is  not used even if the client has credentials.  For anonymous, nothing is used.  Any SASL-authed client also has the ability to add one or more authentication  id:pass pair on all future writes, and to reset them later. Field Summary Fields inherited from class org.apache.hadoop.service.CompositeService STOP_ONLY_STARTED_SERVICES Fields inherited from interface org.apache.hadoop.registry.client.api.RegistryConstants DEFAULT_REGISTRY_CLIENT_JAAS_CONTEXT, DEFAULT_REGISTRY_ENABLED, DEFAULT_REGISTRY_SECURE, DEFAULT_REGISTRY_SYSTEM_ACCOUNTS, DEFAULT_REGISTRY_USER_ACCOUNTS, DEFAULT_REGISTRY_ZK_QUORUM, DEFAULT_ZK_CONNECTION_TIMEOUT, DEFAULT_ZK_REGISTRY_ROOT, DEFAULT_ZK_RETRY_CEILING, DEFAULT_ZK_RETRY_INTERVAL, DEFAULT_ZK_RETRY_TIMES, DEFAULT_ZK_SESSION_TIMEOUT, KEY_REGISTRY_CLIENT_AUTH, KEY_REGISTRY_CLIENT_AUTHENTICATION_ID, KEY_REGISTRY_CLIENT_AUTHENTICATION_PASSWORD, KEY_REGISTRY_CLIENT_JAAS_CONTEXT, KEY_REGISTRY_ENABLED, KEY_REGISTRY_KERBEROS_REALM, KEY_REGISTRY_SECURE, KEY_REGISTRY_SYSTEM_ACCOUNTS, KEY_REGISTRY_USER_ACCOUNTS, KEY_REGISTRY_ZK_CONNECTION_TIMEOUT, KEY_REGISTRY_ZK_QUORUM, KEY_REGISTRY_ZK_RETRY_CEILING, KEY_REGISTRY_ZK_RETRY_INTERVAL, KEY_REGISTRY_ZK_RETRY_TIMES, KEY_REGISTRY_ZK_ROOT, KEY_REGISTRY_ZK_SESSION_TIMEOUT, PATH_SYSTEM_SERVICES, PATH_USER_SERVICES, PATH_USERS, REGISTRY_CLIENT_AUTH_ANONYMOUS, REGISTRY_CLIENT_AUTH_DIGEST, REGISTRY_CLIENT_AUTH_KERBEROS, REGISTRY_PREFIX, SUBPATH_COMPONENTS, ZK_PREFIX Constructor Summary Constructors  Constructor and Description RegistryOperationsClient(String name)  RegistryOperationsClient(String name,                                                 RegistryBindingSource bindingSource)  Method Summary Methods inherited from class org.apache.hadoop.registry.client.impl.zk.RegistryOperationsService bind, delete, exists, getClientAcls, list, mknode, resolve, stat, validatePath Methods inherited from class org.apache.hadoop.registry.client.impl.zk.CuratorService addWriteAccessor, bindingDiagnosticDetails, buildConnectionString, buildSecurityDiagnostics, clearWriteAccessors, createEnsembleProvider, createFullPath, dumpPath, dumpRegistryRobustly, getBindingSource, getRegistrySecurity, isSecure, maybeCreate, operationFailure, operationFailure, serviceInit, serviceStart, serviceStop, supplyBindingInformation, toString, zkCreate, zkDelete, zkGetACLS, zkList, zkMkParentPath, zkMkPath, zkPathExists, zkPathMustExist, zkRead, zkSet, zkStat, zkUpdate Methods inherited from class org.apache.hadoop.service.CompositeService addIfService, addService, getServices, removeService Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, setConfig, start, stop, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Methods inherited from interface org.apache.hadoop.registry.client.api.RegistryOperations addWriteAccessor, clearWriteAccessors Methods inherited from interface org.apache.hadoop.service.Service close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, registerServiceListener, start, stop, unregisterServiceListener, waitForServiceToStop Constructor Detail RegistryOperationsClient public RegistryOperationsClient(String name) RegistryOperationsClient public RegistryOperationsClient(String name,                         RegistryBindingSource bindingSource) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegistryOperationsService (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegistryOperationsService (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.impl.zk Class RegistryOperationsService java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.service.CompositeService org.apache.hadoop.registry.client.impl.zk.CuratorService org.apache.hadoop.registry.client.impl.zk.RegistryOperationsService All Implemented Interfaces: Closeable, AutoCloseable, RegistryConstants, RegistryOperations, RegistryBindingSource, Service Direct Known Subclasses: RegistryOperationsClient @InterfaceAudience.Public @InterfaceStability.Evolving public class RegistryOperationsService extends org.apache.hadoop.registry.client.impl.zk.CuratorService implements RegistryOperations The Registry operations service.    This service implements the RegistryOperations  API by mapping the commands to zookeeper operations, and translating  results and exceptions back into those specified by the API.    Factory methods should hide the detail that this has been implemented via  the CuratorService by returning it cast to that  RegistryOperations interface, rather than this implementation class. Field Summary Fields inherited from class org.apache.hadoop.service.CompositeService STOP_ONLY_STARTED_SERVICES Fields inherited from interface org.apache.hadoop.registry.client.api.RegistryConstants DEFAULT_REGISTRY_CLIENT_JAAS_CONTEXT, DEFAULT_REGISTRY_ENABLED, DEFAULT_REGISTRY_SECURE, DEFAULT_REGISTRY_SYSTEM_ACCOUNTS, DEFAULT_REGISTRY_USER_ACCOUNTS, DEFAULT_REGISTRY_ZK_QUORUM, DEFAULT_ZK_CONNECTION_TIMEOUT, DEFAULT_ZK_REGISTRY_ROOT, DEFAULT_ZK_RETRY_CEILING, DEFAULT_ZK_RETRY_INTERVAL, DEFAULT_ZK_RETRY_TIMES, DEFAULT_ZK_SESSION_TIMEOUT, KEY_REGISTRY_CLIENT_AUTH, KEY_REGISTRY_CLIENT_AUTHENTICATION_ID, KEY_REGISTRY_CLIENT_AUTHENTICATION_PASSWORD, KEY_REGISTRY_CLIENT_JAAS_CONTEXT, KEY_REGISTRY_ENABLED, KEY_REGISTRY_KERBEROS_REALM, KEY_REGISTRY_SECURE, KEY_REGISTRY_SYSTEM_ACCOUNTS, KEY_REGISTRY_USER_ACCOUNTS, KEY_REGISTRY_ZK_CONNECTION_TIMEOUT, KEY_REGISTRY_ZK_QUORUM, KEY_REGISTRY_ZK_RETRY_CEILING, KEY_REGISTRY_ZK_RETRY_INTERVAL, KEY_REGISTRY_ZK_RETRY_TIMES, KEY_REGISTRY_ZK_ROOT, KEY_REGISTRY_ZK_SESSION_TIMEOUT, PATH_SYSTEM_SERVICES, PATH_USER_SERVICES, PATH_USERS, REGISTRY_CLIENT_AUTH_ANONYMOUS, REGISTRY_CLIENT_AUTH_DIGEST, REGISTRY_CLIENT_AUTH_KERBEROS, REGISTRY_PREFIX, SUBPATH_COMPONENTS, ZK_PREFIX Constructor Summary Constructors  Constructor and Description RegistryOperationsService()  RegistryOperationsService(String name)  RegistryOperationsService(String name,                                                   RegistryBindingSource bindingSource)  Method Summary Methods  Modifier and Type Method and Description void bind(String path,         ServiceRecord record,         int flags) Bind a path in the registry to a service record void delete(String path,             boolean recursive) Delete a path. boolean exists(String path) Probe for a path existing. List<org.apache.zookeeper.data.ACL> getClientAcls() Get the aggregate set of ACLs the client should use  to create directories List<String> list(String path) List all entries under a registry path, returning the relative names  of the entries. boolean mknode(String path,             boolean createParents) Create a path. ServiceRecord resolve(String path) Resolve the record at a path RegistryPathStatus stat(String path) Get the status of a path protected void validatePath(String path) Validate a path Methods inherited from class org.apache.hadoop.registry.client.impl.zk.CuratorService addWriteAccessor, bindingDiagnosticDetails, buildConnectionString, buildSecurityDiagnostics, clearWriteAccessors, createEnsembleProvider, createFullPath, dumpPath, dumpRegistryRobustly, getBindingSource, getRegistrySecurity, isSecure, maybeCreate, operationFailure, operationFailure, serviceInit, serviceStart, serviceStop, supplyBindingInformation, toString, zkCreate, zkDelete, zkGetACLS, zkList, zkMkParentPath, zkMkPath, zkPathExists, zkPathMustExist, zkRead, zkSet, zkStat, zkUpdate Methods inherited from class org.apache.hadoop.service.CompositeService addIfService, addService, getServices, removeService Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, setConfig, start, stop, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Methods inherited from interface org.apache.hadoop.registry.client.api.RegistryOperations addWriteAccessor, clearWriteAccessors Methods inherited from interface org.apache.hadoop.service.Service close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, registerServiceListener, start, stop, unregisterServiceListener, waitForServiceToStop Constructor Detail RegistryOperationsService public RegistryOperationsService(String name) RegistryOperationsService public RegistryOperationsService() RegistryOperationsService public RegistryOperationsService(String name,                          RegistryBindingSource bindingSource) Method Detail getClientAcls public List<org.apache.zookeeper.data.ACL> getClientAcls() Get the aggregate set of ACLs the client should use  to create directories Returns:the ACL list validatePath protected void validatePath(String path)                      throws InvalidPathnameException Validate a path Parameters:path - path to validate Throws: InvalidPathnameException - if a path is considered invalid mknode public boolean mknode(String path,              boolean createParents)                throws IOException Description copied from interface: RegistryOperations Create a path.  It is not an error if the path exists already, be it empty or not.  The createParents flag also requests creating the parents.  As entries in the registry can hold data while still having  child entries, it is not an error if any of the parent path  elements have service records. Specified by: mknode in interface RegistryOperations Parameters:path - path to createcreateParents - also create the parents. Returns:true if the path was created, false if it existed. Throws: org.apache.hadoop.fs.PathNotFoundException - parent path is not in the registry. InvalidPathnameException - path name is invalid. IOException - Any other IO Exception. bind public void bind(String path,         ServiceRecord record,         int flags)           throws IOException Description copied from interface: RegistryOperations Bind a path in the registry to a service record Specified by: bind in interface RegistryOperations Parameters:path - path to service recordrecord - service record service record to create/updateflags - bind flags Throws: org.apache.hadoop.fs.PathNotFoundException - the parent path does not exist FileAlreadyExistsException - path exists but create flags  do not include "overwrite" InvalidPathnameException - path name is invalid. IOException - Any other IO Exception. resolve public ServiceRecord resolve(String path)                       throws IOException Description copied from interface: RegistryOperations Resolve the record at a path Specified by: resolve in interface RegistryOperations Parameters:path - path to an entry containing a ServiceRecord Returns:the record Throws: org.apache.hadoop.fs.PathNotFoundException - path is not in the registry. NoRecordException - if there is not a service record InvalidRecordException - if there was a service record but it could  not be parsed. IOException - Any other IO Exception exists public boolean exists(String path)                throws IOException Description copied from interface: RegistryOperations Probe for a path existing.  This is equivalent to RegistryOperations.stat(String) with  any failure downgraded to a Specified by: exists in interface RegistryOperations Parameters:path - path to query Returns:true if the path was found Throws: IOException stat public RegistryPathStatus stat(String path)                         throws IOException Description copied from interface: RegistryOperations Get the status of a path Specified by: stat in interface RegistryOperations Parameters:path - path to query Returns:the status of the path Throws: org.apache.hadoop.fs.PathNotFoundException - path is not in the registry. InvalidPathnameException - the path is invalid. IOException - Any other IO Exception list public List<String> list(String path)                   throws IOException Description copied from interface: RegistryOperations List all entries under a registry path, returning the relative names  of the entries. Specified by: list in interface RegistryOperations Parameters:path - path to query Returns:a possibly empty list of the short path names of  child entries. Throws: org.apache.hadoop.fs.PathNotFoundException InvalidPathnameException IOException delete public void delete(String path,           boolean recursive)             throws IOException Description copied from interface: RegistryOperations Delete a path.  If the operation returns without an error then the entry has been  deleted. Specified by: delete in interface RegistryOperations Parameters:path - path delete recursivelyrecursive - recursive flag Throws: org.apache.hadoop.fs.PathNotFoundException - path is not in the registry. InvalidPathnameException - the path is invalid. org.apache.hadoop.fs.PathIsNotEmptyDirectoryException - path has child entries, but  recursive is false. IOException - Any other IO Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegistryPathStatus (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegistryPathStatus (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.types Class RegistryPathStatus java.lang.Object org.apache.hadoop.registry.client.types.RegistryPathStatus @InterfaceAudience.Public @InterfaceStability.Evolving public final class RegistryPathStatus extends Object Output of a RegistryOperations.stat() call Field Summary Fields  Modifier and Type Field and Description int children Number of child nodes String path Short path in the registry to this entry long size Entry size in bytes, as returned by the storage infrastructure. long time Timestamp Constructor Summary Constructors  Constructor and Description RegistryPathStatus(String path,                                     long time,                                     long size,                                     int children) Construct an instance Method Summary Methods  Modifier and Type Method and Description boolean equals(Object other) Equality operator checks size, time and path of the entries. int hashCode() The hash code is derived from the path. String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail path public final String path Short path in the registry to this entry time public final long time Timestamp size public final long size Entry size in bytes, as returned by the storage infrastructure.  In zookeeper, even "empty" nodes have a non-zero size. children public final int children Number of child nodes Constructor Detail RegistryPathStatus public RegistryPathStatus(String path,                   long time,                   long size,                   int children) Construct an instance Parameters:path - full pathtime - timesize - entry sizechildren - number of children Method Detail equals public boolean equals(Object other) Equality operator checks size, time and path of the entries.  It does not check children. Overrides: equals in class Object Parameters:other - the other entry Returns:true if the entries are considered equal. hashCode public int hashCode() The hash code is derived from the path. Overrides: hashCode in class Object Returns:hash code for storing the path in maps. toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegistryTypeUtils (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegistryTypeUtils (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.binding Class RegistryTypeUtils java.lang.Object org.apache.hadoop.registry.client.binding.RegistryTypeUtils @InterfaceAudience.Public @InterfaceStability.Evolving public class RegistryTypeUtils extends Object Static methods to work with registry types —primarily endpoints and the  list representation of addresses. Constructor Summary Constructors  Constructor and Description RegistryTypeUtils()  Method Summary Methods  Modifier and Type Method and Description static String getAddressField(Map<String,String> address,                               String field) Get a specific field from an address -raising an exception if  the field is not present static Map<String,String> hostnamePortPair(InetSocketAddress address) Create a (hostname, port) address pair static Map<String,String> hostnamePortPair(String hostname,                                 int port) Create a (hostname, port) address pair static Endpoint inetAddrEndpoint(String api,                                 String protocolType,                                 String hostname,                                 int port) Create an internet address endpoint from a list of URIs static Endpoint ipcEndpoint(String api,                       InetSocketAddress address) Create an IPC endpoint static Map<String,String> map(String key,       String val) Create a single entry map static void requireAddressType(String required,                                     Endpoint epr) Require a specific address type on an endpoint static Endpoint restEndpoint(String api,                         URI... uris) Create a REST endpoint from a list of URIs static List<String> retrieveAddressesUriType(Endpoint epr) Get a single URI endpoint static List<URL> retrieveAddressURLs(Endpoint epr) Get the address URLs. static Map<String,String> uri(String uri) Create a URI static Endpoint urlEndpoint(String api,                       String protocolType,                       URI... uris) Create a URL endpoint from a list of URIs static void validateEndpoint(String path,                                 Endpoint endpoint) Validate the endpoint by checking for null fields and other invalid  conditions static void validateServiceRecord(String path,                                           ServiceRecord record) Validate the record by checking for null fields and other invalid  conditions static Endpoint webEndpoint(String api,                       URI... uris) Create a Web UI endpoint from a list of URIs Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RegistryTypeUtils public RegistryTypeUtils() Method Detail urlEndpoint public static Endpoint urlEndpoint(String api,                    String protocolType,                    URI... uris) Create a URL endpoint from a list of URIs Parameters:api - implemented APIprotocolType - protocol typeuris - URIs Returns:a new endpoint restEndpoint public static Endpoint restEndpoint(String api,                     URI... uris) Create a REST endpoint from a list of URIs Parameters:api - implemented APIuris - URIs Returns:a new endpoint webEndpoint public static Endpoint webEndpoint(String api,                    URI... uris) Create a Web UI endpoint from a list of URIs Parameters:api - implemented APIuris - URIs Returns:a new endpoint inetAddrEndpoint public static Endpoint inetAddrEndpoint(String api,                         String protocolType,                         String hostname,                         int port) Create an internet address endpoint from a list of URIs Parameters:api - implemented APIprotocolType - protocol typehostname - hostname/FQDNport - port Returns:a new endpoint ipcEndpoint public static Endpoint ipcEndpoint(String api,                    InetSocketAddress address) Create an IPC endpoint Parameters:api - APIaddress - the address as a tuple of (hostname, port) Returns:the new endpoint map public static Map<String,String> map(String key,                      String val) Create a single entry map Parameters:key - map entry keyval - map entry value Returns:a 1 entry map. uri public static Map<String,String> uri(String uri) Create a URI Parameters:uri - value Returns:a 1 entry map. hostnamePortPair public static Map<String,String> hostnamePortPair(String hostname,                                   int port) Create a (hostname, port) address pair Parameters:hostname - hostnameport - port Returns:a 1 entry map. hostnamePortPair public static Map<String,String> hostnamePortPair(InetSocketAddress address) Create a (hostname, port) address pair Parameters:address - socket address whose hostname and port are used for the  generated address. Returns:a 1 entry map. requireAddressType public static void requireAddressType(String required,                       Endpoint epr)                                throws InvalidRecordException Require a specific address type on an endpoint Parameters:required - required typeepr - endpoint Throws: InvalidRecordException - if the type is wrong retrieveAddressesUriType public static List<String> retrieveAddressesUriType(Endpoint epr)                                              throws InvalidRecordException Get a single URI endpoint Parameters:epr - endpoint Returns:the uri of the first entry in the address list. Null if the endpoint  itself is null Throws: InvalidRecordException - if the type is wrong, there are no addresses  or the payload ill-formatted getAddressField public static String getAddressField(Map<String,String> address,                      String field)                               throws InvalidRecordException Get a specific field from an address -raising an exception if  the field is not present Parameters:address - address to queryfield - field to resolve Returns:the resolved value. Guaranteed to be non-null. Throws: InvalidRecordException - if the field did not resolve retrieveAddressURLs public static List<URL> retrieveAddressURLs(Endpoint epr)                                      throws InvalidRecordException,                                             MalformedURLException Get the address URLs. Guranteed to return at least one address. Parameters:epr - endpoint Returns:the address as a URL Throws: InvalidRecordException - if the type is wrong, there are no addresses  or the payload ill-formatted MalformedURLException - address can't be turned into a URL validateServiceRecord public static void validateServiceRecord(String path,                          ServiceRecord record)                                   throws InvalidRecordException Validate the record by checking for null fields and other invalid  conditions Parameters:path - path for exceptionsrecord - record to validate. May be null Throws: InvalidRecordException - on invalid entries validateEndpoint public static void validateEndpoint(String path,                     Endpoint endpoint)                              throws InvalidRecordException Validate the endpoint by checking for null fields and other invalid  conditions Parameters:path - path for exceptionsendpoint - endpoint to validate. May be null Throws: InvalidRecordException - on invalid entries Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RegistryUtils (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RegistryUtils (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.binding Class RegistryUtils java.lang.Object org.apache.hadoop.registry.client.binding.RegistryUtils @InterfaceAudience.Public @InterfaceStability.Evolving public class RegistryUtils extends Object Utility methods for working with a registry. Constructor Summary Constructors  Constructor and Description RegistryUtils()  Method Summary Methods  Modifier and Type Method and Description static String componentListPath(String user,                                   String serviceClass,                                   String serviceName) Create a path for listing components under a service static String componentPath(String user,                           String serviceClass,                           String serviceName,                           String componentName) Create the path to a service record for a component static String convertUsername(String username) Convert the username to that which can be used for registry  entries. static String currentUser() Get the current user path formatted for the registry static Map<String,ServiceRecord> extractServiceRecords(RegistryOperations operations,                                           String parentpath) Extract all service records under a list of stat operations...this  non-atomic action skips entries that are too short or simply not matching. static Map<String,ServiceRecord> extractServiceRecords(RegistryOperations operations,                                           String parentpath,                                           Collection<RegistryPathStatus> stats) Extract all service records under a list of stat operations...this  skips entries that are too short or simply not matching static Map<String,ServiceRecord> extractServiceRecords(RegistryOperations operations,                                           String parentpath,                                           Map<String,RegistryPathStatus> stats) Extract all service records under a list of stat operations...this  non-atomic action skips entries that are too short or simply not matching. static String getCurrentUsernameUnencoded(String env_hadoop_username) Get the current username, using the value of the parameter  env_hadoop_username if it is set on an insecure cluster. static String homePathForCurrentUser() Get the home path of the current user. static String homePathForUser(String username) Buld the user path -switches to the system path if the user is "". static Map<String,ServiceRecord> listServiceRecords(RegistryOperations registryOperations,                                     String path) List service records directly under a path static String serviceclassPath(String user,                                 String serviceClass) Create a service classpath static String servicePath(String user,                       String serviceClass,                       String serviceName) Create a path to a service under a user and service class static Map<String,RegistryPathStatus> statChildren(RegistryOperations registryOperations,                         String path) List children of a directory and retrieve their  RegistryPathStatus values. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail RegistryUtils public RegistryUtils() Method Detail homePathForUser public static String homePathForUser(String username) Buld the user path -switches to the system path if the user is "".  It also cross-converts the username to ascii via punycode Parameters:username - username or "" Returns:the path to the user convertUsername public static String convertUsername(String username) Convert the username to that which can be used for registry  entries. Lower cases it,  Strip the kerberos realm off a username if needed, and any "/" hostname  entries Parameters:username - user Returns:the converted username serviceclassPath public static String serviceclassPath(String user,                       String serviceClass) Create a service classpath Parameters:user - username or ""serviceClass - service name Returns:a full path servicePath public static String servicePath(String user,                  String serviceClass,                  String serviceName) Create a path to a service under a user and service class Parameters:user - username or ""serviceClass - service nameserviceName - service name unique for that user and service class Returns:a full path componentListPath public static String componentListPath(String user,                        String serviceClass,                        String serviceName) Create a path for listing components under a service Parameters:user - username or ""serviceClass - service nameserviceName - service name unique for that user and service class Returns:a full path componentPath public static String componentPath(String user,                    String serviceClass,                    String serviceName,                    String componentName) Create the path to a service record for a component Parameters:user - username or ""serviceClass - service nameserviceName - service name unique for that user and service classcomponentName - unique name/ID of the component Returns:a full path listServiceRecords public static Map<String,ServiceRecord> listServiceRecords(RegistryOperations registryOperations,                                            String path)                                                     throws IOException List service records directly under a path Parameters:registryOperations - registry operations instancepath - path to list Returns:a mapping of the service records that were resolved, indexed  by their full path Throws: IOException statChildren public static Map<String,RegistryPathStatus> statChildren(RegistryOperations registryOperations,                                           String path)                                                    throws org.apache.hadoop.fs.PathNotFoundException,                                                           InvalidPathnameException,                                                           IOException List children of a directory and retrieve their  RegistryPathStatus values.    This is not an atomic operation; A child may be deleted  during the iteration through the child entries. If this happens,  the PathNotFoundException is caught and that child  entry ommitted. Parameters:path - path Returns:a possibly empty map of child entries listed by  their short name. Throws: org.apache.hadoop.fs.PathNotFoundException - path is not in the registry. InvalidPathnameException - the path is invalid. IOException - Any other IO Exception homePathForCurrentUser public static String homePathForCurrentUser() Get the home path of the current user.     In an insecure cluster, the environment variable   HADOOP_USER_NAME is queried first.    This means that in a YARN container where the creator set this  environment variable to propagate their identity, the defined  user name is used in preference to the actual user.    In a secure cluster, the kerberos identity of the current user is used. Returns:a path for the current user's home dir. Throws: RuntimeException - if the current user identity cannot be determined  from the OS/kerberos. getCurrentUsernameUnencoded public static String getCurrentUsernameUnencoded(String env_hadoop_username) Get the current username, using the value of the parameter  env_hadoop_username if it is set on an insecure cluster.  This ensures that the username propagates correctly across processes  started by YARN.    This method is primarly made visible for testing. Parameters:env_hadoop_username - the environment variable Returns:the selected username Throws: RuntimeException - if there is a problem getting the short user  name of the current user. currentUser public static String currentUser() Get the current user path formatted for the registry     In an insecure cluster, the environment variable   HADOOP_USER_NAME  is queried first.    This means that in a YARN container where the creator set this  environment variable to propagate their identity, the defined  user name is used in preference to the actual user.    In a secure cluster, the kerberos identity of the current user is used. Returns:the encoded shortname of the current user Throws: RuntimeException - if the current user identity cannot be determined  from the OS/kerberos. extractServiceRecords public static Map<String,ServiceRecord> extractServiceRecords(RegistryOperations operations,                                               String parentpath,                                               Collection<RegistryPathStatus> stats)                                                        throws IOException Extract all service records under a list of stat operations...this  skips entries that are too short or simply not matching Parameters:operations - operation support for fetchesparentpath - path of the parent of all the entriesstats - Collection of stat results Returns:a possibly empty map of fullpath:record. Throws: IOException - for any IO Operation that wasn't ignored. extractServiceRecords public static Map<String,ServiceRecord> extractServiceRecords(RegistryOperations operations,                                               String parentpath,                                               Map<String,RegistryPathStatus> stats)                                                        throws IOException Extract all service records under a list of stat operations...this  non-atomic action skips entries that are too short or simply not matching.   Parameters:operations - operation support for fetchesparentpath - path of the parent of all the entries Returns:a possibly empty map of fullpath:record. Throws: IOException - for any IO Operation that wasn't ignored. extractServiceRecords public static Map<String,ServiceRecord> extractServiceRecords(RegistryOperations operations,                                               String parentpath)                                                        throws IOException Extract all service records under a list of stat operations...this  non-atomic action skips entries that are too short or simply not matching.   Parameters:operations - operation support for fetchesparentpath - path of the parent of all the entries Returns:a possibly empty map of fullpath:record. Throws: IOException - for any IO Operation that wasn't ignored. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReleaseSharedCacheResourceRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReleaseSharedCacheResourceRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class ReleaseSharedCacheResourceRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReleaseSharedCacheResourceRequest extends Object The request from clients to release a resource in the shared cache. Constructor Summary Constructors  Constructor and Description ReleaseSharedCacheResourceRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationId getAppId() Get the ApplicationId of the resource to be released. abstract String getResourceKey() Get the key of the resource to be released. abstract void setAppId(ApplicationId id) Set the ApplicationId of the resource to be released. abstract void setResourceKey(String key) Set the key of the resource to be released. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReleaseSharedCacheResourceRequest public ReleaseSharedCacheResourceRequest() Method Detail getAppId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ApplicationId getAppId() Get the ApplicationId of the resource to be released. Returns:ApplicationId setAppId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setAppId(ApplicationId id) Set the ApplicationId of the resource to be released. Parameters:id - ApplicationId getResourceKey @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getResourceKey() Get the key of the resource to be released. Returns:key setResourceKey @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setResourceKey(String key) Set the key of the resource to be released. Parameters:key - unique identifier for the resource Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReleaseSharedCacheResourceResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReleaseSharedCacheResourceResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class ReleaseSharedCacheResourceResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceResponse @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReleaseSharedCacheResourceResponse extends Object  The response to clients from the SharedCacheManager when  releasing a resource in the shared cache.      Currently, this is empty.   Constructor Summary Constructors  Constructor and Description ReleaseSharedCacheResourceResponse()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReleaseSharedCacheResourceResponse public ReleaseSharedCacheResourceResponse() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RemoveScheme (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RemoveScheme (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util.bloom Interface RemoveScheme All Known Implementing Classes: RetouchedBloomFilter @InterfaceAudience.Public @InterfaceStability.Stable public interface RemoveScheme Defines the different remove scheme for retouched Bloom filters.    Originally created by  European Commission One-Lab Project 034819. Field Summary Fields  Modifier and Type Field and Description static short MAXIMUM_FP MaximumFP Selection. static short MINIMUM_FN MinimumFN Selection. static short RANDOM Random selection. static short RATIO Ratio Selection. Field Detail RANDOM static final short RANDOM Random selection.    The idea is to randomly select a bit to reset. See Also:Constant Field Values MINIMUM_FN static final short MINIMUM_FN MinimumFN Selection.    The idea is to select the bit to reset that will generate the minimum  number of false negative. See Also:Constant Field Values MAXIMUM_FP static final short MAXIMUM_FP MaximumFP Selection.    The idea is to select the bit to reset that will remove the maximum number  of false positive. See Also:Constant Field Values RATIO static final short RATIO Ratio Selection.    The idea is to select the bit to reset that will, at the same time, remove  the maximum number of false positve while minimizing the amount of false  negative generated. See Also:Constant Field Values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RenewDelegationTokenRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RenewDelegationTokenRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.v2.api.protocolrecords Interface RenewDelegationTokenRequest @InterfaceAudience.Public @InterfaceStability.Evolving public interface RenewDelegationTokenRequest The request issued by the client to renew a delegation token from  the ResourceManager. Method Summary Methods  Modifier and Type Method and Description Token getDelegationToken()  void setDelegationToken(Token dToken)  Method Detail getDelegationToken Token getDelegationToken() setDelegationToken void setDelegationToken(Token dToken) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RenewDelegationTokenResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RenewDelegationTokenResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.v2.api.protocolrecords Interface RenewDelegationTokenResponse @InterfaceAudience.Public @InterfaceStability.Evolving public interface RenewDelegationTokenResponse The response to a renewDelegationToken call to the ResourceManager. Method Summary Methods  Modifier and Type Method and Description long getNextExpirationTime()  void setNextExpirationTime(long expTime)  Method Detail getNextExpirationTime long getNextExpirationTime() setNextExpirationTime void setNextExpirationTime(long expTime) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Reporter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Reporter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Interface Reporter All Superinterfaces: Progressable @InterfaceAudience.Public @InterfaceStability.Stable public interface Reporter extends Progressable A facility for Map-Reduce applications to report progress and update   counters, status information etc.    Mapper and Reducer can use the Reporter  provided to report progress or just indicate that they are alive. In   scenarios where the application takes significant amount of time to  process individual key/value pairs, this is crucial since the framework   might assume that the task has timed-out and kill that task.  Applications can also update Counters via the provided   Reporter . See Also:Progressable,  Counters Field Summary Fields  Modifier and Type Field and Description static Reporter NULL A constant of Reporter type that does nothing. Method Summary Methods  Modifier and Type Method and Description Counters.Counter getCounter(Enum<?> name) Get the Counters.Counter of the given group with the given name. Counters.Counter getCounter(String group,                     String name) Get the Counters.Counter of the given group with the given name. InputSplit getInputSplit() Get the InputSplit object for a map. float getProgress() Get the progress of the task. void incrCounter(Enum<?> key,                       long amount) Increments the counter identified by the key, which can be of  any Enum type, by the specified amount. void incrCounter(String group,                       String counter,                       long amount) Increments the counter identified by the group and counter name  by the specified amount. void setStatus(String status) Set the status description for the task. Methods inherited from interface org.apache.hadoop.util.Progressable progress Field Detail NULL static final Reporter NULL A constant of Reporter type that does nothing. Method Detail setStatus void setStatus(String status) Set the status description for the task. Parameters:status - brief description of the current status. getCounter Counters.Counter getCounter(Enum<?> name) Get the Counters.Counter of the given group with the given name. Parameters:name - counter name Returns:the Counter of the given group/name. getCounter Counters.Counter getCounter(String group,                           String name) Get the Counters.Counter of the given group with the given name. Parameters:group - counter groupname - counter name Returns:the Counter of the given group/name. incrCounter void incrCounter(Enum<?> key,                long amount) Increments the counter identified by the key, which can be of  any Enum type, by the specified amount. Parameters:key - key to identify the counter to be incremented. The key can be             be any Enum.amount - A non-negative amount by which the counter is to                 be incremented. incrCounter void incrCounter(String group,                String counter,                long amount) Increments the counter identified by the group and counter name  by the specified amount. Parameters:group - name to identify the group of the counter to be incremented.counter - name to identify the counter within the group.amount - A non-negative amount by which the counter is to                 be incremented. getInputSplit InputSplit getInputSplit()                          throws UnsupportedOperationException Get the InputSplit object for a map. Returns:the InputSplit that the map is reading from. Throws: UnsupportedOperationException - if called outside a mapper getProgress float getProgress() Get the progress of the task. Progress is represented as a number between  0 and 1 (inclusive). Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationDefinition (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationDefinition (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ReservationDefinition java.lang.Object org.apache.hadoop.yarn.api.records.ReservationDefinition @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationDefinition extends Object ReservationDefinition captures the set of resource and time  constraints the user cares about regarding a reservation. See Also:ResourceRequest Constructor Summary Constructors  Constructor and Description ReservationDefinition()  Method Summary Methods  Modifier and Type Method and Description abstract long getArrival() Get the arrival time or the earliest time from which the resource(s) can be  allocated. abstract long getDeadline() Get the deadline or the latest time by when the resource(s) must be  allocated. abstract String getReservationName() Get the name for this reservation. abstract ReservationRequests getReservationRequests() Get the list of ReservationRequests representing the resources  required by the application static ReservationDefinition newInstance(long arrival,                       long deadline,                       ReservationRequests reservationRequests,                       String name)  abstract void setArrival(long earliestStartTime) Set the arrival time or the earliest time from which the resource(s) can be  allocated. abstract void setDeadline(long latestEndTime) Set the deadline or the latest time by when the resource(s) must be  allocated. abstract void setReservationName(String name) Set the name for this reservation. abstract void setReservationRequests(ReservationRequests reservationRequests) Set the list of ReservationRequests representing the resources  required by the application Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReservationDefinition public ReservationDefinition() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static ReservationDefinition newInstance(long arrival,                                                                                      long deadline,                                                                                      ReservationRequests reservationRequests,                                                                                      String name) getArrival @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getArrival() Get the arrival time or the earliest time from which the resource(s) can be  allocated. Time expressed as UTC. Returns:the earliest valid time for this reservation setArrival @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setArrival(long earliestStartTime) Set the arrival time or the earliest time from which the resource(s) can be  allocated. Time expressed as UTC. Parameters:earliestStartTime - the earliest valid time for this reservation getDeadline @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getDeadline() Get the deadline or the latest time by when the resource(s) must be  allocated. Time expressed as UTC. Returns:the deadline or the latest time by when the resource(s) must be          allocated setDeadline @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setDeadline(long latestEndTime) Set the deadline or the latest time by when the resource(s) must be  allocated. Time expressed as UTC. Parameters:latestEndTime - the deadline or the latest time by when the           resource(s) should be allocated getReservationRequests @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationRequests getReservationRequests() Get the list of ReservationRequests representing the resources  required by the application Returns:the list of ReservationRequests setReservationRequests @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setReservationRequests(ReservationRequests reservationRequests) Set the list of ReservationRequests representing the resources  required by the application Parameters:reservationRequests - the list of ReservationRequests getReservationName @InterfaceAudience.Public @InterfaceStability.Evolving public abstract String getReservationName() Get the name for this reservation. The name need-not be unique, and it is  just a mnemonic for the user (akin to job names). Accepted reservations are  uniquely identified by a system-generated ReservationId. Returns:string representing the name of the corresponding reserved resource          allocation in the scheduler setReservationName @InterfaceAudience.Public @InterfaceStability.Evolving public abstract void setReservationName(String name) Set the name for this reservation. The name need-not be unique, and it is  just a mnemonic for the user (akin to job names). Accepted reservations are  uniquely identified by a system-generated ReservationId. Parameters:name - representing the name of the corresponding reserved resource           allocation in the scheduler Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationDeleteRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationDeleteRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class ReservationDeleteRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationDeleteRequest extends Object ReservationDeleteRequest captures the set of requirements the user  has to delete an existing reservation. See Also:ReservationDefinition Constructor Summary Constructors  Constructor and Description ReservationDeleteRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ReservationId getReservationId() Get the ReservationId, that corresponds to a valid resource  allocation in the scheduler (between start and end time of this  reservation) static ReservationDeleteRequest newInstance(ReservationId reservationId)  abstract void setReservationId(ReservationId reservationId) Set the ReservationId, that correspond to a valid resource  allocation in the scheduler (between start and end time of this  reservation) Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReservationDeleteRequest public ReservationDeleteRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static ReservationDeleteRequest newInstance(ReservationId reservationId) getReservationId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationId getReservationId() Get the ReservationId, that corresponds to a valid resource  allocation in the scheduler (between start and end time of this  reservation) Returns:the ReservationId representing the unique id of the          corresponding reserved resource allocation in the scheduler setReservationId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setReservationId(ReservationId reservationId) Set the ReservationId, that correspond to a valid resource  allocation in the scheduler (between start and end time of this  reservation) Parameters:reservationId - the ReservationId representing the the unique           id of the corresponding reserved resource allocation in the           scheduler Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationDeleteResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationDeleteResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class ReservationDeleteResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationDeleteResponse extends Object ReservationDeleteResponse contains the answer of the admission  control system in the ResourceManager to a reservation delete  operation. Currently response is empty if the operation was successful, if  not an exception reporting reason for a failure. See Also:ReservationDefinition Constructor Summary Constructors  Constructor and Description ReservationDeleteResponse()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReservationDeleteResponse public ReservationDeleteResponse() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationId (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationId (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ReservationId java.lang.Object org.apache.hadoop.yarn.api.records.ReservationId All Implemented Interfaces: Comparable<ReservationId> @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationId extends Object implements Comparable<ReservationId>  ReservationId represents the globally unique identifier for  a reservation.        The globally unique nature of the identifier is achieved by using the  cluster timestamp i.e. start-time of the ResourceManager  along with a monotonically increasing counter for the reservation.   Field Summary Fields  Modifier and Type Field and Description protected long clusterTimestamp  protected long id  Constructor Summary Constructors  Constructor and Description ReservationId()  Method Summary Methods  Modifier and Type Method and Description protected abstract void build()  int compareTo(ReservationId other)  boolean equals(Object obj)  abstract long getClusterTimestamp() Get the start time of the ResourceManager which is used to  generate globally unique ReservationId. abstract long getId() Get the long identifier of the ReservationId which is unique for  all Reservations started by a particular instance of the  ResourceManager. int hashCode()  static ReservationId parseReservationId(String reservationId) Parse the string argument as a ReservationId String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail clusterTimestamp protected long clusterTimestamp id protected long id Constructor Detail ReservationId public ReservationId() Method Detail getId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getId() Get the long identifier of the ReservationId which is unique for  all Reservations started by a particular instance of the  ResourceManager. Returns:long identifier of the ReservationId getClusterTimestamp @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getClusterTimestamp() Get the start time of the ResourceManager which is used to  generate globally unique ReservationId. Returns:start time of the ResourceManager build protected abstract void build() compareTo public int compareTo(ReservationId other) Specified by: compareTo in interface Comparable<ReservationId> toString public String toString() Overrides: toString in class Object parseReservationId @InterfaceAudience.Public @InterfaceStability.Unstable public static ReservationId parseReservationId(String reservationId)                                         throws IOException Parse the string argument as a ReservationId Parameters:reservationId - the string representation of the ReservationId Returns:the ReservationId corresponding to the input string if          valid, null if input is null Throws: IOException - if unable to parse the input string hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationRequest.ReservationRequestComparator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationRequest.ReservationRequestComparator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ReservationRequest.ReservationRequestComparator java.lang.Object org.apache.hadoop.yarn.api.records.ReservationRequest.ReservationRequestComparator All Implemented Interfaces: Serializable, Comparator<ReservationRequest> Enclosing class: ReservationRequest @InterfaceAudience.Public @InterfaceStability.Unstable public static class ReservationRequest.ReservationRequestComparator extends Object implements Comparator<ReservationRequest>, Serializable See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ReservationRequest.ReservationRequestComparator()  Method Summary Methods  Modifier and Type Method and Description int compare(ReservationRequest r1,               ReservationRequest r2)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface java.util.Comparator equals Constructor Detail ReservationRequest.ReservationRequestComparator public ReservationRequest.ReservationRequestComparator() Method Detail compare public int compare(ReservationRequest r1,           ReservationRequest r2) Specified by: compare in interface Comparator<ReservationRequest> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ReservationRequest java.lang.Object org.apache.hadoop.yarn.api.records.ReservationRequest All Implemented Interfaces: Comparable<ReservationRequest> @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationRequest extends Object implements Comparable<ReservationRequest> ReservationRequest represents the request made by an application to  the ResourceManager to reserve Resources.    It includes:      Resource required for each request.          Number of containers, of above specifications, which are required by the      application.        Concurrency that indicates the gang size of the request.   Nested Class Summary Nested Classes  Modifier and Type Class and Description static class  ReservationRequest.ReservationRequestComparator  Constructor Summary Constructors  Constructor and Description ReservationRequest()  Method Summary Methods  Modifier and Type Method and Description int compareTo(ReservationRequest other)  boolean equals(Object obj)  abstract Resource getCapability() Get the Resource capability of the request. abstract int getConcurrency() Get the number of containers that need to be scheduled concurrently. abstract long getDuration() Get the duration in milliseconds for which the resource is required. abstract int getNumContainers() Get the number of containers required with the given specifications. int hashCode()  static ReservationRequest newInstance(Resource capability,                       int numContainers)  static ReservationRequest newInstance(Resource capability,                       int numContainers,                       int concurrency,                       long duration)  abstract void setCapability(Resource capability) Set the Resource capability of the request abstract void setConcurrency(int numContainers) Set the number of containers that need to be scheduled concurrently. abstract void setDuration(long duration) Set the duration in milliseconds for which the resource is required. abstract void setNumContainers(int numContainers) Set the number of containers required with the given specifications Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReservationRequest public ReservationRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static ReservationRequest newInstance(Resource capability,                                                                                   int numContainers) newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static ReservationRequest newInstance(Resource capability,                                                                                   int numContainers,                                                                                   int concurrency,                                                                                   long duration) getCapability @InterfaceAudience.Public @InterfaceStability.Unstable public abstract Resource getCapability() Get the Resource capability of the request. Returns:Resource capability of the request setCapability @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setCapability(Resource capability) Set the Resource capability of the request Parameters:capability - Resource capability of the request getNumContainers @InterfaceAudience.Public @InterfaceStability.Unstable public abstract int getNumContainers() Get the number of containers required with the given specifications. Returns:number of containers required with the given specifications setNumContainers @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setNumContainers(int numContainers) Set the number of containers required with the given specifications Parameters:numContainers - number of containers required with the given           specifications getConcurrency @InterfaceAudience.Public @InterfaceStability.Unstable public abstract int getConcurrency() Get the number of containers that need to be scheduled concurrently. The  default value of 1 would fall back to the current non concurrency  constraints on the scheduling behavior. Returns:the number of containers to be concurrently scheduled setConcurrency @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setConcurrency(int numContainers) Set the number of containers that need to be scheduled concurrently. The  default value of 1 would fall back to the current non concurrency  constraints on the scheduling behavior. Parameters:numContainers - the number of containers to be concurrently scheduled getDuration @InterfaceAudience.Public @InterfaceStability.Unstable public abstract long getDuration() Get the duration in milliseconds for which the resource is required. A  default value of -1, indicates an unspecified lease duration, and fallback  to current behavior. Returns:the duration in milliseconds for which the resource is required setDuration @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setDuration(long duration) Set the duration in milliseconds for which the resource is required. Parameters:duration - the duration in milliseconds for which the resource is           required hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object compareTo public int compareTo(ReservationRequest other) Specified by: compareTo in interface Comparable<ReservationRequest> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationRequestInterpreter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationRequestInterpreter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum ReservationRequestInterpreter java.lang.Object java.lang.Enum<ReservationRequestInterpreter> org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter All Implemented Interfaces: Serializable, Comparable<ReservationRequestInterpreter> @InterfaceAudience.Public @InterfaceStability.Evolving public enum ReservationRequestInterpreter extends Enum<ReservationRequestInterpreter> Enumeration of various types of dependencies among multiple  ReservationRequests within one ReservationDefinition (from  least constraining to most constraining). Enum Constant Summary Enum Constants  Enum Constant and Description R_ALL Requires that ALL of the ReservationRequest submitted as part of a  ReservationDefinition are satisfied for the overall  ReservationDefinition to be satisfied. R_ANY Requires that exactly ONE among the ReservationRequest submitted as  of a ReservationDefinition is satisfied to satisfy the overall  ReservationDefinition. R_ORDER Requires that ALL of the ReservationRequest submitted as part of a  ReservationDefinition are satisfied for the overall  ReservationDefinition to be satisfied. R_ORDER_NO_GAP Requires that ALL of the ReservationRequest submitted as part of a  ReservationDefinition are satisfied for the overall  ReservationDefinition to be satisfied. Method Summary Methods  Modifier and Type Method and Description static ReservationRequestInterpreter valueOf(String name) Returns the enum constant of this type with the specified name. static ReservationRequestInterpreter[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail R_ANY public static final ReservationRequestInterpreter R_ANY Requires that exactly ONE among the ReservationRequest submitted as  of a ReservationDefinition is satisfied to satisfy the overall  ReservationDefinition.    WHEN TO USE THIS: This is useful when the user have multiple equivalent  ways to run an application, and wants to expose to the ReservationAgent  such flexibility. For example an application could use one  <32GB,16core> container for 10min, or 16 <2GB,1core>  containers for 15min, the ReservationAgent will decide which one of the  two it is best for the system to place. R_ALL public static final ReservationRequestInterpreter R_ALL Requires that ALL of the ReservationRequest submitted as part of a  ReservationDefinition are satisfied for the overall  ReservationDefinition to be satisfied. No constraints are imposed  on the temporal ordering of the allocation used to satisfy the  ResourceRequests.    WHEN TO USE THIS: This is useful to capture a scenario in which the user  cares for multiple ReservationDefinition to be all accepted, or none. For  example, a user might want a reservation R1: with 10 x  <8GB,4core> for 10min, and a reservation R2:  with 2 <1GB,1core> for 1h, and only if both are satisfied  the workflow run in this reservation succeeds. The key differentiator  from ALL and ORDER, ORDER_NO_GAP, is that ALL imposes no restrictions  on the relative allocations used to place R1 and R2 above. R_ORDER public static final ReservationRequestInterpreter R_ORDER Requires that ALL of the ReservationRequest submitted as part of a  ReservationDefinition are satisfied for the overall  ReservationDefinition to be satisfied. Moreover, it imposes a  strict temporal ordering on the allocation used to satisfy the  ReservationRequests. The allocations satisfying the  ReservationRequest in position k must strictly precede the  allocations for the ReservationRequest at position k+1. No  constraints are imposed on temporal gaps between subsequent allocations  (the last instant of the previous allocation can be an arbitrary long  period of time before the first instant of the subsequent allocation).    WHEN TO USE THIS: Like ALL this requires all ReservationDefinitions to be  placed, but it also imposes a time ordering on the allocations used. This  is important if the ReservationDefinition(s) are used to describe a  workflow with inherent inter-stage dependencies. For example, a first job  runs in a ReservaitonDefinition R1 (10 x <1GB,1core>  for 20min), and its output is consumed by a second job described by  a ReservationDefinition R2 (5 x <1GB,1core>) for 50min).  R2 allocation cannot overlap R1, as R2 models a job depending on  the output of the job modeled by R1. R_ORDER_NO_GAP public static final ReservationRequestInterpreter R_ORDER_NO_GAP Requires that ALL of the ReservationRequest submitted as part of a  ReservationDefinition are satisfied for the overall  ReservationDefinition to be satisfied. Moreover, it imposes a  strict temporal ordering on the allocation used to satisfy the  ReservationRequests. It imposes a strict temporal ordering on the  allocation used to satisfy the ReservationRequests. The allocations  satisfying the ReservationRequest in position k must strictly  precede the allocations for the ReservationRequest at position k+1.  Moreover it imposes a "zero-size gap" between subsequent allocations, i.e.,  the last instant in time of the allocations associated with the  ReservationRequest at position k must be exactly preceding the  first instant in time of the ReservationRequest at position k+1.  Time ranges are interpreted as [a,b) inclusive left, exclusive right.    WHEN TO USE THIS: This is a stricter version of R_ORDER, which allows no  gaps between the allocations that satisfy R1 and R2. The use of this is  twofold: 1) prevent long gaps between subsequent stages that produce very  large intermediate output (e.g., the output of R1 is too large to be kept  around for long before the job running in R2 consumes it, and disposes of  it), 2) if the job being modeled has a time-varying resource need, one can  combine multiple ResourceDefinition each approximating a portion of the job  execution (think of using multiple rectangular bounding boxes to described  an arbitrarily shaped area). By asking for no-gaps we guarantee  "continuity" of resources given to this job. This still allow for some  flexibility, as the entire "train" of allocations can be moved rigidly back  or forth within the start-deadline time range (if there is slack). Method Detail values public static ReservationRequestInterpreter[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (ReservationRequestInterpreter c : ReservationRequestInterpreter.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static ReservationRequestInterpreter valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationRequests (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationRequests (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ReservationRequests java.lang.Object org.apache.hadoop.yarn.api.records.ReservationRequests @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationRequests extends Object ReservationRequests captures the set of resource and constraints the  user cares about regarding a reservation. See Also:ReservationRequest Constructor Summary Constructors  Constructor and Description ReservationRequests()  Method Summary Methods  Modifier and Type Method and Description abstract ReservationRequestInterpreter getInterpreter() Get the ReservationRequestInterpreter, representing how the list of  resources should be allocated, this captures temporal ordering and other  constraints. abstract List<ReservationRequest> getReservationResources() Get the list of ReservationRequest representing the resources  required by the application static ReservationRequests newInstance(List<ReservationRequest> reservationResources,                       ReservationRequestInterpreter type)  abstract void setInterpreter(ReservationRequestInterpreter interpreter) Set the ReservationRequestInterpreter, representing how the list of  resources should be allocated, this captures temporal ordering and other  constraints. abstract void setReservationResources(List<ReservationRequest> reservationResources) Set the list of ReservationRequest representing the resources  required by the application Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReservationRequests public ReservationRequests() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static ReservationRequests newInstance(List<ReservationRequest> reservationResources,                                                                                    ReservationRequestInterpreter type) getReservationResources @InterfaceAudience.Public @InterfaceStability.Unstable public abstract List<ReservationRequest> getReservationResources() Get the list of ReservationRequest representing the resources  required by the application Returns:the list of ReservationRequest setReservationResources @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setReservationResources(List<ReservationRequest> reservationResources) Set the list of ReservationRequest representing the resources  required by the application Parameters:reservationResources - the list of ReservationRequest getInterpreter @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationRequestInterpreter getInterpreter() Get the ReservationRequestInterpreter, representing how the list of  resources should be allocated, this captures temporal ordering and other  constraints. Returns:the list of ReservationRequestInterpreter setInterpreter @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setInterpreter(ReservationRequestInterpreter interpreter) Set the ReservationRequestInterpreter, representing how the list of  resources should be allocated, this captures temporal ordering and other  constraints. Parameters:interpreter - the ReservationRequestInterpreter for this           reservation Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationSubmissionRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationSubmissionRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class ReservationSubmissionRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationSubmissionRequest extends Object ReservationSubmissionRequest captures the set of requirements the  user has to create a reservation. See Also:ReservationDefinition Constructor Summary Constructors  Constructor and Description ReservationSubmissionRequest()  Method Summary Methods  Modifier and Type Method and Description abstract String getQueue() Get the name of the Plan that corresponds to the name of the  QueueInfo in the scheduler to which the reservation will be  submitted to. abstract ReservationDefinition getReservationDefinition() Get the ReservationDefinition representing the user constraints for  this reservation static ReservationSubmissionRequest newInstance(ReservationDefinition reservationDefinition,                       String queueName)  abstract void setQueue(String queueName) Set the name of the Plan that corresponds to the name of the  QueueInfo in the scheduler to which the reservation will be  submitted to abstract void setReservationDefinition(ReservationDefinition reservationDefinition) Set the ReservationDefinition representing the user constraints for  this reservation Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReservationSubmissionRequest public ReservationSubmissionRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static ReservationSubmissionRequest newInstance(ReservationDefinition reservationDefinition,                                                                                             String queueName) getReservationDefinition @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationDefinition getReservationDefinition() Get the ReservationDefinition representing the user constraints for  this reservation Returns:the reservation definition representing user constraints setReservationDefinition @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setReservationDefinition(ReservationDefinition reservationDefinition) Set the ReservationDefinition representing the user constraints for  this reservation Parameters:reservationDefinition - the reservation request representing the           reservation getQueue @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getQueue() Get the name of the Plan that corresponds to the name of the  QueueInfo in the scheduler to which the reservation will be  submitted to. Returns:the name of the Plan that corresponds to the name of the          QueueInfo in the scheduler to which the reservation will be          submitted to setQueue @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setQueue(String queueName) Set the name of the Plan that corresponds to the name of the  QueueInfo in the scheduler to which the reservation will be  submitted to Parameters:queueName - the name of the parent Plan that corresponds to           the name of the QueueInfo in the scheduler to which the           reservation will be submitted to Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationSubmissionResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationSubmissionResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class ReservationSubmissionResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationSubmissionResponse extends Object ReservationSubmissionResponse contains the answer of the admission  control system in the ResourceManager to a reservation create  operation. Response contains a ReservationId if the operation was  successful, if not an exception reporting reason for a failure. See Also:ReservationDefinition Constructor Summary Constructors  Constructor and Description ReservationSubmissionResponse()  Method Summary Methods  Modifier and Type Method and Description abstract ReservationId getReservationId() Get the ReservationId, that corresponds to a valid resource  allocation in the scheduler (between start and end time of this  reservation) Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReservationSubmissionResponse public ReservationSubmissionResponse() Method Detail getReservationId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationId getReservationId() Get the ReservationId, that corresponds to a valid resource  allocation in the scheduler (between start and end time of this  reservation) Returns:the ReservationId representing the unique id of the          corresponding reserved resource allocation in the scheduler Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationUpdateRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationUpdateRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class ReservationUpdateRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationUpdateRequest extends Object ReservationUpdateRequest captures the set of requirements the user  has to update an existing reservation. See Also:ReservationDefinition Constructor Summary Constructors  Constructor and Description ReservationUpdateRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ReservationDefinition getReservationDefinition() Get the ReservationDefinition representing the updated user  constraints for this reservation abstract ReservationId getReservationId() Get the ReservationId, that corresponds to a valid resource  allocation in the scheduler (between start and end time of this  reservation) static ReservationUpdateRequest newInstance(ReservationDefinition reservationDefinition,                       ReservationId reservationId)  abstract void setReservationDefinition(ReservationDefinition reservationDefinition) Set the ReservationDefinition representing the updated user  constraints for this reservation abstract void setReservationId(ReservationId reservationId) Set the ReservationId, that correspond to a valid resource  allocation in the scheduler (between start and end time of this  reservation) Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReservationUpdateRequest public ReservationUpdateRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Unstable public static ReservationUpdateRequest newInstance(ReservationDefinition reservationDefinition,                                                                                         ReservationId reservationId) getReservationDefinition @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationDefinition getReservationDefinition() Get the ReservationDefinition representing the updated user  constraints for this reservation Returns:the reservation definition representing user constraints setReservationDefinition @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setReservationDefinition(ReservationDefinition reservationDefinition) Set the ReservationDefinition representing the updated user  constraints for this reservation Parameters:reservationDefinition - the reservation request representing the           reservation getReservationId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationId getReservationId() Get the ReservationId, that corresponds to a valid resource  allocation in the scheduler (between start and end time of this  reservation) Returns:the ReservationId representing the unique id of the          corresponding reserved resource allocation in the scheduler setReservationId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setReservationId(ReservationId reservationId) Set the ReservationId, that correspond to a valid resource  allocation in the scheduler (between start and end time of this  reservation) Parameters:reservationId - the ReservationId representing the the unique           id of the corresponding reserved resource allocation in the           scheduler Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ReservationUpdateResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ReservationUpdateResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class ReservationUpdateResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class ReservationUpdateResponse extends Object ReservationUpdateResponse contains the answer of the admission  control system in the ResourceManager to a reservation update  operation. Currently response is empty if the operation was successful, if  not an exception reporting reason for a failure. See Also:ReservationDefinition Constructor Summary Constructors  Constructor and Description ReservationUpdateResponse()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ReservationUpdateResponse public ReservationUpdateResponse() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ResetableIterator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ResetableIterator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Interface ResetableIterator<T extends Writable> All Known Subinterfaces: ResetableIterator<T> All Known Implementing Classes: ArrayListBackedIterator, ArrayListBackedIterator, StreamBackedIterator, StreamBackedIterator @InterfaceAudience.Public @InterfaceStability.Stable public interface ResetableIterator<T extends Writable> This defines an interface to a stateful Iterator that can replay elements  added to it directly.  Note that this does not extend Iterator. Method Summary Methods  Modifier and Type Method and Description void add(T item) Add an element to the collection of elements to iterate over. void clear() Close datasources, but do not release internal resources. void close() Close datasources and release resources. boolean hasNext() True if a call to next may return a value. boolean next(T val) Assign next value to actual. boolean replay(T val) Assign last value returned to actual. void reset() Set iterator to return to the start of its range. Method Detail hasNext boolean hasNext() True if a call to next may return a value. This is permitted false  positives, but not false negatives. next boolean next(T val)              throws IOException Assign next value to actual.  It is required that elements added to a ResetableIterator be returned in  the same order after a call to reset() (FIFO).  Note that a call to this may fail for nested joins (i.e. more elements  available, but none satisfying the constraints of the join) Throws: IOException replay boolean replay(T val)                throws IOException Assign last value returned to actual. Throws: IOException reset void reset() Set iterator to return to the start of its range. Must be called after  calling add(T) to avoid a ConcurrentModificationException. add void add(T item)          throws IOException Add an element to the collection of elements to iterate over. Throws: IOException close void close()            throws IOException Close datasources and release resources. Calling methods on the iterator  after calling close has undefined behavior. Throws: IOException clear void clear() Close datasources, but do not release internal resources. Calling this  method should permit the object to be reused with a different datasource. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Resource (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Resource (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class Resource java.lang.Object org.apache.hadoop.yarn.api.records.Resource All Implemented Interfaces: Comparable<Resource> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class Resource extends Object implements Comparable<Resource> Resource models a set of computer resources in the   cluster.    Currently it models both memory and CPU.    The unit for memory is megabytes. CPU is modeled with virtual cores  (vcores), a unit for expressing parallelism. A node's capacity should  be configured with virtual cores equal to its number of physical cores. A  container should be requested with the number of cores it can saturate, i.e.  the average number of threads it expects to have runnable at a time.    Virtual cores take integer values and thus currently CPU-scheduling is  very coarse.  A complementary axis for CPU requests that represents processing  power will likely be added in the future to enable finer-grained resource  configuration.    Typically, applications request Resource of suitable  capability to run their component tasks. See Also:ResourceRequest,  ApplicationMasterProtocol.allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest) Constructor Summary Constructors  Constructor and Description Resource()  Method Summary Methods  Modifier and Type Method and Description boolean equals(Object obj)  abstract int getMemory() Get memory of the resource. abstract int getVirtualCores() Get number of virtual cpu cores of the resource. int hashCode()  static Resource newInstance(int memory,                       int vCores)  abstract void setMemory(int memory) Set memory of the resource. abstract void setVirtualCores(int vCores) Set number of virtual cpu cores of the resource. String toString()  Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Methods inherited from interface java.lang.Comparable compareTo Constructor Detail Resource public Resource() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static Resource newInstance(int memory,                                                                       int vCores) getMemory @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getMemory() Get memory of the resource. Returns:memory of the resource setMemory @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setMemory(int memory) Set memory of the resource. Parameters:memory - memory of the resource getVirtualCores @InterfaceAudience.Public @InterfaceStability.Evolving public abstract int getVirtualCores() Get number of virtual cpu cores of the resource.    Virtual cores are a unit for expressing CPU parallelism. A node's capacity  should be configured with virtual cores equal to its number of physical cores.  A container should be requested with the number of cores it can saturate, i.e.  the average number of threads it expects to have runnable at a time. Returns:num of virtual cpu cores of the resource setVirtualCores @InterfaceAudience.Public @InterfaceStability.Evolving public abstract void setVirtualCores(int vCores) Set number of virtual cpu cores of the resource.    Virtual cores are a unit for expressing CPU parallelism. A node's capacity  should be configured with virtual cores equal to its number of physical cores.  A container should be requested with the number of cores it can saturate, i.e.  the average number of threads it expects to have runnable at a time. Parameters:vCores - number of virtual cpu cores of the resource hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ResourceBlacklistRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ResourceBlacklistRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ResourceBlacklistRequest java.lang.Object org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ResourceBlacklistRequest extends Object ResourceBlacklistRequest encapsulates the list of resource-names   which should be added or removed from the blacklist of resources   for the application. See Also:ResourceRequest,  ApplicationMasterProtocol.allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest) Constructor Summary Constructors  Constructor and Description ResourceBlacklistRequest()  Method Summary Methods  Modifier and Type Method and Description abstract List<String> getBlacklistAdditions() Get the list of resource-names which should be added to the   application blacklist. abstract List<String> getBlacklistRemovals() Get the list of resource-names which should be removed from the   application blacklist. static ResourceBlacklistRequest newInstance(List<String> additions,                       List<String> removals)  abstract void setBlacklistAdditions(List<String> resourceNames) Set list of resource-names which should be added to the application blacklist. abstract void setBlacklistRemovals(List<String> resourceNames) Set list of resource-names which should be removed from the   application blacklist. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ResourceBlacklistRequest public ResourceBlacklistRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ResourceBlacklistRequest newInstance(List<String> additions,                                                                                       List<String> removals) getBlacklistAdditions @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<String> getBlacklistAdditions() Get the list of resource-names which should be added to the   application blacklist. Returns:list of resource-names which should be added to the           application blacklist setBlacklistAdditions @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setBlacklistAdditions(List<String> resourceNames) Set list of resource-names which should be added to the application blacklist. Parameters:resourceNames - list of resource-names which should be added to the                    application blacklist getBlacklistRemovals @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<String> getBlacklistRemovals() Get the list of resource-names which should be removed from the   application blacklist. Returns:list of resource-names which should be removed from the           application blacklist setBlacklistRemovals @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setBlacklistRemovals(List<String> resourceNames) Set list of resource-names which should be removed from the   application blacklist. Parameters:resourceNames - list of resource-names which should be removed from the                    application blacklist Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ResourceCalculatorProcessTree (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ResourceCalculatorProcessTree (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.util Class ResourceCalculatorProcessTree java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.yarn.util.ResourceCalculatorProcessTree All Implemented Interfaces: Configurable @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class ResourceCalculatorProcessTree extends Configured Interface class to obtain process resource usage  NOTE: This class should not be used by external users, but only by external  developers to extend and include their own process-tree implementation,   especially for platforms other than Linux and Windows. Field Summary Fields  Modifier and Type Field and Description static int UNAVAILABLE  Constructor Summary Constructors  Constructor and Description ResourceCalculatorProcessTree(String root) Create process-tree instance with specified root process. Method Summary Methods  Modifier and Type Method and Description abstract boolean checkPidPgrpidForMatch() Verify that the tree process id is same as its process group id. float getCpuUsagePercent() Get the CPU usage by all the processes in the process-tree based on  average between samples as a ratio of overall CPU cycles similar to top. long getCumulativeCpuTime() Get the CPU time in millisecond used by all the processes in the  process-tree since the process-tree was created long getCumulativeRssmem() Deprecated.  long getCumulativeRssmem(int olderThanAge) Deprecated.  long getCumulativeVmem() Deprecated.  long getCumulativeVmem(int olderThanAge) Deprecated.  abstract String getProcessTreeDump() Get a dump of the process-tree. static ResourceCalculatorProcessTree getResourceCalculatorProcessTree(String pid,                                                                 Class<? extends ResourceCalculatorProcessTree> clazz,                                                                 Configuration conf) Create the ResourceCalculatorProcessTree rooted to specified process   from the class name and configure it. long getRssMemorySize() Get the resident set size (rss) memory used by all the processes  in the process-tree. long getRssMemorySize(int olderThanAge) Get the resident set size (rss) memory used by all the processes  in the process-tree that are older than the passed in age. long getVirtualMemorySize() Get the virtual memory used by all the processes in the  process-tree. long getVirtualMemorySize(int olderThanAge) Get the virtual memory used by all the processes in the  process-tree that are older than the passed in age. abstract void updateProcessTree() Update the process-tree with latest state. Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail UNAVAILABLE public static final int UNAVAILABLE See Also:Constant Field Values Constructor Detail ResourceCalculatorProcessTree public ResourceCalculatorProcessTree(String root) Create process-tree instance with specified root process.  Subclass must override this. Parameters:root - process-tree root-process Method Detail updateProcessTree public abstract void updateProcessTree() Update the process-tree with latest state.  Each call to this function should increment the age of the running  processes that already exist in the process tree. Age is used other API's  of the interface. getProcessTreeDump public abstract String getProcessTreeDump() Get a dump of the process-tree. Returns:a string concatenating the dump of information of all the processes          in the process-tree getVirtualMemorySize public long getVirtualMemorySize() Get the virtual memory used by all the processes in the  process-tree. Returns:virtual memory used by the process-tree in bytes,  UNAVAILABLE if it cannot be calculated. getCumulativeVmem @Deprecated public long getCumulativeVmem() Deprecated.  Get the virtual memory used by all the processes in the  process-tree. Returns:virtual memory used by the process-tree in bytes,  UNAVAILABLE if it cannot be calculated. getRssMemorySize public long getRssMemorySize() Get the resident set size (rss) memory used by all the processes  in the process-tree. Returns:rss memory used by the process-tree in bytes,  UNAVAILABLE if it cannot be calculated. getCumulativeRssmem @Deprecated public long getCumulativeRssmem() Deprecated.  Get the resident set size (rss) memory used by all the processes  in the process-tree. Returns:rss memory used by the process-tree in bytes,  UNAVAILABLE if it cannot be calculated. getVirtualMemorySize public long getVirtualMemorySize(int olderThanAge) Get the virtual memory used by all the processes in the  process-tree that are older than the passed in age. Parameters:olderThanAge - processes above this age are included in the                      memory addition Returns:virtual memory used by the process-tree in bytes for  processes older than the specified age, UNAVAILABLE if it  cannot be calculated. getCumulativeVmem @Deprecated public long getCumulativeVmem(int olderThanAge) Deprecated.  Get the virtual memory used by all the processes in the  process-tree that are older than the passed in age. Parameters:olderThanAge - processes above this age are included in the                      memory addition Returns:virtual memory used by the process-tree in bytes for  processes older than the specified age, UNAVAILABLE if it  cannot be calculated. getRssMemorySize public long getRssMemorySize(int olderThanAge) Get the resident set size (rss) memory used by all the processes  in the process-tree that are older than the passed in age. Parameters:olderThanAge - processes above this age are included in the                      memory addition Returns:rss memory used by the process-tree in bytes for  processes older than specified age, UNAVAILABLE if it cannot be  calculated. getCumulativeRssmem @Deprecated public long getCumulativeRssmem(int olderThanAge) Deprecated.  Get the resident set size (rss) memory used by all the processes  in the process-tree that are older than the passed in age. Parameters:olderThanAge - processes above this age are included in the                      memory addition Returns:rss memory used by the process-tree in bytes for  processes older than specified age, UNAVAILABLE if it cannot be  calculated. getCumulativeCpuTime public long getCumulativeCpuTime() Get the CPU time in millisecond used by all the processes in the  process-tree since the process-tree was created Returns:cumulative CPU time in millisecond since the process-tree  created, UNAVAILABLE if it cannot be calculated. getCpuUsagePercent public float getCpuUsagePercent() Get the CPU usage by all the processes in the process-tree based on  average between samples as a ratio of overall CPU cycles similar to top.  Thus, if 2 out of 4 cores are used this should return 200.0. Returns:percentage CPU usage since the process-tree was created,  UNAVAILABLE if it cannot be calculated. checkPidPgrpidForMatch public abstract boolean checkPidPgrpidForMatch() Verify that the tree process id is same as its process group id. Returns:true if the process id matches else return false. getResourceCalculatorProcessTree public static ResourceCalculatorProcessTree getResourceCalculatorProcessTree(String pid,                                                              Class<? extends ResourceCalculatorProcessTree> clazz,                                                              Configuration conf) Create the ResourceCalculatorProcessTree rooted to specified process   from the class name and configure it. If class name is null, this method  will try and return a process tree plugin available for this system. Parameters:pid - process pid of the root of the process treeclazz - class-nameconf - configure the plugin with this. Returns:ResourceCalculatorProcessTree or null if ResourceCalculatorPluginTree          is not available for this system. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ResourceOption (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ResourceOption (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ResourceOption java.lang.Object org.apache.hadoop.yarn.api.records.ResourceOption @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class ResourceOption extends Object Constructor Summary Constructors  Constructor and Description ResourceOption()  Method Summary Methods  Modifier and Type Method and Description static ResourceOption newInstance(Resource resource,                       int overCommitTimeout)  String toString()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ResourceOption public ResourceOption() Method Detail newInstance public static ResourceOption newInstance(Resource resource,                          int overCommitTimeout) toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ResourceRequest.ResourceRequestComparator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ResourceRequest.ResourceRequestComparator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ResourceRequest.ResourceRequestComparator java.lang.Object org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestComparator All Implemented Interfaces: Serializable, Comparator<ResourceRequest> Enclosing class: ResourceRequest @InterfaceAudience.Public @InterfaceStability.Stable public static class ResourceRequest.ResourceRequestComparator extends Object implements Comparator<ResourceRequest>, Serializable See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ResourceRequest.ResourceRequestComparator()  Method Summary Methods  Modifier and Type Method and Description int compare(ResourceRequest r1,               ResourceRequest r2)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface java.util.Comparator equals Constructor Detail ResourceRequest.ResourceRequestComparator public ResourceRequest.ResourceRequestComparator() Method Detail compare public int compare(ResourceRequest r1,           ResourceRequest r2) Specified by: compare in interface Comparator<ResourceRequest> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ResourceRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ResourceRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class ResourceRequest java.lang.Object org.apache.hadoop.yarn.api.records.ResourceRequest All Implemented Interfaces: Comparable<ResourceRequest> @InterfaceAudience.Public @InterfaceStability.Stable public abstract class ResourceRequest extends Object implements Comparable<ResourceRequest> ResourceRequest represents the request made  by an application to the ResourceManager  to obtain various Container allocations.    It includes:      Priority of the request.          The name of the machine or rack on which the allocation is      desired. A special value of * signifies that      any host/rack is acceptable to the application.        Resource required for each request.          Number of containers, of above specifications, which are required      by the application.              A boolean relaxLocality flag, defaulting to true,      which tells the ResourceManager if the application wants      locality to be loose (i.e. allows fall-through to rack or any)      or strict (i.e. specify hard constraint on resource allocation).       See Also:Resource,  ApplicationMasterProtocol.allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest) Nested Class Summary Nested Classes  Modifier and Type Class and Description static class  ResourceRequest.ResourceRequestComparator  Field Summary Fields  Modifier and Type Field and Description static String ANY The constant string representing no locality. Constructor Summary Constructors  Constructor and Description ResourceRequest()  Method Summary Methods  Modifier and Type Method and Description int compareTo(ResourceRequest other)  boolean equals(Object obj)  abstract Resource getCapability() Get the Resource capability of the request. abstract String getNodeLabelExpression() Get node-label-expression for this Resource Request. abstract int getNumContainers() Get the number of containers required with the given specifications. abstract Priority getPriority() Get the Priority of the request. abstract boolean getRelaxLocality() Get whether locality relaxation is enabled with this  ResourceRequest. abstract String getResourceName() Get the resource (e.g. int hashCode()  static boolean isAnyLocation(String hostName) Check whether the given host/rack string represents an arbitrary  host name. static ResourceRequest newInstance(Priority priority,                       String hostName,                       Resource capability,                       int numContainers)  static ResourceRequest newInstance(Priority priority,                       String hostName,                       Resource capability,                       int numContainers,                       boolean relaxLocality)  static ResourceRequest newInstance(Priority priority,                       String hostName,                       Resource capability,                       int numContainers,                       boolean relaxLocality,                       String labelExpression)  abstract void setCapability(Resource capability) Set the Resource capability of the request abstract void setNodeLabelExpression(String nodelabelExpression) Set node label expression of this resource request. abstract void setNumContainers(int numContainers) Set the number of containers required with the given specifications abstract void setPriority(Priority priority) Set the Priority of the request abstract void setRelaxLocality(boolean relaxLocality) For a request at a network hierarchy level, set whether locality can be relaxed  to that level and beyond. abstract void setResourceName(String resourceName) Set the resource name (e.g. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Field Detail ANY public static final String ANY The constant string representing no locality.  It should be used by all references that want to pass an arbitrary host  name in. See Also:Constant Field Values Constructor Detail ResourceRequest public ResourceRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ResourceRequest newInstance(Priority priority,                                                                              String hostName,                                                                              Resource capability,                                                                              int numContainers) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ResourceRequest newInstance(Priority priority,                                                                              String hostName,                                                                              Resource capability,                                                                              int numContainers,                                                                              boolean relaxLocality) newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static ResourceRequest newInstance(Priority priority,                                                                              String hostName,                                                                              Resource capability,                                                                              int numContainers,                                                                              boolean relaxLocality,                                                                              String labelExpression) isAnyLocation @InterfaceAudience.Public @InterfaceStability.Stable public static boolean isAnyLocation(String hostName) Check whether the given host/rack string represents an arbitrary  host name. Parameters:hostName - host/rack on which the allocation is desired Returns:whether the given host/rack string represents an arbitrary  host name getPriority @InterfaceAudience.Public @InterfaceStability.Stable public abstract Priority getPriority() Get the Priority of the request. Returns:Priority of the request setPriority @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setPriority(Priority priority) Set the Priority of the request Parameters:priority - Priority of the request getResourceName @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getResourceName() Get the resource (e.g. host/rack) on which the allocation   is desired.    A special value of * signifies that any resource   (host/rack) is acceptable. Returns:resource (e.g. host/rack) on which the allocation                    is desired setResourceName @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setResourceName(String resourceName) Set the resource name (e.g. host/rack) on which the allocation   is desired.    A special value of * signifies that any resource name  (e.g. host/rack) is acceptable. Parameters:resourceName - (e.g. host/rack) on which the                       allocation is desired getCapability @InterfaceAudience.Public @InterfaceStability.Stable public abstract Resource getCapability() Get the Resource capability of the request. Returns:Resource capability of the request setCapability @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setCapability(Resource capability) Set the Resource capability of the request Parameters:capability - Resource capability of the request getNumContainers @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getNumContainers() Get the number of containers required with the given specifications. Returns:number of containers required with the given specifications setNumContainers @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setNumContainers(int numContainers) Set the number of containers required with the given specifications Parameters:numContainers - number of containers required with the given                        specifications getRelaxLocality @InterfaceAudience.Public @InterfaceStability.Stable public abstract boolean getRelaxLocality() Get whether locality relaxation is enabled with this  ResourceRequest. Defaults to true. Returns:whether locality relaxation is enabled with this  ResourceRequest. setRelaxLocality @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setRelaxLocality(boolean relaxLocality) For a request at a network hierarchy level, set whether locality can be relaxed  to that level and beyond.    If the flag is off on a rack-level ResourceRequest,  containers at that request's priority will not be assigned to nodes on that  request's rack unless requests specifically for those nodes have also been  submitted.    If the flag is off on an ANY-level  ResourceRequest, containers at that request's priority will  only be assigned on racks for which specific requests have also been  submitted.    For example, to request a container strictly on a specific node, the  corresponding rack-level and any-level requests should have locality  relaxation set to false.  Similarly, to request a container strictly on a  specific rack, the corresponding any-level request should have locality  relaxation set to false. Parameters:relaxLocality - whether locality relaxation is enabled with this  ResourceRequest. getNodeLabelExpression @InterfaceAudience.Public @InterfaceStability.Evolving public abstract String getNodeLabelExpression() Get node-label-expression for this Resource Request. If this is set, all  containers allocated to satisfy this resource-request will be only on those  nodes that satisfy this node-label-expression.     Please note that node label expression now can only take effect when the  resource request has resourceName = ANY Returns:node-label-expression setNodeLabelExpression @InterfaceAudience.Public @InterfaceStability.Evolving public abstract void setNodeLabelExpression(String nodelabelExpression) Set node label expression of this resource request. Now only support  specifying a single node label. In the future we will support more complex  node label expression specification like AND(&&), OR(||), etc.    Any please note that node label expression now can only take effect when  the resource request has resourceName = ANY Parameters:nodelabelExpression - node-label-expression of this ResourceRequest hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object compareTo public int compareTo(ResourceRequest other) Specified by: compareTo in interface Comparable<ResourceRequest> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RetouchedBloomFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RetouchedBloomFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util.bloom Class RetouchedBloomFilter java.lang.Object org.apache.hadoop.util.bloom.Filter org.apache.hadoop.util.bloom.BloomFilter org.apache.hadoop.util.bloom.RetouchedBloomFilter All Implemented Interfaces: Writable, RemoveScheme @InterfaceAudience.Public @InterfaceStability.Stable public final class RetouchedBloomFilter extends BloomFilter implements RemoveScheme Implements a retouched Bloom filter, as defined in the CoNEXT 2006 paper.    It allows the removal of selected false positives at the cost of introducing  random false negatives, and with the benefit of eliminating some random false  positives at the same time.      Originally created by  European Commission One-Lab Project 034819. See Also:The general behavior of a filter,  A Bloom filter,  The different selective clearing algorithms,  Retouched Bloom Filters: Allowing Networked Applications to Trade Off Selected False Positives Against False Negatives Field Summary Fields inherited from class org.apache.hadoop.util.bloom.Filter hash, hashType, nbHash, vectorSize Fields inherited from interface org.apache.hadoop.util.bloom.RemoveScheme MAXIMUM_FP, MINIMUM_FN, RANDOM, RATIO Constructor Summary Constructors  Constructor and Description RetouchedBloomFilter() Default constructor - use with readFields RetouchedBloomFilter(int vectorSize,                                         int nbHash,                                         int hashType) Constructor Method Summary Methods  Modifier and Type Method and Description void add(org.apache.hadoop.util.bloom.Key key) Adds a key to this filter. void addFalsePositive(Collection<org.apache.hadoop.util.bloom.Key> coll) Adds a collection of false positive information to this retouched Bloom filter. void addFalsePositive(org.apache.hadoop.util.bloom.Key key) Adds a false positive information to this retouched Bloom filter. void addFalsePositive(org.apache.hadoop.util.bloom.Key[] keys) Adds an array of false positive information to this retouched Bloom filter. void addFalsePositive(List<org.apache.hadoop.util.bloom.Key> keys) Adds a list of false positive information to this retouched Bloom filter. void readFields(DataInput in) Deserialize the fields of this object from in. void selectiveClearing(org.apache.hadoop.util.bloom.Key k,                                   short scheme) Performs the selective clearing for a given key. void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.util.bloom.BloomFilter and, getVectorSize, membershipTest, not, or, toString, xor Methods inherited from class org.apache.hadoop.util.bloom.Filter add, add, add Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail RetouchedBloomFilter public RetouchedBloomFilter() Default constructor - use with readFields RetouchedBloomFilter public RetouchedBloomFilter(int vectorSize,                     int nbHash,                     int hashType) Constructor Parameters:vectorSize - The vector size of this filter.nbHash - The number of hash function to consider.hashType - type of the hashing function (see  Hash). Method Detail add public void add(org.apache.hadoop.util.bloom.Key key) Description copied from class: org.apache.hadoop.util.bloom.Filter Adds a key to this filter. Overrides: add in class BloomFilter Parameters:key - The key to add. addFalsePositive public void addFalsePositive(org.apache.hadoop.util.bloom.Key key) Adds a false positive information to this retouched Bloom filter.    Invariant: if the false positive is null, nothing happens. Parameters:key - The false positive key to add. addFalsePositive public void addFalsePositive(Collection<org.apache.hadoop.util.bloom.Key> coll) Adds a collection of false positive information to this retouched Bloom filter. Parameters:coll - The collection of false positive. addFalsePositive public void addFalsePositive(List<org.apache.hadoop.util.bloom.Key> keys) Adds a list of false positive information to this retouched Bloom filter. Parameters:keys - The list of false positive. addFalsePositive public void addFalsePositive(org.apache.hadoop.util.bloom.Key[] keys) Adds an array of false positive information to this retouched Bloom filter. Parameters:keys - The array of false positive. selectiveClearing public void selectiveClearing(org.apache.hadoop.util.bloom.Key k,                      short scheme) Performs the selective clearing for a given key. Parameters:k - The false positive key to remove from this retouched Bloom filter.scheme - The selective clearing scheme to apply. write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Overrides: write in class BloomFilter Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Overrides: readFields in class BloomFilter Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  RunningJob (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="RunningJob (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Interface RunningJob @InterfaceAudience.Public @InterfaceStability.Stable public interface RunningJob RunningJob is the user-interface to query for details on a   running Map-Reduce job.    Clients can get hold of RunningJob via the JobClient  and then query the running-job for details such as name, configuration,   progress etc. See Also:JobClient Method Summary Methods  Modifier and Type Method and Description float cleanupProgress() Get the progress of the job's cleanup-tasks, as a float between 0.0   and 1.0. Configuration getConfiguration() Get the underlying job configuration Counters getCounters() Gets the counters for this job. String getFailureInfo() Get failure info for the job. String getHistoryUrl() Get the url where history file is archived. JobID getID() Get the job identifier. String getJobFile() Get the path of the submitted job configuration. String getJobID() Deprecated.  This method is deprecated and will be removed. Applications should   rather use getID(). String getJobName() Get the name of the job. int getJobState() Returns the current state of the Job. JobStatus getJobStatus() Returns a snapshot of the current status, JobStatus, of the Job. TaskCompletionEvent[] getTaskCompletionEvents(int startFrom) Get events indicating completion (success/failure) of component tasks. String[] getTaskDiagnostics(TaskAttemptID taskid) Gets the diagnostic messages for a given task attempt. String getTrackingURL() Get the URL where some job progress information will be displayed. boolean isComplete() Check if the job is finished or not. boolean isRetired() Check whether the job has been removed from JobTracker memory and retired. boolean isSuccessful() Check if the job completed successfully. void killJob() Kill the running job. void killTask(String taskId,                 boolean shouldFail) Deprecated.  Applications should rather use killTask(TaskAttemptID, boolean) void killTask(TaskAttemptID taskId,                 boolean shouldFail) Kill indicated task attempt. float mapProgress() Get the progress of the job's map-tasks, as a float between 0.0   and 1.0. float reduceProgress() Get the progress of the job's reduce-tasks, as a float between 0.0   and 1.0. void setJobPriority(String priority) Set the priority of a running job. float setupProgress() Get the progress of the job's setup-tasks, as a float between 0.0   and 1.0. void waitForCompletion() Blocks until the job is complete. Method Detail getConfiguration Configuration getConfiguration() Get the underlying job configuration Returns:the configuration of the job. getID JobID getID() Get the job identifier. Returns:the job identifier. getJobID @Deprecated String getJobID() Deprecated. This method is deprecated and will be removed. Applications should   rather use getID(). getJobName String getJobName() Get the name of the job. Returns:the name of the job. getJobFile String getJobFile() Get the path of the submitted job configuration. Returns:the path of the submitted job configuration. getTrackingURL String getTrackingURL() Get the URL where some job progress information will be displayed. Returns:the URL where some job progress information will be displayed. mapProgress float mapProgress()                   throws IOException Get the progress of the job's map-tasks, as a float between 0.0   and 1.0.  When all map tasks have completed, the function returns 1.0. Returns:the progress of the job's map-tasks. Throws: IOException reduceProgress float reduceProgress()                      throws IOException Get the progress of the job's reduce-tasks, as a float between 0.0   and 1.0.  When all reduce tasks have completed, the function returns 1.0. Returns:the progress of the job's reduce-tasks. Throws: IOException cleanupProgress float cleanupProgress()                       throws IOException Get the progress of the job's cleanup-tasks, as a float between 0.0   and 1.0.  When all cleanup tasks have completed, the function returns 1.0. Returns:the progress of the job's cleanup-tasks. Throws: IOException setupProgress float setupProgress()                     throws IOException Get the progress of the job's setup-tasks, as a float between 0.0   and 1.0.  When all setup tasks have completed, the function returns 1.0. Returns:the progress of the job's setup-tasks. Throws: IOException isComplete boolean isComplete()                    throws IOException Check if the job is finished or not.   This is a non-blocking call. Returns:true if the job is complete, else false. Throws: IOException isSuccessful boolean isSuccessful()                      throws IOException Check if the job completed successfully. Returns:true if the job succeeded, else false. Throws: IOException waitForCompletion void waitForCompletion()                        throws IOException Blocks until the job is complete. Throws: IOException getJobState int getJobState()                 throws IOException Returns the current state of the Job.  JobStatus Throws: IOException getJobStatus JobStatus getJobStatus()                        throws IOException Returns a snapshot of the current status, JobStatus, of the Job.  Need to call again for latest information. Throws: IOException killJob void killJob()              throws IOException Kill the running job. Blocks until all job tasks have been killed as well.  If the job is no longer running, it simply returns. Throws: IOException setJobPriority void setJobPriority(String priority)                     throws IOException Set the priority of a running job. Parameters:priority - the new priority for the job. Throws: IOException getTaskCompletionEvents TaskCompletionEvent[] getTaskCompletionEvents(int startFrom)                                               throws IOException Get events indicating completion (success/failure) of component tasks. Parameters:startFrom - index to start fetching events from Returns:an array of TaskCompletionEvents Throws: IOException killTask void killTask(TaskAttemptID taskId,             boolean shouldFail)               throws IOException Kill indicated task attempt. Parameters:taskId - the id of the task to be terminated.shouldFail - if true the task is failed and added to failed tasks                     list, otherwise it is just killed, w/o affecting                     job failure status. Throws: IOException killTask @Deprecated void killTask(String taskId,                        boolean shouldFail)               throws IOException Deprecated. Applications should rather use killTask(TaskAttemptID, boolean) Throws: IOException getCounters Counters getCounters()                      throws IOException Gets the counters for this job. Returns:the counters for this job or null if the job has been retired. Throws: IOException getTaskDiagnostics String[] getTaskDiagnostics(TaskAttemptID taskid)                             throws IOException Gets the diagnostic messages for a given task attempt. Parameters:taskid -  Returns:the list of diagnostic messages for the task Throws: IOException getHistoryUrl String getHistoryUrl()                      throws IOException Get the url where history file is archived. Returns empty string if   history file is not available yet. Returns:the url where history file is archived Throws: IOException isRetired boolean isRetired()                   throws IOException Check whether the job has been removed from JobTracker memory and retired.  On retire, the job history file is copied to a location known by   getHistoryUrl() Returns:true if the job retired, else false. Throws: IOException getFailureInfo String getFailureInfo()                       throws IOException Get failure info for the job. Returns:the failure info for the job. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  S3Exception (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="S3Exception (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.s3 Class S3Exception java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.s3.S3Exception All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class S3Exception extends IOException Thrown if there is a problem communicating with Amazon S3. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description S3Exception(Throwable t)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail S3Exception public S3Exception(Throwable t) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  S3FileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="S3FileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.s3 Class S3FileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem org.apache.hadoop.fs.s3.S3FileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class S3FileSystem extends FileSystem A block-based FileSystem backed by  Amazon S3. See Also:NativeS3FileSystem Field Summary Fields inherited from class org.apache.hadoop.fs.FileSystem DEFAULT_FS, FS_DEFAULT_NAME_KEY, LOG, SHUTDOWN_HOOK_PRIORITY, statistics Constructor Summary Constructors  Constructor and Description S3FileSystem()  S3FileSystem(org.apache.hadoop.fs.s3.FileSystemStore store)  Method Summary Methods  Modifier and Type Method and Description FSDataOutputStream append(Path f,             int bufferSize,             Progressable progress) This optional operation is not yet supported. FSDataOutputStream create(Path file,             FsPermission permission,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. boolean delete(Path path,             boolean recursive) Delete a file. String getCanonicalServiceName() Get a canonical service name for this file system. long getDefaultBlockSize() Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. FileStatus getFileStatus(Path f) FileStatus for S3 file systems. String getScheme() Return the protocol scheme for the FileSystem. URI getUri() Returns a URI whose scheme and authority identify this FileSystem. Path getWorkingDirectory() Get the current working directory for the given file system void initialize(URI uri,                     Configuration conf) Called after a new FileSystem instance is constructed. boolean isFile(Path path) True iff the named path is a regular file. FileStatus[] listStatus(Path f) List the statuses of the files/directories in the given path if the path is  a directory. boolean mkdirs(Path path,             FsPermission permission) Make the given file and all non-existent parents into  directories. FSDataInputStream open(Path path,         int bufferSize) Opens an FSDataInputStream at the indicated Path. boolean rename(Path src,             Path dst) Renames Path src to Path dst. void setWorkingDirectory(Path dir) Set the current working directory for the given file system. Methods inherited from class org.apache.hadoop.fs.FileSystem append, append, areSymlinksEnabled, cancelDeleteOnExit, canonicalizeUri, checkPath, clearStatistics, close, closeAll, closeAllForUGI, completeLocalOutput, concat, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyToLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, create, create, createNewFile, createNonRecursive, createNonRecursive, createNonRecursive, createSnapshot, createSnapshot, createSymlink, delete, deleteOnExit, deleteSnapshot, enableSymlinks, exists, fixRelativePart, get, get, get, getAclStatus, getAllStatistics, getBlockSize, getCanonicalUri, getContentSummary, getDefaultBlockSize, getDefaultPort, getDefaultReplication, getDefaultReplication, getDefaultUri, getFileBlockLocations, getFileBlockLocations, getFileChecksum, getFileChecksum, getFileLinkStatus, getFileSystemClass, getFSofPath, getHomeDirectory, getInitialWorkingDirectory, getLength, getLinkTarget, getLocal, getName, getNamed, getReplication, getServerDefaults, getServerDefaults, getStatistics, getStatistics, getStatus, getStatus, getUsed, getXAttr, getXAttrs, getXAttrs, globStatus, globStatus, isDirectory, listCorruptFileBlocks, listFiles, listLocatedStatus, listLocatedStatus, listStatus, listStatus, listStatus, listStatusIterator, listXAttrs, makeQualified, mkdirs, mkdirs, modifyAclEntries, moveFromLocalFile, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveCreate, primitiveMkdir, primitiveMkdir, printStatistics, processDeleteOnExit, removeAcl, removeAclEntries, removeDefaultAcl, removeXAttr, rename, renameSnapshot, resolveLink, resolvePath, setAcl, setDefaultUri, setDefaultUri, setOwner, setPermission, setReplication, setTimes, setVerifyChecksum, setWriteChecksum, setXAttr, setXAttr, startLocalOutput, supportsSymlinks, truncate Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail S3FileSystem public S3FileSystem() S3FileSystem public S3FileSystem(org.apache.hadoop.fs.s3.FileSystemStore store) Method Detail getScheme public String getScheme() Return the protocol scheme for the FileSystem. Overrides: getScheme in class FileSystem Returns:s3 getUri public URI getUri() Description copied from class: FileSystem Returns a URI whose scheme and authority identify this FileSystem. Specified by: getUri in class FileSystem initialize public void initialize(URI uri,               Configuration conf)                 throws IOException Description copied from class: FileSystem Called after a new FileSystem instance is constructed. Overrides: initialize in class FileSystem Parameters:uri - a uri whose authority section names the host, port, etc.    for this FileSystemconf - the configuration Throws: IOException getWorkingDirectory public Path getWorkingDirectory() Description copied from class: FileSystem Get the current working directory for the given file system Specified by: getWorkingDirectory in class FileSystem Returns:the directory pathname setWorkingDirectory public void setWorkingDirectory(Path dir) Description copied from class: FileSystem Set the current working directory for the given file system. All relative  paths will be resolved relative to it. Specified by: setWorkingDirectory in class FileSystem mkdirs public boolean mkdirs(Path path,              FsPermission permission)                throws IOException Description copied from class: FileSystem Make the given file and all non-existent parents into  directories. Has the semantics of Unix 'mkdir -p'.  Existence of the directory hierarchy is not an error. Specified by: mkdirs in class FileSystem Parameters:permission - Currently ignored.path - path to create Throws: IOException isFile public boolean isFile(Path path)                throws IOException Description copied from class: FileSystem True iff the named path is a regular file.  Note: Avoid using this method. Instead reuse the FileStatus   returned by getFileStatus() or listStatus() methods. Overrides: isFile in class FileSystem Parameters:path - path to check Throws: IOException listStatus public FileStatus[] listStatus(Path f)                         throws IOException Description copied from class: FileSystem List the statuses of the files/directories in the given path if the path is  a directory. Specified by: listStatus in class FileSystem Parameters:f - given path Returns:the statuses of the files/directories in the given patch Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException append public FSDataOutputStream append(Path f,                         int bufferSize,                         Progressable progress)                           throws IOException This optional operation is not yet supported. Specified by: append in class FileSystem Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used.progress - for reporting progress if it is not null. Throws: IOException create public FSDataOutputStream create(Path file,                         FsPermission permission,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Specified by: create in class FileSystem Parameters:permission - Currently ignored.file - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) open public FSDataInputStream open(Path path,                      int bufferSize)                        throws IOException Description copied from class: FileSystem Opens an FSDataInputStream at the indicated Path. Specified by: open in class FileSystem Parameters:path - the file name to openbufferSize - the size of the buffer to be used. Throws: IOException rename public boolean rename(Path src,              Path dst)                throws IOException Description copied from class: FileSystem Renames Path src to Path dst.  Can take place on local fs  or remote DFS. Specified by: rename in class FileSystem Parameters:src - path to be renameddst - new path after rename Returns:true if rename is successful Throws: IOException - on failure delete public boolean delete(Path path,              boolean recursive)                throws IOException Description copied from class: FileSystem Delete a file. Specified by: delete in class FileSystem Parameters:path - the path to delete.recursive - if path is a directory and set to   true, the directory is deleted else throws an exception. In  case of a file the recursive can be set to either true or false. Returns:true if delete is successful else false. Throws: IOException getFileStatus public FileStatus getFileStatus(Path f)                          throws IOException FileStatus for S3 file systems. Specified by: getFileStatus in class FileSystem Parameters:f - The path we want information from Returns:a FileStatus object Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation IOException getDefaultBlockSize public long getDefaultBlockSize() Description copied from class: FileSystem Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. Overrides: getDefaultBlockSize in class FileSystem getCanonicalServiceName public String getCanonicalServiceName() Description copied from class: FileSystem Get a canonical service name for this file system.  The token cache is  the only user of the canonical service name, and uses it to lookup this  filesystem's service tokens.  If file system provides a token of its own then it must have a canonical  name, otherwise canonical name can be null.    Default Impl: If the file system has child file systems   (such as an embedded file system) then it is assumed that the fs has no  tokens of its own and hence returns a null name; otherwise a service  name is built using Uri and port. Returns:a service string that uniquely identifies this file system, null          if the filesystem does not implement tokensSee Also:SecurityUtil.buildDTServiceName(URI, int) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  S3FileSystemException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="S3FileSystemException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.s3 Class S3FileSystemException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.s3.S3FileSystemException All Implemented Interfaces: Serializable Direct Known Subclasses: VersionMismatchException @InterfaceAudience.Public @InterfaceStability.Stable public class S3FileSystemException extends IOException Thrown when there is a fatal exception while using S3FileSystem. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description S3FileSystemException(String message)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail S3FileSystemException public S3FileSystemException(String message) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SchedulerSecurityInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SchedulerSecurityInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security Class SchedulerSecurityInfo java.lang.Object org.apache.hadoop.security.SecurityInfo org.apache.hadoop.yarn.security.SchedulerSecurityInfo @InterfaceAudience.Public @InterfaceStability.Stable public class SchedulerSecurityInfo extends org.apache.hadoop.security.SecurityInfo Constructor Summary Constructors  Constructor and Description SchedulerSecurityInfo()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                               Configuration conf) Get the KerberosInfo for a given protocol. org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                         Configuration conf) Get the TokenInfo for a given protocol. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SchedulerSecurityInfo public SchedulerSecurityInfo() Method Detail getKerberosInfo public org.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the KerberosInfo for a given protocol. Specified by: getKerberosInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration Returns:KerberosInfo getTokenInfo public org.apache.hadoop.security.token.TokenInfo getTokenInfo(Class<?> protocol,                                                       Configuration conf) Description copied from class: org.apache.hadoop.security.SecurityInfo Get the TokenInfo for a given protocol. Specified by: getTokenInfo in class org.apache.hadoop.security.SecurityInfo Parameters:protocol - interface classconf - configuration object. Returns:TokenInfo instance Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ScriptBasedMapping (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ScriptBasedMapping (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.net Class ScriptBasedMapping java.lang.Object org.apache.hadoop.net.AbstractDNSToSwitchMapping org.apache.hadoop.net.CachedDNSToSwitchMapping org.apache.hadoop.net.ScriptBasedMapping All Implemented Interfaces: Configurable, DNSToSwitchMapping @InterfaceAudience.Public @InterfaceStability.Evolving public class ScriptBasedMapping extends CachedDNSToSwitchMapping This class implements the DNSToSwitchMapping interface using a   script configured via the  CommonConfigurationKeysPublic.NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY option.    It contains a static class RawScriptBasedMapping that performs  the work: reading the configuration parameters, executing any defined  script, handling errors and such like. The outer  class extends CachedDNSToSwitchMapping to cache the delegated  queries.    This DNS mapper's CachedDNSToSwitchMapping.isSingleSwitch() predicate returns  true if and only if a script is defined. Field Summary Fields  Modifier and Type Field and Description static String NO_SCRIPT Text used in the toString() method if there is no string  "no script" Fields inherited from class org.apache.hadoop.net.CachedDNSToSwitchMapping rawMapping Constructor Summary Constructors  Constructor and Description ScriptBasedMapping() Create an instance with the default configuration. ScriptBasedMapping(Configuration conf) Create an instance from the given configuration ScriptBasedMapping(DNSToSwitchMapping rawMap) Create an instance from the given raw mapping Method Summary Methods  Modifier and Type Method and Description Configuration getConf() Return the configuration used by this object. void setConf(Configuration conf) Set the configuration to be used by this object. String toString()  Methods inherited from class org.apache.hadoop.net.CachedDNSToSwitchMapping getSwitchMap, isSingleSwitch, reloadCachedMappings, reloadCachedMappings, resolve Methods inherited from class org.apache.hadoop.net.AbstractDNSToSwitchMapping dumpTopology, isMappingSingleSwitch, isSingleSwitchByScriptPolicy Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail NO_SCRIPT public static final String NO_SCRIPT Text used in the toString() method if there is no string  "no script" See Also:Constant Field Values Constructor Detail ScriptBasedMapping public ScriptBasedMapping() Create an instance with the default configuration.    Calling setConf(Configuration) will trigger a  re-evaluation of the configuration settings and so be used to  set up the mapping script. ScriptBasedMapping public ScriptBasedMapping(DNSToSwitchMapping rawMap) Create an instance from the given raw mapping Parameters:rawMap - raw DNSTOSwithMapping ScriptBasedMapping public ScriptBasedMapping(Configuration conf) Create an instance from the given configuration Parameters:conf - configuration Method Detail getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable Overrides: getConf in class AbstractDNSToSwitchMapping toString public String toString() Overrides: toString in class CachedDNSToSwitchMapping setConf public void setConf(Configuration conf) Set the configuration to be used by this object.    This will get called in the superclass constructor, so a check is needed  to ensure that the raw mapping is defined before trying to relaying a null  configuration. Specified by: setConf in interface Configurable Overrides: setConf in class AbstractDNSToSwitchMapping Parameters:conf -  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Seekable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Seekable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Interface Seekable All Known Implementing Classes: BlockDecompressorStream, CompressionInputStream, DecompressorStream, FSDataInputStream, SplitCompressionInputStream @InterfaceAudience.Public @InterfaceStability.Evolving public interface Seekable Stream that permits seeking. Method Summary Methods  Modifier and Type Method and Description long getPos() Return the current offset from the start of the file void seek(long pos) Seek to the given offset from the start of the file. Method Detail seek void seek(long pos)           throws IOException Seek to the given offset from the start of the file.  The next read() will be from that location.  Can't  seek past the end of the file. Throws: IOException getPos long getPos()             throws IOException Return the current offset from the start of the file Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SequenceFile (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SequenceFile (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class SequenceFile java.lang.Object org.apache.hadoop.io.SequenceFile @InterfaceAudience.Public @InterfaceStability.Stable public class SequenceFile extends Object SequenceFiles are flat files consisting of binary key/value   pairs.    SequenceFile provides SequenceFile.Writer,  SequenceFile.Reader and SequenceFile.Sorter classes for writing,  reading and sorting respectively.    There are three SequenceFile Writers based on the   SequenceFile.CompressionType used to compress key/value pairs:          Writer : Uncompressed records.            RecordCompressWriter : Record-compressed files, only compress                                         values.            BlockCompressWriter : Block-compressed files, both keys &                                        values are collected in 'blocks'                                        separately and compressed. The size of                                        the 'block' is configurable.      The actual compression algorithm used to compress key and/or values can be  specified by using the appropriate CompressionCodec.    The recommended way is to use the static createWriter methods  provided by the SequenceFile to chose the preferred format.  The SequenceFile.Reader acts as the bridge and can read any of the  above SequenceFile formats.  SequenceFile Formats    Essentially there are 3 different formats for SequenceFiles  depending on the CompressionType specified. All of them share a  common header described below.    SequenceFile Header          version - 3 bytes of magic header SEQ, followed by 1 byte of actual               version number (e.g. SEQ4 or SEQ6)            keyClassName -key class            valueClassName - value class            compression - A boolean which specifies if compression is turned on for                   keys/values in this file.            blockCompression - A boolean which specifies if block-compression is                        turned on for keys/values in this file.            compression codec - CompressionCodec class which is used for                          compression of keys and/or values (if compression is                         enabled).            metadata - SequenceFile.Metadata for this file.            sync - A sync marker to denote end of the header.          Uncompressed SequenceFile Format      Header      Record          Record length      Key length      Key      Value          A sync-marker every few 100 bytes or so.      Record-Compressed SequenceFile Format      Header      Record          Record length      Key length      Key      Compressed Value          A sync-marker every few 100 bytes or so.        Block-Compressed SequenceFile Format      Header      Record Block          Uncompressed number of records in the block      Compressed key-lengths block-size      Compressed key-lengths block      Compressed keys block-size      Compressed keys block      Compressed value-lengths block-size      Compressed value-lengths block      Compressed values block-size      Compressed values block          A sync-marker every block.        The compressed blocks of key lengths and value lengths consist of the   actual lengths of individual keys/values encoded in ZeroCompressedInteger   format. See Also:CompressionCodec Field Summary Fields  Modifier and Type Field and Description static int SYNC_INTERVAL The number of bytes between sync points. Method Summary Methods  Modifier and Type Method and Description static org.apache.hadoop.io.SequenceFile.Writer createWriter(Configuration conf,                         FSDataOutputStream out,                         Class keyClass,                         Class valClass,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                         CompressionCodec codec) Deprecated.  Use createWriter(Configuration, Writer.Option...)      instead. static org.apache.hadoop.io.SequenceFile.Writer createWriter(Configuration conf,                         FSDataOutputStream out,                         Class keyClass,                         Class valClass,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                         CompressionCodec codec,                         org.apache.hadoop.io.SequenceFile.Metadata metadata) Deprecated.  Use createWriter(Configuration, Writer.Option...)      instead. static org.apache.hadoop.io.SequenceFile.Writer createWriter(Configuration conf,                         org.apache.hadoop.io.SequenceFile.Writer.Option... opts) Create a new Writer with the given options. static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileContext fc,                         Configuration conf,                         Path name,                         Class keyClass,                         Class valClass,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                         CompressionCodec codec,                         org.apache.hadoop.io.SequenceFile.Metadata metadata,                         EnumSet<CreateFlag> createFlag,                         org.apache.hadoop.fs.Options.CreateOpts... opts) Construct the preferred type of SequenceFile Writer. static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                         Configuration conf,                         Path name,                         Class keyClass,                         Class valClass) Deprecated.  Use createWriter(Configuration, Writer.Option...)      instead. static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                         Configuration conf,                         Path name,                         Class keyClass,                         Class valClass,                         int bufferSize,                         short replication,                         long blockSize,                         boolean createParent,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                         CompressionCodec codec,                         org.apache.hadoop.io.SequenceFile.Metadata metadata) Deprecated.  static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                         Configuration conf,                         Path name,                         Class keyClass,                         Class valClass,                         int bufferSize,                         short replication,                         long blockSize,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                         CompressionCodec codec,                         Progressable progress,                         org.apache.hadoop.io.SequenceFile.Metadata metadata) Deprecated.  Use createWriter(Configuration, Writer.Option...)      instead. static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                         Configuration conf,                         Path name,                         Class keyClass,                         Class valClass,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType) Deprecated.  Use createWriter(Configuration, Writer.Option...)      instead. static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                         Configuration conf,                         Path name,                         Class keyClass,                         Class valClass,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                         CompressionCodec codec) Deprecated.  Use createWriter(Configuration, Writer.Option...)      instead. static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                         Configuration conf,                         Path name,                         Class keyClass,                         Class valClass,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                         CompressionCodec codec,                         Progressable progress) Deprecated.  Use createWriter(Configuration, Writer.Option...)      instead. static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                         Configuration conf,                         Path name,                         Class keyClass,                         Class valClass,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                         CompressionCodec codec,                         Progressable progress,                         org.apache.hadoop.io.SequenceFile.Metadata metadata) Deprecated.  Use createWriter(Configuration, Writer.Option...)      instead. static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                         Configuration conf,                         Path name,                         Class keyClass,                         Class valClass,                         org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                         Progressable progress) Deprecated.  Use createWriter(Configuration, Writer.Option...)      instead. static org.apache.hadoop.io.SequenceFile.CompressionType getDefaultCompressionType(Configuration job) Get the compression type for the reduce outputs static void setDefaultCompressionType(Configuration job,                                                   org.apache.hadoop.io.SequenceFile.CompressionType val) Set the default compression type for sequence files. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail SYNC_INTERVAL public static final int SYNC_INTERVAL The number of bytes between sync points. See Also:Constant Field Values Method Detail getDefaultCompressionType public static org.apache.hadoop.io.SequenceFile.CompressionType getDefaultCompressionType(Configuration job) Get the compression type for the reduce outputs Parameters:job - the job config to look in Returns:the kind of compression to use setDefaultCompressionType public static void setDefaultCompressionType(Configuration job,                              org.apache.hadoop.io.SequenceFile.CompressionType val) Set the default compression type for sequence files. Parameters:job - the configuration to modifyval - the new compression type (none, block, record) createWriter public static org.apache.hadoop.io.SequenceFile.Writer createWriter(Configuration conf,                                                     org.apache.hadoop.io.SequenceFile.Writer.Option... opts)                                                              throws IOException Create a new Writer with the given options. Parameters:conf - the configuration to useopts - the options to create the file with Returns:a new Writer Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                                                                Configuration conf,                                                                Path name,                                                                Class keyClass,                                                                Class valClass)                                                              throws IOException Deprecated. Use createWriter(Configuration, Writer.Option...)      instead. Construct the preferred type of SequenceFile Writer. Parameters:fs - The configured filesystem.conf - The configuration.name - The name of the file.keyClass - The 'key' type.valClass - The 'value' type. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                                                                Configuration conf,                                                                Path name,                                                                Class keyClass,                                                                Class valClass,                                                                org.apache.hadoop.io.SequenceFile.CompressionType compressionType)                                                              throws IOException Deprecated. Use createWriter(Configuration, Writer.Option...)      instead. Construct the preferred type of SequenceFile Writer. Parameters:fs - The configured filesystem.conf - The configuration.name - The name of the file.keyClass - The 'key' type.valClass - The 'value' type.compressionType - The compression type. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                                                                Configuration conf,                                                                Path name,                                                                Class keyClass,                                                                Class valClass,                                                                org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                                                                Progressable progress)                                                              throws IOException Deprecated. Use createWriter(Configuration, Writer.Option...)      instead. Construct the preferred type of SequenceFile Writer. Parameters:fs - The configured filesystem.conf - The configuration.name - The name of the file.keyClass - The 'key' type.valClass - The 'value' type.compressionType - The compression type.progress - The Progressable object to track progress. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                                                                Configuration conf,                                                                Path name,                                                                Class keyClass,                                                                Class valClass,                                                                org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                                                                CompressionCodec codec)                                                              throws IOException Deprecated. Use createWriter(Configuration, Writer.Option...)      instead. Construct the preferred type of SequenceFile Writer. Parameters:fs - The configured filesystem.conf - The configuration.name - The name of the file.keyClass - The 'key' type.valClass - The 'value' type.compressionType - The compression type.codec - The compression codec. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                                                                Configuration conf,                                                                Path name,                                                                Class keyClass,                                                                Class valClass,                                                                org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                                                                CompressionCodec codec,                                                                Progressable progress,                                                                org.apache.hadoop.io.SequenceFile.Metadata metadata)                                                              throws IOException Deprecated. Use createWriter(Configuration, Writer.Option...)      instead. Construct the preferred type of SequenceFile Writer. Parameters:fs - The configured filesystem.conf - The configuration.name - The name of the file.keyClass - The 'key' type.valClass - The 'value' type.compressionType - The compression type.codec - The compression codec.progress - The Progressable object to track progress.metadata - The metadata of the file. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                                                                Configuration conf,                                                                Path name,                                                                Class keyClass,                                                                Class valClass,                                                                int bufferSize,                                                                short replication,                                                                long blockSize,                                                                org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                                                                CompressionCodec codec,                                                                Progressable progress,                                                                org.apache.hadoop.io.SequenceFile.Metadata metadata)                                                              throws IOException Deprecated. Use createWriter(Configuration, Writer.Option...)      instead. Construct the preferred type of SequenceFile Writer. Parameters:fs - The configured filesystem.conf - The configuration.name - The name of the file.keyClass - The 'key' type.valClass - The 'value' type.bufferSize - buffer size for the underlaying outputstream.replication - replication factor for the file.blockSize - block size for the file.compressionType - The compression type.codec - The compression codec.progress - The Progressable object to track progress.metadata - The metadata of the file. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                                                                Configuration conf,                                                                Path name,                                                                Class keyClass,                                                                Class valClass,                                                                int bufferSize,                                                                short replication,                                                                long blockSize,                                                                boolean createParent,                                                                org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                                                                CompressionCodec codec,                                                                org.apache.hadoop.io.SequenceFile.Metadata metadata)                                                              throws IOException Deprecated.  Construct the preferred type of SequenceFile Writer. Parameters:fs - The configured filesystem.conf - The configuration.name - The name of the file.keyClass - The 'key' type.valClass - The 'value' type.bufferSize - buffer size for the underlaying outputstream.replication - replication factor for the file.blockSize - block size for the file.createParent - create parent directory if non-existentcompressionType - The compression type.codec - The compression codec.metadata - The metadata of the file. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter public static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileContext fc,                                                     Configuration conf,                                                     Path name,                                                     Class keyClass,                                                     Class valClass,                                                     org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                                                     CompressionCodec codec,                                                     org.apache.hadoop.io.SequenceFile.Metadata metadata,                                                     EnumSet<CreateFlag> createFlag,                                                     org.apache.hadoop.fs.Options.CreateOpts... opts)                                                              throws IOException Construct the preferred type of SequenceFile Writer. Parameters:fc - The context for the specified file.conf - The configuration.name - The name of the file.keyClass - The 'key' type.valClass - The 'value' type.compressionType - The compression type.codec - The compression codec.metadata - The metadata of the file.createFlag - gives the semantics of create: overwrite, append etc.opts - file creation options; see Options.CreateOpts. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(FileSystem fs,                                                                Configuration conf,                                                                Path name,                                                                Class keyClass,                                                                Class valClass,                                                                org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                                                                CompressionCodec codec,                                                                Progressable progress)                                                              throws IOException Deprecated. Use createWriter(Configuration, Writer.Option...)      instead. Construct the preferred type of SequenceFile Writer. Parameters:fs - The configured filesystem.conf - The configuration.name - The name of the file.keyClass - The 'key' type.valClass - The 'value' type.compressionType - The compression type.codec - The compression codec.progress - The Progressable object to track progress. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(Configuration conf,                                                                FSDataOutputStream out,                                                                Class keyClass,                                                                Class valClass,                                                                org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                                                                CompressionCodec codec,                                                                org.apache.hadoop.io.SequenceFile.Metadata metadata)                                                              throws IOException Deprecated. Use createWriter(Configuration, Writer.Option...)      instead. Construct the preferred type of 'raw' SequenceFile Writer. Parameters:conf - The configuration.out - The stream on top which the writer is to be constructed.keyClass - The 'key' type.valClass - The 'value' type.compressionType - The compression type.codec - The compression codec.metadata - The metadata of the file. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException createWriter @Deprecated public static org.apache.hadoop.io.SequenceFile.Writer createWriter(Configuration conf,                                                                FSDataOutputStream out,                                                                Class keyClass,                                                                Class valClass,                                                                org.apache.hadoop.io.SequenceFile.CompressionType compressionType,                                                                CompressionCodec codec)                                                              throws IOException Deprecated. Use createWriter(Configuration, Writer.Option...)      instead. Construct the preferred type of 'raw' SequenceFile Writer. Parameters:conf - The configuration.out - The stream on top which the writer is to be constructed.keyClass - The 'key' type.valClass - The 'value' type.compressionType - The compression type.codec - The compression codec. Returns:Returns the handle to the constructed SequenceFile Writer. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SequenceFileAsBinaryInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SequenceFileAsBinaryInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class SequenceFileAsBinaryInputFormat java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat<BytesWritable,BytesWritable> org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class SequenceFileAsBinaryInputFormat extends SequenceFileInputFormat<BytesWritable,BytesWritable> InputFormat reading keys, values from SequenceFiles in binary (raw)  format. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description SequenceFileAsBinaryInputFormat()  Method Summary Methods  Modifier and Type Method and Description RecordReader<BytesWritable,BytesWritable> createRecordReader(InputSplit split,                                     TaskAttemptContext context) Create a record reader for a given split. Methods inherited from class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat getFormatMinSplitSize, listStatus Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, getSplits, isSplitable, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SequenceFileAsBinaryInputFormat public SequenceFileAsBinaryInputFormat() Method Detail createRecordReader public RecordReader<BytesWritable,BytesWritable> createRecordReader(InputSplit split,                                                            TaskAttemptContext context)                                                              throws IOException Description copied from class: InputFormat Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Overrides: createRecordReader in class SequenceFileInputFormat<BytesWritable,BytesWritable> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SequenceFileAsBinaryOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SequenceFileAsBinaryOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class SequenceFileAsBinaryOutputFormat java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat<BytesWritable,BytesWritable> org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class SequenceFileAsBinaryOutputFormat extends SequenceFileOutputFormat<BytesWritable,BytesWritable> An OutputFormat that writes keys,   values to SequenceFiles in binary(raw) format Field Summary Fields  Modifier and Type Field and Description static String KEY_CLASS  static String VALUE_CLASS  Fields inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat BASE_OUTPUT_NAME, COMPRESS, COMPRESS_CODEC, COMPRESS_TYPE, OUTDIR, PART Constructor Summary Constructors  Constructor and Description SequenceFileAsBinaryOutputFormat()  Method Summary Methods  Modifier and Type Method and Description void checkOutputSpecs(JobContext job) Check for validity of the output-specification for the job. RecordWriter<BytesWritable,BytesWritable> getRecordWriter(TaskAttemptContext context) Get the RecordWriter for the given task. static Class<? extends WritableComparable> getSequenceFileOutputKeyClass(JobContext job) Get the key class for the SequenceFile static Class<? extends Writable> getSequenceFileOutputValueClass(JobContext job) Get the value class for the SequenceFile static void setSequenceFileOutputKeyClass(Job job,                                                           Class<?> theClass) Set the key class for the SequenceFile static void setSequenceFileOutputValueClass(Job job,                                                               Class<?> theClass) Set the value class for the SequenceFile Methods inherited from class org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat getOutputCompressionType, getSequenceWriter, setOutputCompressionType Methods inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat getCompressOutput, getDefaultWorkFile, getOutputCommitter, getOutputCompressorClass, getOutputName, getOutputPath, getPathForWorkFile, getUniqueFile, getWorkOutputPath, setCompressOutput, setOutputCompressorClass, setOutputName, setOutputPath Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail KEY_CLASS public static String KEY_CLASS VALUE_CLASS public static String VALUE_CLASS Constructor Detail SequenceFileAsBinaryOutputFormat public SequenceFileAsBinaryOutputFormat() Method Detail setSequenceFileOutputKeyClass public static void setSequenceFileOutputKeyClass(Job job,                                  Class<?> theClass) Set the key class for the SequenceFile  This allows the user to specify the key class to be different   from the actual class (BytesWritable) used for writing  Parameters:job - the Job to modifytheClass - the SequenceFile output key class. setSequenceFileOutputValueClass public static void setSequenceFileOutputValueClass(Job job,                                    Class<?> theClass) Set the value class for the SequenceFile  This allows the user to specify the value class to be different   from the actual class (BytesWritable) used for writing  Parameters:job - the Job to modifytheClass - the SequenceFile output key class. getSequenceFileOutputKeyClass public static Class<? extends WritableComparable> getSequenceFileOutputKeyClass(JobContext job) Get the key class for the SequenceFile Returns:the key class of the SequenceFile getSequenceFileOutputValueClass public static Class<? extends Writable> getSequenceFileOutputValueClass(JobContext job) Get the value class for the SequenceFile Returns:the value class of the SequenceFile getRecordWriter public RecordWriter<BytesWritable,BytesWritable> getRecordWriter(TaskAttemptContext context)                                                           throws IOException Description copied from class: OutputFormat Get the RecordWriter for the given task. Overrides: getRecordWriter in class SequenceFileOutputFormat<BytesWritable,BytesWritable> Parameters:context - the information about the current task. Returns:a RecordWriter to write the output for the job. Throws: IOException checkOutputSpecs public void checkOutputSpecs(JobContext job)                       throws IOException Description copied from class: OutputFormat Check for validity of the output-specification for the job.     This is to validate the output specification for the job when it is  a job is submitted.  Typically checks that it does not already exist,  throwing an exception when it already exists, so that output is not  overwritten. Overrides: checkOutputSpecs in class FileOutputFormat<BytesWritable,BytesWritable> Parameters:job - information about the job Throws: IOException - when output should not be attempted Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SequenceFileAsTextInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SequenceFileAsTextInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class SequenceFileAsTextInputFormat java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat<Text,Text> org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class SequenceFileAsTextInputFormat extends SequenceFileInputFormat<Text,Text> This class is similar to SequenceFileInputFormat, except it generates  SequenceFileAsTextRecordReader which converts the input keys and values  to their String forms by calling toString() method. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description SequenceFileAsTextInputFormat()  Method Summary Methods  Modifier and Type Method and Description RecordReader<Text,Text> createRecordReader(InputSplit split,                                     TaskAttemptContext context) Create a record reader for a given split. Methods inherited from class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat getFormatMinSplitSize, listStatus Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, getSplits, isSplitable, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SequenceFileAsTextInputFormat public SequenceFileAsTextInputFormat() Method Detail createRecordReader public RecordReader<Text,Text> createRecordReader(InputSplit split,                                          TaskAttemptContext context)                                            throws IOException Description copied from class: InputFormat Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Overrides: createRecordReader in class SequenceFileInputFormat<Text,Text> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SequenceFileAsTextRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SequenceFileAsTextRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class SequenceFileAsTextRecordReader java.lang.Object org.apache.hadoop.mapreduce.RecordReader<Text,Text> org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader All Implemented Interfaces: Closeable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Stable public class SequenceFileAsTextRecordReader extends RecordReader<Text,Text> This class converts the input keys and values to their String forms by  calling toString() method. This class to SequenceFileAsTextInputFormat  class is as LineRecordReader class to TextInputFormat class. Constructor Summary Constructors  Constructor and Description SequenceFileAsTextRecordReader()  Method Summary Methods  Modifier and Type Method and Description void close() Close the record reader. Text getCurrentKey() Get the current key Text getCurrentValue() Get the current value. float getProgress() The current progress of the record reader through its data. void initialize(InputSplit split,                     TaskAttemptContext context) Called once at initialization. boolean nextKeyValue() Read key/value pair in a line. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SequenceFileAsTextRecordReader public SequenceFileAsTextRecordReader()                                throws IOException Throws: IOException Method Detail initialize public void initialize(InputSplit split,               TaskAttemptContext context)                 throws IOException,                        InterruptedException Description copied from class: RecordReader Called once at initialization. Specified by: initialize in class RecordReader<Text,Text> Parameters:split - the split that defines the range of records to readcontext - the information about the task Throws: IOException InterruptedException getCurrentKey public Text getCurrentKey()                    throws IOException,                           InterruptedException Description copied from class: RecordReader Get the current key Specified by: getCurrentKey in class RecordReader<Text,Text> Returns:the current key or null if there is no current key Throws: IOException InterruptedException getCurrentValue public Text getCurrentValue()                      throws IOException,                             InterruptedException Description copied from class: RecordReader Get the current value. Specified by: getCurrentValue in class RecordReader<Text,Text> Returns:the object that was read Throws: IOException InterruptedException nextKeyValue public boolean nextKeyValue()                      throws IOException,                             InterruptedException Read key/value pair in a line. Specified by: nextKeyValue in class RecordReader<Text,Text> Returns:true if a key/value pair was read Throws: IOException InterruptedException getProgress public float getProgress()                   throws IOException,                          InterruptedException Description copied from class: RecordReader The current progress of the record reader through its data. Specified by: getProgress in class RecordReader<Text,Text> Returns:a number between 0.0 and 1.0 that is the fraction of the data read Throws: IOException InterruptedException close public void close()            throws IOException Description copied from class: RecordReader Close the record reader. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in class RecordReader<Text,Text> Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SequenceFileInputFilter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SequenceFileInputFilter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class SequenceFileInputFilter<K,V> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class SequenceFileInputFilter<K,V> extends SequenceFileInputFormat<K,V> A class that allows a map/red job to work on a sample of sequence files.  The sample is decided by the filter class set by the job. Field Summary Fields  Modifier and Type Field and Description static String FILTER_CLASS  static String FILTER_FREQUENCY  static String FILTER_REGEX  static org.apache.commons.logging.Log LOG  Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description SequenceFileInputFilter()  Method Summary Methods  Modifier and Type Method and Description RecordReader<K,V> createRecordReader(InputSplit split,                                     TaskAttemptContext context) Create a record reader for the given split static void setFilterClass(Job job,                             Class<?> filterClass) set the filter class Methods inherited from class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat getFormatMinSplitSize, listStatus Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, getSplits, isSplitable, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail LOG public static final org.apache.commons.logging.Log LOG FILTER_CLASS public static final String FILTER_CLASS See Also:Constant Field Values FILTER_FREQUENCY public static final String FILTER_FREQUENCY See Also:Constant Field Values FILTER_REGEX public static final String FILTER_REGEX See Also:Constant Field Values Constructor Detail SequenceFileInputFilter public SequenceFileInputFilter() Method Detail createRecordReader public RecordReader<K,V> createRecordReader(InputSplit split,                                    TaskAttemptContext context)                                      throws IOException Create a record reader for the given split Overrides: createRecordReader in class SequenceFileInputFormat<K,V> Parameters:split - file splitcontext - the task-attempt context Returns:RecordReader Throws: IOException setFilterClass public static void setFilterClass(Job job,                   Class<?> filterClass) set the filter class Parameters:job - The jobfilterClass - filter class Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SequenceFileInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SequenceFileInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class SequenceFileInputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat<K,V> Direct Known Subclasses: SequenceFileAsBinaryInputFormat, SequenceFileAsTextInputFormat, SequenceFileInputFilter @InterfaceAudience.Public @InterfaceStability.Stable public class SequenceFileInputFormat<K,V> extends FileInputFormat<K,V> An InputFormat for SequenceFiles. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description SequenceFileInputFormat()  Method Summary Methods  Modifier and Type Method and Description RecordReader<K,V> createRecordReader(InputSplit split,                                     TaskAttemptContext context) Create a record reader for a given split. protected long getFormatMinSplitSize() Get the lower bound on split size imposed by the format. protected List<FileStatus> listStatus(JobContext job) List input directories. Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, getSplits, isSplitable, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SequenceFileInputFormat public SequenceFileInputFormat() Method Detail createRecordReader public RecordReader<K,V> createRecordReader(InputSplit split,                                    TaskAttemptContext context)                                      throws IOException Description copied from class: InputFormat Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Specified by: createRecordReader in class InputFormat<K,V> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader Throws: IOException getFormatMinSplitSize protected long getFormatMinSplitSize() Description copied from class: FileInputFormat Get the lower bound on split size imposed by the format. Overrides: getFormatMinSplitSize in class FileInputFormat<K,V> Returns:the number of bytes of the minimal split for this format listStatus protected List<FileStatus> listStatus(JobContext job)                                throws IOException Description copied from class: FileInputFormat List input directories.  Subclasses may override to, e.g., select only files matching a regular  expression. Overrides: listStatus in class FileInputFormat<K,V> Parameters:job - the job to list input paths for Returns:array of FileStatus objects Throws: IOException - if zero items. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SequenceFileOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SequenceFileOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class SequenceFileOutputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat<K,V> Direct Known Subclasses: SequenceFileAsBinaryOutputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class SequenceFileOutputFormat<K,V> extends FileOutputFormat<K,V> An OutputFormat that writes SequenceFiles. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat BASE_OUTPUT_NAME, COMPRESS, COMPRESS_CODEC, COMPRESS_TYPE, OUTDIR, PART Constructor Summary Constructors  Constructor and Description SequenceFileOutputFormat()  Method Summary Methods  Modifier and Type Method and Description static org.apache.hadoop.io.SequenceFile.CompressionType getOutputCompressionType(JobContext job) Get the SequenceFile.CompressionType for the output SequenceFile. RecordWriter<K,V> getRecordWriter(TaskAttemptContext context) Get the RecordWriter for the given task. protected org.apache.hadoop.io.SequenceFile.Writer getSequenceWriter(TaskAttemptContext context,                                   Class<?> keyClass,                                   Class<?> valueClass)  static void setOutputCompressionType(Job job,                                                 org.apache.hadoop.io.SequenceFile.CompressionType style) Set the SequenceFile.CompressionType for the output SequenceFile. Methods inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat checkOutputSpecs, getCompressOutput, getDefaultWorkFile, getOutputCommitter, getOutputCompressorClass, getOutputName, getOutputPath, getPathForWorkFile, getUniqueFile, getWorkOutputPath, setCompressOutput, setOutputCompressorClass, setOutputName, setOutputPath Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SequenceFileOutputFormat public SequenceFileOutputFormat() Method Detail getSequenceWriter protected org.apache.hadoop.io.SequenceFile.Writer getSequenceWriter(TaskAttemptContext context,                                                          Class<?> keyClass,                                                          Class<?> valueClass)                                                               throws IOException Throws: IOException getRecordWriter public RecordWriter<K,V> getRecordWriter(TaskAttemptContext context)                                   throws IOException,                                          InterruptedException Description copied from class: OutputFormat Get the RecordWriter for the given task. Specified by: getRecordWriter in class FileOutputFormat<K,V> Parameters:context - the information about the current task. Returns:a RecordWriter to write the output for the job. Throws: IOException InterruptedException getOutputCompressionType public static org.apache.hadoop.io.SequenceFile.CompressionType getOutputCompressionType(JobContext job) Get the SequenceFile.CompressionType for the output SequenceFile. Parameters:job - the Job Returns:the SequenceFile.CompressionType for the output SequenceFile,           defaulting to SequenceFile.CompressionType.RECORD setOutputCompressionType public static void setOutputCompressionType(Job job,                             org.apache.hadoop.io.SequenceFile.CompressionType style) Set the SequenceFile.CompressionType for the output SequenceFile. Parameters:job - the Job to modifystyle - the SequenceFile.CompressionType for the output               SequenceFile Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SequenceFileRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SequenceFileRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class SequenceFileRecordReader<K,V> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader<K,V> All Implemented Interfaces: Closeable, AutoCloseable @InterfaceAudience.Public @InterfaceStability.Stable public class SequenceFileRecordReader<K,V> extends RecordReader<K,V> An RecordReader for SequenceFiles. Field Summary Fields  Modifier and Type Field and Description protected Configuration conf  Constructor Summary Constructors  Constructor and Description SequenceFileRecordReader()  Method Summary Methods  Modifier and Type Method and Description void close() Close the record reader. K getCurrentKey() Get the current key V getCurrentValue() Get the current value. float getProgress() Return the progress within the input split void initialize(InputSplit split,                     TaskAttemptContext context) Called once at initialization. boolean nextKeyValue() Read the next key, value pair. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail conf protected Configuration conf Constructor Detail SequenceFileRecordReader public SequenceFileRecordReader() Method Detail initialize public void initialize(InputSplit split,               TaskAttemptContext context)                 throws IOException,                        InterruptedException Description copied from class: RecordReader Called once at initialization. Specified by: initialize in class RecordReader<K,V> Parameters:split - the split that defines the range of records to readcontext - the information about the task Throws: IOException InterruptedException nextKeyValue public boolean nextKeyValue()                      throws IOException,                             InterruptedException Description copied from class: RecordReader Read the next key, value pair. Specified by: nextKeyValue in class RecordReader<K,V> Returns:true if a key/value pair was read Throws: IOException InterruptedException getCurrentKey public K getCurrentKey() Description copied from class: RecordReader Get the current key Specified by: getCurrentKey in class RecordReader<K,V> Returns:the current key or null if there is no current key getCurrentValue public V getCurrentValue() Description copied from class: RecordReader Get the current value. Specified by: getCurrentValue in class RecordReader<K,V> Returns:the object that was read getProgress public float getProgress()                   throws IOException Return the progress within the input split Specified by: getProgress in class RecordReader<K,V> Returns:0.0 to 1.0 of the input byte range Throws: IOException close public void close()            throws IOException Description copied from class: RecordReader Close the record reader. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in class RecordReader<K,V> Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ServerProxy (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ServerProxy (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client Class ServerProxy java.lang.Object org.apache.hadoop.yarn.client.ServerProxy Direct Known Subclasses: NMProxy @InterfaceAudience.Public @InterfaceStability.Unstable public class ServerProxy extends Object Constructor Summary Constructors  Constructor and Description ServerProxy()  Method Summary Methods  Modifier and Type Method and Description protected static <T> T createRetriableProxy(Configuration conf,                                         Class<T> protocol,                                         org.apache.hadoop.security.UserGroupInformation user,                                         org.apache.hadoop.yarn.ipc.YarnRPC rpc,                                         InetSocketAddress serverAddress,                                         org.apache.hadoop.io.retry.RetryPolicy retryPolicy)  protected static org.apache.hadoop.io.retry.RetryPolicy createRetryPolicy(Configuration conf,                                   String maxWaitTimeStr,                                   long defMaxWaitTime,                                   String connectRetryIntervalStr,                                   long defRetryInterval)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ServerProxy public ServerProxy() Method Detail createRetryPolicy protected static org.apache.hadoop.io.retry.RetryPolicy createRetryPolicy(Configuration conf,                                                        String maxWaitTimeStr,                                                        long defMaxWaitTime,                                                        String connectRetryIntervalStr,                                                        long defRetryInterval) createRetriableProxy protected static <T> T createRetriableProxy(Configuration conf,                          Class<T> protocol,                          org.apache.hadoop.security.UserGroupInformation user,                          org.apache.hadoop.yarn.ipc.YarnRPC rpc,                          InetSocketAddress serverAddress,                          org.apache.hadoop.io.retry.RetryPolicy retryPolicy) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Servers (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Servers (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics2.util Class Servers java.lang.Object org.apache.hadoop.metrics2.util.Servers @InterfaceAudience.Public @InterfaceStability.Evolving public class Servers extends Object Helpers to handle server addresses Method Summary Methods  Modifier and Type Method and Description static List<InetSocketAddress> parse(String specs,           int defaultPort) Parses a space and/or comma separated sequence of server specifications  of the form hostname or hostname:port. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail parse public static List<InetSocketAddress> parse(String specs,                             int defaultPort) Parses a space and/or comma separated sequence of server specifications  of the form hostname or hostname:port.  If  the specs string is null, defaults to localhost:defaultPort. Parameters:specs - server specs (see description)defaultPort - the default port if not specified Returns:a list of InetSocketAddress objects. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Service (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Service (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.service Interface Service All Superinterfaces: AutoCloseable, Closeable All Known Subinterfaces: RegistryOperations All Known Implementing Classes: AbstractLivelinessMonitor, AbstractService, AddingCompositeService, AHSClient, AMRMClient, AMRMClientAsync, AsyncDispatcher, CompositeService, org.apache.hadoop.registry.client.impl.zk.CuratorService, HistoryFileManager, NMClient, NMClientAsync, RegistryOperationsClient, RegistryOperationsService, SharedCacheClient, TimelineClient, YarnClient @InterfaceAudience.Public @InterfaceStability.Evolving public interface Service extends Closeable Service LifeCycle. Method Summary Methods  Modifier and Type Method and Description void close() A version of stop() that is designed to be usable in Java7 closure  clauses. Map<String,String> getBlockers() Get the blockers on a service -remote dependencies  that are stopping the service from being live. Configuration getConfig() Get the configuration of this service. Throwable getFailureCause() Get the first exception raised during the service failure. org.apache.hadoop.service.Service.STATE getFailureState() Get the state in which the failure in getFailureCause() occurred. List<LifecycleEvent> getLifecycleHistory() Get a snapshot of the lifecycle history; it is a static list String getName() Get the name of this service. org.apache.hadoop.service.Service.STATE getServiceState() Get the current service state long getStartTime() Get the service start time void init(Configuration config) Initialize the service. boolean isInState(org.apache.hadoop.service.Service.STATE state) Query to see if the service is in a specific state. void registerServiceListener(ServiceStateChangeListener listener) Register a listener to the service state change events. void start() Start the service. void stop() Stop the service. void unregisterServiceListener(ServiceStateChangeListener listener) Unregister a previously registered listener of the service state  change events. boolean waitForServiceToStop(long timeout) Block waiting for the service to stop; uses the termination notification  object to do so. Method Detail init void init(Configuration config) Initialize the service.  The transition MUST be from Service.STATE.NOTINITED to Service.STATE.INITED  unless the operation failed and an exception was raised, in which case  stop() MUST be invoked and the service enter the state  Service.STATE.STOPPED. Parameters:config - the configuration of the service Throws: RuntimeException - on any failure during the operation start void start() Start the service.  The transition MUST be from Service.STATE.INITED to Service.STATE.STARTED  unless the operation failed and an exception was raised, in which case  stop() MUST be invoked and the service enter the state  Service.STATE.STOPPED. Throws: RuntimeException - on any failure during the operation stop void stop() Stop the service. This MUST be a no-op if the service is already  in the Service.STATE.STOPPED state. It SHOULD be a best-effort attempt  to stop all parts of the service.  The implementation must be designed to complete regardless of the service  state, including the initialized/uninitialized state of all its internal  fields. Throws: RuntimeException - on any failure during the stop operation close void close()            throws IOException A version of stop() that is designed to be usable in Java7 closure  clauses.  Implementation classes MUST relay this directly to stop() Specified by: close in interface AutoCloseable Specified by: close in interface Closeable Throws: IOException - never RuntimeException - on any failure during the stop operation registerServiceListener void registerServiceListener(ServiceStateChangeListener listener) Register a listener to the service state change events.  If the supplied listener is already listening to this service,  this method is a no-op. Parameters:listener - a new listener unregisterServiceListener void unregisterServiceListener(ServiceStateChangeListener listener) Unregister a previously registered listener of the service state  change events. No-op if the listener is already unregistered. Parameters:listener - the listener to unregister. getName String getName() Get the name of this service. Returns:the service name getConfig Configuration getConfig() Get the configuration of this service.  This is normally not a clone and may be manipulated, though there are no  guarantees as to what the consequences of such actions may be Returns:the current configuration, unless a specific implentation chooses  otherwise. getServiceState org.apache.hadoop.service.Service.STATE getServiceState() Get the current service state Returns:the state of the service getStartTime long getStartTime() Get the service start time Returns:the start time of the service. This will be zero if the service  has not yet been started. isInState boolean isInState(org.apache.hadoop.service.Service.STATE state) Query to see if the service is in a specific state.  In a multi-threaded system, the state may not hold for very long. Parameters:state - the expected state Returns:true if, at the time of invocation, the service was in that state. getFailureCause Throwable getFailureCause() Get the first exception raised during the service failure. If null,  no exception was logged Returns:the failure logged during a transition to the stopped state getFailureState org.apache.hadoop.service.Service.STATE getFailureState() Get the state in which the failure in getFailureCause() occurred. Returns:the state or null if there was no failure waitForServiceToStop boolean waitForServiceToStop(long timeout) Block waiting for the service to stop; uses the termination notification  object to do so.  This method will only return after all the service stop actions  have been executed (to success or failure), or the timeout elapsed  This method can be called before the service is inited or started; this is  to eliminate any race condition with the service stopping before  this event occurs. Parameters:timeout - timeout in milliseconds. A value of zero means "forever" Returns:true iff the service stopped in the time period getLifecycleHistory List<LifecycleEvent> getLifecycleHistory() Get a snapshot of the lifecycle history; it is a static list Returns:a possibly empty but never null list of lifecycle events. getBlockers Map<String,String> getBlockers() Get the blockers on a service -remote dependencies  that are stopping the service from being live. Returns:a (snapshotted) map of blocker name->description values Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ServiceFailedException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ServiceFailedException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha Class ServiceFailedException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.ha.ServiceFailedException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class ServiceFailedException extends IOException Exception thrown to indicate that an operation performed  to modify the state of a service or application failed. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ServiceFailedException(String message)  ServiceFailedException(String message,                                             Throwable cause)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ServiceFailedException public ServiceFailedException(String message) ServiceFailedException public ServiceFailedException(String message,                       Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ServiceOperations (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ServiceOperations (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.service Class ServiceOperations java.lang.Object org.apache.hadoop.service.ServiceOperations @InterfaceAudience.Public @InterfaceStability.Evolving public final class ServiceOperations extends Object This class contains a set of methods to work with services, especially  to walk them through their lifecycle. Method Summary Methods  Modifier and Type Method and Description static void stop(Service service) Stop a service. static Exception stopQuietly(org.apache.commons.logging.Log log,                       Service service) Stop a service; if it is null do nothing. static Exception stopQuietly(Service service) Stop a service; if it is null do nothing. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail stop public static void stop(Service service) Stop a service.  Do nothing if the service is null or not  in a state in which it can be/needs to be stopped.    The service state is checked before the operation begins.  This process is not thread safe. Parameters:service - a service or null stopQuietly public static Exception stopQuietly(Service service) Stop a service; if it is null do nothing. Exceptions are caught and  logged at warn level. (but not Throwables). This operation is intended to  be used in cleanup operations Parameters:service - a service; may be null Returns:any exception that was caught; null if none was. stopQuietly public static Exception stopQuietly(org.apache.commons.logging.Log log,                     Service service) Stop a service; if it is null do nothing. Exceptions are caught and  logged at warn level. (but not Throwables). This operation is intended to  be used in cleanup operations Parameters:log - the log to warn atservice - a service; may be null Returns:any exception that was caught; null if none was.See Also:stopQuietly(Service) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ServiceRecord (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ServiceRecord (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.registry.client.types Class ServiceRecord java.lang.Object org.apache.hadoop.registry.client.types.ServiceRecord All Implemented Interfaces: Cloneable @InterfaceAudience.Public @InterfaceStability.Evolving public class ServiceRecord extends Object implements Cloneable JSON-marshallable description of a single component.  It supports the deserialization of unknown attributes, but does  not support their creation. Field Summary Fields  Modifier and Type Field and Description String description Description string List<Endpoint> external List of endpoints intended for use to external callers List<Endpoint> internal List of endpoints for use within an application. static String RECORD_TYPE A type string which MUST be in the serialized json. String type The type field. Constructor Summary Constructors  Constructor and Description ServiceRecord() Create a service record with no ID, description or registration time. ServiceRecord(ServiceRecord that) Deep cloning constructor Method Summary Methods  Modifier and Type Method and Description void addExternalEndpoint(Endpoint endpoint) Add an external endpoint void addInternalEndpoint(Endpoint endpoint) Add an internal endpoint Map<String,String> attributes() The map of "other" attributes set when parsing. protected Object clone() Shallow clone: all endpoints will be shared across instances String get(String key) Get the "other" attribute with a specific key String get(String key,       String defVal) Get the "other" attribute with a specific key. Endpoint getExternalEndpoint(String api) Look up an external endpoint Endpoint getInternalEndpoint(String api) Look up an internal endpoint void set(String key,       Object value) Handle unknown attributes by storing them in the  attributes map String toString()  Methods inherited from class java.lang.Object equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail RECORD_TYPE public static final String RECORD_TYPE A type string which MUST be in the serialized json. This permits  fast discarding of invalid entries See Also:Constant Field Values type public String type The type field. This must be the string RECORD_TYPE description public String description Description string external public List<Endpoint> external List of endpoints intended for use to external callers internal public List<Endpoint> internal List of endpoints for use within an application. Constructor Detail ServiceRecord public ServiceRecord() Create a service record with no ID, description or registration time.  Endpoint lists are set to empty lists. ServiceRecord public ServiceRecord(ServiceRecord that) Deep cloning constructor Parameters:that - service record source Method Detail addExternalEndpoint public void addExternalEndpoint(Endpoint endpoint) Add an external endpoint Parameters:endpoint - endpoint to set addInternalEndpoint public void addInternalEndpoint(Endpoint endpoint) Add an internal endpoint Parameters:endpoint - endpoint to set getInternalEndpoint public Endpoint getInternalEndpoint(String api) Look up an internal endpoint Parameters:api - API Returns:the endpoint or null if there was no match getExternalEndpoint public Endpoint getExternalEndpoint(String api) Look up an external endpoint Parameters:api - API Returns:the endpoint or null if there was no match set public void set(String key,        Object value) Handle unknown attributes by storing them in the  attributes map Parameters:key - attribute namevalue - attribute value. attributes public Map<String,String> attributes() The map of "other" attributes set when parsing. These  are not included in the JSON value of this record when it  is generated. Returns:a map of any unknown attributes in the deserialized JSON. get public String get(String key) Get the "other" attribute with a specific key Parameters:key - key to look up Returns:the value or null get public String get(String key,          String defVal) Get the "other" attribute with a specific key. Parameters:key - key to look updefVal - default value Returns:the value as a string,  or defval if the value was not present toString public String toString() Overrides: toString in class Object clone protected Object clone()                 throws CloneNotSupportedException Shallow clone: all endpoints will be shared across instances Overrides: clone in class Object Returns:a clone of the instance Throws: CloneNotSupportedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ServiceStateChangeListener (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ServiceStateChangeListener (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.service Interface ServiceStateChangeListener All Known Implementing Classes: LoggingStateChangeListener @InterfaceAudience.Public @InterfaceStability.Stable public interface ServiceStateChangeListener Interface to notify state changes of a service. Method Summary Methods  Modifier and Type Method and Description void stateChanged(Service service) Callback to notify of a state change. Method Detail stateChanged void stateChanged(Service service) Callback to notify of a state change. The service will already  have changed state before this callback is invoked.  This operation is invoked on the thread that initiated the state change,  while the service itself in in a sychronized section.      Any long-lived operation here will prevent the service state    change from completing in a timely manner.    If another thread is somehow invoked from the listener, and    that thread invokes the methods of the service (including    subclass-specific methods), there is a risk of a deadlock.   Parameters:service - the service that has changed. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ServiceStateException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ServiceStateException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.service Class ServiceStateException java.lang.Object java.lang.Throwable java.lang.Exception java.lang.RuntimeException org.apache.hadoop.service.ServiceStateException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Evolving public class ServiceStateException extends RuntimeException Exception that is raised on state change operations. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description ServiceStateException(String message)  ServiceStateException(String message,                                           Throwable cause)  ServiceStateException(Throwable cause)  Method Summary Methods  Modifier and Type Method and Description static RuntimeException convert(String text,               Throwable fault) Convert any exception into a RuntimeException. static RuntimeException convert(Throwable fault) Convert any exception into a RuntimeException. Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ServiceStateException public ServiceStateException(String message) ServiceStateException public ServiceStateException(String message,                      Throwable cause) ServiceStateException public ServiceStateException(Throwable cause) Method Detail convert public static RuntimeException convert(Throwable fault) Convert any exception into a RuntimeException.  If the caught exception is already of that type, it is typecast to a  RuntimeException and returned.  All other exception types are wrapped in a new instance of  ServiceStateException Parameters:fault - exception or throwable Returns:a ServiceStateException to rethrow convert public static RuntimeException convert(String text,                        Throwable fault) Convert any exception into a RuntimeException.  If the caught exception is already of that type, it is typecast to a  RuntimeException and returned.  All other exception types are wrapped in a new instance of  ServiceStateException Parameters:text - text to use if a new exception is createdfault - exception or throwable Returns:a ServiceStateException to rethrow Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ServiceStateModel (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ServiceStateModel (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.service Class ServiceStateModel java.lang.Object org.apache.hadoop.service.ServiceStateModel @InterfaceAudience.Public @InterfaceStability.Evolving public class ServiceStateModel extends Object Implements the service state model. Constructor Summary Constructors  Constructor and Description ServiceStateModel(String name) Create the service state model in the Service.STATE.NOTINITED  state. ServiceStateModel(String name,                                   org.apache.hadoop.service.Service.STATE state) Create a service state model instance in the chosen state Method Summary Methods  Modifier and Type Method and Description static void checkStateTransition(String name,                                         org.apache.hadoop.service.Service.STATE state,                                         org.apache.hadoop.service.Service.STATE proposed) Check that a state tansition is valid and  throw an exception if not void ensureCurrentState(org.apache.hadoop.service.Service.STATE expectedState) Verify that that a service is in a given state. org.apache.hadoop.service.Service.STATE enterState(org.apache.hadoop.service.Service.STATE proposed) Enter a state -thread safe. org.apache.hadoop.service.Service.STATE getState() Query the service state. boolean isInState(org.apache.hadoop.service.Service.STATE proposed) Query that the state is in a specific state static boolean isValidStateTransition(org.apache.hadoop.service.Service.STATE current,                                             org.apache.hadoop.service.Service.STATE proposed) Is a state transition valid?  There are no checks for current==proposed  as that is considered a non-transition. String toString() return the state text as the toString() value Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail ServiceStateModel public ServiceStateModel(String name) Create the service state model in the Service.STATE.NOTINITED  state. ServiceStateModel public ServiceStateModel(String name,                  org.apache.hadoop.service.Service.STATE state) Create a service state model instance in the chosen state Parameters:state - the starting state Method Detail getState public org.apache.hadoop.service.Service.STATE getState() Query the service state. This is a non-blocking operation. Returns:the state isInState public boolean isInState(org.apache.hadoop.service.Service.STATE proposed) Query that the state is in a specific state Parameters:proposed - proposed new state Returns:the state ensureCurrentState public void ensureCurrentState(org.apache.hadoop.service.Service.STATE expectedState) Verify that that a service is in a given state. Parameters:expectedState - the desired state Throws: ServiceStateException - if the service state is different from  the desired state enterState public org.apache.hadoop.service.Service.STATE enterState(org.apache.hadoop.service.Service.STATE proposed) Enter a state -thread safe. Parameters:proposed - proposed new state Returns:the original state Throws: ServiceStateException - if the transition is not permitted checkStateTransition public static void checkStateTransition(String name,                         org.apache.hadoop.service.Service.STATE state,                         org.apache.hadoop.service.Service.STATE proposed) Check that a state tansition is valid and  throw an exception if not Parameters:name - name of the service (can be null)state - current stateproposed - proposed new state isValidStateTransition public static boolean isValidStateTransition(org.apache.hadoop.service.Service.STATE current,                              org.apache.hadoop.service.Service.STATE proposed) Is a state transition valid?  There are no checks for current==proposed  as that is considered a non-transition.  using an array kills off all branch misprediction costs, at the expense  of cache line misses. Parameters:current - current stateproposed - proposed new state Returns:true if the transition to a new state is valid toString public String toString() return the state text as the toString() value Overrides: toString in class Object Returns:the current state's description Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SetFile (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SetFile (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class SetFile java.lang.Object org.apache.hadoop.io.MapFile org.apache.hadoop.io.SetFile @InterfaceAudience.Public @InterfaceStability.Stable public class SetFile extends MapFile A file-based set of keys. Field Summary Fields inherited from class org.apache.hadoop.io.MapFile DATA_FILE_NAME, INDEX_FILE_NAME Constructor Summary Constructors  Modifier Constructor and Description protected  SetFile()  Method Summary Methods inherited from class org.apache.hadoop.io.MapFile delete, fix, main, rename Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SetFile protected SetFile() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SharedCacheChecksum (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SharedCacheChecksum (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.sharedcache Interface SharedCacheChecksum @InterfaceAudience.Public @InterfaceStability.Evolving public interface SharedCacheChecksum Method Summary Methods  Modifier and Type Method and Description String computeChecksum(InputStream in) Calculate the checksum of the passed input stream. Method Detail computeChecksum String computeChecksum(InputStream in)                        throws IOException Calculate the checksum of the passed input stream. Parameters:in - InputStream to be checksumed Returns:the message digest of the input stream Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SharedCacheChecksumFactory (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SharedCacheChecksumFactory (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.sharedcache Class SharedCacheChecksumFactory java.lang.Object org.apache.hadoop.yarn.sharedcache.SharedCacheChecksumFactory @InterfaceAudience.Public @InterfaceStability.Evolving public class SharedCacheChecksumFactory extends Object Constructor Summary Constructors  Constructor and Description SharedCacheChecksumFactory()  Method Summary Methods  Modifier and Type Method and Description static SharedCacheChecksum getChecksum(Configuration conf) Get a new SharedCacheChecksum object based on the configurable  algorithm implementation  (see yarn.sharedcache.checksum.algo.impl) Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SharedCacheChecksumFactory public SharedCacheChecksumFactory() Method Detail getChecksum public static SharedCacheChecksum getChecksum(Configuration conf) Get a new SharedCacheChecksum object based on the configurable  algorithm implementation  (see yarn.sharedcache.checksum.algo.impl) Returns:SharedCacheChecksum object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SharedCacheClient (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SharedCacheClient (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api Class SharedCacheClient java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.client.api.SharedCacheClient All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class SharedCacheClient extends AbstractService This is the client for YARN's shared cache. Constructor Summary Constructors  Constructor and Description SharedCacheClient(String name)  Method Summary Methods  Modifier and Type Method and Description static SharedCacheClient createSharedCacheClient()  abstract String getFileChecksum(Path sourceFile) A convenience method to calculate the checksum of a specified file. abstract void release(ApplicationId applicationId,               String resourceKey)  The method to release a resource with the SharedCacheManager.  This method is called once an application is no longer using a claimed  resource in the shared cache. abstract Path use(ApplicationId applicationId,       String resourceKey)  The method to claim a resource with the SharedCacheManager.  The client uses a checksum to identify the resource and an  ApplicationId to identify which application will be using the  resource. Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceInit, serviceStart, serviceStop, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail SharedCacheClient @InterfaceAudience.Private public SharedCacheClient(String name) Method Detail createSharedCacheClient @InterfaceAudience.Public public static SharedCacheClient createSharedCacheClient() use @InterfaceAudience.Public @InterfaceStability.Unstable public abstract Path use(ApplicationId applicationId,                                                             String resourceKey)                   throws YarnException  The method to claim a resource with the SharedCacheManager.  The client uses a checksum to identify the resource and an  ApplicationId to identify which application will be using the  resource.        The SharedCacheManager responds with whether or not the  resource exists in the cache. If the resource exists, a Path  to the resource in the shared cache is returned. If the resource does not  exist, null is returned instead.   Parameters:applicationId - ApplicationId of the application using the resourceresourceKey - the key (i.e. checksum) that identifies the resource Returns:Path to the resource, or null if it does not exist Throws: YarnException release @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void release(ApplicationId applicationId,                                                                 String resourceKey)                       throws YarnException  The method to release a resource with the SharedCacheManager.  This method is called once an application is no longer using a claimed  resource in the shared cache. The client uses a checksum to identify the  resource and an ApplicationId to identify which application is  releasing the resource.        Note: This method is an optimization and the client is not required to call  it for correctness.   Parameters:applicationId - ApplicationId of the application releasing the           resourceresourceKey - the key (i.e. checksum) that identifies the resource Throws: YarnException getFileChecksum @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getFileChecksum(Path sourceFile)                                 throws IOException A convenience method to calculate the checksum of a specified file. Parameters:sourceFile - A path to the input file Returns:A hex string containing the checksum digest Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ShortWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ShortWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class ShortWritable java.lang.Object org.apache.hadoop.io.ShortWritable All Implemented Interfaces: Comparable<ShortWritable>, Writable, WritableComparable<ShortWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class ShortWritable extends Object implements WritableComparable<ShortWritable> A WritableComparable for shorts. Constructor Summary Constructors  Constructor and Description ShortWritable()  ShortWritable(short value)  Method Summary Methods  Modifier and Type Method and Description int compareTo(ShortWritable o) Compares two ShortWritable. boolean equals(Object o) Returns true iff o is a ShortWritable with the same value. short get() Return the value of this ShortWritable. int hashCode() hash code void readFields(DataInput in) read the short value void set(short value) Set the value of this ShortWritable. String toString() Short values in string format void write(DataOutput out) write short value Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail ShortWritable public ShortWritable() ShortWritable public ShortWritable(short value) Method Detail set public void set(short value) Set the value of this ShortWritable. get public short get() Return the value of this ShortWritable. readFields public void readFields(DataInput in)                 throws IOException read the short value Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException write short value Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object o) Returns true iff o is a ShortWritable with the same value. Overrides: equals in class Object hashCode public int hashCode() hash code Overrides: hashCode in class Object compareTo public int compareTo(ShortWritable o) Compares two ShortWritable. Specified by: compareTo in interface Comparable<ShortWritable> toString public String toString() Short values in string format Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SimpleCharStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SimpleCharStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler.generated Class SimpleCharStream java.lang.Object org.apache.hadoop.record.compiler.generated.SimpleCharStream Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class SimpleCharStream extends Object An implementation of interface CharStream, where the stream is assumed to  contain only ASCII characters (without unicode processing). Field Summary Fields  Modifier and Type Field and Description protected int[] bufcolumn Deprecated.    protected char[] buffer Deprecated.    protected int[] bufline Deprecated.    int bufpos Deprecated.    protected int column Deprecated.    protected int inBuf Deprecated.    protected Reader inputStream Deprecated.    protected int line Deprecated.    protected int maxNextCharInd Deprecated.    protected boolean prevCharIsCR Deprecated.    protected boolean prevCharIsLF Deprecated.    static boolean staticFlag Deprecated.    protected int tabSize Deprecated.    Constructor Summary Constructors  Constructor and Description SimpleCharStream(InputStream dstream) Deprecated.    SimpleCharStream(InputStream dstream,                                 int startline,                                 int startcolumn) Deprecated.    SimpleCharStream(InputStream dstream,                                 int startline,                                 int startcolumn,                                 int buffersize) Deprecated.    SimpleCharStream(InputStream dstream,                                 String encoding) Deprecated.    SimpleCharStream(InputStream dstream,                                 String encoding,                                 int startline,                                 int startcolumn) Deprecated.    SimpleCharStream(InputStream dstream,                                 String encoding,                                 int startline,                                 int startcolumn,                                 int buffersize) Deprecated.    SimpleCharStream(Reader dstream) Deprecated.    SimpleCharStream(Reader dstream,                                 int startline,                                 int startcolumn) Deprecated.    SimpleCharStream(Reader dstream,                                 int startline,                                 int startcolumn,                                 int buffersize) Deprecated.    Method Summary Methods  Modifier and Type Method and Description void adjustBeginLineColumn(int newLine,                                           int newCol) Deprecated.  Method to adjust line and column numbers for the start of a token. void backup(int amount) Deprecated.    char BeginToken() Deprecated.    void Done() Deprecated.    protected void ExpandBuff(boolean wrapAround) Deprecated.    protected void FillBuff() Deprecated.    int getBeginColumn() Deprecated.    int getBeginLine() Deprecated.    int getEndColumn() Deprecated.    int getEndLine() Deprecated.    String GetImage() Deprecated.    char[] GetSuffix(int len) Deprecated.    protected int getTabSize(int i) Deprecated.    char readChar() Deprecated.    void ReInit(InputStream dstream) Deprecated.    void ReInit(InputStream dstream,             int startline,             int startcolumn) Deprecated.    void ReInit(InputStream dstream,             int startline,             int startcolumn,             int buffersize) Deprecated.    void ReInit(InputStream dstream,             String encoding) Deprecated.    void ReInit(InputStream dstream,             String encoding,             int startline,             int startcolumn) Deprecated.    void ReInit(InputStream dstream,             String encoding,             int startline,             int startcolumn,             int buffersize) Deprecated.    void ReInit(Reader dstream) Deprecated.    void ReInit(Reader dstream,             int startline,             int startcolumn) Deprecated.    void ReInit(Reader dstream,             int startline,             int startcolumn,             int buffersize) Deprecated.    protected void setTabSize(int i) Deprecated.    protected void UpdateLineColumn(char c) Deprecated.    Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail staticFlag public static final boolean staticFlag Deprecated.  See Also:Constant Field Values bufpos public int bufpos Deprecated.  bufline protected int[] bufline Deprecated.  bufcolumn protected int[] bufcolumn Deprecated.  column protected int column Deprecated.  line protected int line Deprecated.  prevCharIsCR protected boolean prevCharIsCR Deprecated.  prevCharIsLF protected boolean prevCharIsLF Deprecated.  inputStream protected Reader inputStream Deprecated.  buffer protected char[] buffer Deprecated.  maxNextCharInd protected int maxNextCharInd Deprecated.  inBuf protected int inBuf Deprecated.  tabSize protected int tabSize Deprecated.  Constructor Detail SimpleCharStream public SimpleCharStream(Reader dstream,                 int startline,                 int startcolumn,                 int buffersize) Deprecated.  SimpleCharStream public SimpleCharStream(Reader dstream,                 int startline,                 int startcolumn) Deprecated.  SimpleCharStream public SimpleCharStream(Reader dstream) Deprecated.  SimpleCharStream public SimpleCharStream(InputStream dstream,                 String encoding,                 int startline,                 int startcolumn,                 int buffersize)                  throws UnsupportedEncodingException Deprecated.  Throws: UnsupportedEncodingException SimpleCharStream public SimpleCharStream(InputStream dstream,                 int startline,                 int startcolumn,                 int buffersize) Deprecated.  SimpleCharStream public SimpleCharStream(InputStream dstream,                 String encoding,                 int startline,                 int startcolumn)                  throws UnsupportedEncodingException Deprecated.  Throws: UnsupportedEncodingException SimpleCharStream public SimpleCharStream(InputStream dstream,                 int startline,                 int startcolumn) Deprecated.  SimpleCharStream public SimpleCharStream(InputStream dstream,                 String encoding)                  throws UnsupportedEncodingException Deprecated.  Throws: UnsupportedEncodingException SimpleCharStream public SimpleCharStream(InputStream dstream) Deprecated.  Method Detail setTabSize protected void setTabSize(int i) Deprecated.  getTabSize protected int getTabSize(int i) Deprecated.  ExpandBuff protected void ExpandBuff(boolean wrapAround) Deprecated.  FillBuff protected void FillBuff()                  throws IOException Deprecated.  Throws: IOException BeginToken public char BeginToken()                 throws IOException Deprecated.  Throws: IOException UpdateLineColumn protected void UpdateLineColumn(char c) Deprecated.  readChar public char readChar()               throws IOException Deprecated.  Throws: IOException getEndColumn public int getEndColumn() Deprecated.  getEndLine public int getEndLine() Deprecated.  getBeginColumn public int getBeginColumn() Deprecated.  getBeginLine public int getBeginLine() Deprecated.  backup public void backup(int amount) Deprecated.  ReInit public void ReInit(Reader dstream,           int startline,           int startcolumn,           int buffersize) Deprecated.  ReInit public void ReInit(Reader dstream,           int startline,           int startcolumn) Deprecated.  ReInit public void ReInit(Reader dstream) Deprecated.  ReInit public void ReInit(InputStream dstream,           String encoding,           int startline,           int startcolumn,           int buffersize)             throws UnsupportedEncodingException Deprecated.  Throws: UnsupportedEncodingException ReInit public void ReInit(InputStream dstream,           int startline,           int startcolumn,           int buffersize) Deprecated.  ReInit public void ReInit(InputStream dstream,           String encoding)             throws UnsupportedEncodingException Deprecated.  Throws: UnsupportedEncodingException ReInit public void ReInit(InputStream dstream) Deprecated.  ReInit public void ReInit(InputStream dstream,           String encoding,           int startline,           int startcolumn)             throws UnsupportedEncodingException Deprecated.  Throws: UnsupportedEncodingException ReInit public void ReInit(InputStream dstream,           int startline,           int startcolumn) Deprecated.  GetImage public String GetImage() Deprecated.  GetSuffix public char[] GetSuffix(int len) Deprecated.  Done public void Done() Deprecated.  adjustBeginLineColumn public void adjustBeginLineColumn(int newLine,                          int newCol) Deprecated.  Method to adjust line and column numbers for the start of a token. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SingleArcTransition (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SingleArcTransition (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.state Interface SingleArcTransition<OPERAND,EVENT> @InterfaceAudience.Public @InterfaceStability.Evolving public interface SingleArcTransition<OPERAND,EVENT> Hook for Transition. This lead to state machine to move to   the post state as registered in the state machine. Method Summary Methods  Modifier and Type Method and Description void transition(OPERAND operand,                     EVENT event) Transition hook. Method Detail transition void transition(OPERAND operand,               EVENT event) Transition hook. Parameters:operand - the entity attached to the FSM, whose internal                  state may change.event - causal event Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SkipBadRecords (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SkipBadRecords (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class SkipBadRecords java.lang.Object org.apache.hadoop.mapred.SkipBadRecords @InterfaceAudience.Public @InterfaceStability.Stable public class SkipBadRecords extends Object Utility class for skip bad records functionality. It contains various   settings related to skipping of bad records.    Hadoop provides an optional mode of execution in which the bad records  are detected and skipped in further attempts.    This feature can be used when map/reduce tasks crashes deterministically on   certain input. This happens due to bugs in the map/reduce function. The usual  course would be to fix these bugs. But sometimes this is not possible;   perhaps the bug is in third party libraries for which the source code is   not available. Due to this, the task never reaches to completion even with   multiple attempts and complete data for that task is lost.     With this feature, only a small portion of data is lost surrounding   the bad record, which may be acceptable for some user applications.  see setMapperMaxSkipRecords(Configuration, long)    The skipping mode gets kicked off after certain no of failures   see setAttemptsToStartSkipping(Configuration, int)     In the skipping mode, the map/reduce task maintains the record range which   is getting processed at all times. Before giving the input to the  map/reduce function, it sends this record range to the Task tracker.  If task crashes, the Task tracker knows which one was the last reported  range. On further attempts that range get skipped. Field Summary Fields  Modifier and Type Field and Description static String COUNTER_GROUP Special counters which are written by the application and are   used by the framework for detecting bad records. static String COUNTER_MAP_PROCESSED_RECORDS Number of processed map records. static String COUNTER_REDUCE_PROCESSED_GROUPS Number of processed reduce groups. Constructor Summary Constructors  Constructor and Description SkipBadRecords()  Method Summary Methods  Modifier and Type Method and Description static int getAttemptsToStartSkipping(Configuration conf) Get the number of Task attempts AFTER which skip mode   will be kicked off. static boolean getAutoIncrMapperProcCount(Configuration conf) Get the flag which if set to true,   COUNTER_MAP_PROCESSED_RECORDS is incremented   by MapRunner after invoking the map function. static boolean getAutoIncrReducerProcCount(Configuration conf) Get the flag which if set to true,   COUNTER_REDUCE_PROCESSED_GROUPS is incremented   by framework after invoking the reduce function. static long getMapperMaxSkipRecords(Configuration conf) Get the number of acceptable skip records surrounding the bad record PER   bad record in mapper. static long getReducerMaxSkipGroups(Configuration conf) Get the number of acceptable skip groups surrounding the bad group PER   bad group in reducer. static Path getSkipOutputPath(Configuration conf) Get the directory to which skipped records are written. static void setAttemptsToStartSkipping(Configuration conf,                                                     int attemptsToStartSkipping) Set the number of Task attempts AFTER which skip mode   will be kicked off. static void setAutoIncrMapperProcCount(Configuration conf,                                                     boolean autoIncr) Set the flag which if set to true,   COUNTER_MAP_PROCESSED_RECORDS is incremented   by MapRunner after invoking the map function. static void setAutoIncrReducerProcCount(Configuration conf,                                                       boolean autoIncr) Set the flag which if set to true,   COUNTER_REDUCE_PROCESSED_GROUPS is incremented   by framework after invoking the reduce function. static void setMapperMaxSkipRecords(Configuration conf,                                               long maxSkipRecs) Set the number of acceptable skip records surrounding the bad record PER   bad record in mapper. static void setReducerMaxSkipGroups(Configuration conf,                                               long maxSkipGrps) Set the number of acceptable skip groups surrounding the bad group PER   bad group in reducer. static void setSkipOutputPath(JobConf conf,                                   Path path) Set the directory to which skipped records are written. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail COUNTER_GROUP public static final String COUNTER_GROUP Special counters which are written by the application and are   used by the framework for detecting bad records. For detecting bad records   these counters must be incremented by the application. See Also:Constant Field Values COUNTER_MAP_PROCESSED_RECORDS public static final String COUNTER_MAP_PROCESSED_RECORDS Number of processed map records. See Also:getAutoIncrMapperProcCount(Configuration),  Constant Field Values COUNTER_REDUCE_PROCESSED_GROUPS public static final String COUNTER_REDUCE_PROCESSED_GROUPS Number of processed reduce groups. See Also:getAutoIncrReducerProcCount(Configuration),  Constant Field Values Constructor Detail SkipBadRecords public SkipBadRecords() Method Detail getAttemptsToStartSkipping public static int getAttemptsToStartSkipping(Configuration conf) Get the number of Task attempts AFTER which skip mode   will be kicked off. When skip mode is kicked off, the   tasks reports the range of records which it will process   next to the TaskTracker. So that on failures, TT knows which   ones are possibly the bad records. On further executions,   those are skipped.  Default value is 2. Parameters:conf - the configuration Returns:attemptsToStartSkipping no of task attempts setAttemptsToStartSkipping public static void setAttemptsToStartSkipping(Configuration conf,                               int attemptsToStartSkipping) Set the number of Task attempts AFTER which skip mode   will be kicked off. When skip mode is kicked off, the   tasks reports the range of records which it will process   next to the TaskTracker. So that on failures, TT knows which   ones are possibly the bad records. On further executions,   those are skipped.  Default value is 2. Parameters:conf - the configurationattemptsToStartSkipping - no of task attempts getAutoIncrMapperProcCount public static boolean getAutoIncrMapperProcCount(Configuration conf) Get the flag which if set to true,   COUNTER_MAP_PROCESSED_RECORDS is incremented   by MapRunner after invoking the map function. This value must be set to   false for applications which process the records asynchronously   or buffer the input records. For example streaming.   In such cases applications should increment this counter on their own.  Default value is true. Parameters:conf - the configuration Returns:true if auto increment                         COUNTER_MAP_PROCESSED_RECORDS.          false otherwise. setAutoIncrMapperProcCount public static void setAutoIncrMapperProcCount(Configuration conf,                               boolean autoIncr) Set the flag which if set to true,   COUNTER_MAP_PROCESSED_RECORDS is incremented   by MapRunner after invoking the map function. This value must be set to   false for applications which process the records asynchronously   or buffer the input records. For example streaming.   In such cases applications should increment this counter on their own.  Default value is true. Parameters:conf - the configurationautoIncr - whether to auto increment          COUNTER_MAP_PROCESSED_RECORDS. getAutoIncrReducerProcCount public static boolean getAutoIncrReducerProcCount(Configuration conf) Get the flag which if set to true,   COUNTER_REDUCE_PROCESSED_GROUPS is incremented   by framework after invoking the reduce function. This value must be set to   false for applications which process the records asynchronously   or buffer the input records. For example streaming.   In such cases applications should increment this counter on their own.  Default value is true. Parameters:conf - the configuration Returns:true if auto increment                      COUNTER_REDUCE_PROCESSED_GROUPS.          false otherwise. setAutoIncrReducerProcCount public static void setAutoIncrReducerProcCount(Configuration conf,                                boolean autoIncr) Set the flag which if set to true,   COUNTER_REDUCE_PROCESSED_GROUPS is incremented   by framework after invoking the reduce function. This value must be set to   false for applications which process the records asynchronously   or buffer the input records. For example streaming.   In such cases applications should increment this counter on their own.  Default value is true. Parameters:conf - the configurationautoIncr - whether to auto increment          COUNTER_REDUCE_PROCESSED_GROUPS. getSkipOutputPath public static Path getSkipOutputPath(Configuration conf) Get the directory to which skipped records are written. By default it is   the sub directory of the output _logs directory.  User can stop writing skipped records by setting the value null. Parameters:conf - the configuration. Returns:path skip output directory. Null is returned if this is not set   and output directory is also not set. setSkipOutputPath public static void setSkipOutputPath(JobConf conf,                      Path path) Set the directory to which skipped records are written. By default it is   the sub directory of the output _logs directory.  User can stop writing skipped records by setting the value null. Parameters:conf - the configuration.path - skip output directory path getMapperMaxSkipRecords public static long getMapperMaxSkipRecords(Configuration conf) Get the number of acceptable skip records surrounding the bad record PER   bad record in mapper. The number includes the bad record as well.  To turn the feature of detection/skipping of bad records off, set the   value to 0.  The framework tries to narrow down the skipped range by retrying    until this threshold is met OR all attempts get exhausted for this task.   Set the value to Long.MAX_VALUE to indicate that framework need not try to   narrow down. Whatever records(depends on application) get skipped are   acceptable.  Default value is 0. Parameters:conf - the configuration Returns:maxSkipRecs acceptable skip records. setMapperMaxSkipRecords public static void setMapperMaxSkipRecords(Configuration conf,                            long maxSkipRecs) Set the number of acceptable skip records surrounding the bad record PER   bad record in mapper. The number includes the bad record as well.  To turn the feature of detection/skipping of bad records off, set the   value to 0.  The framework tries to narrow down the skipped range by retrying    until this threshold is met OR all attempts get exhausted for this task.   Set the value to Long.MAX_VALUE to indicate that framework need not try to   narrow down. Whatever records(depends on application) get skipped are   acceptable.  Default value is 0. Parameters:conf - the configurationmaxSkipRecs - acceptable skip records. getReducerMaxSkipGroups public static long getReducerMaxSkipGroups(Configuration conf) Get the number of acceptable skip groups surrounding the bad group PER   bad group in reducer. The number includes the bad group as well.  To turn the feature of detection/skipping of bad groups off, set the   value to 0.  The framework tries to narrow down the skipped range by retrying    until this threshold is met OR all attempts get exhausted for this task.   Set the value to Long.MAX_VALUE to indicate that framework need not try to   narrow down. Whatever groups(depends on application) get skipped are   acceptable.  Default value is 0. Parameters:conf - the configuration Returns:maxSkipGrps acceptable skip groups. setReducerMaxSkipGroups public static void setReducerMaxSkipGroups(Configuration conf,                            long maxSkipGrps) Set the number of acceptable skip groups surrounding the bad group PER   bad group in reducer. The number includes the bad group as well.  To turn the feature of detection/skipping of bad groups off, set the   value to 0.  The framework tries to narrow down the skipped range by retrying    until this threshold is met OR all attempts get exhausted for this task.   Set the value to Long.MAX_VALUE to indicate that framework need not try to   narrow down. Whatever groups(depends on application) get skipped are   acceptable.  Default value is 0. Parameters:conf - the configurationmaxSkipGrps - acceptable skip groups. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SocksSocketFactory (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SocksSocketFactory (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.net Class SocksSocketFactory java.lang.Object javax.net.SocketFactory org.apache.hadoop.net.SocksSocketFactory All Implemented Interfaces: Configurable @InterfaceAudience.Public @InterfaceStability.Evolving public class SocksSocketFactory extends SocketFactory implements Configurable Specialized SocketFactory to create sockets with a SOCKS proxy Constructor Summary Constructors  Constructor and Description SocksSocketFactory() Default empty constructor (for use with the reflection API). SocksSocketFactory(Proxy proxy) Constructor with a supplied Proxy Method Summary Methods  Modifier and Type Method and Description Socket createSocket()  Socket createSocket(InetAddress addr,                         int port)  Socket createSocket(InetAddress addr,                         int port,                         InetAddress localHostAddr,                         int localPort)  Socket createSocket(String host,                         int port)  Socket createSocket(String host,                         int port,                         InetAddress localHostAddr,                         int localPort)  boolean equals(Object obj)  Configuration getConf() Return the configuration used by this object. int hashCode()  void setConf(Configuration conf) Set the configuration to be used by this object. Methods inherited from class javax.net.SocketFactory getDefault Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail SocksSocketFactory public SocksSocketFactory() Default empty constructor (for use with the reflection API). SocksSocketFactory public SocksSocketFactory(Proxy proxy) Constructor with a supplied Proxy Parameters:proxy - the proxy to use to create sockets Method Detail createSocket public Socket createSocket()                     throws IOException Overrides: createSocket in class SocketFactory Throws: IOException createSocket public Socket createSocket(InetAddress addr,                   int port)                     throws IOException Specified by: createSocket in class SocketFactory Throws: IOException createSocket public Socket createSocket(InetAddress addr,                   int port,                   InetAddress localHostAddr,                   int localPort)                     throws IOException Specified by: createSocket in class SocketFactory Throws: IOException createSocket public Socket createSocket(String host,                   int port)                     throws IOException,                            UnknownHostException Specified by: createSocket in class SocketFactory Throws: IOException UnknownHostException createSocket public Socket createSocket(String host,                   int port,                   InetAddress localHostAddr,                   int localPort)                     throws IOException,                            UnknownHostException Specified by: createSocket in class SocketFactory Throws: IOException UnknownHostException hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SortedMapWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SortedMapWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class SortedMapWritable java.lang.Object org.apache.hadoop.io.AbstractMapWritable org.apache.hadoop.io.SortedMapWritable All Implemented Interfaces: Map<WritableComparable,Writable>, SortedMap<WritableComparable,Writable>, Configurable, Writable @InterfaceAudience.Public @InterfaceStability.Stable public class SortedMapWritable extends AbstractMapWritable implements SortedMap<WritableComparable,Writable> A Writable SortedMap. Constructor Summary Constructors  Constructor and Description SortedMapWritable() default constructor. SortedMapWritable(SortedMapWritable other) Copy constructor. Method Summary Methods  Modifier and Type Method and Description void clear()  Comparator<? super WritableComparable> comparator()  boolean containsKey(Object key)  boolean containsValue(Object value)  Set<Map.Entry<WritableComparable,Writable>> entrySet()  boolean equals(Object obj)  WritableComparable firstKey()  Writable get(Object key)  int hashCode()  SortedMap<WritableComparable,Writable> headMap(WritableComparable toKey)  boolean isEmpty()  Set<WritableComparable> keySet()  WritableComparable lastKey()  Writable put(WritableComparable key,       Writable value)  void putAll(Map<? extends WritableComparable,? extends Writable> t)  void readFields(DataInput in) Deserialize the fields of this object from in. Writable remove(Object key)  int size()  SortedMap<WritableComparable,Writable> subMap(WritableComparable fromKey,             WritableComparable toKey)  SortedMap<WritableComparable,Writable> tailMap(WritableComparable fromKey)  Collection<Writable> values()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.io.AbstractMapWritable addToMap, copy, getClass, getConf, getId, setConf Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail SortedMapWritable public SortedMapWritable() default constructor. SortedMapWritable public SortedMapWritable(SortedMapWritable other) Copy constructor. Parameters:other - the map to copy from Method Detail comparator public Comparator<? super WritableComparable> comparator() Specified by: comparator in interface SortedMap<WritableComparable,Writable> firstKey public WritableComparable firstKey() Specified by: firstKey in interface SortedMap<WritableComparable,Writable> headMap public SortedMap<WritableComparable,Writable> headMap(WritableComparable toKey) Specified by: headMap in interface SortedMap<WritableComparable,Writable> lastKey public WritableComparable lastKey() Specified by: lastKey in interface SortedMap<WritableComparable,Writable> subMap public SortedMap<WritableComparable,Writable> subMap(WritableComparable fromKey,                                             WritableComparable toKey) Specified by: subMap in interface SortedMap<WritableComparable,Writable> tailMap public SortedMap<WritableComparable,Writable> tailMap(WritableComparable fromKey) Specified by: tailMap in interface SortedMap<WritableComparable,Writable> clear public void clear() Specified by: clear in interface Map<WritableComparable,Writable> containsKey public boolean containsKey(Object key) Specified by: containsKey in interface Map<WritableComparable,Writable> containsValue public boolean containsValue(Object value) Specified by: containsValue in interface Map<WritableComparable,Writable> entrySet public Set<Map.Entry<WritableComparable,Writable>> entrySet() Specified by: entrySet in interface Map<WritableComparable,Writable> Specified by: entrySet in interface SortedMap<WritableComparable,Writable> get public Writable get(Object key) Specified by: get in interface Map<WritableComparable,Writable> isEmpty public boolean isEmpty() Specified by: isEmpty in interface Map<WritableComparable,Writable> keySet public Set<WritableComparable> keySet() Specified by: keySet in interface Map<WritableComparable,Writable> Specified by: keySet in interface SortedMap<WritableComparable,Writable> put public Writable put(WritableComparable key,            Writable value) Specified by: put in interface Map<WritableComparable,Writable> putAll public void putAll(Map<? extends WritableComparable,? extends Writable> t) Specified by: putAll in interface Map<WritableComparable,Writable> remove public Writable remove(Object key) Specified by: remove in interface Map<WritableComparable,Writable> size public int size() Specified by: size in interface Map<WritableComparable,Writable> values public Collection<Writable> values() Specified by: values in interface Map<WritableComparable,Writable> Specified by: values in interface SortedMap<WritableComparable,Writable> readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Overrides: readFields in class AbstractMapWritable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Overrides: write in class AbstractMapWritable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object obj) Specified by: equals in interface Map<WritableComparable,Writable> Overrides: equals in class Object hashCode public int hashCode() Specified by: hashCode in interface Map<WritableComparable,Writable> Overrides: hashCode in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SpanReceiverInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SpanReceiverInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.tracing Class SpanReceiverInfo java.lang.Object org.apache.hadoop.tracing.SpanReceiverInfo @InterfaceAudience.Public @InterfaceStability.Stable public class SpanReceiverInfo extends Object Method Summary Methods  Modifier and Type Method and Description String getClassName()  long getId()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail getId public long getId() getClassName public String getClassName() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SpanReceiverInfoBuilder (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SpanReceiverInfoBuilder (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.tracing Class SpanReceiverInfoBuilder java.lang.Object org.apache.hadoop.tracing.SpanReceiverInfoBuilder @InterfaceAudience.Public @InterfaceStability.Stable public class SpanReceiverInfoBuilder extends Object Constructor Summary Constructors  Constructor and Description SpanReceiverInfoBuilder(String className)  Method Summary Methods  Modifier and Type Method and Description void addConfigurationPair(String key,                                         String value)  SpanReceiverInfo build()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SpanReceiverInfoBuilder public SpanReceiverInfoBuilder(String className) Method Detail addConfigurationPair public void addConfigurationPair(String key,                         String value) build public SpanReceiverInfo build() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SplitCompressionInputStream (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SplitCompressionInputStream (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Class SplitCompressionInputStream java.lang.Object java.io.InputStream org.apache.hadoop.io.compress.CompressionInputStream org.apache.hadoop.io.compress.SplitCompressionInputStream All Implemented Interfaces: Closeable, AutoCloseable, Seekable @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class SplitCompressionInputStream extends CompressionInputStream An InputStream covering a range of compressed data. The start and end  offsets requested by a client may be modified by the codec to fit block  boundaries or other algorithm-dependent requirements. Field Summary Fields inherited from class org.apache.hadoop.io.compress.CompressionInputStream in, maxAvailableData Constructor Summary Constructors  Constructor and Description SplitCompressionInputStream(InputStream in,                                                       long start,                                                       long end)  Method Summary Methods  Modifier and Type Method and Description long getAdjustedEnd() After calling createInputStream, the values of start or end  might change. long getAdjustedStart() After calling createInputStream, the values of start or end  might change. protected void setEnd(long end)  protected void setStart(long start)  Methods inherited from class org.apache.hadoop.io.compress.CompressionInputStream close, getPos, read, resetState, seek, seekToNewSource Methods inherited from class java.io.InputStream available, mark, markSupported, read, read, reset, skip Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SplitCompressionInputStream public SplitCompressionInputStream(InputStream in,                            long start,                            long end)                             throws IOException Throws: IOException Method Detail setStart protected void setStart(long start) setEnd protected void setEnd(long end) getAdjustedStart public long getAdjustedStart() After calling createInputStream, the values of start or end  might change.  So this method can be used to get the new value of start. Returns:The changed value of start getAdjustedEnd public long getAdjustedEnd() After calling createInputStream, the values of start or end  might change.  So this method can be used to get the new value of end. Returns:The changed value of end Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SplitLocationInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SplitLocationInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class SplitLocationInfo java.lang.Object org.apache.hadoop.mapred.SplitLocationInfo @InterfaceAudience.Public @InterfaceStability.Evolving public class SplitLocationInfo extends Object Constructor Summary Constructors  Constructor and Description SplitLocationInfo(String location,                                   boolean inMemory)  Method Summary Methods  Modifier and Type Method and Description String getLocation()  boolean isInMemory()  boolean isOnDisk()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SplitLocationInfo public SplitLocationInfo(String location,                  boolean inMemory) Method Detail isOnDisk public boolean isOnDisk() isInMemory public boolean isInMemory() getLocation public String getLocation() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SplittableCompressionCodec (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SplittableCompressionCodec (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.compress Interface SplittableCompressionCodec All Superinterfaces: CompressionCodec All Known Implementing Classes: BZip2Codec @InterfaceAudience.Public @InterfaceStability.Evolving public interface SplittableCompressionCodec extends CompressionCodec This interface is meant to be implemented by those compression codecs  which are capable to compress / de-compress a stream starting at any  arbitrary position.  Especially the process of de-compressing a stream starting at some arbitrary  position is challenging.  Most of the codecs are only able to successfully  de-compress a stream, if they start from the very beginning till the end.  One of the reasons is the stored state at the beginning of the stream which  is crucial for de-compression.  Yet there are few codecs which do not save the whole state at the beginning  of the stream and hence can be used to de-compress stream starting at any  arbitrary points.  This interface is meant to be used by such codecs.  Such  codecs are highly valuable, especially in the context of Hadoop, because  an input compressed file can be split and hence can be worked on by multiple  machines in parallel. Method Summary Methods  Modifier and Type Method and Description SplitCompressionInputStream createInputStream(InputStream seekableIn,                                   Decompressor decompressor,                                   long start,                                   long end,                                   org.apache.hadoop.io.compress.SplittableCompressionCodec.READ_MODE readMode) Create a stream as dictated by the readMode. Methods inherited from interface org.apache.hadoop.io.compress.CompressionCodec createCompressor, createDecompressor, createInputStream, createInputStream, createOutputStream, createOutputStream, getCompressorType, getDecompressorType, getDefaultExtension Method Detail createInputStream SplitCompressionInputStream createInputStream(InputStream seekableIn,                                             Decompressor decompressor,                                             long start,                                             long end,                                             org.apache.hadoop.io.compress.SplittableCompressionCodec.READ_MODE readMode)                                               throws IOException Create a stream as dictated by the readMode.  This method is used when  the codecs wants the ability to work with the underlying stream positions. Parameters:seekableIn - The seekable input stream (seeks in compressed data)start - The start offset into the compressed stream. May be changed               by the underlying codec.end - The end offset into the compressed stream. May be changed by             the underlying codec.readMode - Controls whether stream position is reported continuously                  from the compressed stream only only at block boundaries. Returns:a stream to read uncompressed bytes from Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StandardSocketFactory (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StandardSocketFactory (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.net Class StandardSocketFactory java.lang.Object javax.net.SocketFactory org.apache.hadoop.net.StandardSocketFactory @InterfaceAudience.Public @InterfaceStability.Evolving public class StandardSocketFactory extends SocketFactory Specialized SocketFactory to create sockets with a SOCKS proxy Constructor Summary Constructors  Constructor and Description StandardSocketFactory() Default empty constructor (for use with the reflection API). Method Summary Methods  Modifier and Type Method and Description Socket createSocket()  Socket createSocket(InetAddress addr,                         int port)  Socket createSocket(InetAddress addr,                         int port,                         InetAddress localHostAddr,                         int localPort)  Socket createSocket(String host,                         int port)  Socket createSocket(String host,                         int port,                         InetAddress localHostAddr,                         int localPort)  boolean equals(Object obj)  int hashCode()  Methods inherited from class javax.net.SocketFactory getDefault Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail StandardSocketFactory public StandardSocketFactory() Default empty constructor (for use with the reflection API). Method Detail createSocket public Socket createSocket()                     throws IOException Overrides: createSocket in class SocketFactory Throws: IOException createSocket public Socket createSocket(InetAddress addr,                   int port)                     throws IOException Specified by: createSocket in class SocketFactory Throws: IOException createSocket public Socket createSocket(InetAddress addr,                   int port,                   InetAddress localHostAddr,                   int localPort)                     throws IOException Specified by: createSocket in class SocketFactory Throws: IOException createSocket public Socket createSocket(String host,                   int port)                     throws IOException,                            UnknownHostException Specified by: createSocket in class SocketFactory Throws: IOException UnknownHostException createSocket public Socket createSocket(String host,                   int port,                   InetAddress localHostAddr,                   int localPort)                     throws IOException,                            UnknownHostException Specified by: createSocket in class SocketFactory Throws: IOException UnknownHostException equals public boolean equals(Object obj) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StartContainerRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StartContainerRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class StartContainerRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class StartContainerRequest extends Object The request sent by the ApplicationMaster to the  NodeManager to start a container.    The ApplicationMaster has to provide details such as  allocated resource capability, security tokens (if enabled), command  to be executed to start the container, environment for the process,   necessary binaries/jar/shared-objects etc. via the   ContainerLaunchContext. See Also:ContainerManagementProtocol.startContainers(StartContainersRequest) Constructor Summary Constructors  Constructor and Description StartContainerRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ContainerLaunchContext getContainerLaunchContext() Get the ContainerLaunchContext for the container to be started  by the NodeManager. abstract Token getContainerToken() Get the container token to be used for authorization during starting  container. static StartContainerRequest newInstance(ContainerLaunchContext context,                       Token container)  abstract void setContainerLaunchContext(ContainerLaunchContext context) Set the ContainerLaunchContext for the container to be started  by the NodeManager abstract void setContainerToken(Token container)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StartContainerRequest public StartContainerRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static StartContainerRequest newInstance(ContainerLaunchContext context,                                                                                    Token container) getContainerLaunchContext @InterfaceAudience.Public @InterfaceStability.Stable public abstract ContainerLaunchContext getContainerLaunchContext() Get the ContainerLaunchContext for the container to be started  by the NodeManager. Returns:ContainerLaunchContext for the container to be started          by the NodeManager setContainerLaunchContext @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setContainerLaunchContext(ContainerLaunchContext context) Set the ContainerLaunchContext for the container to be started  by the NodeManager Parameters:context - ContainerLaunchContext for the container to be                  started by the NodeManager getContainerToken @InterfaceAudience.Public @InterfaceStability.Stable public abstract Token getContainerToken() Get the container token to be used for authorization during starting  container.    Note: NMToken will be used for authenticating communication with  NodeManager. Returns:the container token to be used for authorization during starting  container.See Also:NMToken,  ContainerManagementProtocol.startContainers(StartContainersRequest) setContainerToken @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setContainerToken(Token container) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StartContainersRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StartContainersRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class StartContainersRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class StartContainersRequest extends Object  The request which contains a list of StartContainerRequest sent by  the ApplicationMaster to the NodeManager to  start containers.        In each StartContainerRequest, the ApplicationMaster has  to provide details such as allocated resource capability, security tokens (if  enabled), command to be executed to start the container, environment for the  process, necessary binaries/jar/shared-objects etc. via the  ContainerLaunchContext.   See Also:ContainerManagementProtocol.startContainers(StartContainersRequest) Constructor Summary Constructors  Constructor and Description StartContainersRequest()  Method Summary Methods  Modifier and Type Method and Description abstract List<StartContainerRequest> getStartContainerRequests() Get a list of StartContainerRequest to start containers. static StartContainersRequest newInstance(List<StartContainerRequest> requests)  abstract void setStartContainerRequests(List<StartContainerRequest> request) Set a list of StartContainerRequest to start containers. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StartContainersRequest public StartContainersRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static StartContainersRequest newInstance(List<StartContainerRequest> requests) getStartContainerRequests @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<StartContainerRequest> getStartContainerRequests() Get a list of StartContainerRequest to start containers. Returns:a list of StartContainerRequest to start containers. setStartContainerRequests @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setStartContainerRequests(List<StartContainerRequest> request) Set a list of StartContainerRequest to start containers. Parameters:request - a list of StartContainerRequest to start containers Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StartContainersResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StartContainersResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class StartContainersResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class StartContainersResponse extends Object  The response sent by the NodeManager to the  ApplicationMaster when asked to start an allocated  container.   See Also:ContainerManagementProtocol.startContainers(StartContainersRequest) Constructor Summary Constructors  Constructor and Description StartContainersResponse()  Method Summary Methods  Modifier and Type Method and Description abstract Map<String,ByteBuffer> getAllServicesMetaData()  Get the meta-data from all auxiliary services running on the  NodeManager. abstract Map<ContainerId,org.apache.hadoop.yarn.api.records.SerializedException> getFailedRequests() Get the containerId-to-exception map in which the exception indicates error  from per container for failed requests abstract List<ContainerId> getSuccessfullyStartedContainers() Get the list of ContainerId s of the containers that are  started successfully. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StartContainersResponse public StartContainersResponse() Method Detail getSuccessfullyStartedContainers @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ContainerId> getSuccessfullyStartedContainers() Get the list of ContainerId s of the containers that are  started successfully. Returns:the list of ContainerId s of the containers that are          started successfully.See Also:ContainerManagementProtocol.startContainers(StartContainersRequest) getFailedRequests @InterfaceAudience.Public @InterfaceStability.Stable public abstract Map<ContainerId,org.apache.hadoop.yarn.api.records.SerializedException> getFailedRequests() Get the containerId-to-exception map in which the exception indicates error  from per container for failed requests getAllServicesMetaData @InterfaceAudience.Public @InterfaceStability.Stable public abstract Map<String,ByteBuffer> getAllServicesMetaData()  Get the meta-data from all auxiliary services running on the  NodeManager.      The meta-data is returned as a Map between the auxiliary service names and  their corresponding per service meta-data as an opaque blob  ByteBuffer        To be able to interpret the per-service meta-data, you should consult the  documentation for the Auxiliary-service configured on the NodeManager   Returns:a Map between the names of auxiliary services and their          corresponding meta-data Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StateMachine (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StateMachine (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.state Interface StateMachine<STATE extends Enum<STATE>,EVENTTYPE extends Enum<EVENTTYPE>,EVENT> @InterfaceAudience.Public @InterfaceStability.Evolving public interface StateMachine<STATE extends Enum<STATE>,EVENTTYPE extends Enum<EVENTTYPE>,EVENT> Method Summary Methods  Modifier and Type Method and Description STATE doTransition(EVENTTYPE eventType,                         EVENT event)  STATE getCurrentState()  Method Detail getCurrentState STATE getCurrentState() doTransition STATE doTransition(EVENTTYPE eventType,                  EVENT event)                                        throws InvalidStateTransitonException Throws: InvalidStateTransitonException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StateMachineFactory (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StateMachineFactory (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.state Class StateMachineFactory<OPERAND,STATE extends Enum<STATE>,EVENTTYPE extends Enum<EVENTTYPE>,EVENT> java.lang.Object org.apache.hadoop.yarn.state.StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> Type Parameters:OPERAND - The object type on which this state machine operates.STATE - The state of the entity.EVENTTYPE - The external eventType to be handled.EVENT - The event object. @InterfaceAudience.Public @InterfaceStability.Evolving public final class StateMachineFactory<OPERAND,STATE extends Enum<STATE>,EVENTTYPE extends Enum<EVENTTYPE>,EVENT> extends Object State machine topology.  This object is semantically immutable.  If you have a  StateMachineFactory there's no operation in the API that changes  its semantic properties. Constructor Summary Constructors  Constructor and Description StateMachineFactory(STATE defaultInitialState) Constructor  This is the only constructor in the API. Method Summary Methods  Modifier and Type Method and Description StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                           Set<STATE> postStates,                           EVENTTYPE eventType,                           MultipleArcTransition<OPERAND,EVENT,STATE> hook)  StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                           STATE postState,                           EVENTTYPE eventType)  StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                           STATE postState,                           EVENTTYPE eventType,                           SingleArcTransition<OPERAND,EVENT> hook)  StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                           STATE postState,                           Set<EVENTTYPE> eventTypes)  StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                           STATE postState,                           Set<EVENTTYPE> eventTypes,                           SingleArcTransition<OPERAND,EVENT> hook)  org.apache.hadoop.yarn.state.Graph generateStateGraph(String name) Generate a graph represents the state graph of this StateMachine StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> installTopology()  StateMachine<STATE,EVENTTYPE,EVENT> make(OPERAND operand)  StateMachine<STATE,EVENTTYPE,EVENT> make(OPERAND operand,         STATE initialState)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StateMachineFactory public StateMachineFactory(STATE defaultInitialState) Constructor  This is the only constructor in the API. Method Detail addTransition public StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                                                                STATE postState,                                                                EVENTTYPE eventType) Parameters:preState - pre-transition statepostState - post-transition stateeventType - stimulus for the transition Returns:a NEW StateMachineFactory just like this with the current           transition added as a new legal transition.  This overload           has no hook object.          Note that the returned StateMachineFactory is a distinct          object.          This method is part of the API. addTransition public StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                                                                STATE postState,                                                                Set<EVENTTYPE> eventTypes) Parameters:preState - pre-transition statepostState - post-transition stateeventTypes - List of stimuli for the transitions Returns:a NEW StateMachineFactory just like this with the current           transition added as a new legal transition.  This overload           has no hook object.          Note that the returned StateMachineFactory is a distinct          object.          This method is part of the API. addTransition public StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                                                                STATE postState,                                                                Set<EVENTTYPE> eventTypes,                                                                SingleArcTransition<OPERAND,EVENT> hook) Parameters:preState - pre-transition statepostState - post-transition stateeventTypes - List of stimuli for the transitionshook - transition hook Returns:a NEW StateMachineFactory just like this with the current           transition added as a new legal transition          Note that the returned StateMachineFactory is a distinct          object.          This method is part of the API. addTransition public StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                                                                STATE postState,                                                                EVENTTYPE eventType,                                                                SingleArcTransition<OPERAND,EVENT> hook) Parameters:preState - pre-transition statepostState - post-transition stateeventType - stimulus for the transitionhook - transition hook Returns:a NEW StateMachineFactory just like this with the current           transition added as a new legal transition          Note that the returned StateMachineFactory is a distinct object.          This method is part of the API. addTransition public StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> addTransition(STATE preState,                                                                Set<STATE> postStates,                                                                EVENTTYPE eventType,                                                                MultipleArcTransition<OPERAND,EVENT,STATE> hook) Parameters:preState - pre-transition statepostStates - valid post-transition stateseventType - stimulus for the transitionhook - transition hook Returns:a NEW StateMachineFactory just like this with the current           transition added as a new legal transition          Note that the returned StateMachineFactory is a distinct object.          This method is part of the API. installTopology public StateMachineFactory<OPERAND,STATE,EVENTTYPE,EVENT> installTopology() Returns:a StateMachineFactory just like this, except that if          you won't need any synchronization to build a state machine          Note that the returned StateMachineFactory is a distinct object.          This method is part of the API.          The only way you could distinguish the returned          StateMachineFactory from this would be by          measuring the performance of the derived           StateMachine you can get from it.  Calling this is optional.  It doesn't change the semantics of the factory,    if you call it then when you use the factory there is no synchronization. make public StateMachine<STATE,EVENTTYPE,EVENT> make(OPERAND operand,                                        STATE initialState) make public StateMachine<STATE,EVENTTYPE,EVENT> make(OPERAND operand) generateStateGraph public org.apache.hadoop.yarn.state.Graph generateStateGraph(String name) Generate a graph represents the state graph of this StateMachine Parameters:name - graph name Returns:Graph object generated Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StopContainersRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StopContainersRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class StopContainersRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class StopContainersRequest extends Object The request sent by the ApplicationMaster to the  NodeManager to stop containers. See Also:ContainerManagementProtocol.stopContainers(StopContainersRequest) Constructor Summary Constructors  Constructor and Description StopContainersRequest()  Method Summary Methods  Modifier and Type Method and Description abstract List<ContainerId> getContainerIds() Get the ContainerIds of the containers to be stopped. static StopContainersRequest newInstance(List<ContainerId> containerIds)  abstract void setContainerIds(List<ContainerId> containerIds) Set the ContainerIds of the containers to be stopped. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StopContainersRequest public StopContainersRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static StopContainersRequest newInstance(List<ContainerId> containerIds) getContainerIds @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ContainerId> getContainerIds() Get the ContainerIds of the containers to be stopped. Returns:ContainerIds of containers to be stopped setContainerIds @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setContainerIds(List<ContainerId> containerIds) Set the ContainerIds of the containers to be stopped. Parameters:containerIds - ContainerIds of the containers to be stopped Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StopContainersResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StopContainersResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class StopContainersResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class StopContainersResponse extends Object  The response sent by the NodeManager to the  ApplicationMaster when asked to stop allocated  containers.   See Also:ContainerManagementProtocol.stopContainers(StopContainersRequest) Constructor Summary Constructors  Constructor and Description StopContainersResponse()  Method Summary Methods  Modifier and Type Method and Description abstract Map<ContainerId,org.apache.hadoop.yarn.api.records.SerializedException> getFailedRequests() Get the containerId-to-exception map in which the exception indicates error  from per container for failed requests abstract List<ContainerId> getSuccessfullyStoppedContainers() Get the list of containerIds of successfully stopped containers. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StopContainersResponse public StopContainersResponse() Method Detail getSuccessfullyStoppedContainers @InterfaceAudience.Public @InterfaceStability.Stable public abstract List<ContainerId> getSuccessfullyStoppedContainers() Get the list of containerIds of successfully stopped containers. Returns:the list of containerIds of successfully stopped containers. getFailedRequests @InterfaceAudience.Public @InterfaceStability.Stable public abstract Map<ContainerId,org.apache.hadoop.yarn.api.records.SerializedException> getFailedRequests() Get the containerId-to-exception map in which the exception indicates error  from per container for failed requests Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StorageType (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StorageType (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.fs Enum StorageType java.lang.Object java.lang.Enum<StorageType> org.apache.hadoop.fs.StorageType All Implemented Interfaces: Serializable, Comparable<StorageType> @InterfaceAudience.Public @InterfaceStability.Unstable public enum StorageType extends Enum<StorageType> Defines the types of supported storage media. The default storage  medium is assumed to be DISK. Enum Constant Summary Enum Constants  Enum Constant and Description ARCHIVE  DISK  RAM_DISK  SSD  Field Summary Fields  Modifier and Type Field and Description static StorageType DEFAULT  static StorageType[] EMPTY_ARRAY  Method Summary Methods  Modifier and Type Method and Description static List<StorageType> asList()  static List<StorageType> getMovableTypes()  static List<StorageType> getTypesSupportingQuota()  boolean isMovable()  boolean isTransient()  static StorageType parseStorageType(int i)  static StorageType parseStorageType(String s)  boolean supportTypeQuota()  static StorageType valueOf(String name) Returns the enum constant of this type with the specified name. static StorageType[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail RAM_DISK public static final StorageType RAM_DISK SSD public static final StorageType SSD DISK public static final StorageType DISK ARCHIVE public static final StorageType ARCHIVE Field Detail DEFAULT public static final StorageType DEFAULT EMPTY_ARRAY public static final StorageType[] EMPTY_ARRAY Method Detail values public static StorageType[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (StorageType c : StorageType.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static StorageType valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null isTransient public boolean isTransient() supportTypeQuota public boolean supportTypeQuota() isMovable public boolean isMovable() asList public static List<StorageType> asList() getMovableTypes public static List<StorageType> getMovableTypes() getTypesSupportingQuota public static List<StorageType> getTypesSupportingQuota() parseStorageType public static StorageType parseStorageType(int i) parseStorageType public static StorageType parseStorageType(String s) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StreamBackedIterator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StreamBackedIterator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class StreamBackedIterator<X extends Writable> java.lang.Object org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator<X> All Implemented Interfaces: ResetableIterator<X> Direct Known Subclasses: StreamBackedIterator @InterfaceAudience.Public @InterfaceStability.Stable public class StreamBackedIterator<X extends Writable> extends Object implements ResetableIterator<X> This class provides an implementation of ResetableIterator. This  implementation uses a byte array to store elements added to it. Constructor Summary Constructors  Constructor and Description StreamBackedIterator()  Method Summary Methods  Modifier and Type Method and Description void add(X item) Add an element to the collection of elements to iterate over. void clear() Close datasources, but do not release internal resources. void close() Close datasources and release resources. boolean hasNext() True if a call to next may return a value. boolean next(X val) Assign next value to actual. boolean replay(X val) Assign last value returned to actual. void reset() Set iterator to return to the start of its range. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StreamBackedIterator public StreamBackedIterator() Method Detail hasNext public boolean hasNext() Description copied from interface: ResetableIterator True if a call to next may return a value. This is permitted false  positives, but not false negatives. Specified by: hasNext in interface ResetableIterator<X extends Writable> next public boolean next(X val)              throws IOException Description copied from interface: ResetableIterator Assign next value to actual.  It is required that elements added to a ResetableIterator be returned in  the same order after a call to ResetableIterator.reset() (FIFO).  Note that a call to this may fail for nested joins (i.e. more elements  available, but none satisfying the constraints of the join) Specified by: next in interface ResetableIterator<X extends Writable> Throws: IOException replay public boolean replay(X val)                throws IOException Description copied from interface: ResetableIterator Assign last value returned to actual. Specified by: replay in interface ResetableIterator<X extends Writable> Throws: IOException reset public void reset() Description copied from interface: ResetableIterator Set iterator to return to the start of its range. Must be called after  calling ResetableIterator.add(T) to avoid a ConcurrentModificationException. Specified by: reset in interface ResetableIterator<X extends Writable> add public void add(X item)          throws IOException Description copied from interface: ResetableIterator Add an element to the collection of elements to iterate over. Specified by: add in interface ResetableIterator<X extends Writable> Throws: IOException close public void close()            throws IOException Description copied from interface: ResetableIterator Close datasources and release resources. Calling methods on the iterator  after calling close has undefined behavior. Specified by: close in interface ResetableIterator<X extends Writable> Throws: IOException clear public void clear() Description copied from interface: ResetableIterator Close datasources, but do not release internal resources. Calling this  method should permit the object to be reused with a different datasource. Specified by: clear in interface ResetableIterator<X extends Writable> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StrictPreemptionContract (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StrictPreemptionContract (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class StrictPreemptionContract java.lang.Object org.apache.hadoop.yarn.api.records.StrictPreemptionContract @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class StrictPreemptionContract extends Object Enumeration of particular allocations to be reclaimed. The platform will  reclaim exactly these resources, so the ApplicationMaster (AM)  may attempt to checkpoint work or adjust its execution plan to accommodate  it. In contrast to PreemptionContract, the AM has no flexibility in  selecting which resources to return to the cluster. See Also:PreemptionMessage Constructor Summary Constructors  Constructor and Description StrictPreemptionContract()  Method Summary Methods  Modifier and Type Method and Description abstract Set<PreemptionContainer> getContainers() Get the set of PreemptionContainer specifying containers owned by  the ApplicationMaster that may be reclaimed by the  ResourceManager. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StrictPreemptionContract public StrictPreemptionContract() Method Detail getContainers @InterfaceAudience.Public @InterfaceStability.Evolving public abstract Set<PreemptionContainer> getContainers() Get the set of PreemptionContainer specifying containers owned by  the ApplicationMaster that may be reclaimed by the  ResourceManager. Returns:the set of ContainerId to be preempted. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StringInterner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StringInterner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util Class StringInterner java.lang.Object org.apache.hadoop.util.StringInterner @InterfaceAudience.Public @InterfaceStability.Stable public class StringInterner extends Object Provides equivalent behavior to String.intern() to optimize performance,   whereby does not consume memory in the permanent generation. Constructor Summary Constructors  Constructor and Description StringInterner()  Method Summary Methods  Modifier and Type Method and Description static String strongIntern(String sample) Interns and returns a reference to the representative instance   for any of a collection of string instances that are equal to each other. static String weakIntern(String sample) Interns and returns a reference to the representative instance   for any of a collection of string instances that are equal to each other. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StringInterner public StringInterner() Method Detail strongIntern public static String strongIntern(String sample) Interns and returns a reference to the representative instance   for any of a collection of string instances that are equal to each other.  Retains strong reference to the instance,   thus preventing it from being garbage-collected. Parameters:sample - string instance to be interned Returns:strong reference to interned string instance weakIntern public static String weakIntern(String sample) Interns and returns a reference to the representative instance   for any of a collection of string instances that are equal to each other.  Retains weak reference to the instance,   and so does not prevent it from being garbage-collected. Parameters:sample - string instance to be interned Returns:weak reference to interned string instance Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StringValueMax (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StringValueMax (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class StringValueMax java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax All Implemented Interfaces: ValueAggregator<String> Direct Known Subclasses: StringValueMax @InterfaceAudience.Public @InterfaceStability.Stable public class StringValueMax extends Object implements ValueAggregator<String> This class implements a value aggregator that maintain the biggest of   a sequence of strings. Constructor Summary Constructors  Constructor and Description StringValueMax() the default constructor Method Summary Methods  Modifier and Type Method and Description void addNextValue(Object val) add a value to the aggregator ArrayList<String> getCombinerOutput()  String getReport()  String getVal()  void reset() reset the aggregator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StringValueMax public StringValueMax() the default constructor Method Detail addNextValue public void addNextValue(Object val) add a value to the aggregator Specified by: addNextValue in interface ValueAggregator<String> Parameters:val - a string. getVal public String getVal() Returns:the aggregated value getReport public String getReport() Specified by: getReport in interface ValueAggregator<String> Returns:the string representation of the aggregated value reset public void reset() reset the aggregator Specified by: reset in interface ValueAggregator<String> getCombinerOutput public ArrayList<String> getCombinerOutput() Specified by: getCombinerOutput in interface ValueAggregator<String> Returns:return an array of one element. The element is a string          representation of the aggregated value. The return value is          expected to be used by the a combiner. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StringValueMin (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StringValueMin (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class StringValueMin java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin All Implemented Interfaces: ValueAggregator<String> Direct Known Subclasses: StringValueMin @InterfaceAudience.Public @InterfaceStability.Stable public class StringValueMin extends Object implements ValueAggregator<String> This class implements a value aggregator that maintain the smallest of   a sequence of strings. Constructor Summary Constructors  Constructor and Description StringValueMin() the default constructor Method Summary Methods  Modifier and Type Method and Description void addNextValue(Object val) add a value to the aggregator ArrayList<String> getCombinerOutput()  String getReport()  String getVal()  void reset() reset the aggregator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail StringValueMin public StringValueMin() the default constructor Method Detail addNextValue public void addNextValue(Object val) add a value to the aggregator Specified by: addNextValue in interface ValueAggregator<String> Parameters:val - a string. getVal public String getVal() Returns:the aggregated value getReport public String getReport() Specified by: getReport in interface ValueAggregator<String> Returns:the string representation of the aggregated value reset public void reset() reset the aggregator Specified by: reset in interface ValueAggregator<String> getCombinerOutput public ArrayList<String> getCombinerOutput() Specified by: getCombinerOutput in interface ValueAggregator<String> Returns:return an array of one element. The element is a string          representation of the aggregated value. The return value is          expected to be used by the a combiner. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Stringifier (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Stringifier (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Interface Stringifier<T> Type Parameters:T - the class of the objects to stringify All Superinterfaces: AutoCloseable, Closeable All Known Implementing Classes: DefaultStringifier @InterfaceAudience.Public @InterfaceStability.Stable public interface Stringifier<T> extends Closeable Stringifier interface offers two methods to convert an object   to a string representation and restore the object given its   string representation. Method Summary Methods  Modifier and Type Method and Description void close() Closes this object. T fromString(String str) Restores the object from its string representation. String toString(T obj) Converts the object to a string representation Method Detail toString String toString(T obj)                 throws IOException Converts the object to a string representation Parameters:obj - the object to convert Returns:the string representation of the object Throws: IOException - if the object cannot be converted fromString T fromString(String str)              throws IOException Restores the object from its string representation. Parameters:str - the string representation of the object Returns:restored object Throws: IOException - if the object cannot be restored close void close()            throws IOException Closes this object. Specified by: close in interface AutoCloseable Specified by: close in interface Closeable Throws: IOException - if an I/O error occurs Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  StructTypeID (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="StructTypeID (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.meta Class StructTypeID java.lang.Object org.apache.hadoop.record.meta.TypeID org.apache.hadoop.record.meta.StructTypeID Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class StructTypeID extends TypeID Represents typeID for a struct Field Summary Fields inherited from class org.apache.hadoop.record.meta.TypeID BoolTypeID, BufferTypeID, ByteTypeID, DoubleTypeID, FloatTypeID, IntTypeID, LongTypeID, StringTypeID, typeVal Constructor Summary Constructors  Constructor and Description StructTypeID(RecordTypeInfo rti) Deprecated.  Create a StructTypeID based on the RecordTypeInfo of some record Method Summary Methods  Modifier and Type Method and Description boolean equals(Object o) Deprecated.  Two base typeIDs are equal if they refer to the same type Collection<FieldTypeInfo> getFieldTypeInfos() Deprecated.    int hashCode() Deprecated.  We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Methods inherited from class org.apache.hadoop.record.meta.TypeID getTypeVal Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail StructTypeID public StructTypeID(RecordTypeInfo rti) Deprecated.  Create a StructTypeID based on the RecordTypeInfo of some record Method Detail getFieldTypeInfos public Collection<FieldTypeInfo> getFieldTypeInfos() Deprecated.  equals public boolean equals(Object o) Deprecated.  Description copied from class: TypeID Two base typeIDs are equal if they refer to the same type Overrides: equals in class TypeID hashCode public int hashCode() Deprecated.  Description copied from class: TypeID We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Overrides: hashCode in class TypeID Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SubmitApplicationRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SubmitApplicationRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class SubmitApplicationRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest @InterfaceAudience.Public @InterfaceStability.Stable public abstract class SubmitApplicationRequest extends Object The request sent by a client to submit an application to the   ResourceManager.    The request, via ApplicationSubmissionContext, contains  details such as queue, Resource required to run the   ApplicationMaster, the equivalent of   ContainerLaunchContext for launching the   ApplicationMaster etc. See Also:ApplicationClientProtocol.submitApplication(SubmitApplicationRequest) Constructor Summary Constructors  Constructor and Description SubmitApplicationRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationSubmissionContext getApplicationSubmissionContext() Get the ApplicationSubmissionContext for the application. static SubmitApplicationRequest newInstance(ApplicationSubmissionContext context)  abstract void setApplicationSubmissionContext(ApplicationSubmissionContext context) Set the ApplicationSubmissionContext for the application. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SubmitApplicationRequest public SubmitApplicationRequest() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static SubmitApplicationRequest newInstance(ApplicationSubmissionContext context) getApplicationSubmissionContext @InterfaceAudience.Public @InterfaceStability.Stable public abstract ApplicationSubmissionContext getApplicationSubmissionContext() Get the ApplicationSubmissionContext for the application. Returns:ApplicationSubmissionContext for the application setApplicationSubmissionContext @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setApplicationSubmissionContext(ApplicationSubmissionContext context) Set the ApplicationSubmissionContext for the application. Parameters:context - ApplicationSubmissionContext for the                  application Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SubmitApplicationResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SubmitApplicationResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class SubmitApplicationResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse @InterfaceAudience.Public @InterfaceStability.Stable public abstract class SubmitApplicationResponse extends Object The response sent by the ResourceManager to a client on  application submission.    Currently, this is empty. See Also:ApplicationClientProtocol.submitApplication(SubmitApplicationRequest) Constructor Summary Constructors  Constructor and Description SubmitApplicationResponse()  Method Summary Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SubmitApplicationResponse public SubmitApplicationResponse() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Submitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Submitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred.pipes Class Submitter java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.mapred.pipes.Submitter All Implemented Interfaces: Configurable, Tool @InterfaceAudience.Public @InterfaceStability.Stable public class Submitter extends Configured implements Tool The main entry point and job submitter. It may either be used as a command  line-based or API-based method to launch Pipes jobs. Field Summary Fields  Modifier and Type Field and Description static String EXECUTABLE  static String INPUT_FORMAT  static String INTERPRETOR  static String IS_JAVA_MAP  static String IS_JAVA_REDUCE  static String IS_JAVA_RR  static String IS_JAVA_RW  protected static org.apache.commons.logging.Log LOG  static String PARTITIONER  static String PORT  static String PRESERVE_COMMANDFILE  Constructor Summary Constructors  Constructor and Description Submitter()  Submitter(Configuration conf)  Method Summary Methods  Modifier and Type Method and Description static String getExecutable(JobConf conf) Get the URI of the application's executable. static boolean getIsJavaMapper(JobConf conf) Check whether the job is using a Java Mapper. static boolean getIsJavaRecordReader(JobConf conf) Check whether the job is using a Java RecordReader static boolean getIsJavaRecordWriter(JobConf conf) Will the reduce use a Java RecordWriter? static boolean getIsJavaReducer(JobConf conf) Check whether the job is using a Java Reducer. static boolean getKeepCommandFile(JobConf conf) Does the user want to keep the command file for debugging? If this is  true, pipes will write a copy of the command data to a file in the  task directory named "downlink.data", which may be used to run the C++  program under the debugger. static RunningJob jobSubmit(JobConf conf) Submit a job to the Map-Reduce framework. static void main(String[] args) Submit a pipes job based on the command line arguments. int run(String[] args) Execute the command with the given arguments. static RunningJob runJob(JobConf conf) Submit a job to the map/reduce cluster. static void setExecutable(JobConf conf,                           String executable) Set the URI for the application's executable. static void setIsJavaMapper(JobConf conf,                               boolean value) Set whether the Mapper is written in Java. static void setIsJavaRecordReader(JobConf conf,                                           boolean value) Set whether the job is using a Java RecordReader. static void setIsJavaRecordWriter(JobConf conf,                                           boolean value) Set whether the job will use a Java RecordWriter. static void setIsJavaReducer(JobConf conf,                                 boolean value) Set whether the Reducer is written in Java. static void setKeepCommandFile(JobConf conf,                                     boolean keep) Set whether to keep the command file for debugging static RunningJob submitJob(JobConf conf) Deprecated.  Use runJob(JobConf) Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Field Detail LOG protected static final org.apache.commons.logging.Log LOG PRESERVE_COMMANDFILE public static final String PRESERVE_COMMANDFILE See Also:Constant Field Values EXECUTABLE public static final String EXECUTABLE See Also:Constant Field Values INTERPRETOR public static final String INTERPRETOR See Also:Constant Field Values IS_JAVA_MAP public static final String IS_JAVA_MAP See Also:Constant Field Values IS_JAVA_RR public static final String IS_JAVA_RR See Also:Constant Field Values IS_JAVA_RW public static final String IS_JAVA_RW See Also:Constant Field Values IS_JAVA_REDUCE public static final String IS_JAVA_REDUCE See Also:Constant Field Values PARTITIONER public static final String PARTITIONER See Also:Constant Field Values INPUT_FORMAT public static final String INPUT_FORMAT See Also:Constant Field Values PORT public static final String PORT See Also:Constant Field Values Constructor Detail Submitter public Submitter() Submitter public Submitter(Configuration conf) Method Detail getExecutable public static String getExecutable(JobConf conf) Get the URI of the application's executable. Parameters:conf -  Returns:the URI where the application's executable is located setExecutable public static void setExecutable(JobConf conf,                  String executable) Set the URI for the application's executable. Normally this is a hdfs:   location. Parameters:conf - executable - The URI of the application's executable. setIsJavaRecordReader public static void setIsJavaRecordReader(JobConf conf,                          boolean value) Set whether the job is using a Java RecordReader. Parameters:conf - the configuration to modifyvalue - the new value getIsJavaRecordReader public static boolean getIsJavaRecordReader(JobConf conf) Check whether the job is using a Java RecordReader Parameters:conf - the configuration to check Returns:is it a Java RecordReader? setIsJavaMapper public static void setIsJavaMapper(JobConf conf,                    boolean value) Set whether the Mapper is written in Java. Parameters:conf - the configuration to modifyvalue - the new value getIsJavaMapper public static boolean getIsJavaMapper(JobConf conf) Check whether the job is using a Java Mapper. Parameters:conf - the configuration to check Returns:is it a Java Mapper? setIsJavaReducer public static void setIsJavaReducer(JobConf conf,                     boolean value) Set whether the Reducer is written in Java. Parameters:conf - the configuration to modifyvalue - the new value getIsJavaReducer public static boolean getIsJavaReducer(JobConf conf) Check whether the job is using a Java Reducer. Parameters:conf - the configuration to check Returns:is it a Java Reducer? setIsJavaRecordWriter public static void setIsJavaRecordWriter(JobConf conf,                          boolean value) Set whether the job will use a Java RecordWriter. Parameters:conf - the configuration to modifyvalue - the new value to set getIsJavaRecordWriter public static boolean getIsJavaRecordWriter(JobConf conf) Will the reduce use a Java RecordWriter? Parameters:conf - the configuration to check Returns:true, if the output of the job will be written by Java getKeepCommandFile public static boolean getKeepCommandFile(JobConf conf) Does the user want to keep the command file for debugging? If this is  true, pipes will write a copy of the command data to a file in the  task directory named "downlink.data", which may be used to run the C++  program under the debugger. You probably also want to set   JobConf.setKeepFailedTaskFiles(true) to keep the entire directory from  being deleted.  To run using the data file, set the environment variable   "mapreduce.pipes.commandfile" to point to the file. Parameters:conf - the configuration to check Returns:will the framework save the command file? setKeepCommandFile public static void setKeepCommandFile(JobConf conf,                       boolean keep) Set whether to keep the command file for debugging Parameters:conf - the configuration to modifykeep - the new value submitJob @Deprecated public static RunningJob submitJob(JobConf conf)                             throws IOException Deprecated. Use runJob(JobConf) Submit a job to the map/reduce cluster. All of the necessary modifications  to the job to run under pipes are made to the configuration. Parameters:conf - the job to submit to the cluster (MODIFIED) Throws: IOException runJob public static RunningJob runJob(JobConf conf)                          throws IOException Submit a job to the map/reduce cluster. All of the necessary modifications  to the job to run under pipes are made to the configuration. Parameters:conf - the job to submit to the cluster (MODIFIED) Throws: IOException jobSubmit public static RunningJob jobSubmit(JobConf conf)                             throws IOException Submit a job to the Map-Reduce framework.  This returns a handle to the RunningJob which can be used to track  the running-job. Parameters:conf - the job configuration. Returns:a handle to the RunningJob which can be used to track the          running-job. Throws: IOException run public int run(String[] args)         throws Exception Description copied from interface: Tool Execute the command with the given arguments. Specified by: run in interface Tool Parameters:args - command specific arguments. Returns:exit code. Throws: Exception main public static void main(String[] args)                  throws Exception Submit a pipes job based on the command line arguments. Parameters:args -  Throws: Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Syncable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Syncable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Interface Syncable All Known Implementing Classes: FSDataOutputStream @InterfaceAudience.Public @InterfaceStability.Evolving public interface Syncable This interface for flush/sync operation. Method Summary Methods  Modifier and Type Method and Description void hflush() Flush out the data in client's user buffer. void hsync() Similar to posix fsync, flush out the data in client's user buffer   all the way to the disk device (but the disk may have it in its cache). void sync() Deprecated.  As of HADOOP 0.21.0, replaced by hflush Method Detail sync @Deprecated void sync()           throws IOException Deprecated. As of HADOOP 0.21.0, replaced by hflush Throws: IOExceptionSee Also:hflush() hflush void hflush()             throws IOException Flush out the data in client's user buffer. After the return of  this call, new readers will see the data. Throws: IOException - if any error occurs hsync void hsync()            throws IOException Similar to posix fsync, flush out the data in client's user buffer   all the way to the disk device (but the disk may have it in its cache). Throws: IOException - if error occurs Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  SystemClock (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="SystemClock (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.util Class SystemClock java.lang.Object org.apache.hadoop.yarn.util.SystemClock All Implemented Interfaces: Clock @InterfaceAudience.Public @InterfaceStability.Stable public class SystemClock extends Object implements Clock Implementation of Clock that gives the current time from the system  clock in milliseconds. Constructor Summary Constructors  Constructor and Description SystemClock()  Method Summary Methods  Modifier and Type Method and Description long getTime()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail SystemClock public SystemClock() Method Detail getTime public long getTime() Specified by: getTime in interface Clock Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TFile (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TFile (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.file.tfile Class TFile java.lang.Object org.apache.hadoop.io.file.tfile.TFile @InterfaceAudience.Public @InterfaceStability.Evolving public class TFile extends Object A TFile is a container of key-value pairs. Both keys and values are type-less  bytes. Keys are restricted to 64KB, value length is not restricted  (practically limited to the available disk storage). TFile further provides  the following features:    Block Compression.  Named meta data blocks.  Sorted or unsorted keys.  Seek by key or by file offset.    The memory footprint of a TFile includes the following:    Some constant overhead of reading or writing a compressed block.    Each compressed block requires one compression/decompression codec for  I/O.  Temporary space to buffer the key.  Temporary space to buffer the value (for TFile.Writer only). Values are  chunk encoded, so that we buffer at most one chunk of user data. By default,  the chunk buffer is 1MB. Reading chunked value does not require additional  memory.    TFile index, which is proportional to the total number of Data Blocks.  The total amount of memory needed to hold the index can be estimated as  (56+AvgKeySize)*NumBlocks.  MetaBlock index, which is proportional to the total number of Meta  Blocks.The total amount of memory needed to hold the index for Meta Blocks  can be estimated as (40+AvgMetaBlockName)*NumMetaBlock.      The behavior of TFile can be customized by the following variables through  Configuration:    tfile.io.chunk.size: Value chunk size. Integer (in bytes). Default  to 1MB. Values of the length less than the chunk size is guaranteed to have  known value length in read time (See  TFile.Reader.Scanner.Entry.isValueLengthKnown()).  tfile.fs.output.buffer.size: Buffer size used for  FSDataOutputStream. Integer (in bytes). Default to 256KB.  tfile.fs.input.buffer.size: Buffer size used for  FSDataInputStream. Integer (in bytes). Default to 256KB.      Suggestions on performance optimization.    Minimum block size. We recommend a setting of minimum block size between  256KB to 1MB for general usage. Larger block size is preferred if files are  primarily for sequential access. However, it would lead to inefficient random  access (because there are more data to decompress). Smaller blocks are good  for random access, but require more memory to hold the block index, and may  be slower to create (because we must flush the compressor stream at the  conclusion of each data block, which leads to an FS I/O flush). Further, due  to the internal caching in Compression codec, the smallest possible block  size would be around 20KB-30KB.  The current implementation does not offer true multi-threading for  reading. The implementation uses FSDataInputStream seek()+read(), which is  shown to be much faster than positioned-read call in single thread mode.  However, it also means that if multiple threads attempt to access the same  TFile (using multiple scanners) simultaneously, the actual I/O is carried out  sequentially even if they access different DFS blocks.  Compression codec. Use "none" if the data is not very compressable (by  compressable, I mean a compression ratio at least 2:1). Generally, use "lzo"  as the starting point for experimenting. "gz" overs slightly better  compression ratio over "lzo" but requires 4x CPU to compress and 2x CPU to  decompress, comparing to "lzo".  File system buffering, if the underlying FSDataInputStream and  FSDataOutputStream is already adequately buffered; or if applications  reads/writes keys and values in large buffers, we can reduce the sizes of  input/output buffering in TFile layer by setting the configuration parameters  "tfile.fs.input.buffer.size" and "tfile.fs.output.buffer.size".      Some design rationale behind TFile can be found at Hadoop-3315. Field Summary Fields  Modifier and Type Field and Description static String COMPARATOR_JCLASS comparator prefix: java class static String COMPARATOR_MEMCMP comparator: memcmp static String COMPRESSION_GZ compression: gzip static String COMPRESSION_LZO compression: lzo static String COMPRESSION_NONE compression: none Method Summary Methods  Modifier and Type Method and Description static String[] getSupportedCompressionAlgorithms() Get names of supported compression algorithms. static void main(String[] args) Dumping the TFile information. static Comparator<RawComparable> makeComparator(String name) Make a raw comparator from a string name. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail COMPRESSION_GZ public static final String COMPRESSION_GZ compression: gzip See Also:Constant Field Values COMPRESSION_LZO public static final String COMPRESSION_LZO compression: lzo See Also:Constant Field Values COMPRESSION_NONE public static final String COMPRESSION_NONE compression: none See Also:Constant Field Values COMPARATOR_MEMCMP public static final String COMPARATOR_MEMCMP comparator: memcmp See Also:Constant Field Values COMPARATOR_JCLASS public static final String COMPARATOR_JCLASS comparator prefix: java class See Also:Constant Field Values Method Detail makeComparator public static Comparator<RawComparable> makeComparator(String name) Make a raw comparator from a string name. Parameters:name - Comparator name Returns:A RawComparable comparator. getSupportedCompressionAlgorithms public static String[] getSupportedCompressionAlgorithms() Get names of supported compression algorithms. The names are acceptable by  TFile.Writer. Returns:Array of strings, each represents a supported compression          algorithm. Currently, the following compression algorithms are          supported.                    "none" - No compression.          "lzo" - LZO compression.          "gz" - GZIP compression.           main public static void main(String[] args) Dumping the TFile information. Parameters:args - A list of TFile paths. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TableMapping (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TableMapping (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.net Class TableMapping java.lang.Object org.apache.hadoop.net.AbstractDNSToSwitchMapping org.apache.hadoop.net.CachedDNSToSwitchMapping org.apache.hadoop.net.TableMapping All Implemented Interfaces: Configurable, DNSToSwitchMapping @InterfaceAudience.Public @InterfaceStability.Evolving public class TableMapping extends CachedDNSToSwitchMapping  Simple DNSToSwitchMapping implementation that reads a 2 column text  file. The columns are separated by whitespace. The first column is a DNS or  IP address and the second column specifies the rack where the address maps.      This class uses the configuration parameter net.topology.table.file.name to locate the mapping file.      Calls to CachedDNSToSwitchMapping.resolve(List) will look up the address as defined in the  mapping file. If no entry corresponding to the address is found, the value  /default-rack is returned.   Field Summary Fields inherited from class org.apache.hadoop.net.CachedDNSToSwitchMapping rawMapping Constructor Summary Constructors  Constructor and Description TableMapping()  Method Summary Methods  Modifier and Type Method and Description Configuration getConf() Return the configuration used by this object. void reloadCachedMappings() Reload all of the cached mappings. void setConf(Configuration conf) Set the configuration to be used by this object. Methods inherited from class org.apache.hadoop.net.CachedDNSToSwitchMapping getSwitchMap, isSingleSwitch, reloadCachedMappings, resolve, toString Methods inherited from class org.apache.hadoop.net.AbstractDNSToSwitchMapping dumpTopology, isMappingSingleSwitch, isSingleSwitchByScriptPolicy Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail TableMapping public TableMapping() Method Detail getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable Overrides: getConf in class AbstractDNSToSwitchMapping setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable Overrides: setConf in class AbstractDNSToSwitchMapping reloadCachedMappings public void reloadCachedMappings() Description copied from interface: DNSToSwitchMapping Reload all of the cached mappings.  If there is a cache, this method will clear it, so that future accesses  will get a chance to see the new data. Specified by: reloadCachedMappings in interface DNSToSwitchMapping Overrides: reloadCachedMappings in class CachedDNSToSwitchMapping Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskAttemptContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskAttemptContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Interface TaskAttemptContext All Superinterfaces: JobContext, org.apache.hadoop.mapreduce.MRJobConfig, Progressable All Known Subinterfaces: MapContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT>, ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT>, TaskAttemptContext, TaskInputOutputContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Evolving public interface TaskAttemptContext extends JobContext, Progressable The context for task attempts. Field Summary Fields inherited from interface org.apache.hadoop.mapreduce.MRJobConfig APPLICATION_ATTEMPT_ID, APPLICATION_MASTER_CLASS, CACHE_ARCHIVES, CACHE_ARCHIVES_SIZES, CACHE_ARCHIVES_TIMESTAMPS, CACHE_ARCHIVES_VISIBILITIES, CACHE_FILE_TIMESTAMPS, CACHE_FILE_VISIBILITIES, CACHE_FILES, CACHE_FILES_SIZES, CACHE_LOCALARCHIVES, CACHE_LOCALFILES, CACHE_SYMLINK, CLASSPATH_ARCHIVES, CLASSPATH_FILES, COMBINE_CLASS_ATTR, COMBINE_RECORDS_BEFORE_PROGRESS, COMBINER_GROUP_COMPARATOR_CLASS, COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, COUNTER_GROUP_NAME_MAX_DEFAULT, COUNTER_GROUP_NAME_MAX_KEY, COUNTER_GROUPS_MAX_DEFAULT, COUNTER_GROUPS_MAX_KEY, COUNTER_NAME_MAX_DEFAULT, COUNTER_NAME_MAX_KEY, COUNTERS_MAX_DEFAULT, COUNTERS_MAX_KEY, DEFAULT_JOB_ACL_MODIFY_JOB, DEFAULT_JOB_ACL_VIEW_JOB, DEFAULT_JOB_AM_ACCESS_DISABLED, DEFAULT_JOB_RUNNING_MAP_LIMIT, DEFAULT_JOB_RUNNING_REDUCE_LIMIT, DEFAULT_JOB_TOKEN_TRACKING_IDS_ENABLED, DEFAULT_LOG_LEVEL, DEFAULT_MAP_CPU_VCORES, DEFAULT_MAP_MEMORY_MB, DEFAULT_MAPRED_ADMIN_JAVA_OPTS, DEFAULT_MAPRED_ADMIN_USER_ENV, DEFAULT_MAPREDUCE_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_CROSS_PLATFORM_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA, DEFAULT_MAX_ALLOWED_FETCH_FAILURES_FRACTION, DEFAULT_MAX_FETCH_FAILURES_NOTIFICATIONS, DEFAULT_MAX_SHUFFLE_FETCH_HOST_FAILURES, DEFAULT_MAX_SHUFFLE_FETCH_RETRY_DELAY, DEFAULT_MR_AM_ADMIN_COMMAND_OPTS, DEFAULT_MR_AM_COMMAND_OPTS, DEFAULT_MR_AM_COMMIT_WINDOW_MS, DEFAULT_MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, DEFAULT_MR_AM_CPU_VCORES, DEFAULT_MR_AM_HARD_KILL_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, DEFAULT_MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERCENT, DEFAULT_MR_AM_JOB_CLIENT_THREAD_COUNT, DEFAULT_MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, DEFAULT_MR_AM_JOB_REDUCE_RAMP_UP_LIMIT, DEFAULT_MR_AM_LOG_BACKUPS, DEFAULT_MR_AM_LOG_KB, DEFAULT_MR_AM_LOG_LEVEL, DEFAULT_MR_AM_MAX_ATTEMPTS, DEFAULT_MR_AM_NUM_PROGRESS_SPLITS, DEFAULT_MR_AM_PROFILE, DEFAULT_MR_AM_STAGING_DIR, DEFAULT_MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, DEFAULT_MR_AM_TASK_LISTENER_THREAD_COUNT, DEFAULT_MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, DEFAULT_MR_AM_TO_RM_WAIT_INTERVAL_MS, DEFAULT_MR_AM_VMEM_MB, DEFAULT_MR_CLIENT_JOB_MAX_RETRIES, DEFAULT_MR_CLIENT_JOB_RETRY_INTERVAL, DEFAULT_MR_CLIENT_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, DEFAULT_MR_JOB_END_NOTIFICATION_TIMEOUT, DEFAULT_MR_JOB_REDUCER_PREEMPT_DELAY_SEC, DEFAULT_REDUCE_CPU_VCORES, DEFAULT_REDUCE_MEMORY_MB, DEFAULT_REDUCE_SEPARATE_SHUFFLE_LOG, DEFAULT_SHELL, DEFAULT_SHUFFLE_FETCH_RETRY_INTERVAL_MS, DEFAULT_SHUFFLE_INPUT_BUFFER_PERCENT, DEFAULT_SHUFFLE_LOG_BACKUPS, DEFAULT_SHUFFLE_LOG_KB, DEFAULT_SPECULATIVE_MINIMUM_ALLOWED_TASKS, DEFAULT_SPECULATIVE_RETRY_AFTER_NO_SPECULATE, DEFAULT_SPECULATIVE_RETRY_AFTER_SPECULATE, DEFAULT_SPECULATIVECAP_RUNNING_TASKS, DEFAULT_SPECULATIVECAP_TOTAL_TASKS, DEFAULT_SPLIT_METAINFO_MAXSIZE, DEFAULT_TASK_ISMAP, DEFAULT_TASK_LOG_BACKUPS, DEFAULT_TASK_PROFILE_PARAMS, GROUP_COMPARATOR_CLASS, HADOOP_WORK_DIR, ID, INDEX_CACHE_MEMORY_LIMIT, INPUT_FORMAT_CLASS_ATTR, IO_SORT_FACTOR, IO_SORT_MB, JAR, JAR_UNPACK_PATTERN, JOB_ACL_MODIFY_JOB, JOB_ACL_VIEW_JOB, JOB_AM_ACCESS_DISABLED, JOB_CANCEL_DELEGATION_TOKEN, JOB_CONF_FILE, JOB_JAR, JOB_JOBTRACKER_ID, JOB_LOCAL_DIR, JOB_NAME, JOB_NAMENODES, JOB_RUNNING_MAP_LIMIT, JOB_RUNNING_REDUCE_LIMIT, JOB_SPLIT, JOB_SPLIT_METAINFO, JOB_SUBMIT_DIR, JOB_SUBMITHOST, JOB_SUBMITHOSTADDR, JOB_TAGS, JOB_TOKEN_TRACKING_IDS, JOB_TOKEN_TRACKING_IDS_ENABLED, JOB_UBERTASK_ENABLE, JOB_UBERTASK_MAXBYTES, JOB_UBERTASK_MAXMAPS, JOB_UBERTASK_MAXREDUCES, JVM_NUMTASKS_TORUN, KEY_COMPARATOR, MAP_CLASS_ATTR, MAP_COMBINE_MIN_SPILLS, MAP_CPU_VCORES, MAP_DEBUG_SCRIPT, MAP_ENV, MAP_FAILURES_MAX_PERCENT, MAP_INPUT_FILE, MAP_INPUT_PATH, MAP_INPUT_START, MAP_JAVA_OPTS, MAP_LOG_LEVEL, MAP_MAX_ATTEMPTS, MAP_MEMORY_MB, MAP_OUTPUT_COLLECTOR_CLASS_ATTR, MAP_OUTPUT_COMPRESS, MAP_OUTPUT_COMPRESS_CODEC, MAP_OUTPUT_KEY_CLASS, MAP_OUTPUT_KEY_FIELD_SEPERATOR, MAP_OUTPUT_VALUE_CLASS, MAP_SKIP_INCR_PROC_COUNT, MAP_SKIP_MAX_RECORDS, MAP_SORT_SPILL_PERCENT, MAP_SPECULATIVE, MAPRED_ADMIN_USER_ENV, MAPRED_ADMIN_USER_SHELL, MAPRED_MAP_ADMIN_JAVA_OPTS, MAPRED_REDUCE_ADMIN_JAVA_OPTS, MAPREDUCE_APPLICATION_CLASSPATH, MAPREDUCE_APPLICATION_FRAMEWORK_PATH, MAPREDUCE_JOB_CLASSLOADER, MAPREDUCE_JOB_CLASSLOADER_SYSTEM_CLASSES, MAPREDUCE_JOB_CREDENTIALS_BINARY, MAPREDUCE_JOB_DIR, MAPREDUCE_JOB_EMIT_TIMELINE_DATA, MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE, MAPREDUCE_JOB_SHUFFLE_PROVIDER_SERVICES, MAPREDUCE_JOB_USER_CLASSPATH_FIRST, MAPREDUCE_V2_CHILD_CLASS, MAX_ALLOWED_FETCH_FAILURES_FRACTION, MAX_FETCH_FAILURES_NOTIFICATIONS, MAX_SHUFFLE_FETCH_HOST_FAILURES, MAX_SHUFFLE_FETCH_RETRY_DELAY, MAX_TASK_FAILURES_PER_TRACKER, MR_AM_ADMIN_COMMAND_OPTS, MR_AM_ADMIN_USER_ENV, MR_AM_COMMAND_OPTS, MR_AM_COMMIT_WINDOW_MS, MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, MR_AM_CPU_VCORES, MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR, MR_AM_ENV, MR_AM_HARD_KILL_TIMEOUT_MS, MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERECENT, MR_AM_JOB_CLIENT_PORT_RANGE, MR_AM_JOB_CLIENT_THREAD_COUNT, MR_AM_JOB_NODE_BLACKLISTING_ENABLE, MR_AM_JOB_RECOVERY_ENABLE, MR_AM_JOB_RECOVERY_ENABLE_DEFAULT, MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, MR_AM_JOB_REDUCE_RAMPUP_UP_LIMIT, MR_AM_JOB_SPECULATOR, MR_AM_LOG_BACKUPS, MR_AM_LOG_KB, MR_AM_LOG_LEVEL, MR_AM_MAX_ATTEMPTS, MR_AM_NUM_PROGRESS_SPLITS, MR_AM_PREFIX, MR_AM_PROFILE, MR_AM_PROFILE_PARAMS, MR_AM_SECURITY_SERVICE_AUTHORIZATION_CLIENT, MR_AM_SECURITY_SERVICE_AUTHORIZATION_TASK_UMBILICAL, MR_AM_STAGING_DIR, MR_AM_TASK_ESTIMATOR, MR_AM_TASK_ESTIMATOR_EXPONENTIAL_RATE_ENABLE, MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, MR_AM_TASK_LISTENER_THREAD_COUNT, MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, MR_AM_TO_RM_WAIT_INTERVAL_MS, MR_AM_VMEM_MB, MR_APPLICATION_TYPE, MR_CLIENT_JOB_MAX_RETRIES, MR_CLIENT_JOB_RETRY_INTERVAL, MR_CLIENT_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, MR_ENCRYPTED_INTERMEDIATE_DATA, MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, MR_JOB_END_NOTIFICATION_MAX_ATTEMPTS, MR_JOB_END_NOTIFICATION_MAX_RETRY_INTERVAL, MR_JOB_END_NOTIFICATION_PROXY, MR_JOB_END_NOTIFICATION_TIMEOUT, MR_JOB_END_NOTIFICATION_URL, MR_JOB_END_RETRY_ATTEMPTS, MR_JOB_END_RETRY_INTERVAL, MR_JOB_REDUCER_PREEMPT_DELAY_SEC, MR_PREFIX, NUM_MAP_PROFILES, NUM_MAPS, NUM_REDUCE_PROFILES, NUM_REDUCES, OUTPUT, OUTPUT_FORMAT_CLASS_ATTR, OUTPUT_KEY_CLASS, OUTPUT_VALUE_CLASS, PARTITIONER_CLASS_ATTR, PRESERVE_FAILED_TASK_FILES, PRESERVE_FILES_PATTERN, PRIORITY, QUEUE_NAME, RECORDS_BEFORE_PROGRESS, REDUCE_CLASS_ATTR, REDUCE_CPU_VCORES, REDUCE_DEBUG_SCRIPT, REDUCE_ENV, REDUCE_FAILURES_MAXPERCENT, REDUCE_INPUT_BUFFER_PERCENT, REDUCE_JAVA_OPTS, REDUCE_LOG_LEVEL, REDUCE_MARKRESET_BUFFER_PERCENT, REDUCE_MARKRESET_BUFFER_SIZE, REDUCE_MAX_ATTEMPTS, REDUCE_MEMORY_MB, REDUCE_MEMORY_TOTAL_BYTES, REDUCE_MEMTOMEM_ENABLED, REDUCE_MEMTOMEM_THRESHOLD, REDUCE_MERGE_INMEM_THRESHOLD, REDUCE_SEPARATE_SHUFFLE_LOG, REDUCE_SKIP_INCR_PROC_COUNT, REDUCE_SKIP_MAXGROUPS, REDUCE_SPECULATIVE, RESERVATION_ID, SETUP_CLEANUP_NEEDED, SHUFFLE_CONNECT_TIMEOUT, SHUFFLE_FETCH_FAILURES, SHUFFLE_FETCH_RETRY_ENABLED, SHUFFLE_FETCH_RETRY_INTERVAL_MS, SHUFFLE_FETCH_RETRY_TIMEOUT_MS, SHUFFLE_INPUT_BUFFER_PERCENT, SHUFFLE_LOG_BACKUPS, SHUFFLE_LOG_KB, SHUFFLE_MEMORY_LIMIT_PERCENT, SHUFFLE_MERGE_PERCENT, SHUFFLE_NOTIFY_READERROR, SHUFFLE_PARALLEL_COPIES, SHUFFLE_READ_TIMEOUT, SKIP_OUTDIR, SKIP_RECORDS, SKIP_START_ATTEMPTS, SPECULATIVE_MINIMUM_ALLOWED_TASKS, SPECULATIVE_RETRY_AFTER_NO_SPECULATE, SPECULATIVE_RETRY_AFTER_SPECULATE, SPECULATIVE_SLOWNODE_THRESHOLD, SPECULATIVE_SLOWTASK_THRESHOLD, SPECULATIVECAP, SPECULATIVECAP_RUNNING_TASKS, SPECULATIVECAP_TOTAL_TASKS, SPLIT_FILE, SPLIT_METAINFO_MAXSIZE, STDERR_LOGFILE_ENV, STDOUT_LOGFILE_ENV, TASK_ATTEMPT_ID, TASK_CLEANUP_NEEDED, TASK_DEBUGOUT_LINES, TASK_ID, TASK_ISMAP, TASK_LOG_BACKUPS, TASK_MAP_PROFILE_PARAMS, TASK_OUTPUT_DIR, TASK_PARTITION, TASK_PROFILE, TASK_PROFILE_PARAMS, TASK_REDUCE_PROFILE_PARAMS, TASK_TIMEOUT, TASK_TIMEOUT_CHECK_INTERVAL_MS, TASK_USERLOG_LIMIT, USER_LOG_RETAIN_HOURS, USER_NAME, WORKDIR, WORKFLOW_ADJACENCY_PREFIX_PATTERN, WORKFLOW_ADJACENCY_PREFIX_STRING, WORKFLOW_ID, WORKFLOW_NAME, WORKFLOW_NODE_NAME, WORKFLOW_TAGS, WORKING_DIR Method Summary Methods  Modifier and Type Method and Description Counter getCounter(Enum<?> counterName) Get the Counter for the given counterName. Counter getCounter(String groupName,                     String counterName) Get the Counter for the given groupName and   counterName. float getProgress() The current progress of the task attempt. String getStatus() Get the last set status message. TaskAttemptID getTaskAttemptID() Get the unique name for this task attempt. void setStatus(String msg) Set the current status of the task to the given string. Methods inherited from interface org.apache.hadoop.mapreduce.JobContext getArchiveClassPaths, getArchiveTimestamps, getCacheArchives, getCacheFiles, getCombinerClass, getCombinerKeyGroupingComparator, getConfiguration, getCredentials, getFileClassPaths, getFileTimestamps, getGroupingComparator, getInputFormatClass, getJar, getJobID, getJobName, getJobSetupCleanupNeeded, getLocalCacheArchives, getLocalCacheFiles, getMapOutputKeyClass, getMapOutputValueClass, getMapperClass, getMaxMapAttempts, getMaxReduceAttempts, getNumReduceTasks, getOutputFormatClass, getOutputKeyClass, getOutputValueClass, getPartitionerClass, getProfileEnabled, getProfileParams, getProfileTaskRange, getReducerClass, getSortComparator, getSymlink, getTaskCleanupNeeded, getUser, getWorkingDirectory Methods inherited from interface org.apache.hadoop.util.Progressable progress Method Detail getTaskAttemptID TaskAttemptID getTaskAttemptID() Get the unique name for this task attempt. setStatus void setStatus(String msg) Set the current status of the task to the given string. getStatus String getStatus() Get the last set status message. Returns:the current status message getProgress float getProgress() The current progress of the task attempt. Returns:a number between 0.0 and 1.0 (inclusive) indicating the attempt's  progress. getCounter Counter getCounter(Enum<?> counterName) Get the Counter for the given counterName. Parameters:counterName - counter name Returns:the Counter for the given counterName getCounter Counter getCounter(String groupName,                  String counterName) Get the Counter for the given groupName and   counterName. Parameters:counterName - counter name Returns:the Counter for the given groupName and           counterName Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskAttemptID (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskAttemptID (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class TaskAttemptID java.lang.Object org.apache.hadoop.mapreduce.ID org.apache.hadoop.mapred.ID org.apache.hadoop.mapreduce.TaskAttemptID All Implemented Interfaces: Comparable<ID>, Writable, WritableComparable<ID> Direct Known Subclasses: TaskAttemptID @InterfaceAudience.Public @InterfaceStability.Stable public class TaskAttemptID extends ID TaskAttemptID represents the immutable and unique identifier for   a task attempt. Each task attempt is one particular instance of a Map or  Reduce Task identified by its TaskID.     TaskAttemptID consists of 2 parts. First part is the   TaskID, that this TaskAttemptID belongs to.  Second part is the task attempt number.    An example TaskAttemptID is :   attempt_200707121733_0003_m_000005_0 , which represents the  zeroth task attempt for the fifth map task in the third job   running at the jobtracker started at 200707121733.    Applications should never construct or parse TaskAttemptID strings  , but rather use appropriate constructors or forName(String)   method. See Also:JobID,  TaskID Field Summary Fields  Modifier and Type Field and Description protected static String ATTEMPT  Fields inherited from class org.apache.hadoop.mapreduce.ID id, SEPARATOR Constructor Summary Constructors  Constructor and Description TaskAttemptID()  TaskAttemptID(String jtIdentifier,                           int jobId,                           boolean isMap,                           int taskId,                           int id) Deprecated.  TaskAttemptID(String jtIdentifier,                           int jobId,                           TaskType type,                           int taskId,                           int id) Constructs a TaskId object from given parts. TaskAttemptID(TaskID taskId,                           int id) Constructs a TaskAttemptID object from given TaskID. Method Summary Methods  Modifier and Type Method and Description protected StringBuilder appendTo(StringBuilder builder) Add the unique string to the StringBuilder int compareTo(ID o) Compare TaskIds by first tipIds, then by task numbers. boolean equals(Object o)  static TaskAttemptID forName(String str) Construct a TaskAttemptID object from given string JobID getJobID() Returns the JobID object that this task attempt belongs to TaskID getTaskID() Returns the TaskID object that this task attempt belongs to TaskType getTaskType() Returns the TaskType of the TaskAttemptID int hashCode()  boolean isMap() Deprecated.  void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.mapreduce.ID getId Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail ATTEMPT protected static final String ATTEMPT See Also:Constant Field Values Constructor Detail TaskAttemptID public TaskAttemptID(TaskID taskId,              int id) Constructs a TaskAttemptID object from given TaskID. Parameters:taskId - TaskID that this task belongs toid - the task attempt number TaskAttemptID public TaskAttemptID(String jtIdentifier,              int jobId,              TaskType type,              int taskId,              int id) Constructs a TaskId object from given parts. Parameters:jtIdentifier - jobTracker identifierjobId - job numbertype - the TaskTypetaskId - taskId numberid - the task attempt number TaskAttemptID @Deprecated public TaskAttemptID(String jtIdentifier,                         int jobId,                         boolean isMap,                         int taskId,                         int id) Deprecated.  Constructs a TaskId object from given parts. Parameters:jtIdentifier - jobTracker identifierjobId - job numberisMap - whether the tip is a maptaskId - taskId numberid - the task attempt number TaskAttemptID public TaskAttemptID() Method Detail getJobID public JobID getJobID() Returns the JobID object that this task attempt belongs to getTaskID public TaskID getTaskID() Returns the TaskID object that this task attempt belongs to isMap @Deprecated public boolean isMap() Deprecated.  Returns whether this TaskID is a map ID getTaskType public TaskType getTaskType() Returns the TaskType of the TaskAttemptID equals public boolean equals(Object o) Overrides: equals in class ID appendTo protected StringBuilder appendTo(StringBuilder builder) Add the unique string to the StringBuilder Parameters:builder - the builder to append ot Returns:the builder that was passed in. readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Overrides: readFields in class ID Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Overrides: write in class ID Parameters:out - DataOuput to serialize this object into. Throws: IOException hashCode public int hashCode() Overrides: hashCode in class ID compareTo public int compareTo(ID o) Compare TaskIds by first tipIds, then by task numbers. Specified by: compareTo in interface Comparable<ID> Overrides: compareTo in class ID toString public String toString() Overrides: toString in class ID forName public static TaskAttemptID forName(String str)                              throws IllegalArgumentException Construct a TaskAttemptID object from given string Returns:constructed TaskAttemptID object or null if the given String is null Throws: IllegalArgumentException - if the given string is malformed Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskCompletionEvent.Status (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskCompletionEvent.Status (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.mapreduce Enum TaskCompletionEvent.Status java.lang.Object java.lang.Enum<TaskCompletionEvent.Status> org.apache.hadoop.mapreduce.TaskCompletionEvent.Status All Implemented Interfaces: Serializable, Comparable<TaskCompletionEvent.Status> Enclosing class: TaskCompletionEvent @InterfaceAudience.Public @InterfaceStability.Evolving public static enum TaskCompletionEvent.Status extends Enum<TaskCompletionEvent.Status> Enum Constant Summary Enum Constants  Enum Constant and Description FAILED Task Event Attempt failed but there are attempts remaining. KILLED Task Event was killed. OBSOLETE Used to Override a previously successful event status. SUCCEEDED Task Event was successful. TIPFAILED Task Event attempt failed and no further attempts exist. Method Summary Methods  Modifier and Type Method and Description static TaskCompletionEvent.Status valueOf(String name) Returns the enum constant of this type with the specified name. static TaskCompletionEvent.Status[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail FAILED public static final TaskCompletionEvent.Status FAILED Task Event Attempt failed but there are attempts remaining. KILLED public static final TaskCompletionEvent.Status KILLED Task Event was killed. SUCCEEDED public static final TaskCompletionEvent.Status SUCCEEDED Task Event was successful. OBSOLETE public static final TaskCompletionEvent.Status OBSOLETE Used to Override a previously successful event status.  Example:  Map attempt runs and a SUCCEEDED event is sent. Later a task  is retroactively failed due to excessive fetch failure during shuffle  phase. When the retroactive attempt failure occurs, an OBSOLETE event is  sent for the map attempt indicating the prior event is no longer valid. TIPFAILED public static final TaskCompletionEvent.Status TIPFAILED Task Event attempt failed and no further attempts exist.  reached MAX attempts. When a reducer receives a TIPFAILED event it  gives up trying to shuffle data from that map task. Method Detail values public static TaskCompletionEvent.Status[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (TaskCompletionEvent.Status c : TaskCompletionEvent.Status.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static TaskCompletionEvent.Status valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskCompletionEvent (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskCompletionEvent (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class TaskCompletionEvent java.lang.Object org.apache.hadoop.mapreduce.TaskCompletionEvent All Implemented Interfaces: Writable Direct Known Subclasses: TaskCompletionEvent @InterfaceAudience.Public @InterfaceStability.Evolving public class TaskCompletionEvent extends Object implements Writable This is used to track task completion events on   job tracker. Nested Class Summary Nested Classes  Modifier and Type Class and Description static class  TaskCompletionEvent.Status  Field Summary Fields  Modifier and Type Field and Description static TaskCompletionEvent[] EMPTY_ARRAY  Constructor Summary Constructors  Constructor and Description TaskCompletionEvent() Default constructor for Writable. TaskCompletionEvent(int eventId,                                       TaskAttemptID taskId,                                       int idWithinJob,                                       boolean isMap,                                       TaskCompletionEvent.Status status,                                       String taskTrackerHttp) Constructor. Method Summary Methods  Modifier and Type Method and Description boolean equals(Object o)  int getEventId() Returns event Id. TaskCompletionEvent.Status getStatus() Returns TaskCompletionEvent.Status TaskAttemptID getTaskAttemptId() Returns task id. int getTaskRunTime() Returns time (in millisec) the task took to complete. String getTaskTrackerHttp() http location of the tasktracker where this task ran. int hashCode()  int idWithinJob()  boolean isMapTask()  void readFields(DataInput in) Deserialize the fields of this object from in. protected void setEventId(int eventId) set event Id. protected void setTaskAttemptId(TaskAttemptID taskId) Sets task id. protected void setTaskRunTime(int taskCompletionTime) Set the task completion time protected void setTaskStatus(TaskCompletionEvent.Status status) Set task status. protected void setTaskTrackerHttp(String taskTrackerHttp) Set task tracker http location. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail EMPTY_ARRAY public static final TaskCompletionEvent[] EMPTY_ARRAY Constructor Detail TaskCompletionEvent public TaskCompletionEvent() Default constructor for Writable. TaskCompletionEvent public TaskCompletionEvent(int eventId,                    TaskAttemptID taskId,                    int idWithinJob,                    boolean isMap,                    TaskCompletionEvent.Status status,                    String taskTrackerHttp) Constructor. eventId should be created externally and incremented  per event for each job. Parameters:eventId - event id, event id should be unique and assigned in   incrementally, starting from 0.taskId - task idstatus - task's statustaskTrackerHttp - task tracker's host:port for http. Method Detail getEventId public int getEventId() Returns event Id. Returns:event id getTaskAttemptId public TaskAttemptID getTaskAttemptId() Returns task id. Returns:task id getStatus public TaskCompletionEvent.Status getStatus() Returns TaskCompletionEvent.Status Returns:task completion status getTaskTrackerHttp public String getTaskTrackerHttp() http location of the tasktracker where this task ran. Returns:http location of tasktracker user logs getTaskRunTime public int getTaskRunTime() Returns time (in millisec) the task took to complete. setTaskRunTime protected void setTaskRunTime(int taskCompletionTime) Set the task completion time Parameters:taskCompletionTime - time (in millisec) the task took to complete setEventId protected void setEventId(int eventId) set event Id. should be assigned incrementally starting from 0. Parameters:eventId -  setTaskAttemptId protected void setTaskAttemptId(TaskAttemptID taskId) Sets task id. Parameters:taskId -  setTaskStatus protected void setTaskStatus(TaskCompletionEvent.Status status) Set task status. Parameters:status -  setTaskTrackerHttp protected void setTaskTrackerHttp(String taskTrackerHttp) Set task tracker http location. Parameters:taskTrackerHttp -  toString public String toString() Overrides: toString in class Object equals public boolean equals(Object o) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object isMapTask public boolean isMapTask() idWithinJob public int idWithinJob() write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskCounter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskCounter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.mapreduce Enum TaskCounter java.lang.Object java.lang.Enum<TaskCounter> org.apache.hadoop.mapreduce.TaskCounter All Implemented Interfaces: Serializable, Comparable<TaskCounter> @InterfaceAudience.Public @InterfaceStability.Evolving public enum TaskCounter extends Enum<TaskCounter> Enum Constant Summary Enum Constants  Enum Constant and Description COMBINE_INPUT_RECORDS  COMBINE_OUTPUT_RECORDS  COMMITTED_HEAP_BYTES  CPU_MILLISECONDS  FAILED_SHUFFLE  GC_TIME_MILLIS  MAP_INPUT_RECORDS  MAP_OUTPUT_BYTES  MAP_OUTPUT_MATERIALIZED_BYTES  MAP_OUTPUT_RECORDS  MAP_SKIPPED_RECORDS  MERGED_MAP_OUTPUTS  PHYSICAL_MEMORY_BYTES  REDUCE_INPUT_GROUPS  REDUCE_INPUT_RECORDS  REDUCE_OUTPUT_RECORDS  REDUCE_SHUFFLE_BYTES  REDUCE_SKIPPED_GROUPS  REDUCE_SKIPPED_RECORDS  SHUFFLED_MAPS  SPILLED_RECORDS  SPLIT_RAW_BYTES  VIRTUAL_MEMORY_BYTES  Method Summary Methods  Modifier and Type Method and Description static TaskCounter valueOf(String name) Returns the enum constant of this type with the specified name. static TaskCounter[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail MAP_INPUT_RECORDS public static final TaskCounter MAP_INPUT_RECORDS MAP_OUTPUT_RECORDS public static final TaskCounter MAP_OUTPUT_RECORDS MAP_SKIPPED_RECORDS public static final TaskCounter MAP_SKIPPED_RECORDS MAP_OUTPUT_BYTES public static final TaskCounter MAP_OUTPUT_BYTES MAP_OUTPUT_MATERIALIZED_BYTES public static final TaskCounter MAP_OUTPUT_MATERIALIZED_BYTES SPLIT_RAW_BYTES public static final TaskCounter SPLIT_RAW_BYTES COMBINE_INPUT_RECORDS public static final TaskCounter COMBINE_INPUT_RECORDS COMBINE_OUTPUT_RECORDS public static final TaskCounter COMBINE_OUTPUT_RECORDS REDUCE_INPUT_GROUPS public static final TaskCounter REDUCE_INPUT_GROUPS REDUCE_SHUFFLE_BYTES public static final TaskCounter REDUCE_SHUFFLE_BYTES REDUCE_INPUT_RECORDS public static final TaskCounter REDUCE_INPUT_RECORDS REDUCE_OUTPUT_RECORDS public static final TaskCounter REDUCE_OUTPUT_RECORDS REDUCE_SKIPPED_GROUPS public static final TaskCounter REDUCE_SKIPPED_GROUPS REDUCE_SKIPPED_RECORDS public static final TaskCounter REDUCE_SKIPPED_RECORDS SPILLED_RECORDS public static final TaskCounter SPILLED_RECORDS SHUFFLED_MAPS public static final TaskCounter SHUFFLED_MAPS FAILED_SHUFFLE public static final TaskCounter FAILED_SHUFFLE MERGED_MAP_OUTPUTS public static final TaskCounter MERGED_MAP_OUTPUTS GC_TIME_MILLIS public static final TaskCounter GC_TIME_MILLIS CPU_MILLISECONDS public static final TaskCounter CPU_MILLISECONDS PHYSICAL_MEMORY_BYTES public static final TaskCounter PHYSICAL_MEMORY_BYTES VIRTUAL_MEMORY_BYTES public static final TaskCounter VIRTUAL_MEMORY_BYTES COMMITTED_HEAP_BYTES public static final TaskCounter COMMITTED_HEAP_BYTES Method Detail values public static TaskCounter[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (TaskCounter c : TaskCounter.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static TaskCounter valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskID (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskID (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class TaskID java.lang.Object org.apache.hadoop.mapreduce.ID org.apache.hadoop.mapred.ID org.apache.hadoop.mapreduce.TaskID All Implemented Interfaces: Comparable<ID>, Writable, WritableComparable<ID> Direct Known Subclasses: TaskID @InterfaceAudience.Public @InterfaceStability.Stable public class TaskID extends ID TaskID represents the immutable and unique identifier for   a Map or Reduce Task. Each TaskID encompasses multiple attempts made to  execute the Map or Reduce Task, each of which are uniquely indentified by  their TaskAttemptID.    TaskID consists of 3 parts. First part is the JobID, that this   TaskInProgress belongs to. Second part of the TaskID is either 'm' or 'r'   representing whether the task is a map task or a reduce task.   And the third part is the task number.    An example TaskID is :   task_200707121733_0003_m_000005 , which represents the  fifth map task in the third job running at the jobtracker   started at 200707121733.     Applications should never construct or parse TaskID strings  , but rather use appropriate constructors or forName(String)   method. See Also:JobID,  TaskAttemptID Field Summary Fields  Modifier and Type Field and Description protected static NumberFormat idFormat  protected static String TASK  Fields inherited from class org.apache.hadoop.mapreduce.ID id, SEPARATOR Constructor Summary Constructors  Constructor and Description TaskID()  TaskID(JobID jobId,             boolean isMap,             int id) Deprecated.  TaskID(JobID jobId,             TaskType type,             int id) Constructs a TaskID object from given JobID. TaskID(String jtIdentifier,             int jobId,             boolean isMap,             int id) Deprecated.  TaskID(String jtIdentifier,             int jobId,             TaskType type,             int id) Constructs a TaskInProgressId object from given parts. Method Summary Methods  Modifier and Type Method and Description protected StringBuilder appendTo(StringBuilder builder) Add the unique string to the given builder. int compareTo(ID o) Compare TaskInProgressIds by first jobIds, then by tip numbers. boolean equals(Object o)  static TaskID forName(String str) Construct a TaskID object from given string static String getAllTaskTypes()  JobID getJobID() Returns the JobID object that this tip belongs to static char getRepresentingCharacter(TaskType type) Gets the character representing the TaskType TaskType getTaskType() Get the type of the task static TaskType getTaskType(char c) Gets the TaskType corresponding to the character int hashCode()  boolean isMap() Deprecated.  void readFields(DataInput in) Deserialize the fields of this object from in. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class org.apache.hadoop.mapreduce.ID getId Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail TASK protected static final String TASK See Also:Constant Field Values idFormat protected static final NumberFormat idFormat Constructor Detail TaskID public TaskID(JobID jobId,       TaskType type,       int id) Constructs a TaskID object from given JobID. Parameters:jobId - JobID that this tip belongs totype - the TaskType of the taskid - the tip number TaskID public TaskID(String jtIdentifier,       int jobId,       TaskType type,       int id) Constructs a TaskInProgressId object from given parts. Parameters:jtIdentifier - jobTracker identifierjobId - job numbertype - the TaskTypeid - the tip number TaskID @Deprecated public TaskID(JobID jobId,                  boolean isMap,                  int id) Deprecated.  Constructs a TaskID object from given JobID. Parameters:jobId - JobID that this tip belongs toisMap - whether the tip is a mapid - the tip number TaskID @Deprecated public TaskID(String jtIdentifier,                  int jobId,                  boolean isMap,                  int id) Deprecated.  Constructs a TaskInProgressId object from given parts. Parameters:jtIdentifier - jobTracker identifierjobId - job numberisMap - whether the tip is a mapid - the tip number TaskID public TaskID() Method Detail getJobID public JobID getJobID() Returns the JobID object that this tip belongs to isMap @Deprecated public boolean isMap() Deprecated.  Returns whether this TaskID is a map ID getTaskType public TaskType getTaskType() Get the type of the task equals public boolean equals(Object o) Overrides: equals in class ID compareTo public int compareTo(ID o) Compare TaskInProgressIds by first jobIds, then by tip numbers. Reduces are   defined as greater then maps. Specified by: compareTo in interface Comparable<ID> Overrides: compareTo in class ID toString public String toString() Overrides: toString in class ID appendTo protected StringBuilder appendTo(StringBuilder builder) Add the unique string to the given builder. Parameters:builder - the builder to append to Returns:the builder that was passed in hashCode public int hashCode() Overrides: hashCode in class ID readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Overrides: readFields in class ID Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Overrides: write in class ID Parameters:out - DataOuput to serialize this object into. Throws: IOException forName public static TaskID forName(String str)                       throws IllegalArgumentException Construct a TaskID object from given string Returns:constructed TaskID object or null if the given String is null Throws: IllegalArgumentException - if the given string is malformed getRepresentingCharacter public static char getRepresentingCharacter(TaskType type) Gets the character representing the TaskType Parameters:type - the TaskType Returns:the character getTaskType public static TaskType getTaskType(char c) Gets the TaskType corresponding to the character Parameters:c - the character Returns:the TaskType getAllTaskTypes public static String getAllTaskTypes() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskInputOutputContext (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskInputOutputContext (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Interface TaskInputOutputContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> Type Parameters:KEYIN - the input key type for the taskVALUEIN - the input value type for the taskKEYOUT - the output key type for the taskVALUEOUT - the output value type for the task All Superinterfaces: JobContext, org.apache.hadoop.mapreduce.MRJobConfig, Progressable, TaskAttemptContext All Known Subinterfaces: MapContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT>, ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Evolving public interface TaskInputOutputContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends TaskAttemptContext A context object that allows input and output from the task. It is only  supplied to the Mapper or Reducer. Field Summary Fields inherited from interface org.apache.hadoop.mapreduce.MRJobConfig APPLICATION_ATTEMPT_ID, APPLICATION_MASTER_CLASS, CACHE_ARCHIVES, CACHE_ARCHIVES_SIZES, CACHE_ARCHIVES_TIMESTAMPS, CACHE_ARCHIVES_VISIBILITIES, CACHE_FILE_TIMESTAMPS, CACHE_FILE_VISIBILITIES, CACHE_FILES, CACHE_FILES_SIZES, CACHE_LOCALARCHIVES, CACHE_LOCALFILES, CACHE_SYMLINK, CLASSPATH_ARCHIVES, CLASSPATH_FILES, COMBINE_CLASS_ATTR, COMBINE_RECORDS_BEFORE_PROGRESS, COMBINER_GROUP_COMPARATOR_CLASS, COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, COUNTER_GROUP_NAME_MAX_DEFAULT, COUNTER_GROUP_NAME_MAX_KEY, COUNTER_GROUPS_MAX_DEFAULT, COUNTER_GROUPS_MAX_KEY, COUNTER_NAME_MAX_DEFAULT, COUNTER_NAME_MAX_KEY, COUNTERS_MAX_DEFAULT, COUNTERS_MAX_KEY, DEFAULT_JOB_ACL_MODIFY_JOB, DEFAULT_JOB_ACL_VIEW_JOB, DEFAULT_JOB_AM_ACCESS_DISABLED, DEFAULT_JOB_RUNNING_MAP_LIMIT, DEFAULT_JOB_RUNNING_REDUCE_LIMIT, DEFAULT_JOB_TOKEN_TRACKING_IDS_ENABLED, DEFAULT_LOG_LEVEL, DEFAULT_MAP_CPU_VCORES, DEFAULT_MAP_MEMORY_MB, DEFAULT_MAPRED_ADMIN_JAVA_OPTS, DEFAULT_MAPRED_ADMIN_USER_ENV, DEFAULT_MAPREDUCE_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_CROSS_PLATFORM_APPLICATION_CLASSPATH, DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA, DEFAULT_MAX_ALLOWED_FETCH_FAILURES_FRACTION, DEFAULT_MAX_FETCH_FAILURES_NOTIFICATIONS, DEFAULT_MAX_SHUFFLE_FETCH_HOST_FAILURES, DEFAULT_MAX_SHUFFLE_FETCH_RETRY_DELAY, DEFAULT_MR_AM_ADMIN_COMMAND_OPTS, DEFAULT_MR_AM_COMMAND_OPTS, DEFAULT_MR_AM_COMMIT_WINDOW_MS, DEFAULT_MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, DEFAULT_MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, DEFAULT_MR_AM_CPU_VCORES, DEFAULT_MR_AM_HARD_KILL_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, DEFAULT_MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERCENT, DEFAULT_MR_AM_JOB_CLIENT_THREAD_COUNT, DEFAULT_MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, DEFAULT_MR_AM_JOB_REDUCE_RAMP_UP_LIMIT, DEFAULT_MR_AM_LOG_BACKUPS, DEFAULT_MR_AM_LOG_KB, DEFAULT_MR_AM_LOG_LEVEL, DEFAULT_MR_AM_MAX_ATTEMPTS, DEFAULT_MR_AM_NUM_PROGRESS_SPLITS, DEFAULT_MR_AM_PROFILE, DEFAULT_MR_AM_STAGING_DIR, DEFAULT_MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, DEFAULT_MR_AM_TASK_LISTENER_THREAD_COUNT, DEFAULT_MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, DEFAULT_MR_AM_TO_RM_WAIT_INTERVAL_MS, DEFAULT_MR_AM_VMEM_MB, DEFAULT_MR_CLIENT_JOB_MAX_RETRIES, DEFAULT_MR_CLIENT_JOB_RETRY_INTERVAL, DEFAULT_MR_CLIENT_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES, DEFAULT_MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, DEFAULT_MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, DEFAULT_MR_JOB_END_NOTIFICATION_TIMEOUT, DEFAULT_MR_JOB_REDUCER_PREEMPT_DELAY_SEC, DEFAULT_REDUCE_CPU_VCORES, DEFAULT_REDUCE_MEMORY_MB, DEFAULT_REDUCE_SEPARATE_SHUFFLE_LOG, DEFAULT_SHELL, DEFAULT_SHUFFLE_FETCH_RETRY_INTERVAL_MS, DEFAULT_SHUFFLE_INPUT_BUFFER_PERCENT, DEFAULT_SHUFFLE_LOG_BACKUPS, DEFAULT_SHUFFLE_LOG_KB, DEFAULT_SPECULATIVE_MINIMUM_ALLOWED_TASKS, DEFAULT_SPECULATIVE_RETRY_AFTER_NO_SPECULATE, DEFAULT_SPECULATIVE_RETRY_AFTER_SPECULATE, DEFAULT_SPECULATIVECAP_RUNNING_TASKS, DEFAULT_SPECULATIVECAP_TOTAL_TASKS, DEFAULT_SPLIT_METAINFO_MAXSIZE, DEFAULT_TASK_ISMAP, DEFAULT_TASK_LOG_BACKUPS, DEFAULT_TASK_PROFILE_PARAMS, GROUP_COMPARATOR_CLASS, HADOOP_WORK_DIR, ID, INDEX_CACHE_MEMORY_LIMIT, INPUT_FORMAT_CLASS_ATTR, IO_SORT_FACTOR, IO_SORT_MB, JAR, JAR_UNPACK_PATTERN, JOB_ACL_MODIFY_JOB, JOB_ACL_VIEW_JOB, JOB_AM_ACCESS_DISABLED, JOB_CANCEL_DELEGATION_TOKEN, JOB_CONF_FILE, JOB_JAR, JOB_JOBTRACKER_ID, JOB_LOCAL_DIR, JOB_NAME, JOB_NAMENODES, JOB_RUNNING_MAP_LIMIT, JOB_RUNNING_REDUCE_LIMIT, JOB_SPLIT, JOB_SPLIT_METAINFO, JOB_SUBMIT_DIR, JOB_SUBMITHOST, JOB_SUBMITHOSTADDR, JOB_TAGS, JOB_TOKEN_TRACKING_IDS, JOB_TOKEN_TRACKING_IDS_ENABLED, JOB_UBERTASK_ENABLE, JOB_UBERTASK_MAXBYTES, JOB_UBERTASK_MAXMAPS, JOB_UBERTASK_MAXREDUCES, JVM_NUMTASKS_TORUN, KEY_COMPARATOR, MAP_CLASS_ATTR, MAP_COMBINE_MIN_SPILLS, MAP_CPU_VCORES, MAP_DEBUG_SCRIPT, MAP_ENV, MAP_FAILURES_MAX_PERCENT, MAP_INPUT_FILE, MAP_INPUT_PATH, MAP_INPUT_START, MAP_JAVA_OPTS, MAP_LOG_LEVEL, MAP_MAX_ATTEMPTS, MAP_MEMORY_MB, MAP_OUTPUT_COLLECTOR_CLASS_ATTR, MAP_OUTPUT_COMPRESS, MAP_OUTPUT_COMPRESS_CODEC, MAP_OUTPUT_KEY_CLASS, MAP_OUTPUT_KEY_FIELD_SEPERATOR, MAP_OUTPUT_VALUE_CLASS, MAP_SKIP_INCR_PROC_COUNT, MAP_SKIP_MAX_RECORDS, MAP_SORT_SPILL_PERCENT, MAP_SPECULATIVE, MAPRED_ADMIN_USER_ENV, MAPRED_ADMIN_USER_SHELL, MAPRED_MAP_ADMIN_JAVA_OPTS, MAPRED_REDUCE_ADMIN_JAVA_OPTS, MAPREDUCE_APPLICATION_CLASSPATH, MAPREDUCE_APPLICATION_FRAMEWORK_PATH, MAPREDUCE_JOB_CLASSLOADER, MAPREDUCE_JOB_CLASSLOADER_SYSTEM_CLASSES, MAPREDUCE_JOB_CREDENTIALS_BINARY, MAPREDUCE_JOB_DIR, MAPREDUCE_JOB_EMIT_TIMELINE_DATA, MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE, MAPREDUCE_JOB_SHUFFLE_PROVIDER_SERVICES, MAPREDUCE_JOB_USER_CLASSPATH_FIRST, MAPREDUCE_V2_CHILD_CLASS, MAX_ALLOWED_FETCH_FAILURES_FRACTION, MAX_FETCH_FAILURES_NOTIFICATIONS, MAX_SHUFFLE_FETCH_HOST_FAILURES, MAX_SHUFFLE_FETCH_RETRY_DELAY, MAX_TASK_FAILURES_PER_TRACKER, MR_AM_ADMIN_COMMAND_OPTS, MR_AM_ADMIN_USER_ENV, MR_AM_COMMAND_OPTS, MR_AM_COMMIT_WINDOW_MS, MR_AM_COMMITTER_CANCEL_TIMEOUT_MS, MR_AM_CONTAINERLAUNCHER_THREAD_COUNT_LIMIT, MR_AM_CONTAINERLAUNCHER_THREADPOOL_INITIAL_SIZE, MR_AM_CPU_VCORES, MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR, MR_AM_ENV, MR_AM_HARD_KILL_TIMEOUT_MS, MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS, MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER, MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS, MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD, MR_AM_IGNORE_BLACKLISTING_BLACKLISTED_NODE_PERECENT, MR_AM_JOB_CLIENT_PORT_RANGE, MR_AM_JOB_CLIENT_THREAD_COUNT, MR_AM_JOB_NODE_BLACKLISTING_ENABLE, MR_AM_JOB_RECOVERY_ENABLE, MR_AM_JOB_RECOVERY_ENABLE_DEFAULT, MR_AM_JOB_REDUCE_PREEMPTION_LIMIT, MR_AM_JOB_REDUCE_RAMPUP_UP_LIMIT, MR_AM_JOB_SPECULATOR, MR_AM_LOG_BACKUPS, MR_AM_LOG_KB, MR_AM_LOG_LEVEL, MR_AM_MAX_ATTEMPTS, MR_AM_NUM_PROGRESS_SPLITS, MR_AM_PREFIX, MR_AM_PROFILE, MR_AM_PROFILE_PARAMS, MR_AM_SECURITY_SERVICE_AUTHORIZATION_CLIENT, MR_AM_SECURITY_SERVICE_AUTHORIZATION_TASK_UMBILICAL, MR_AM_STAGING_DIR, MR_AM_TASK_ESTIMATOR, MR_AM_TASK_ESTIMATOR_EXPONENTIAL_RATE_ENABLE, MR_AM_TASK_ESTIMATOR_SMOOTH_LAMBDA_MS, MR_AM_TASK_LISTENER_THREAD_COUNT, MR_AM_TO_RM_HEARTBEAT_INTERVAL_MS, MR_AM_TO_RM_WAIT_INTERVAL_MS, MR_AM_VMEM_MB, MR_APPLICATION_TYPE, MR_CLIENT_JOB_MAX_RETRIES, MR_CLIENT_JOB_RETRY_INTERVAL, MR_CLIENT_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES, MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS, MR_ENCRYPTED_INTERMEDIATE_DATA, MR_ENCRYPTED_INTERMEDIATE_DATA_BUFFER_KB, MR_ENCRYPTED_INTERMEDIATE_DATA_KEY_SIZE_BITS, MR_JOB_END_NOTIFICATION_MAX_ATTEMPTS, MR_JOB_END_NOTIFICATION_MAX_RETRY_INTERVAL, MR_JOB_END_NOTIFICATION_PROXY, MR_JOB_END_NOTIFICATION_TIMEOUT, MR_JOB_END_NOTIFICATION_URL, MR_JOB_END_RETRY_ATTEMPTS, MR_JOB_END_RETRY_INTERVAL, MR_JOB_REDUCER_PREEMPT_DELAY_SEC, MR_PREFIX, NUM_MAP_PROFILES, NUM_MAPS, NUM_REDUCE_PROFILES, NUM_REDUCES, OUTPUT, OUTPUT_FORMAT_CLASS_ATTR, OUTPUT_KEY_CLASS, OUTPUT_VALUE_CLASS, PARTITIONER_CLASS_ATTR, PRESERVE_FAILED_TASK_FILES, PRESERVE_FILES_PATTERN, PRIORITY, QUEUE_NAME, RECORDS_BEFORE_PROGRESS, REDUCE_CLASS_ATTR, REDUCE_CPU_VCORES, REDUCE_DEBUG_SCRIPT, REDUCE_ENV, REDUCE_FAILURES_MAXPERCENT, REDUCE_INPUT_BUFFER_PERCENT, REDUCE_JAVA_OPTS, REDUCE_LOG_LEVEL, REDUCE_MARKRESET_BUFFER_PERCENT, REDUCE_MARKRESET_BUFFER_SIZE, REDUCE_MAX_ATTEMPTS, REDUCE_MEMORY_MB, REDUCE_MEMORY_TOTAL_BYTES, REDUCE_MEMTOMEM_ENABLED, REDUCE_MEMTOMEM_THRESHOLD, REDUCE_MERGE_INMEM_THRESHOLD, REDUCE_SEPARATE_SHUFFLE_LOG, REDUCE_SKIP_INCR_PROC_COUNT, REDUCE_SKIP_MAXGROUPS, REDUCE_SPECULATIVE, RESERVATION_ID, SETUP_CLEANUP_NEEDED, SHUFFLE_CONNECT_TIMEOUT, SHUFFLE_FETCH_FAILURES, SHUFFLE_FETCH_RETRY_ENABLED, SHUFFLE_FETCH_RETRY_INTERVAL_MS, SHUFFLE_FETCH_RETRY_TIMEOUT_MS, SHUFFLE_INPUT_BUFFER_PERCENT, SHUFFLE_LOG_BACKUPS, SHUFFLE_LOG_KB, SHUFFLE_MEMORY_LIMIT_PERCENT, SHUFFLE_MERGE_PERCENT, SHUFFLE_NOTIFY_READERROR, SHUFFLE_PARALLEL_COPIES, SHUFFLE_READ_TIMEOUT, SKIP_OUTDIR, SKIP_RECORDS, SKIP_START_ATTEMPTS, SPECULATIVE_MINIMUM_ALLOWED_TASKS, SPECULATIVE_RETRY_AFTER_NO_SPECULATE, SPECULATIVE_RETRY_AFTER_SPECULATE, SPECULATIVE_SLOWNODE_THRESHOLD, SPECULATIVE_SLOWTASK_THRESHOLD, SPECULATIVECAP, SPECULATIVECAP_RUNNING_TASKS, SPECULATIVECAP_TOTAL_TASKS, SPLIT_FILE, SPLIT_METAINFO_MAXSIZE, STDERR_LOGFILE_ENV, STDOUT_LOGFILE_ENV, TASK_ATTEMPT_ID, TASK_CLEANUP_NEEDED, TASK_DEBUGOUT_LINES, TASK_ID, TASK_ISMAP, TASK_LOG_BACKUPS, TASK_MAP_PROFILE_PARAMS, TASK_OUTPUT_DIR, TASK_PARTITION, TASK_PROFILE, TASK_PROFILE_PARAMS, TASK_REDUCE_PROFILE_PARAMS, TASK_TIMEOUT, TASK_TIMEOUT_CHECK_INTERVAL_MS, TASK_USERLOG_LIMIT, USER_LOG_RETAIN_HOURS, USER_NAME, WORKDIR, WORKFLOW_ADJACENCY_PREFIX_PATTERN, WORKFLOW_ADJACENCY_PREFIX_STRING, WORKFLOW_ID, WORKFLOW_NAME, WORKFLOW_NODE_NAME, WORKFLOW_TAGS, WORKING_DIR Method Summary Methods  Modifier and Type Method and Description KEYIN getCurrentKey() Get the current key. VALUEIN getCurrentValue() Get the current value. OutputCommitter getOutputCommitter() Get the OutputCommitter for the task-attempt. boolean nextKeyValue() Advance to the next key, value pair, returning null if at end. void write(KEYOUT key,           VALUEOUT value) Generate an output key/value pair. Methods inherited from interface org.apache.hadoop.mapreduce.TaskAttemptContext getCounter, getCounter, getProgress, getStatus, getTaskAttemptID, setStatus Methods inherited from interface org.apache.hadoop.mapreduce.JobContext getArchiveClassPaths, getArchiveTimestamps, getCacheArchives, getCacheFiles, getCombinerClass, getCombinerKeyGroupingComparator, getConfiguration, getCredentials, getFileClassPaths, getFileTimestamps, getGroupingComparator, getInputFormatClass, getJar, getJobID, getJobName, getJobSetupCleanupNeeded, getLocalCacheArchives, getLocalCacheFiles, getMapOutputKeyClass, getMapOutputValueClass, getMapperClass, getMaxMapAttempts, getMaxReduceAttempts, getNumReduceTasks, getOutputFormatClass, getOutputKeyClass, getOutputValueClass, getPartitionerClass, getProfileEnabled, getProfileParams, getProfileTaskRange, getReducerClass, getSortComparator, getSymlink, getTaskCleanupNeeded, getUser, getWorkingDirectory Methods inherited from interface org.apache.hadoop.util.Progressable progress Method Detail nextKeyValue boolean nextKeyValue()                      throws IOException,                             InterruptedException Advance to the next key, value pair, returning null if at end. Returns:the key object that was read into, or null if no more Throws: IOException InterruptedException getCurrentKey KEYIN getCurrentKey()                     throws IOException,                            InterruptedException Get the current key. Returns:the current key object or null if there isn't one Throws: IOException InterruptedException getCurrentValue VALUEIN getCurrentValue()                         throws IOException,                                InterruptedException Get the current value. Returns:the value object that was read into Throws: IOException InterruptedException write void write(KEYOUT key,          VALUEOUT value)            throws IOException,                   InterruptedException Generate an output key/value pair. Throws: IOException InterruptedException getOutputCommitter OutputCommitter getOutputCommitter() Get the OutputCommitter for the task-attempt. Returns:the OutputCommitter for the task-attempt Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskReport (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskReport (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred Class TaskReport java.lang.Object org.apache.hadoop.mapreduce.TaskReport org.apache.hadoop.mapred.TaskReport All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class TaskReport extends org.apache.hadoop.mapreduce.TaskReport A report on the state of a task. Constructor Summary Constructors  Constructor and Description TaskReport()  Method Summary Methods  Modifier and Type Method and Description Counters getCounters()  Collection<TaskAttemptID> getRunningTaskAttempts() Get the running task attempt IDs for this task TaskAttemptID getSuccessfulTaskAttempt() Get the attempt ID that took this task to completion String getTaskId() The string of the task id. TaskID getTaskID() The id of the task. protected void setFinishTime(long finishTime) set finish time of task. void setRunningTaskAttempts(Collection<TaskAttemptID> runningAttempts) set running attempt(s) of the task. protected void setStartTime(long startTime) set start time of the task. void setSuccessfulAttempt(TaskAttemptID t) set successful attempt ID of the task. Methods inherited from class org.apache.hadoop.mapreduce.TaskReport equals, getCurrentStatus, getDiagnostics, getFinishTime, getProgress, getRunningTaskAttemptIds, getStartTime, getState, getSuccessfulTaskAttemptId, getTaskCounters, hashCode, readFields, setRunningTaskAttemptIds, setSuccessfulAttemptId, write Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail TaskReport public TaskReport() Method Detail getTaskId public String getTaskId() The string of the task id. Overrides: getTaskId in class org.apache.hadoop.mapreduce.TaskReport getTaskID public TaskID getTaskID() The id of the task. Overrides: getTaskID in class org.apache.hadoop.mapreduce.TaskReport getCounters public Counters getCounters() setSuccessfulAttempt public void setSuccessfulAttempt(TaskAttemptID t) set successful attempt ID of the task. getSuccessfulTaskAttempt public TaskAttemptID getSuccessfulTaskAttempt() Get the attempt ID that took this task to completion setRunningTaskAttempts public void setRunningTaskAttempts(Collection<TaskAttemptID> runningAttempts) set running attempt(s) of the task. getRunningTaskAttempts public Collection<TaskAttemptID> getRunningTaskAttempts() Get the running task attempt IDs for this task setFinishTime protected void setFinishTime(long finishTime) set finish time of task. Overrides: setFinishTime in class org.apache.hadoop.mapreduce.TaskReport Parameters:finishTime - finish time of task. setStartTime protected void setStartTime(long startTime) set start time of the task. Overrides: setStartTime in class org.apache.hadoop.mapreduce.TaskReport Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskTrackerInfo (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskTrackerInfo (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce Class TaskTrackerInfo java.lang.Object org.apache.hadoop.mapreduce.TaskTrackerInfo All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class TaskTrackerInfo extends Object implements Writable Information about TaskTracker. Constructor Summary Constructors  Constructor and Description TaskTrackerInfo()  TaskTrackerInfo(String name)  TaskTrackerInfo(String name,                               String reasonForBlacklist,                               String report)  Method Summary Methods  Modifier and Type Method and Description String getBlacklistReport() Gets a descriptive report about why the tasktracker was blacklisted. String getReasonForBlacklist() Gets the reason for which the tasktracker was blacklisted. String getTaskTrackerName() Gets the tasktracker's name. boolean isBlacklisted() Whether tracker is blacklisted void readFields(DataInput in) Deserialize the fields of this object from in. void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TaskTrackerInfo public TaskTrackerInfo() TaskTrackerInfo public TaskTrackerInfo(String name) TaskTrackerInfo public TaskTrackerInfo(String name,                String reasonForBlacklist,                String report) Method Detail getTaskTrackerName public String getTaskTrackerName() Gets the tasktracker's name. Returns:tracker's name. isBlacklisted public boolean isBlacklisted() Whether tracker is blacklisted Returns:true if tracker is blacklisted          false otherwise getReasonForBlacklist public String getReasonForBlacklist() Gets the reason for which the tasktracker was blacklisted. Returns:reason which tracker was blacklisted getBlacklistReport public String getBlacklistReport() Gets a descriptive report about why the tasktracker was blacklisted. Returns:report describing why the tasktracker was blacklisted. readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TaskType (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TaskType (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.mapreduce Enum TaskType java.lang.Object java.lang.Enum<TaskType> org.apache.hadoop.mapreduce.TaskType All Implemented Interfaces: Serializable, Comparable<TaskType> @InterfaceAudience.Public @InterfaceStability.Stable public enum TaskType extends Enum<TaskType> Enum for map, reduce, job-setup, job-cleanup, task-cleanup task types. Enum Constant Summary Enum Constants  Enum Constant and Description JOB_CLEANUP  JOB_SETUP  MAP  REDUCE  TASK_CLEANUP  Method Summary Methods  Modifier and Type Method and Description static TaskType valueOf(String name) Returns the enum constant of this type with the specified name. static TaskType[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail MAP public static final TaskType MAP REDUCE public static final TaskType REDUCE JOB_SETUP public static final TaskType JOB_SETUP JOB_CLEANUP public static final TaskType JOB_CLEANUP TASK_CLEANUP public static final TaskType TASK_CLEANUP Method Detail values public static TaskType[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (TaskType c : TaskType.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static TaskType valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Text (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Text (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class Text java.lang.Object org.apache.hadoop.io.BinaryComparable org.apache.hadoop.io.Text All Implemented Interfaces: Comparable<BinaryComparable>, Writable, WritableComparable<BinaryComparable> @Stringable @InterfaceAudience.Public @InterfaceStability.Stable public class Text extends BinaryComparable implements WritableComparable<BinaryComparable> This class stores text using standard UTF8 encoding.  It provides methods  to serialize, deserialize, and compare texts at byte level.  The type of  length is integer and is serialized using zero-compressed format.  In  addition, it provides methods for string traversal without converting the  byte array to a string.  Also includes utilities for  serializing/deserialing a string, coding/decoding a string, checking if a  byte array contains valid UTF8 code, calculating the length of an encoded  string. Field Summary Fields  Modifier and Type Field and Description static int DEFAULT_MAX_LEN  Constructor Summary Constructors  Constructor and Description Text()  Text(byte[] utf8) Construct from a byte array. Text(String string) Construct from a string. Text(Text utf8) Construct from another text. Method Summary Methods  Modifier and Type Method and Description void append(byte[] utf8,             int start,             int len) Append a range of bytes to the end of the given text static int bytesToCodePoint(ByteBuffer bytes) Returns the next code point at the current position in  the buffer. int charAt(int position) Returns the Unicode Scalar Value (32-bit integer value)  for the character at position. void clear() Clear the string to empty. byte[] copyBytes() Get a copy of the bytes that is exactly the length of the data. static String decode(byte[] utf8) Converts the provided byte array to a String using the  UTF-8 encoding. static String decode(byte[] utf8,             int start,             int length)  static String decode(byte[] utf8,             int start,             int length,             boolean replace) Converts the provided byte array to a String using the  UTF-8 encoding. static ByteBuffer encode(String string) Converts the provided String to bytes using the  UTF-8 encoding. static ByteBuffer encode(String string,             boolean replace) Converts the provided String to bytes using the  UTF-8 encoding. boolean equals(Object o) Returns true iff o is a Text with the same contents. int find(String what)  int find(String what,         int start) Finds any occurence of what in the backing  buffer, starting as position start. byte[] getBytes() Returns the raw bytes; however, only data up to getLength() is  valid. int getLength() Returns the number of bytes in the byte array int hashCode() Return a hash of the bytes returned from {#getBytes()}. void readFields(DataInput in) deserialize void readFields(DataInput in,                     int maxLength)  static String readString(DataInput in) Read a UTF8 encoded string from in static String readString(DataInput in,                     int maxLength) Read a UTF8 encoded string with a maximum size void readWithKnownLength(DataInput in,                                       int len) Read a Text object whose length is already known. void set(byte[] utf8) Set to a utf8 byte array void set(byte[] utf8,       int start,       int len) Set the Text to range of bytes void set(String string) Set to contain the contents of a string. void set(Text other) copy a text. static void skip(DataInput in) Skips over one Text in the input. String toString() Convert text back to string static int utf8Length(String string) For the given string, returns the number of UTF-8 bytes  required to encode the string. static void validateUTF8(byte[] utf8) Check if a byte array contains valid utf-8 static void validateUTF8(byte[] utf8,                         int start,                         int len) Check to see if a byte array is valid utf-8 void write(DataOutput out) serialize  write this object to out  length uses zero-compressed encoding void write(DataOutput out,           int maxLength)  static int writeString(DataOutput out,                       String s) Write a UTF8 encoded string to out static int writeString(DataOutput out,                       String s,                       int maxLength) Write a UTF8 encoded string with a maximum size to out Methods inherited from class org.apache.hadoop.io.BinaryComparable compareTo, compareTo Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Methods inherited from interface java.lang.Comparable compareTo Field Detail DEFAULT_MAX_LEN public static final int DEFAULT_MAX_LEN See Also:Constant Field Values Constructor Detail Text public Text() Text public Text(String string) Construct from a string. Text public Text(Text utf8) Construct from another text. Text public Text(byte[] utf8) Construct from a byte array. Method Detail copyBytes public byte[] copyBytes() Get a copy of the bytes that is exactly the length of the data.  See getBytes() for faster access to the underlying array. getBytes public byte[] getBytes() Returns the raw bytes; however, only data up to getLength() is  valid. Please use copyBytes() if you  need the returned array to be precisely the length of the data. Specified by: getBytes in class BinaryComparable getLength public int getLength() Returns the number of bytes in the byte array Specified by: getLength in class BinaryComparable charAt public int charAt(int position) Returns the Unicode Scalar Value (32-bit integer value)  for the character at position. Note that this  method avoids using the converter or doing String instantiation Returns:the Unicode scalar value at position or -1           if the position is invalid or points to a           trailing byte find public int find(String what) find public int find(String what,        int start) Finds any occurence of what in the backing  buffer, starting as position start. The starting  position is measured in bytes and the return value is in  terms of byte position in the buffer. The backing buffer is  not converted to a string for this operation. Returns:byte position of the first occurence of the search          string in the UTF-8 buffer or -1 if not found set public void set(String string) Set to contain the contents of a string. set public void set(byte[] utf8) Set to a utf8 byte array set public void set(Text other) copy a text. set public void set(byte[] utf8,        int start,        int len) Set the Text to range of bytes Parameters:utf8 - the data to copy fromstart - the first position of the new stringlen - the number of bytes of the new string append public void append(byte[] utf8,           int start,           int len) Append a range of bytes to the end of the given text Parameters:utf8 - the data to copy fromstart - the first position to append from utf8len - the number of bytes to append clear public void clear() Clear the string to empty.  Note: For performance reasons, this call does not clear the  underlying byte array that is retrievable via getBytes().  In order to free the byte-array memory, call set(byte[])  with an empty byte array (For example, new byte[0]). toString public String toString() Convert text back to string Overrides: toString in class Object See Also:Object.toString() readFields public void readFields(DataInput in)                 throws IOException deserialize Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException readFields public void readFields(DataInput in,               int maxLength)                 throws IOException Throws: IOException skip public static void skip(DataInput in)                  throws IOException Skips over one Text in the input. Throws: IOException readWithKnownLength public void readWithKnownLength(DataInput in,                        int len)                          throws IOException Read a Text object whose length is already known.  This allows creating Text from a stream which uses a different serialization  format. Throws: IOException write public void write(DataOutput out)            throws IOException serialize  write this object to out  length uses zero-compressed encoding Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOExceptionSee Also:Writable.write(DataOutput) write public void write(DataOutput out,          int maxLength)            throws IOException Throws: IOException equals public boolean equals(Object o) Returns true iff o is a Text with the same contents. Overrides: equals in class BinaryComparable hashCode public int hashCode() Description copied from class: BinaryComparable Return a hash of the bytes returned from {#getBytes()}. Overrides: hashCode in class BinaryComparable See Also:WritableComparator.hashBytes(byte[],int) decode public static String decode(byte[] utf8)                      throws CharacterCodingException Converts the provided byte array to a String using the  UTF-8 encoding. If the input is malformed,  replace by a default value. Throws: CharacterCodingException decode public static String decode(byte[] utf8,             int start,             int length)                      throws CharacterCodingException Throws: CharacterCodingException decode public static String decode(byte[] utf8,             int start,             int length,             boolean replace)                      throws CharacterCodingException Converts the provided byte array to a String using the  UTF-8 encoding. If replace is true, then  malformed input is replaced with the  substitution character, which is U+FFFD. Otherwise the  method throws a MalformedInputException. Throws: CharacterCodingException encode public static ByteBuffer encode(String string)                          throws CharacterCodingException Converts the provided String to bytes using the  UTF-8 encoding. If the input is malformed,  invalid chars are replaced by a default value. Returns:ByteBuffer: bytes stores at ByteBuffer.array()                       and length is ByteBuffer.limit() Throws: CharacterCodingException encode public static ByteBuffer encode(String string,                 boolean replace)                          throws CharacterCodingException Converts the provided String to bytes using the  UTF-8 encoding. If replace is true, then  malformed input is replaced with the  substitution character, which is U+FFFD. Otherwise the  method throws a MalformedInputException. Returns:ByteBuffer: bytes stores at ByteBuffer.array()                       and length is ByteBuffer.limit() Throws: CharacterCodingException readString public static String readString(DataInput in)                          throws IOException Read a UTF8 encoded string from in Throws: IOException readString public static String readString(DataInput in,                 int maxLength)                          throws IOException Read a UTF8 encoded string with a maximum size Throws: IOException writeString public static int writeString(DataOutput out,               String s)                        throws IOException Write a UTF8 encoded string to out Throws: IOException writeString public static int writeString(DataOutput out,               String s,               int maxLength)                        throws IOException Write a UTF8 encoded string with a maximum size to out Throws: IOException validateUTF8 public static void validateUTF8(byte[] utf8)                          throws MalformedInputException Check if a byte array contains valid utf-8 Parameters:utf8 - byte array Throws: MalformedInputException - if the byte array contains invalid utf-8 validateUTF8 public static void validateUTF8(byte[] utf8,                 int start,                 int len)                          throws MalformedInputException Check to see if a byte array is valid utf-8 Parameters:utf8 - the array of bytesstart - the offset of the first byte in the arraylen - the length of the byte sequence Throws: MalformedInputException - if the byte array contains invalid bytes bytesToCodePoint public static int bytesToCodePoint(ByteBuffer bytes) Returns the next code point at the current position in  the buffer. The buffer's position will be incremented.  Any mark set on this buffer will be changed by this method! utf8Length public static int utf8Length(String string) For the given string, returns the number of UTF-8 bytes  required to encode the string. Parameters:string - text to encode Returns:number of UTF-8 bytes required to encode Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TextInputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TextInputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.input Class TextInputFormat java.lang.Object org.apache.hadoop.mapreduce.InputFormat<K,V> org.apache.hadoop.mapreduce.lib.input.FileInputFormat<LongWritable,Text> org.apache.hadoop.mapreduce.lib.input.TextInputFormat @InterfaceAudience.Public @InterfaceStability.Stable public class TextInputFormat extends FileInputFormat<LongWritable,Text> An InputFormat for plain text files.  Files are broken into lines.  Either linefeed or carriage-return are used to signal end of line.  Keys are  the position in the file, and values are the line of text.. Field Summary Fields inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat DEFAULT_LIST_STATUS_NUM_THREADS, INPUT_DIR, INPUT_DIR_RECURSIVE, LIST_STATUS_NUM_THREADS, NUM_INPUT_FILES, PATHFILTER_CLASS, SPLIT_MAXSIZE, SPLIT_MINSIZE Constructor Summary Constructors  Constructor and Description TextInputFormat()  Method Summary Methods  Modifier and Type Method and Description RecordReader<LongWritable,Text> createRecordReader(InputSplit split,                                     TaskAttemptContext context) Create a record reader for a given split. protected boolean isSplitable(JobContext context,                       Path file) Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be. Methods inherited from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat addInputPath, addInputPathRecursively, addInputPaths, computeSplitSize, getBlockIndex, getFormatMinSplitSize, getInputDirRecursive, getInputPathFilter, getInputPaths, getMaxSplitSize, getMinSplitSize, getSplits, listStatus, makeSplit, makeSplit, setInputDirRecursive, setInputPathFilter, setInputPaths, setInputPaths, setMaxInputSplitSize, setMinInputSplitSize Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TextInputFormat public TextInputFormat() Method Detail createRecordReader public RecordReader<LongWritable,Text> createRecordReader(InputSplit split,                                                  TaskAttemptContext context) Description copied from class: InputFormat Create a record reader for a given split. The framework will call  RecordReader.initialize(InputSplit, TaskAttemptContext) before  the split is used. Specified by: createRecordReader in class InputFormat<LongWritable,Text> Parameters:split - the split to be readcontext - the information about the task Returns:a new record reader isSplitable protected boolean isSplitable(JobContext context,                   Path file) Description copied from class: FileInputFormat Is the given filename splitable? Usually, true, but if the file is  stream compressed, it will not be.    FileInputFormat implementations can override this and return  false to ensure that individual input files are never split-up  so that Mappers process entire files. Overrides: isSplitable in class FileInputFormat<LongWritable,Text> Parameters:context - the job contextfile - the file name to check Returns:is this file splitable? Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TextOutputFormat (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TextOutputFormat (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.output Class TextOutputFormat<K,V> java.lang.Object org.apache.hadoop.mapreduce.OutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat<K,V> org.apache.hadoop.mapreduce.lib.output.TextOutputFormat<K,V> @InterfaceAudience.Public @InterfaceStability.Stable public class TextOutputFormat<K,V> extends FileOutputFormat<K,V> An OutputFormat that writes plain text files. Field Summary Fields  Modifier and Type Field and Description static String SEPERATOR  Fields inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat BASE_OUTPUT_NAME, COMPRESS, COMPRESS_CODEC, COMPRESS_TYPE, OUTDIR, PART Constructor Summary Constructors  Constructor and Description TextOutputFormat()  Method Summary Methods  Modifier and Type Method and Description RecordWriter<K,V> getRecordWriter(TaskAttemptContext job) Get the RecordWriter for the given task. Methods inherited from class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat checkOutputSpecs, getCompressOutput, getDefaultWorkFile, getOutputCommitter, getOutputCompressorClass, getOutputName, getOutputPath, getPathForWorkFile, getUniqueFile, getWorkOutputPath, setCompressOutput, setOutputCompressorClass, setOutputName, setOutputPath Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail SEPERATOR public static String SEPERATOR Constructor Detail TextOutputFormat public TextOutputFormat() Method Detail getRecordWriter public RecordWriter<K,V> getRecordWriter(TaskAttemptContext job)                                   throws IOException,                                          InterruptedException Description copied from class: OutputFormat Get the RecordWriter for the given task. Specified by: getRecordWriter in class FileOutputFormat<K,V> Parameters:job - the information about the current task. Returns:a RecordWriter to write the output for the job. Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TextSplitter (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TextSplitter (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.db Class TextSplitter java.lang.Object org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter org.apache.hadoop.mapreduce.lib.db.TextSplitter All Implemented Interfaces: DBSplitter @InterfaceAudience.Public @InterfaceStability.Evolving public class TextSplitter extends BigDecimalSplitter Implement DBSplitter over text strings. Constructor Summary Constructors  Constructor and Description TextSplitter()  Method Summary Methods  Modifier and Type Method and Description List<InputSplit> split(Configuration conf,           ResultSet results,           String colName) This method needs to determine the splits between two user-provided strings. Methods inherited from class org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter tryDivide Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TextSplitter public TextSplitter() Method Detail split public List<InputSplit> split(Configuration conf,                      ResultSet results,                      String colName)                        throws SQLException This method needs to determine the splits between two user-provided strings.  In the case where the user's strings are 'A' and 'Z', this is not hard; we   could create two splits from ['A', 'M') and ['M', 'Z'], 26 splits for strings  beginning with each letter, etc.  If a user has provided us with the strings "Ham" and "Haze", however, we need  to create splits that differ in the third letter.  The algorithm used is as follows:  Since there are 2**16 unicode characters, we interpret characters as digits in  base 65536. Given a string 's' containing characters s_0, s_1 .. s_n, we interpret  the string as the number: 0.s_0 s_1 s_2.. s_n in base 65536. Having mapped the  low and high strings into floating-point values, we then use the BigDecimalSplitter  to establish the even split points, then map the resulting floating point values  back into strings. Specified by: split in interface DBSplitter Overrides: split in class BigDecimalSplitter Throws: SQLException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineClient (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineClient (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api Class TimelineClient java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.client.api.TimelineClient All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class TimelineClient extends AbstractService A client library that can be used to post some information in terms of a  number of conceptual entities. Constructor Summary Constructors  Modifier Constructor and Description protected  TimelineClient(String name)  Method Summary Methods  Modifier and Type Method and Description abstract void cancelDelegationToken(org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier> timelineDT)  Cancel a timeline delegation token. static TimelineClient createTimelineClient() Create a timeline client. abstract org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier> getDelegationToken(String renewer)  Get a delegation token so as to be able to talk to the timeline server in a  secure way. abstract void putDomain(TimelineDomain domain)  Send the information of a domain to the timeline server. abstract TimelinePutResponse putEntities(TimelineEntity... entities)  Send the information of a number of conceptual entities to the timeline  server. abstract long renewDelegationToken(org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier> timelineDT)  Renew a timeline delegation token. Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceInit, serviceStart, serviceStop, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail TimelineClient @InterfaceAudience.Private protected TimelineClient(String name) Method Detail createTimelineClient @InterfaceAudience.Public public static TimelineClient createTimelineClient() Create a timeline client. The current UGI when the user initialize the  client will be used to do the put and the delegation token operations. The  current user may use UserGroupInformation.doAs(java.security.PrivilegedAction<T>) another user to  construct and initialize a timeline client if the following operations are  supposed to be conducted by that user. Returns:a timeline client putEntities @InterfaceAudience.Public public abstract TimelinePutResponse putEntities(TimelineEntity... entities)                                          throws IOException,                                                 YarnException  Send the information of a number of conceptual entities to the timeline  server. It is a blocking API. The method will not return until it gets the  response from the timeline server.   Parameters:entities - the collection of TimelineEntity Returns:the error information if the sent entities are not correctly stored Throws: IOException YarnException putDomain @InterfaceAudience.Public public abstract void putDomain(TimelineDomain domain)                         throws IOException,                                YarnException  Send the information of a domain to the timeline server. It is a  blocking API. The method will not return until it gets the response from  the timeline server.   Parameters:domain - an TimelineDomain object Throws: IOException YarnException getDelegationToken @InterfaceAudience.Public public abstract org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier> getDelegationToken(String renewer)                                                                                                       throws IOException,                                                                                                              YarnException  Get a delegation token so as to be able to talk to the timeline server in a  secure way.   Parameters:renewer - Address of the renewer who can renew these tokens when needed by           securely talking to the timeline server Returns:a delegation token (Token) that can be used to talk to the          timeline server Throws: IOException YarnException renewDelegationToken @InterfaceAudience.Public public abstract long renewDelegationToken(org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier> timelineDT)                                    throws IOException,                                           YarnException  Renew a timeline delegation token.   Parameters:timelineDT - the delegation token to renew Returns:the new expiration time Throws: IOException YarnException cancelDelegationToken @InterfaceAudience.Public public abstract void cancelDelegationToken(org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier> timelineDT)                                     throws IOException,                                            YarnException  Cancel a timeline delegation token.   Parameters:timelineDT - the delegation token to cancel Throws: IOException YarnException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineDelegationTokenIdentifier (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineDelegationTokenIdentifier (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.client Class TimelineDelegationTokenIdentifier java.lang.Object org.apache.hadoop.security.token.TokenIdentifier org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineDelegationTokenIdentifier extends org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier Field Summary Fields  Modifier and Type Field and Description static Text KIND_NAME  Constructor Summary Constructors  Constructor and Description TimelineDelegationTokenIdentifier()  TimelineDelegationTokenIdentifier(Text owner,                                                                   Text renewer,                                                                   Text realUser) Create a new timeline delegation token identifier Method Summary Methods  Modifier and Type Method and Description Text getKind() Get the token kind Methods inherited from class org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier getProto, readFields, write Methods inherited from class org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier equals, getIssueDate, getMasterKeyId, getMaxDate, getOwner, getRealUser, getRenewer, getSequenceNumber, getUser, hashCode, isEqual, setIssueDate, setMasterKeyId, setMaxDate, setOwner, setRealUser, setRenewer, setSequenceNumber, toString Methods inherited from class org.apache.hadoop.security.token.TokenIdentifier getBytes, getTrackingId Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail KIND_NAME public static final Text KIND_NAME Constructor Detail TimelineDelegationTokenIdentifier public TimelineDelegationTokenIdentifier() TimelineDelegationTokenIdentifier public TimelineDelegationTokenIdentifier(Text owner,                                  Text renewer,                                  Text realUser) Create a new timeline delegation token identifier Parameters:owner - the effective username of the token ownerrenewer - the username of the renewerrealUser - the real username of the token owner Method Detail getKind public Text getKind() Description copied from class: org.apache.hadoop.security.token.TokenIdentifier Get the token kind Specified by: getKind in class org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier Returns:the kind of the token Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineDelegationTokenResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineDelegationTokenResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelineDelegationTokenResponse java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelineDelegationTokenResponse @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineDelegationTokenResponse extends Object The response of delegation token related request Constructor Summary Constructors  Constructor and Description TimelineDelegationTokenResponse()  Method Summary Methods  Modifier and Type Method and Description Object getContent()  String getType()  void setContent(Object content)  void setType(String type)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineDelegationTokenResponse public TimelineDelegationTokenResponse() Method Detail getType public String getType() setType public void setType(String type) getContent public Object getContent() setContent public void setContent(Object content) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineDelegationTokenSelector (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineDelegationTokenSelector (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.security.client Class TimelineDelegationTokenSelector java.lang.Object org.apache.hadoop.yarn.security.client.TimelineDelegationTokenSelector All Implemented Interfaces: org.apache.hadoop.security.token.TokenSelector<TimelineDelegationTokenIdentifier> @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineDelegationTokenSelector extends Object implements org.apache.hadoop.security.token.TokenSelector<TimelineDelegationTokenIdentifier> Constructor Summary Constructors  Constructor and Description TimelineDelegationTokenSelector()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier> selectToken(Text service,                       Collection<org.apache.hadoop.security.token.Token<? extends org.apache.hadoop.security.token.TokenIdentifier>> tokens)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineDelegationTokenSelector public TimelineDelegationTokenSelector() Method Detail selectToken public org.apache.hadoop.security.token.Token<TimelineDelegationTokenIdentifier> selectToken(Text service,                                                                                     Collection<org.apache.hadoop.security.token.Token<? extends org.apache.hadoop.security.token.TokenIdentifier>> tokens) Specified by: selectToken in interface org.apache.hadoop.security.token.TokenSelector<TimelineDelegationTokenIdentifier> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineDomain (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineDomain (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelineDomain java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelineDomain @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineDomain extends Object  This class contains the information about a timeline domain, which is used  to a user to host a number of timeline entities, isolating them from others'.  The user can also define the reader and writer users/groups for the the  domain, which is used to control the access to its entities.        The reader and writer users/groups pattern that the user can supply is the  same as what AccessControlList takes.   Constructor Summary Constructors  Constructor and Description TimelineDomain()  Method Summary Methods  Modifier and Type Method and Description Long getCreatedTime() Get the created time of the domain String getDescription() Get the domain description String getId() Get the domain ID Long getModifiedTime() Get the modified time of the domain String getOwner() Get the domain owner String getReaders() Get the reader (and/or reader group) list string String getWriters() Get the writer (and/or writer group) list string void setCreatedTime(Long createdTime) Set the created time of the domain void setDescription(String description) Set the domain description void setId(String id) Set the domain ID void setModifiedTime(Long modifiedTime) Set the modified time of the domain void setOwner(String owner) Set the domain owner. void setReaders(String readers) Set the reader (and/or reader group) list string void setWriters(String writers) Set the writer (and/or writer group) list string Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineDomain public TimelineDomain() Method Detail getId public String getId() Get the domain ID Returns:the domain ID setId public void setId(String id) Set the domain ID Parameters:id - the domain ID getDescription public String getDescription() Get the domain description Returns:the domain description setDescription public void setDescription(String description) Set the domain description Parameters:description - the domain description getOwner public String getOwner() Get the domain owner Returns:the domain owner setOwner public void setOwner(String owner) Set the domain owner. The user doesn't need to set it, which will  automatically set to the user who puts the domain. Parameters:owner - the domain owner getReaders public String getReaders() Get the reader (and/or reader group) list string Returns:the reader (and/or reader group) list string setReaders public void setReaders(String readers) Set the reader (and/or reader group) list string Parameters:readers - the reader (and/or reader group) list string getWriters public String getWriters() Get the writer (and/or writer group) list string Returns:the writer (and/or writer group) list string setWriters public void setWriters(String writers) Set the writer (and/or writer group) list string Parameters:writers - the writer (and/or writer group) list string getCreatedTime public Long getCreatedTime() Get the created time of the domain Returns:the created time of the domain setCreatedTime public void setCreatedTime(Long createdTime) Set the created time of the domain Parameters:createdTime - the created time of the domain getModifiedTime public Long getModifiedTime() Get the modified time of the domain Returns:the modified time of the domain setModifiedTime public void setModifiedTime(Long modifiedTime) Set the modified time of the domain Parameters:modifiedTime - the modified time of the domain Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineDomains (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineDomains (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelineDomains java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelineDomains @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineDomains extends Object The class that hosts a list of timeline domains. Constructor Summary Constructors  Constructor and Description TimelineDomains()  Method Summary Methods  Modifier and Type Method and Description void addDomain(TimelineDomain domain) Add a single domain into the existing domain list void addDomains(List<TimelineDomain> domains) All a list of domains into the existing domain list List<TimelineDomain> getDomains() Get a list of domains void setDomains(List<TimelineDomain> domains) Set the domain list to the given list of domains Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineDomains public TimelineDomains() Method Detail getDomains public List<TimelineDomain> getDomains() Get a list of domains Returns:a list of domains addDomain public void addDomain(TimelineDomain domain) Add a single domain into the existing domain list Parameters:domain - a single domain addDomains public void addDomains(List<TimelineDomain> domains) All a list of domains into the existing domain list Parameters:domains - a list of domains setDomains public void setDomains(List<TimelineDomain> domains) Set the domain list to the given list of domains Parameters:domains - a list of domains Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineEntities (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineEntities (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelineEntities java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelineEntities @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineEntities extends Object The class that hosts a list of timeline entities. Constructor Summary Constructors  Constructor and Description TimelineEntities()  Method Summary Methods  Modifier and Type Method and Description void addEntities(List<TimelineEntity> entities) All a list of entities into the existing entity list void addEntity(TimelineEntity entity) Add a single entity into the existing entity list List<TimelineEntity> getEntities() Get a list of entities void setEntities(List<TimelineEntity> entities) Set the entity list to the given list of entities Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineEntities public TimelineEntities() Method Detail getEntities public List<TimelineEntity> getEntities() Get a list of entities Returns:a list of entities addEntity public void addEntity(TimelineEntity entity) Add a single entity into the existing entity list Parameters:entity - a single entity addEntities public void addEntities(List<TimelineEntity> entities) All a list of entities into the existing entity list Parameters:entities - a list of entities setEntities public void setEntities(List<TimelineEntity> entities) Set the entity list to the given list of entities Parameters:entities - a list of entities Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineEntity (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineEntity (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelineEntity java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelineEntity All Implemented Interfaces: Comparable<TimelineEntity> @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineEntity extends Object implements Comparable<TimelineEntity>  The class that contains the the meta information of some conceptual entity  and its related events. The entity can be an application, an application  attempt, a container or whatever the user-defined object.        Primary filters will be used to index the entities in  TimelineStore, such that users should carefully choose the  information they want to store as the primary filters. The remaining can be  stored as other information.   Constructor Summary Constructors  Constructor and Description TimelineEntity()  Method Summary Methods  Modifier and Type Method and Description void addEvent(TimelineEvent event) Add a single event related to the entity to the existing event list void addEvents(List<TimelineEvent> events) Add a list of events related to the entity to the existing event list void addOtherInfo(Map<String,Object> otherInfo) Add a map of other information of the entity to the existing other info map void addOtherInfo(String key,                         Object value) Add one piece of other information of the entity to the existing other info  map void addPrimaryFilter(String key,                                 Object value) Add a single piece of primary filter to the existing primary filter map void addPrimaryFilters(Map<String,Set<Object>> primaryFilters) Add a map of primary filters to the existing primary filter map void addRelatedEntities(Map<String,Set<String>> relatedEntities) Add a map of related entities to the existing related entity map void addRelatedEntity(String entityType,                                 String entityId) Add an entity to the existing related entity map int compareTo(TimelineEntity other)  boolean equals(Object obj)  String getDomainId() Get the ID of the domain that the entity is to be put String getEntityId() Get the entity Id String getEntityType() Get the entity type List<TimelineEvent> getEvents() Get a list of events related to the entity Map<String,Object> getOtherInfo() Get the other information of the entity Map<String,Set<Object>> getPrimaryFilters() Get the primary filters Map<String,Set<String>> getRelatedEntities() Get the related entities Long getStartTime() Get the start time of the entity int hashCode()  void setDomainId(String domainId) Set the ID of the domain that the entity is to be put void setEntityId(String entityId) Set the entity Id void setEntityType(String entityType) Set the entity type void setEvents(List<TimelineEvent> events) Set the event list to the given list of events related to the entity void setOtherInfo(Map<String,Object> otherInfo) Set the other info map to the given map of other information void setPrimaryFilters(Map<String,Set<Object>> primaryFilters) Set the primary filter map to the given map of primary filters void setRelatedEntities(Map<String,Set<String>> relatedEntities) Set the related entity map to the given map of related entities void setStartTime(Long startTime) Set the start time of the entity Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineEntity public TimelineEntity() Method Detail getEntityType public String getEntityType() Get the entity type Returns:the entity type setEntityType public void setEntityType(String entityType) Set the entity type Parameters:entityType - the entity type getEntityId public String getEntityId() Get the entity Id Returns:the entity Id setEntityId public void setEntityId(String entityId) Set the entity Id Parameters:entityId - the entity Id getStartTime public Long getStartTime() Get the start time of the entity Returns:the start time of the entity setStartTime public void setStartTime(Long startTime) Set the start time of the entity Parameters:startTime - the start time of the entity getEvents public List<TimelineEvent> getEvents() Get a list of events related to the entity Returns:a list of events related to the entity addEvent public void addEvent(TimelineEvent event) Add a single event related to the entity to the existing event list Parameters:event - a single event related to the entity addEvents public void addEvents(List<TimelineEvent> events) Add a list of events related to the entity to the existing event list Parameters:events - a list of events related to the entity setEvents public void setEvents(List<TimelineEvent> events) Set the event list to the given list of events related to the entity Parameters:events - events a list of events related to the entity getRelatedEntities public Map<String,Set<String>> getRelatedEntities() Get the related entities Returns:the related entities addRelatedEntity public void addRelatedEntity(String entityType,                     String entityId) Add an entity to the existing related entity map Parameters:entityType - the entity typeentityId - the entity Id addRelatedEntities public void addRelatedEntities(Map<String,Set<String>> relatedEntities) Add a map of related entities to the existing related entity map Parameters:relatedEntities - a map of related entities setRelatedEntities public void setRelatedEntities(Map<String,Set<String>> relatedEntities) Set the related entity map to the given map of related entities Parameters:relatedEntities - a map of related entities getPrimaryFilters public Map<String,Set<Object>> getPrimaryFilters() Get the primary filters Returns:the primary filters addPrimaryFilter public void addPrimaryFilter(String key,                     Object value) Add a single piece of primary filter to the existing primary filter map Parameters:key - the primary filter keyvalue - the primary filter value addPrimaryFilters public void addPrimaryFilters(Map<String,Set<Object>> primaryFilters) Add a map of primary filters to the existing primary filter map Parameters:primaryFilters - a map of primary filters setPrimaryFilters public void setPrimaryFilters(Map<String,Set<Object>> primaryFilters) Set the primary filter map to the given map of primary filters Parameters:primaryFilters - a map of primary filters getOtherInfo public Map<String,Object> getOtherInfo() Get the other information of the entity Returns:the other information of the entity addOtherInfo public void addOtherInfo(String key,                 Object value) Add one piece of other information of the entity to the existing other info  map Parameters:key - the other information keyvalue - the other information value addOtherInfo public void addOtherInfo(Map<String,Object> otherInfo) Add a map of other information of the entity to the existing other info map Parameters:otherInfo - a map of other information setOtherInfo public void setOtherInfo(Map<String,Object> otherInfo) Set the other info map to the given map of other information Parameters:otherInfo - a map of other information getDomainId public String getDomainId() Get the ID of the domain that the entity is to be put Returns:the domain ID setDomainId public void setDomainId(String domainId) Set the ID of the domain that the entity is to be put Parameters:domainId - the name space ID hashCode public int hashCode() Overrides: hashCode in class Object equals public boolean equals(Object obj) Overrides: equals in class Object compareTo public int compareTo(TimelineEntity other) Specified by: compareTo in interface Comparable<TimelineEntity> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineEvent (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineEvent (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelineEvent java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelineEvent All Implemented Interfaces: Comparable<TimelineEvent> @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineEvent extends Object implements Comparable<TimelineEvent> The class that contains the information of an event that is related to some  conceptual entity of an application. Users are free to define what the event  means, such as starting an application, getting allocated a container and  etc. Constructor Summary Constructors  Constructor and Description TimelineEvent()  Method Summary Methods  Modifier and Type Method and Description void addEventInfo(Map<String,Object> eventInfo) Add a map of the information of the event to the existing information map void addEventInfo(String key,                         Object value) Add one piece of the information of the event to the existing information  map int compareTo(TimelineEvent other)  boolean equals(Object o)  Map<String,Object> getEventInfo() Set the information of the event String getEventType() Get the event type long getTimestamp() Get the timestamp of the event int hashCode()  void setEventInfo(Map<String,Object> eventInfo) Set the information map to the given map of the information of the event void setEventType(String eventType) Set the event type void setTimestamp(long timestamp) Set the timestamp of the event Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineEvent public TimelineEvent() Method Detail getTimestamp public long getTimestamp() Get the timestamp of the event Returns:the timestamp of the event setTimestamp public void setTimestamp(long timestamp) Set the timestamp of the event Parameters:timestamp - the timestamp of the event getEventType public String getEventType() Get the event type Returns:the event type setEventType public void setEventType(String eventType) Set the event type Parameters:eventType - the event type getEventInfo public Map<String,Object> getEventInfo() Set the information of the event Returns:the information of the event addEventInfo public void addEventInfo(String key,                 Object value) Add one piece of the information of the event to the existing information  map Parameters:key - the information keyvalue - the information value addEventInfo public void addEventInfo(Map<String,Object> eventInfo) Add a map of the information of the event to the existing information map Parameters:eventInfo - a map of of the information of the event setEventInfo public void setEventInfo(Map<String,Object> eventInfo) Set the information map to the given map of the information of the event Parameters:eventInfo - a map of of the information of the event compareTo public int compareTo(TimelineEvent other) Specified by: compareTo in interface Comparable<TimelineEvent> equals public boolean equals(Object o) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineEvents.EventsOfOneEntity (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineEvents.EventsOfOneEntity (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelineEvents.EventsOfOneEntity java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelineEvents.EventsOfOneEntity Enclosing class: TimelineEvents @InterfaceAudience.Public @InterfaceStability.Evolving public static class TimelineEvents.EventsOfOneEntity extends Object The class that hosts a list of events that are only related to one entity. Constructor Summary Constructors  Constructor and Description TimelineEvents.EventsOfOneEntity()  Method Summary Methods  Modifier and Type Method and Description void addEvent(TimelineEvent event) Add a single event to the existing event list void addEvents(List<TimelineEvent> events) Add a list of event to the existing event list String getEntityId() Get the entity Id String getEntityType() Get the entity type List<TimelineEvent> getEvents() Get a list of events void setEntityId(String entityId) Set the entity Id void setEntityType(String entityType) Set the entity type void setEvents(List<TimelineEvent> events) Set the event list to the given list of events Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineEvents.EventsOfOneEntity public TimelineEvents.EventsOfOneEntity() Method Detail getEntityId public String getEntityId() Get the entity Id Returns:the entity Id setEntityId public void setEntityId(String entityId) Set the entity Id Parameters:entityId - the entity Id getEntityType public String getEntityType() Get the entity type Returns:the entity type setEntityType public void setEntityType(String entityType) Set the entity type Parameters:entityType - the entity type getEvents public List<TimelineEvent> getEvents() Get a list of events Returns:a list of events addEvent public void addEvent(TimelineEvent event) Add a single event to the existing event list Parameters:event - a single event addEvents public void addEvents(List<TimelineEvent> events) Add a list of event to the existing event list Parameters:events - a list of events setEvents public void setEvents(List<TimelineEvent> events) Set the event list to the given list of events Parameters:events - a list of events Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineEvents (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineEvents (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelineEvents java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelineEvents @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineEvents extends Object The class that hosts a list of events, which are categorized according to  their related entities. Nested Class Summary Nested Classes  Modifier and Type Class and Description static class  TimelineEvents.EventsOfOneEntity The class that hosts a list of events that are only related to one entity. Constructor Summary Constructors  Constructor and Description TimelineEvents()  Method Summary Methods  Modifier and Type Method and Description void addEvent(TimelineEvents.EventsOfOneEntity eventsOfOneEntity) Add a single TimelineEvents.EventsOfOneEntity instance into the existing list void addEvents(List<TimelineEvents.EventsOfOneEntity> allEvents) Add a list of TimelineEvents.EventsOfOneEntity instances into the existing list List<TimelineEvents.EventsOfOneEntity> getAllEvents() Get a list of TimelineEvents.EventsOfOneEntity instances void setEvents(List<TimelineEvents.EventsOfOneEntity> allEvents) Set the list to the given list of TimelineEvents.EventsOfOneEntity instances Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineEvents public TimelineEvents() Method Detail getAllEvents public List<TimelineEvents.EventsOfOneEntity> getAllEvents() Get a list of TimelineEvents.EventsOfOneEntity instances Returns:a list of TimelineEvents.EventsOfOneEntity instances addEvent public void addEvent(TimelineEvents.EventsOfOneEntity eventsOfOneEntity) Add a single TimelineEvents.EventsOfOneEntity instance into the existing list Parameters:eventsOfOneEntity - a single TimelineEvents.EventsOfOneEntity instance addEvents public void addEvents(List<TimelineEvents.EventsOfOneEntity> allEvents) Add a list of TimelineEvents.EventsOfOneEntity instances into the existing list Parameters:allEvents - a list of TimelineEvents.EventsOfOneEntity instances setEvents public void setEvents(List<TimelineEvents.EventsOfOneEntity> allEvents) Set the list to the given list of TimelineEvents.EventsOfOneEntity instances Parameters:allEvents - a list of TimelineEvents.EventsOfOneEntity instances Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelinePutResponse.TimelinePutError (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelinePutResponse.TimelinePutError (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelinePutResponse.TimelinePutError java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse.TimelinePutError Enclosing class: TimelinePutResponse @InterfaceAudience.Public @InterfaceStability.Evolving public static class TimelinePutResponse.TimelinePutError extends Object A class that holds the error code for one entity. Field Summary Fields  Modifier and Type Field and Description static int ACCESS_DENIED Error code returned if the user is denied to access the timeline data static int FORBIDDEN_RELATION Error code returned if the user is denied to relate the entity to another  one in different domain static int IO_EXCEPTION Error code returned if an IOException is encountered when putting an  entity. static int NO_DOMAIN Error code returned if the entity doesn't have an valid domain ID static int NO_START_TIME Error code returned when no start time can be found when putting an  entity. static int SYSTEM_FILTER_CONFLICT Error code returned if the user specifies the timeline system reserved  filter key Constructor Summary Constructors  Constructor and Description TimelinePutResponse.TimelinePutError()  Method Summary Methods  Modifier and Type Method and Description String getEntityId() Get the entity Id String getEntityType() Get the entity type int getErrorCode() Get the error code void setEntityId(String entityId) Set the entity Id void setEntityType(String entityType) Set the entity type void setErrorCode(int errorCode) Set the error code to the given error code Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail NO_START_TIME public static final int NO_START_TIME Error code returned when no start time can be found when putting an  entity. This occurs when the entity does not already exist in the store  and it is put with no start time or events specified. See Also:Constant Field Values IO_EXCEPTION public static final int IO_EXCEPTION Error code returned if an IOException is encountered when putting an  entity. See Also:Constant Field Values SYSTEM_FILTER_CONFLICT public static final int SYSTEM_FILTER_CONFLICT Error code returned if the user specifies the timeline system reserved  filter key See Also:Constant Field Values ACCESS_DENIED public static final int ACCESS_DENIED Error code returned if the user is denied to access the timeline data See Also:Constant Field Values NO_DOMAIN public static final int NO_DOMAIN Error code returned if the entity doesn't have an valid domain ID See Also:Constant Field Values FORBIDDEN_RELATION public static final int FORBIDDEN_RELATION Error code returned if the user is denied to relate the entity to another  one in different domain See Also:Constant Field Values Constructor Detail TimelinePutResponse.TimelinePutError public TimelinePutResponse.TimelinePutError() Method Detail getEntityId public String getEntityId() Get the entity Id Returns:the entity Id setEntityId public void setEntityId(String entityId) Set the entity Id Parameters:entityId - the entity Id getEntityType public String getEntityType() Get the entity type Returns:the entity type setEntityType public void setEntityType(String entityType) Set the entity type Parameters:entityType - the entity type getErrorCode public int getErrorCode() Get the error code Returns:an error code setErrorCode public void setErrorCode(int errorCode) Set the error code to the given error code Parameters:errorCode - an error code Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelinePutResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelinePutResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records.timeline Class TimelinePutResponse java.lang.Object org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelinePutResponse extends Object A class that holds a list of put errors. This is the response returned when a  list of TimelineEntity objects is added to the timeline. If there are errors  in storing individual entity objects, they will be indicated in the list of  errors. Nested Class Summary Nested Classes  Modifier and Type Class and Description static class  TimelinePutResponse.TimelinePutError A class that holds the error code for one entity. Constructor Summary Constructors  Constructor and Description TimelinePutResponse()  Method Summary Methods  Modifier and Type Method and Description void addError(TimelinePutResponse.TimelinePutError error) Add a single TimelinePutResponse.TimelinePutError instance into the existing list void addErrors(List<TimelinePutResponse.TimelinePutError> errors) Add a list of TimelinePutResponse.TimelinePutError instances into the existing list List<TimelinePutResponse.TimelinePutError> getErrors() Get a list of TimelinePutResponse.TimelinePutError instances void setErrors(List<TimelinePutResponse.TimelinePutError> errors) Set the list to the given list of TimelinePutResponse.TimelinePutError instances Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelinePutResponse public TimelinePutResponse() Method Detail getErrors public List<TimelinePutResponse.TimelinePutError> getErrors() Get a list of TimelinePutResponse.TimelinePutError instances Returns:a list of TimelinePutResponse.TimelinePutError instances addError public void addError(TimelinePutResponse.TimelinePutError error) Add a single TimelinePutResponse.TimelinePutError instance into the existing list Parameters:error - a single TimelinePutResponse.TimelinePutError instance addErrors public void addErrors(List<TimelinePutResponse.TimelinePutError> errors) Add a list of TimelinePutResponse.TimelinePutError instances into the existing list Parameters:errors - a list of TimelinePutResponse.TimelinePutError instances setErrors public void setErrors(List<TimelinePutResponse.TimelinePutError> errors) Set the list to the given list of TimelinePutResponse.TimelinePutError instances Parameters:errors - a list of TimelinePutResponse.TimelinePutError instances Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TimelineUtils (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TimelineUtils (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.util.timeline Class TimelineUtils java.lang.Object org.apache.hadoop.yarn.util.timeline.TimelineUtils @InterfaceAudience.Public @InterfaceStability.Evolving public class TimelineUtils extends Object The helper class for the timeline module. Constructor Summary Constructors  Constructor and Description TimelineUtils()  Method Summary Methods  Modifier and Type Method and Description static Text buildTimelineTokenService(Configuration conf)  static String dumpTimelineRecordtoJSON(Object o) Serialize a POJO object into a JSON string not in a pretty format static String dumpTimelineRecordtoJSON(Object o,                                                 boolean pretty) Serialize a POJO object into a JSON string static InetSocketAddress getTimelineTokenServiceAddress(Configuration conf)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TimelineUtils public TimelineUtils() Method Detail dumpTimelineRecordtoJSON public static String dumpTimelineRecordtoJSON(Object o)                                        throws org.codehaus.jackson.JsonGenerationException,                                               org.codehaus.jackson.map.JsonMappingException,                                               IOException Serialize a POJO object into a JSON string not in a pretty format Parameters:o - an object to serialize Returns:a JSON string Throws: IOException org.codehaus.jackson.map.JsonMappingException org.codehaus.jackson.JsonGenerationException dumpTimelineRecordtoJSON public static String dumpTimelineRecordtoJSON(Object o,                               boolean pretty)                                        throws org.codehaus.jackson.JsonGenerationException,                                               org.codehaus.jackson.map.JsonMappingException,                                               IOException Serialize a POJO object into a JSON string Parameters:o - an object to serializepretty - whether in a pretty format or not Returns:a JSON string Throws: IOException org.codehaus.jackson.map.JsonMappingException org.codehaus.jackson.JsonGenerationException getTimelineTokenServiceAddress public static InetSocketAddress getTimelineTokenServiceAddress(Configuration conf) buildTimelineTokenService public static Text buildTimelineTokenService(Configuration conf) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Token (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Token (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class Token java.lang.Object org.apache.hadoop.yarn.api.records.Token @InterfaceAudience.Public @InterfaceStability.Stable public abstract class Token extends Object Token is the security entity used by the framework  to verify authenticity of any resource. Constructor Summary Constructors  Constructor and Description Token()  Method Summary Methods  Modifier and Type Method and Description abstract ByteBuffer getIdentifier() Get the token identifier. abstract String getKind() Get the token kind. abstract ByteBuffer getPassword() Get the token password abstract String getService() Get the service to which the token is allocated. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Token public Token() Method Detail getIdentifier @InterfaceAudience.Public @InterfaceStability.Stable public abstract ByteBuffer getIdentifier() Get the token identifier. Returns:token identifier getPassword @InterfaceAudience.Public @InterfaceStability.Stable public abstract ByteBuffer getPassword() Get the token password Returns:token password getKind @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getKind() Get the token kind. Returns:token kind getService @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getService() Get the service to which the token is allocated. Returns:service to which the token is allocated Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TokenCache (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TokenCache (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.security Class TokenCache java.lang.Object org.apache.hadoop.mapreduce.security.TokenCache @InterfaceAudience.Public @InterfaceStability.Evolving public class TokenCache extends Object This class provides user facing APIs for transferring secrets from  the job client to the tasks.  The secrets can be stored just before submission of jobs and read during  the task execution. Constructor Summary Constructors  Constructor and Description TokenCache()  Method Summary Methods  Modifier and Type Method and Description static void cleanUpTokenReferral(Configuration conf) Remove jobtoken referrals which don't make sense in the context  of the task execution. static byte[] getSecretKey(org.apache.hadoop.security.Credentials credentials,                         Text alias) auxiliary method to get user's secret keys.. static void obtainTokensForNamenodes(org.apache.hadoop.security.Credentials credentials,                                                 Path[] ps,                                                 Configuration conf) Convenience method to obtain delegation tokens from namenodes   corresponding to the paths passed. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TokenCache public TokenCache() Method Detail getSecretKey public static byte[] getSecretKey(org.apache.hadoop.security.Credentials credentials,                   Text alias) auxiliary method to get user's secret keys.. Parameters:alias -  Returns:secret key from the storage obtainTokensForNamenodes public static void obtainTokensForNamenodes(org.apache.hadoop.security.Credentials credentials,                             Path[] ps,                             Configuration conf)                                      throws IOException Convenience method to obtain delegation tokens from namenodes   corresponding to the paths passed. Parameters:credentials - ps - array of pathsconf - configuration Throws: IOException cleanUpTokenReferral public static void cleanUpTokenReferral(Configuration conf) Remove jobtoken referrals which don't make sense in the context  of the task execution. Parameters:conf -  Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TokenCountMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TokenCountMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapred.lib Class TokenCountMapper<K> java.lang.Object org.apache.hadoop.mapred.MapReduceBase org.apache.hadoop.mapred.lib.TokenCountMapper<K> All Implemented Interfaces: Closeable, AutoCloseable, JobConfigurable, Mapper<K,Text,Text,LongWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class TokenCountMapper<K> extends MapReduceBase implements Mapper<K,Text,Text,LongWritable> A Mapper that maps text values into <token,freq> pairs.  Uses  StringTokenizer to break text into tokens. Constructor Summary Constructors  Constructor and Description TokenCountMapper()  Method Summary Methods  Modifier and Type Method and Description void map(K key,       Text value,       OutputCollector<Text,LongWritable> output,       Reporter reporter) Maps a single input key/value pair into an intermediate key/value pair. Methods inherited from class org.apache.hadoop.mapred.MapReduceBase close, configure Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.mapred.JobConfigurable configure Methods inherited from interface java.io.Closeable close Constructor Detail TokenCountMapper public TokenCountMapper() Method Detail map public void map(K key,        Text value,        OutputCollector<Text,LongWritable> output,        Reporter reporter)          throws IOException Description copied from interface: Mapper Maps a single input key/value pair into an intermediate key/value pair.    Output pairs need not be of the same types as input pairs.  A given   input pair may map to zero or many output pairs.  Output pairs are   collected with calls to   OutputCollector.collect(Object,Object).  Applications can use the Reporter provided to report progress   or just indicate that they are alive. In scenarios where the application   takes significant amount of time to process individual key/value  pairs, this is crucial since the framework might assume that the task has   timed-out and kill that task. The other way of avoiding this is to set     mapreduce.task.timeout to a high-enough value (or even zero for no   time-outs). Specified by: map in interface Mapper<K,Text,Text,LongWritable> Parameters:key - the input key.value - the input value.output - collects mapped keys and values.reporter - facility to report progress. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TokenCounterMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TokenCounterMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.map Class TokenCounterMapper java.lang.Object org.apache.hadoop.mapreduce.Mapper<Object,Text,Text,IntWritable> org.apache.hadoop.mapreduce.lib.map.TokenCounterMapper @InterfaceAudience.Public @InterfaceStability.Stable public class TokenCounterMapper extends Mapper<Object,Text,Text,IntWritable> Tokenize the input values and emit each word with a count of 1. Constructor Summary Constructors  Constructor and Description TokenCounterMapper()  Method Summary Methods  Modifier and Type Method and Description void map(Object key,       Text value,       org.apache.hadoop.mapreduce.Mapper.Context context) Called once for each key/value pair in the input split. Methods inherited from class org.apache.hadoop.mapreduce.Mapper cleanup, run, setup Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TokenCounterMapper public TokenCounterMapper() Method Detail map public void map(Object key,        Text value,        org.apache.hadoop.mapreduce.Mapper.Context context)          throws IOException,                 InterruptedException Description copied from class: Mapper Called once for each key/value pair in the input split. Most applications  should override this, but the default is the identity function. Overrides: map in class Mapper<Object,Text,Text,IntWritable> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TokenMgrError (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TokenMgrError (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.compiler.generated Class TokenMgrError java.lang.Object java.lang.Throwable java.lang.Error org.apache.hadoop.record.compiler.generated.TokenMgrError All Implemented Interfaces: Serializable Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class TokenMgrError extends Error See Also:Serialized Form Constructor Summary Constructors  Constructor and Description TokenMgrError() Deprecated.    TokenMgrError(boolean EOFSeen,                           int lexState,                           int errorLine,                           int errorColumn,                           String errorAfter,                           char curChar,                           int reason) Deprecated.    TokenMgrError(String message,                           int reason) Deprecated.    Method Summary Methods  Modifier and Type Method and Description protected static String addEscapes(String str) Deprecated.  Replaces unprintable characters by their espaced (or unicode escaped)  equivalents in the given string String getMessage() Deprecated.  You can also modify the body of this method to customize your error messages. protected static String LexicalError(boolean EOFSeen,                         int lexState,                         int errorLine,                         int errorColumn,                         String errorAfter,                         char curChar) Deprecated.  Returns a detailed message for the Error when it is thrown by the  token manager to indicate a lexical error. Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail TokenMgrError public TokenMgrError() Deprecated.  TokenMgrError public TokenMgrError(String message,              int reason) Deprecated.  TokenMgrError public TokenMgrError(boolean EOFSeen,              int lexState,              int errorLine,              int errorColumn,              String errorAfter,              char curChar,              int reason) Deprecated.  Method Detail addEscapes protected static final String addEscapes(String str) Deprecated.  Replaces unprintable characters by their espaced (or unicode escaped)  equivalents in the given string LexicalError protected static String LexicalError(boolean EOFSeen,                   int lexState,                   int errorLine,                   int errorColumn,                   String errorAfter,                   char curChar) Deprecated.  Returns a detailed message for the Error when it is thrown by the  token manager to indicate a lexical error.  Parameters :      EOFSeen     : indicates if EOF caused the lexicl error     curLexState : lexical state in which this error occured     errorLine   : line number when the error occured     errorColumn : column number when the error occured     errorAfter  : prefix that was seen before this error occured     curchar     : the offending character  Note: You can customize the lexical error message by modifying this method. getMessage public String getMessage() Deprecated.  You can also modify the body of this method to customize your error messages.  For example, cases like LOOP_DETECTED and INVALID_LEXICAL_STATE are not  of end-users concern, so you can return something like :       "Internal Error : Please file a bug report .... "  from this method for such cases in the release version of your parser. Overrides: getMessage in class Throwable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Tool (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Tool (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util Interface Tool All Superinterfaces: Configurable All Known Implementing Classes: CLI, DistCp, InputSampler, InputSampler, JobClient, LogsCLI, MigrationTool, Submitter, WasbFsck @InterfaceAudience.Public @InterfaceStability.Stable public interface Tool extends Configurable A tool interface that supports handling of generic command-line options.    Tool, is the standard for any Map-Reduce tool/application.   The tool/application should delegate the handling of     standard command-line options to ToolRunner.run(Tool, String[])   and only handle its custom arguments.    Here is how a typical Tool is implemented:        public class MyApp extends Configured implements Tool {              public int run(String[] args) throws Exception {          // Configuration processed by ToolRunner          Configuration conf = getConf();                    // Create a JobConf using the processed conf          JobConf job = new JobConf(conf, MyApp.class);                    // Process custom command-line options          Path in = new Path(args[1]);          Path out = new Path(args[2]);                    // Specify various job-specific parameters               job.setJobName("my-app");          job.setInputPath(in);          job.setOutputPath(out);          job.setMapperClass(MyMapper.class);          job.setReducerClass(MyReducer.class);          // Submit the job, then poll for progress until the job is complete          JobClient.runJob(job);          return 0;        }                public static void main(String[] args) throws Exception {          // Let ToolRunner handle generic command-line options           int res = ToolRunner.run(new Configuration(), new MyApp(), args);                    System.exit(res);        }      }   See Also:GenericOptionsParser,  ToolRunner Method Summary Methods  Modifier and Type Method and Description int run(String[] args) Execute the command with the given arguments. Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Method Detail run int run(String[] args)         throws Exception Execute the command with the given arguments. Parameters:args - command specific arguments. Returns:exit code. Throws: Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ToolRunner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ToolRunner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.util Class ToolRunner java.lang.Object org.apache.hadoop.util.ToolRunner @InterfaceAudience.Public @InterfaceStability.Stable public class ToolRunner extends Object A utility to help run Tools.    ToolRunner can be used to run classes implementing   Tool interface. It works in conjunction with   GenericOptionsParser to parse the     generic hadoop command line arguments and modifies the   Configuration of the Tool. The   application-specific options are passed along without being modified.   See Also:Tool,  GenericOptionsParser Constructor Summary Constructors  Constructor and Description ToolRunner()  Method Summary Methods  Modifier and Type Method and Description static boolean confirmPrompt(String prompt) Print out a prompt to the user, and return true if the user  responds with "y" or "yes". static void printGenericCommandUsage(PrintStream out) Prints generic command-line argurments and usage information. static int run(Configuration conf,       Tool tool,       String[] args) Runs the given Tool by Tool.run(String[]), after   parsing with the given generic arguments. static int run(Tool tool,       String[] args) Runs the Tool with its Configuration. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ToolRunner public ToolRunner() Method Detail run public static int run(Configuration conf,       Tool tool,       String[] args)                throws Exception Runs the given Tool by Tool.run(String[]), after   parsing with the given generic arguments. Uses the given   Configuration, or builds one if null.    Sets the Tool's configuration with the possibly modified   version of the conf. Parameters:conf - Configuration for the Tool.tool - Tool to run.args - command-line arguments to the tool. Returns:exit code of the Tool.run(String[]) method. Throws: Exception run public static int run(Tool tool,       String[] args)                throws Exception Runs the Tool with its Configuration.    Equivalent to run(tool.getConf(), tool, args). Parameters:tool - Tool to run.args - command-line arguments to the tool. Returns:exit code of the Tool.run(String[]) method. Throws: Exception printGenericCommandUsage public static void printGenericCommandUsage(PrintStream out) Prints generic command-line argurments and usage information. Parameters:out - stream to write usage information to. confirmPrompt public static boolean confirmPrompt(String prompt)                              throws IOException Print out a prompt to the user, and return true if the user  responds with "y" or "yes". (case insensitive) Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TotalOrderPartitioner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TotalOrderPartitioner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.partition Class TotalOrderPartitioner<K extends WritableComparable<?>,V> java.lang.Object org.apache.hadoop.mapreduce.Partitioner<K,V> org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner<K,V> All Implemented Interfaces: Configurable Direct Known Subclasses: TotalOrderPartitioner @InterfaceAudience.Public @InterfaceStability.Stable public class TotalOrderPartitioner<K extends WritableComparable<?>,V> extends Partitioner<K,V> implements Configurable Partitioner effecting a total order by reading split points from  an externally generated source. Field Summary Fields  Modifier and Type Field and Description static String DEFAULT_PATH  static String MAX_TRIE_DEPTH  static String NATURAL_ORDER  static String PARTITIONER_PATH  Constructor Summary Constructors  Constructor and Description TotalOrderPartitioner()  Method Summary Methods  Modifier and Type Method and Description Configuration getConf() Return the configuration used by this object. int getPartition(K key,                         V value,                         int numPartitions) Get the partition number for a given key (hence record) given the total   number of partitions i.e. static String getPartitionFile(Configuration conf) Get the path to the SequenceFile storing the sorted partition keyset. void setConf(Configuration conf) Read in the partition file and build indexing data structures. static void setPartitionFile(Configuration conf,                                 Path p) Set the path to the SequenceFile storing the sorted partition keyset. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail DEFAULT_PATH public static final String DEFAULT_PATH See Also:Constant Field Values PARTITIONER_PATH public static final String PARTITIONER_PATH See Also:Constant Field Values MAX_TRIE_DEPTH public static final String MAX_TRIE_DEPTH See Also:Constant Field Values NATURAL_ORDER public static final String NATURAL_ORDER See Also:Constant Field Values Constructor Detail TotalOrderPartitioner public TotalOrderPartitioner() Method Detail setConf public void setConf(Configuration conf) Read in the partition file and build indexing data structures.  If the keytype is BinaryComparable and  total.order.partitioner.natural.order is not false, a trie  of the first total.order.partitioner.max.trie.depth(2) + 1 bytes  will be built. Otherwise, keys will be located using a binary search of  the partition keyset using the RawComparator  defined for this job. The input file must be sorted with the same  comparator and contain JobContextImpl.getNumReduceTasks() - 1 keys. Specified by: setConf in interface Configurable getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable getPartition public int getPartition(K key,                V value,                int numPartitions) Description copied from class: Partitioner Get the partition number for a given key (hence record) given the total   number of partitions i.e. number of reduce-tasks for the job.      Typically a hash function on a all or a subset of the key. Specified by: getPartition in class Partitioner<K extends WritableComparable<?>,V> Parameters:key - the key to be partioned.value - the entry value.numPartitions - the total number of partitions. Returns:the partition number for the key. setPartitionFile public static void setPartitionFile(Configuration conf,                     Path p) Set the path to the SequenceFile storing the sorted partition keyset.  It must be the case that for R reduces, there are R-1  keys in the SequenceFile. getPartitionFile public static String getPartitionFile(Configuration conf) Get the path to the SequenceFile storing the sorted partition keyset. See Also:setPartitionFile(Configuration, Path) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TraceAdminProtocol (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TraceAdminProtocol (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.tracing Interface TraceAdminProtocol @InterfaceAudience.Public @InterfaceStability.Evolving public interface TraceAdminProtocol Protocol interface that provides tracing. Field Summary Fields  Modifier and Type Field and Description static long versionID  Method Summary Methods  Modifier and Type Method and Description long addSpanReceiver(SpanReceiverInfo desc) Add a new trace span receiver. SpanReceiverInfo[] listSpanReceivers() List the currently active trace span receivers. void removeSpanReceiver(long spanReceiverId) Remove a trace span receiver. Field Detail versionID static final long versionID See Also:Constant Field Values Method Detail listSpanReceivers SpanReceiverInfo[] listSpanReceivers()                                      throws IOException List the currently active trace span receivers. Throws: IOException - On error. addSpanReceiver long addSpanReceiver(SpanReceiverInfo desc)                      throws IOException Add a new trace span receiver. Parameters:desc - The span receiver description. Returns:The ID of the new trace span receiver. Throws: IOException - On error. removeSpanReceiver void removeSpanReceiver(long spanReceiverId)                         throws IOException Remove a trace span receiver. Parameters:spanReceiverId - The id of the span receiver to remove. Throws: IOException - On error. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TraceAdminProtocolPB (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TraceAdminProtocolPB (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.tracing Interface TraceAdminProtocolPB All Superinterfaces: org.apache.hadoop.tracing.TraceAdminPB.TraceAdminService.BlockingInterface, org.apache.hadoop.ipc.VersionedProtocol @InterfaceAudience.Public @InterfaceStability.Evolving public interface TraceAdminProtocolPB extends org.apache.hadoop.tracing.TraceAdminPB.TraceAdminService.BlockingInterface, org.apache.hadoop.ipc.VersionedProtocol Method Summary Methods inherited from interface org.apache.hadoop.tracing.TraceAdminPB.TraceAdminService.BlockingInterface addSpanReceiver, listSpanReceivers, removeSpanReceiver Methods inherited from interface org.apache.hadoop.ipc.VersionedProtocol getProtocolSignature, getProtocolVersion Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Trash (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Trash (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class Trash java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.Trash All Implemented Interfaces: Configurable @InterfaceAudience.Public @InterfaceStability.Stable public class Trash extends Configured Provides a trash facility which supports pluggable Trash policies.   See the implementation of the configured TrashPolicy for more  details. Constructor Summary Constructors  Constructor and Description Trash(Configuration conf) Construct a trash can accessor. Trash(FileSystem fs,           Configuration conf) Construct a trash can accessor for the FileSystem provided. Method Summary Methods  Modifier and Type Method and Description void checkpoint() Create a trash checkpoint. void expunge() Delete old checkpoint(s). Runnable getEmptier() Return a Runnable that periodically empties the trash of all  users, intended to be run by the superuser. boolean isEnabled() Returns whether the trash is enabled for this filesystem static boolean moveToAppropriateTrash(FileSystem fs,                                             Path p,                                             Configuration conf) In case of the symlinks or mount points, one has to move the appropriate  trashbin in the actual volume of the path p being deleted. boolean moveToTrash(Path path) Move a file or directory to the current trash directory. Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail Trash public Trash(Configuration conf)       throws IOException Construct a trash can accessor. Parameters:conf - a Configuration Throws: IOException Trash public Trash(FileSystem fs,      Configuration conf)       throws IOException Construct a trash can accessor for the FileSystem provided. Parameters:fs - the FileSystemconf - a Configuration Throws: IOException Method Detail moveToAppropriateTrash public static boolean moveToAppropriateTrash(FileSystem fs,                              Path p,                              Configuration conf)                                       throws IOException In case of the symlinks or mount points, one has to move the appropriate  trashbin in the actual volume of the path p being deleted.  Hence we get the file system of the fully-qualified resolved-path and  then move the path p to the trashbin in that volume, Parameters:fs - - the filesystem of path pp - - the  path being deleted - to be moved to trasgconf - - configuration Returns:false if the item is already in the trash or trash is disabled Throws: IOException - on error isEnabled public boolean isEnabled() Returns whether the trash is enabled for this filesystem moveToTrash public boolean moveToTrash(Path path)                     throws IOException Move a file or directory to the current trash directory. Returns:false if the item is already in the trash or trash is disabled Throws: IOException checkpoint public void checkpoint()                 throws IOException Create a trash checkpoint. Throws: IOException expunge public void expunge()              throws IOException Delete old checkpoint(s). Throws: IOException getEmptier public Runnable getEmptier()                     throws IOException Return a Runnable that periodically empties the trash of all  users, intended to be run by the superuser. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TrashPolicy (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TrashPolicy (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class TrashPolicy java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.TrashPolicy All Implemented Interfaces: Configurable @InterfaceAudience.Public @InterfaceStability.Evolving public abstract class TrashPolicy extends Configured This interface is used for implementing different Trash policies.  Provides factory method to create instances of the configured Trash policy. Field Summary Fields  Modifier and Type Field and Description protected long deletionInterval  protected FileSystem fs  protected Path trash  Constructor Summary Constructors  Constructor and Description TrashPolicy()  Method Summary Methods  Modifier and Type Method and Description abstract void createCheckpoint() Create a trash checkpoint. abstract void deleteCheckpoint() Delete old trash checkpoint(s). abstract Path getCurrentTrashDir() Get the current working directory of the Trash Policy abstract Runnable getEmptier() Return a Runnable that periodically empties the trash of all  users, intended to be run by the superuser. static TrashPolicy getInstance(Configuration conf,                       FileSystem fs,                       Path home) Get an instance of the configured TrashPolicy based on the value   of the configuration parameter fs.trash.classname. abstract void initialize(Configuration conf,                     FileSystem fs,                     Path home) Used to setup the trash policy. abstract boolean isEnabled() Returns whether the Trash Policy is enabled for this filesystem abstract boolean moveToTrash(Path path) Move a file or directory to the current trash directory. Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail fs protected FileSystem fs trash protected Path trash deletionInterval protected long deletionInterval Constructor Detail TrashPolicy public TrashPolicy() Method Detail initialize public abstract void initialize(Configuration conf,               FileSystem fs,               Path home) Used to setup the trash policy. Must be implemented by all TrashPolicy  implementations Parameters:conf - the configuration to be usedfs - the filesystem to be usedhome - the home directory isEnabled public abstract boolean isEnabled() Returns whether the Trash Policy is enabled for this filesystem moveToTrash public abstract boolean moveToTrash(Path path)                              throws IOException Move a file or directory to the current trash directory. Returns:false if the item is already in the trash or trash is disabled Throws: IOException createCheckpoint public abstract void createCheckpoint()                                throws IOException Create a trash checkpoint. Throws: IOException deleteCheckpoint public abstract void deleteCheckpoint()                                throws IOException Delete old trash checkpoint(s). Throws: IOException getCurrentTrashDir public abstract Path getCurrentTrashDir() Get the current working directory of the Trash Policy getEmptier public abstract Runnable getEmptier()                              throws IOException Return a Runnable that periodically empties the trash of all  users, intended to be run by the superuser. Throws: IOException getInstance public static TrashPolicy getInstance(Configuration conf,                       FileSystem fs,                       Path home) Get an instance of the configured TrashPolicy based on the value   of the configuration parameter fs.trash.classname. Parameters:conf - the configuration to be usedfs - the file system to be usedhome - the home directory Returns:an instance of TrashPolicy Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TupleWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TupleWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class TupleWritable java.lang.Object org.apache.hadoop.mapreduce.lib.join.TupleWritable All Implemented Interfaces: Iterable<Writable>, Writable Direct Known Subclasses: TupleWritable @InterfaceAudience.Public @InterfaceStability.Stable public class TupleWritable extends Object implements Writable, Iterable<Writable> Writable type storing multiple Writables.  This is *not* a general-purpose tuple type. In almost all cases, users are  encouraged to implement their own serializable types, which can perform  better validation and provide more efficient encodings than this class is  capable. TupleWritable relies on the join framework for type safety and  assumes its instances will rarely be persisted, assumptions not only  incompatible with, but contrary to the general case. See Also:Writable Field Summary Fields  Modifier and Type Field and Description protected BitSet written  Constructor Summary Constructors  Constructor and Description TupleWritable() Create an empty tuple with no allocated storage for writables. TupleWritable(Writable[] vals) Initialize tuple with storage; unknown whether any of them contain  "written" values. Method Summary Methods  Modifier and Type Method and Description boolean equals(Object other) Writable get(int i) Get ith Writable from Tuple. boolean has(int i) Return true if tuple has an element at the position provided. int hashCode()  Iterator<Writable> iterator() Return an iterator over the elements in this tuple. void readFields(DataInput in) Deserialize the fields of this object from in. int size() The number of children in this Tuple. String toString() Convert Tuple to String as in the following. void write(DataOutput out) Writes each Writable to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Field Detail written protected BitSet written Constructor Detail TupleWritable public TupleWritable() Create an empty tuple with no allocated storage for writables. TupleWritable public TupleWritable(Writable[] vals) Initialize tuple with storage; unknown whether any of them contain  "written" values. Method Detail has public boolean has(int i) Return true if tuple has an element at the position provided. get public Writable get(int i) Get ith Writable from Tuple. size public int size() The number of children in this Tuple. equals public boolean equals(Object other) Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object iterator public Iterator<Writable> iterator() Return an iterator over the elements in this tuple.  Note that this doesn't flatten the tuple; one may receive tuples  from this iterator. Specified by: iterator in interface Iterable<Writable> toString public String toString() Convert Tuple to String as in the following.  [<child1>,<child2>,...,<childn>] Overrides: toString in class Object write public void write(DataOutput out)            throws IOException Writes each Writable to out.  TupleWritable format:  <count><type1><type2>...<typen><obj1><obj2>...<objn>   Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TwoDArrayWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TwoDArrayWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class TwoDArrayWritable java.lang.Object org.apache.hadoop.io.TwoDArrayWritable All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public class TwoDArrayWritable extends Object implements Writable A Writable for 2D arrays containing a matrix of instances of a class. Constructor Summary Constructors  Constructor and Description TwoDArrayWritable(Class valueClass)  TwoDArrayWritable(Class valueClass,                                   Writable[][] values)  Method Summary Methods  Modifier and Type Method and Description Writable[][] get()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(Writable[][] values)  Object toArray()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail TwoDArrayWritable public TwoDArrayWritable(Class valueClass) TwoDArrayWritable public TwoDArrayWritable(Class valueClass,                  Writable[][] values) Method Detail toArray public Object toArray() set public void set(Writable[][] values) get public Writable[][] get() readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  TypeID (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="TypeID (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.meta Class TypeID java.lang.Object org.apache.hadoop.record.meta.TypeID Direct Known Subclasses: MapTypeID, StructTypeID, VectorTypeID Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class TypeID extends Object Represents typeID for basic types. Field Summary Fields  Modifier and Type Field and Description static TypeID BoolTypeID Deprecated.  Constant classes for the basic types, so we can share them. static TypeID BufferTypeID Deprecated.    static TypeID ByteTypeID Deprecated.    static TypeID DoubleTypeID Deprecated.    static TypeID FloatTypeID Deprecated.    static TypeID IntTypeID Deprecated.    static TypeID LongTypeID Deprecated.    static TypeID StringTypeID Deprecated.    protected byte typeVal Deprecated.    Method Summary Methods  Modifier and Type Method and Description boolean equals(Object o) Deprecated.  Two base typeIDs are equal if they refer to the same type byte getTypeVal() Deprecated.  Get the type value. int hashCode() Deprecated.  We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Field Detail BoolTypeID public static final TypeID BoolTypeID Deprecated.  Constant classes for the basic types, so we can share them. BufferTypeID public static final TypeID BufferTypeID Deprecated.  ByteTypeID public static final TypeID ByteTypeID Deprecated.  DoubleTypeID public static final TypeID DoubleTypeID Deprecated.  FloatTypeID public static final TypeID FloatTypeID Deprecated.  IntTypeID public static final TypeID IntTypeID Deprecated.  LongTypeID public static final TypeID LongTypeID Deprecated.  StringTypeID public static final TypeID StringTypeID Deprecated.  typeVal protected byte typeVal Deprecated.  Method Detail getTypeVal public byte getTypeVal() Deprecated.  Get the type value. One of the constants in RIOType. equals public boolean equals(Object o) Deprecated.  Two base typeIDs are equal if they refer to the same type Overrides: equals in class Object hashCode public int hashCode() Deprecated.  We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Overrides: hashCode in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  URL (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="URL (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class URL java.lang.Object org.apache.hadoop.yarn.api.records.URL @InterfaceAudience.Public @InterfaceStability.Stable public abstract class URL extends Object URL represents a serializable URL. Constructor Summary Constructors  Constructor and Description URL()  Method Summary Methods  Modifier and Type Method and Description abstract String getFile() Get the file of the URL. abstract String getHost() Get the host of the URL. abstract int getPort() Get the port of the URL. abstract String getScheme() Get the scheme of the URL. abstract String getUserInfo() Get the user info of the URL. static URL newInstance(String scheme,                       String host,                       int port,                       String file)  abstract void setFile(String file) Set the file of the URL. abstract void setHost(String host) Set the host of the URL. abstract void setPort(int port) Set the port of the URL abstract void setScheme(String scheme) Set the scheme of the URL abstract void setUserInfo(String userInfo) Set the user info of the URL. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail URL public URL() Method Detail newInstance @InterfaceAudience.Public @InterfaceStability.Stable public static URL newInstance(String scheme,                                                                  String host,                                                                  int port,                                                                  String file) getScheme @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getScheme() Get the scheme of the URL. Returns:scheme of the URL setScheme @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setScheme(String scheme) Set the scheme of the URL Parameters:scheme - scheme of the URL getUserInfo @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getUserInfo() Get the user info of the URL. Returns:user info of the URL setUserInfo @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setUserInfo(String userInfo) Set the user info of the URL. Parameters:userInfo - user info of the URL getHost @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getHost() Get the host of the URL. Returns:host of the URL setHost @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setHost(String host) Set the host of the URL. Parameters:host - host of the URL getPort @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getPort() Get the port of the URL. Returns:port of the URL setPort @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setPort(int port) Set the port of the URL Parameters:port - port of the URL getFile @InterfaceAudience.Public @InterfaceStability.Stable public abstract String getFile() Get the file of the URL. Returns:file of the URL setFile @InterfaceAudience.Public @InterfaceStability.Stable public abstract void setFile(String file) Set the file of the URL. Parameters:file - file of the URL Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  UTCClock (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="UTCClock (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.util Class UTCClock java.lang.Object org.apache.hadoop.yarn.util.UTCClock All Implemented Interfaces: Clock @InterfaceAudience.Public @InterfaceStability.Evolving public class UTCClock extends Object implements Clock Implementation of Clock that gives the current UTC time in  milliseconds. Constructor Summary Constructors  Constructor and Description UTCClock()  Method Summary Methods  Modifier and Type Method and Description long getTime()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail UTCClock public UTCClock() Method Detail getTime public long getTime() Specified by: getTime in interface Clock Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  UniqValueCount (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="UniqValueCount (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class UniqValueCount java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount All Implemented Interfaces: ValueAggregator<Object> Direct Known Subclasses: UniqValueCount @InterfaceAudience.Public @InterfaceStability.Stable public class UniqValueCount extends Object implements ValueAggregator<Object> This class implements a value aggregator that dedupes a sequence of objects. Field Summary Fields  Modifier and Type Field and Description static String MAX_NUM_UNIQUE_VALUES  Constructor Summary Constructors  Constructor and Description UniqValueCount() the default constructor UniqValueCount(long maxNum) constructor Method Summary Methods  Modifier and Type Method and Description void addNextValue(Object val) add a value to the aggregator ArrayList<Object> getCombinerOutput()  String getReport()  Set<Object> getUniqueItems()  void reset() reset the aggregator long setMaxItems(long n) Set the limit on the number of unique values Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail MAX_NUM_UNIQUE_VALUES public static final String MAX_NUM_UNIQUE_VALUES See Also:Constant Field Values Constructor Detail UniqValueCount public UniqValueCount() the default constructor UniqValueCount public UniqValueCount(long maxNum) constructor Parameters:maxNum - the limit in the number of unique values to keep. Method Detail setMaxItems public long setMaxItems(long n) Set the limit on the number of unique values Parameters:n - the desired limit on the number of unique values Returns:the new limit on the number of unique values addNextValue public void addNextValue(Object val) add a value to the aggregator Specified by: addNextValue in interface ValueAggregator<Object> Parameters:val - an object. getReport public String getReport() Specified by: getReport in interface ValueAggregator<Object> Returns:return the number of unique objects aggregated getUniqueItems public Set<Object> getUniqueItems() Returns:the set of the unique objects reset public void reset() reset the aggregator Specified by: reset in interface ValueAggregator<Object> getCombinerOutput public ArrayList<Object> getCombinerOutput() Specified by: getCombinerOutput in interface ValueAggregator<Object> Returns:return an array of the unique objects. The return value is          expected to be used by the a combiner. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  UnsupportedFileSystemException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="UnsupportedFileSystemException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Class UnsupportedFileSystemException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.fs.UnsupportedFileSystemException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class UnsupportedFileSystemException extends IOException File system for a given file system name/scheme is not supported See Also:Serialized Form Constructor Summary Constructors  Constructor and Description UnsupportedFileSystemException(String message) Constructs exception with the specified detail message. Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail UnsupportedFileSystemException public UnsupportedFileSystemException(String message) Constructs exception with the specified detail message. Parameters:message - exception message. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  UseSharedCacheResourceRequest (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="UseSharedCacheResourceRequest (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class UseSharedCacheResourceRequest java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class UseSharedCacheResourceRequest extends Object  The request from clients to the SharedCacheManager that claims a  resource in the shared cache.   Constructor Summary Constructors  Constructor and Description UseSharedCacheResourceRequest()  Method Summary Methods  Modifier and Type Method and Description abstract ApplicationId getAppId() Get the ApplicationId of the resource to be used. abstract String getResourceKey() Get the key of the resource to be used. abstract void setAppId(ApplicationId id) Set the ApplicationId of the resource to be used. abstract void setResourceKey(String key) Set the key of the resource to be used. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail UseSharedCacheResourceRequest public UseSharedCacheResourceRequest() Method Detail getAppId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ApplicationId getAppId() Get the ApplicationId of the resource to be used. Returns:ApplicationId setAppId @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setAppId(ApplicationId id) Set the ApplicationId of the resource to be used. Parameters:id - ApplicationId getResourceKey @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getResourceKey() Get the key of the resource to be used. Returns:key setResourceKey @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setResourceKey(String key) Set the key of the resource to be used. Parameters:key - unique identifier for the resource Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  UseSharedCacheResourceResponse (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="UseSharedCacheResourceResponse (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.protocolrecords Class UseSharedCacheResourceResponse java.lang.Object org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceResponse @InterfaceAudience.Public @InterfaceStability.Unstable public abstract class UseSharedCacheResourceResponse extends Object  The response from the SharedCacheManager to the client that indicates whether  a requested resource exists in the cache.   Constructor Summary Constructors  Constructor and Description UseSharedCacheResourceResponse()  Method Summary Methods  Modifier and Type Method and Description abstract String getPath() Get the Path corresponding to the requested resource in the  shared cache. abstract void setPath(String p) Set the Path corresponding to a resource in the shared cache. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail UseSharedCacheResourceResponse public UseSharedCacheResourceResponse() Method Detail getPath @InterfaceAudience.Public @InterfaceStability.Unstable public abstract String getPath() Get the Path corresponding to the requested resource in the  shared cache. Returns:String A Path if the resource exists in the shared          cache, null otherwise setPath @InterfaceAudience.Public @InterfaceStability.Unstable public abstract void setPath(String p) Set the Path corresponding to a resource in the shared cache. Parameters:p - A Path corresponding to a resource in the shared           cache Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  UserDefinedValueAggregatorDescriptor (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="UserDefinedValueAggregatorDescriptor (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class UserDefinedValueAggregatorDescriptor java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor All Implemented Interfaces: ValueAggregatorDescriptor Direct Known Subclasses: UserDefinedValueAggregatorDescriptor @InterfaceAudience.Public @InterfaceStability.Stable public class UserDefinedValueAggregatorDescriptor extends Object implements ValueAggregatorDescriptor This class implements a wrapper for a user defined value   aggregator descriptor.  It serves two functions: One is to create an object of   ValueAggregatorDescriptor from the name of a user defined class  that may be dynamically loaded. The other is to  delegate invocations of generateKeyValPairs function to the created object. Field Summary Fields  Modifier and Type Field and Description protected ValueAggregatorDescriptor theAggregatorDescriptor  Fields inherited from interface org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor ONE, TYPE_SEPARATOR Constructor Summary Constructors  Constructor and Description UserDefinedValueAggregatorDescriptor(String className,                                                                         Configuration conf)  Method Summary Methods  Modifier and Type Method and Description void configure(Configuration conf) Do nothing. static Object createInstance(String className) Create an instance of the given class ArrayList<Map.Entry<Text,Text>> generateKeyValPairs(Object key,                                       Object val) Generate a list of aggregation-id/value pairs for the given     key/value pairs by delegating the invocation to the real object. String toString()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail theAggregatorDescriptor protected ValueAggregatorDescriptor theAggregatorDescriptor Constructor Detail UserDefinedValueAggregatorDescriptor public UserDefinedValueAggregatorDescriptor(String className,                                     Configuration conf) Parameters:className - the class name of the user defined descriptor classconf - a configure object used for decriptor configuration Method Detail createInstance public static Object createInstance(String className) Create an instance of the given class Parameters:className - the name of the class Returns:a dynamically created instance of the given class generateKeyValPairs public ArrayList<Map.Entry<Text,Text>> generateKeyValPairs(Object key,                                                   Object val) Generate a list of aggregation-id/value pairs for the given     key/value pairs by delegating the invocation to the real object. Specified by: generateKeyValPairs in interface ValueAggregatorDescriptor Parameters:key - input keyval - input value Returns:a list of aggregation id/value pairs. An aggregation id encodes an          aggregation type which is used to guide the way to aggregate the          value in the reduce/combiner phrase of an Aggregate based job. toString public String toString() Overrides: toString in class Object Returns:the string representation of this object. configure public void configure(Configuration conf) Do nothing. Specified by: configure in interface ValueAggregatorDescriptor Parameters:conf - a Configuration object that may contain the information            that can be used to configure the object. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  UserGroupInformation.AuthenticationMethod (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="UserGroupInformation.AuthenticationMethod (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.security Enum UserGroupInformation.AuthenticationMethod java.lang.Object java.lang.Enum<UserGroupInformation.AuthenticationMethod> org.apache.hadoop.security.UserGroupInformation.AuthenticationMethod All Implemented Interfaces: Serializable, Comparable<UserGroupInformation.AuthenticationMethod> Enclosing class: org.apache.hadoop.security.UserGroupInformation @InterfaceAudience.Public @InterfaceStability.Evolving public static enum UserGroupInformation.AuthenticationMethod extends Enum<UserGroupInformation.AuthenticationMethod> existing types of authentications' methods Enum Constant Summary Enum Constants  Enum Constant and Description CERTIFICATE  KERBEROS  KERBEROS_SSL  PROXY  SIMPLE  TOKEN  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.security.SaslRpcServer.AuthMethod getAuthMethod()  static UserGroupInformation.AuthenticationMethod valueOf(org.apache.hadoop.security.SaslRpcServer.AuthMethod authMethod)  static UserGroupInformation.AuthenticationMethod valueOf(String name) Returns the enum constant of this type with the specified name. static UserGroupInformation.AuthenticationMethod[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail SIMPLE public static final UserGroupInformation.AuthenticationMethod SIMPLE KERBEROS public static final UserGroupInformation.AuthenticationMethod KERBEROS TOKEN public static final UserGroupInformation.AuthenticationMethod TOKEN CERTIFICATE public static final UserGroupInformation.AuthenticationMethod CERTIFICATE KERBEROS_SSL public static final UserGroupInformation.AuthenticationMethod KERBEROS_SSL PROXY public static final UserGroupInformation.AuthenticationMethod PROXY Method Detail values public static UserGroupInformation.AuthenticationMethod[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (UserGroupInformation.AuthenticationMethod c : UserGroupInformation.AuthenticationMethod.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static UserGroupInformation.AuthenticationMethod valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null getAuthMethod public org.apache.hadoop.security.SaslRpcServer.AuthMethod getAuthMethod() valueOf public static UserGroupInformation.AuthenticationMethod valueOf(org.apache.hadoop.security.SaslRpcServer.AuthMethod authMethod) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Util (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Util (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.metrics.spi Class Util java.lang.Object org.apache.hadoop.metrics.spi.Util @InterfaceAudience.Public @InterfaceStability.Evolving public class Util extends Object Static utility methods Method Summary Methods  Modifier and Type Method and Description static List<InetSocketAddress> parse(String specs,           int defaultPort) Parses a space and/or comma separated sequence of server specifications  of the form hostname or hostname:port. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail parse public static List<InetSocketAddress> parse(String specs,                             int defaultPort) Parses a space and/or comma separated sequence of server specifications  of the form hostname or hostname:port.  If   the specs string is null, defaults to localhost:defaultPort. Returns:a list of InetSocketAddress objects. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Utils (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Utils (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class Utils java.lang.Object org.apache.hadoop.record.Utils Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class Utils extends Object Various utility functions for Hadoop record I/O runtime. Field Summary Fields  Modifier and Type Field and Description static char[] hexchars Deprecated.    Method Summary Methods  Modifier and Type Method and Description static int compareBytes(byte[] b1,                         int s1,                         int l1,                         byte[] b2,                         int s2,                         int l2) Deprecated.  Lexicographic order of binary data. static int getVIntSize(long i) Deprecated.  Get the encoded length if an integer is stored in a variable-length format static double readDouble(byte[] bytes,                     int start) Deprecated.  Parse a double from a byte array. static float readFloat(byte[] bytes,                   int start) Deprecated.  Parse a float from a byte array. static int readVInt(byte[] bytes,                 int start) Deprecated.  Reads a zero-compressed encoded integer from a byte array and returns it. static int readVInt(DataInput in) Deprecated.  Reads a zero-compressed encoded integer from a stream and returns it. static long readVLong(byte[] bytes,                   int start) Deprecated.  Reads a zero-compressed encoded long from a byte array and returns it. static long readVLong(DataInput in) Deprecated.  Reads a zero-compressed encoded long from a stream and return it. static void writeVInt(DataOutput stream,                   int i) Deprecated.  Serializes an int to a binary stream with zero-compressed encoding. static void writeVLong(DataOutput stream,                     long i) Deprecated.  Serializes a long to a binary stream with zero-compressed encoding. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail hexchars public static final char[] hexchars Deprecated.  Method Detail readFloat public static float readFloat(byte[] bytes,               int start) Deprecated.  Parse a float from a byte array. readDouble public static double readDouble(byte[] bytes,                 int start) Deprecated.  Parse a double from a byte array. readVLong public static long readVLong(byte[] bytes,              int start)                       throws IOException Deprecated.  Reads a zero-compressed encoded long from a byte array and returns it. Parameters:bytes - byte array with decode longstart - starting index Returns:deserialized long Throws: IOException readVInt public static int readVInt(byte[] bytes,            int start)                     throws IOException Deprecated.  Reads a zero-compressed encoded integer from a byte array and returns it. Parameters:bytes - byte array with the encoded integerstart - start index Returns:deserialized integer Throws: IOException readVLong public static long readVLong(DataInput in)                       throws IOException Deprecated.  Reads a zero-compressed encoded long from a stream and return it. Parameters:in - input stream Returns:deserialized long Throws: IOException readVInt public static int readVInt(DataInput in)                     throws IOException Deprecated.  Reads a zero-compressed encoded integer from a stream and returns it. Parameters:in - input stream Returns:deserialized integer Throws: IOException getVIntSize public static int getVIntSize(long i) Deprecated.  Get the encoded length if an integer is stored in a variable-length format Returns:the encoded length writeVLong public static void writeVLong(DataOutput stream,               long i)                        throws IOException Deprecated.  Serializes a long to a binary stream with zero-compressed encoding.  For -112 <= i <= 127, only one byte is used with the actual  value. For other values of i, the first byte value indicates whether the  long is positive or negative, and the number of bytes that follow.  If the first byte value v is between -113 and -120, the following long  is positive, with number of bytes that follow are -(v+112).  If the first byte value v is between -121 and -128, the following long  is negative, with number of bytes that follow are -(v+120). Bytes are  stored in the high-non-zero-byte-first order. Parameters:stream - Binary output streami - Long to be serialized Throws: IOException writeVInt public static void writeVInt(DataOutput stream,              int i)                       throws IOException Deprecated.  Serializes an int to a binary stream with zero-compressed encoding. Parameters:stream - Binary output streami - int to be serialized Throws: IOException compareBytes public static int compareBytes(byte[] b1,                int s1,                int l1,                byte[] b2,                int s2,                int l2) Deprecated.  Lexicographic order of binary data. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  VIntWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="VIntWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class VIntWritable java.lang.Object org.apache.hadoop.io.VIntWritable All Implemented Interfaces: Comparable<VIntWritable>, Writable, WritableComparable<VIntWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class VIntWritable extends Object implements WritableComparable<VIntWritable> A WritableComparable for integer values stored in variable-length format.  Such values take between one and five bytes.  Smaller values take fewer bytes. See Also:WritableUtils.readVInt(DataInput) Constructor Summary Constructors  Constructor and Description VIntWritable()  VIntWritable(int value)  Method Summary Methods  Modifier and Type Method and Description int compareTo(VIntWritable o) Compares two VIntWritables. boolean equals(Object o) Returns true iff o is a VIntWritable with the same value. int get() Return the value of this VIntWritable. int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(int value) Set the value of this VIntWritable. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail VIntWritable public VIntWritable() VIntWritable public VIntWritable(int value) Method Detail set public void set(int value) Set the value of this VIntWritable. get public int get() Return the value of this VIntWritable. readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object o) Returns true iff o is a VIntWritable with the same value. Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(VIntWritable o) Compares two VIntWritables. Specified by: compareTo in interface Comparable<VIntWritable> toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  VLongWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="VLongWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class VLongWritable java.lang.Object org.apache.hadoop.io.VLongWritable All Implemented Interfaces: Comparable<VLongWritable>, Writable, WritableComparable<VLongWritable> @InterfaceAudience.Public @InterfaceStability.Stable public class VLongWritable extends Object implements WritableComparable<VLongWritable> A WritableComparable for longs in a variable-length format. Such values take   between one and five bytes.  Smaller values take fewer bytes. See Also:WritableUtils.readVLong(DataInput) Constructor Summary Constructors  Constructor and Description VLongWritable()  VLongWritable(long value)  Method Summary Methods  Modifier and Type Method and Description int compareTo(VLongWritable o) Compares two VLongWritables. boolean equals(Object o) Returns true iff o is a VLongWritable with the same value. long get() Return the value of this LongWritable. int hashCode()  void readFields(DataInput in) Deserialize the fields of this object from in. void set(long value) Set the value of this LongWritable. String toString()  void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, wait, wait, wait Constructor Detail VLongWritable public VLongWritable() VLongWritable public VLongWritable(long value) Method Detail set public void set(long value) Set the value of this LongWritable. get public long get() Return the value of this LongWritable. readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException equals public boolean equals(Object o) Returns true iff o is a VLongWritable with the same value. Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object compareTo public int compareTo(VLongWritable o) Compares two VLongWritables. Specified by: compareTo in interface Comparable<VLongWritable> toString public String toString() Overrides: toString in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ValueAggregator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ValueAggregator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Interface ValueAggregator<E> All Known Subinterfaces: ValueAggregator<E> All Known Implementing Classes: DoubleValueSum, DoubleValueSum, LongValueMax, LongValueMax, LongValueMin, LongValueMin, LongValueSum, LongValueSum, StringValueMax, StringValueMax, StringValueMin, StringValueMin, UniqValueCount, UniqValueCount, ValueHistogram, ValueHistogram @InterfaceAudience.Public @InterfaceStability.Stable public interface ValueAggregator<E> This interface defines the minimal protocol for value aggregators. Method Summary Methods  Modifier and Type Method and Description void addNextValue(Object val) add a value to the aggregator ArrayList<E> getCombinerOutput()  String getReport()  void reset() reset the aggregator Method Detail addNextValue void addNextValue(Object val) add a value to the aggregator Parameters:val - the value to be added reset void reset() reset the aggregator getReport String getReport() Returns:the string representation of the agregator getCombinerOutput ArrayList<E> getCombinerOutput() Returns:an array of values as the outputs of the combiner. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ValueAggregatorBaseDescriptor (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ValueAggregatorBaseDescriptor (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class ValueAggregatorBaseDescriptor java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor All Implemented Interfaces: ValueAggregatorDescriptor Direct Known Subclasses: ValueAggregatorBaseDescriptor @InterfaceAudience.Public @InterfaceStability.Stable public class ValueAggregatorBaseDescriptor extends Object implements ValueAggregatorDescriptor This class implements the common functionalities of   the subclasses of ValueAggregatorDescriptor class. Field Summary Fields  Modifier and Type Field and Description static String DOUBLE_VALUE_SUM  String inputFile  static String LONG_VALUE_MAX  static String LONG_VALUE_MIN  static String LONG_VALUE_SUM  static String STRING_VALUE_MAX  static String STRING_VALUE_MIN  static String UNIQ_VALUE_COUNT  static String VALUE_HISTOGRAM  Fields inherited from interface org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor ONE, TYPE_SEPARATOR Constructor Summary Constructors  Constructor and Description ValueAggregatorBaseDescriptor()  Method Summary Methods  Modifier and Type Method and Description void configure(Configuration conf) get the input file name. static Map.Entry<Text,Text> generateEntry(String type,                           String id,                           Text val)  ArrayList<Map.Entry<Text,Text>> generateKeyValPairs(Object key,                                       Object val) Generate 1 or 2 aggregation-id/value pairs for the given key/value pair. static ValueAggregator generateValueAggregator(String type,                                               long uniqCount)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail UNIQ_VALUE_COUNT public static final String UNIQ_VALUE_COUNT See Also:Constant Field Values LONG_VALUE_SUM public static final String LONG_VALUE_SUM See Also:Constant Field Values DOUBLE_VALUE_SUM public static final String DOUBLE_VALUE_SUM See Also:Constant Field Values VALUE_HISTOGRAM public static final String VALUE_HISTOGRAM See Also:Constant Field Values LONG_VALUE_MAX public static final String LONG_VALUE_MAX See Also:Constant Field Values LONG_VALUE_MIN public static final String LONG_VALUE_MIN See Also:Constant Field Values STRING_VALUE_MAX public static final String STRING_VALUE_MAX See Also:Constant Field Values STRING_VALUE_MIN public static final String STRING_VALUE_MIN See Also:Constant Field Values inputFile public String inputFile Constructor Detail ValueAggregatorBaseDescriptor public ValueAggregatorBaseDescriptor() Method Detail generateEntry public static Map.Entry<Text,Text> generateEntry(String type,                                  String id,                                  Text val) Parameters:type - the aggregation typeid - the aggregation idval - the val associated with the id to be aggregated Returns:an Entry whose key is the aggregation id prefixed with   the aggregation type. generateValueAggregator public static ValueAggregator generateValueAggregator(String type,                                       long uniqCount) Parameters:type - the aggregation typeuniqCount - the limit in the number of unique values to keep,                    if type is UNIQ_VALUE_COUNT Returns:a value aggregator of the given type. generateKeyValPairs public ArrayList<Map.Entry<Text,Text>> generateKeyValPairs(Object key,                                                   Object val) Generate 1 or 2 aggregation-id/value pairs for the given key/value pair.  The first id will be of type LONG_VALUE_SUM, with "record_count" as  its aggregation id. If the input is a file split,  the second id of the same type will be generated too, with the file name   as its aggregation id. This achieves the behavior of counting the total   number of records in the input data, and the number of records   in each input file. Specified by: generateKeyValPairs in interface ValueAggregatorDescriptor Parameters:key - input keyval - input value Returns:a list of aggregation id/value pairs. An aggregation id encodes an          aggregation type which is used to guide the way to aggregate the          value in the reduce/combiner phrase of an Aggregate based job. configure public void configure(Configuration conf) get the input file name. Specified by: configure in interface ValueAggregatorDescriptor Parameters:conf - a configuration object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ValueAggregatorCombiner (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ValueAggregatorCombiner (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class ValueAggregatorCombiner<K1 extends WritableComparable<?>,V1 extends Writable> java.lang.Object org.apache.hadoop.mapreduce.Reducer<Text,Text,Text,Text> org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorCombiner<K1,V1> @InterfaceAudience.Public @InterfaceStability.Stable public class ValueAggregatorCombiner<K1 extends WritableComparable<?>,V1 extends Writable> extends Reducer<Text,Text,Text,Text> This class implements the generic combiner of Aggregate. Constructor Summary Constructors  Constructor and Description ValueAggregatorCombiner()  Method Summary Methods  Modifier and Type Method and Description void reduce(Text key,             Iterable<Text> values,             org.apache.hadoop.mapreduce.Reducer.Context context) Combines values for a given key. Methods inherited from class org.apache.hadoop.mapreduce.Reducer cleanup, run, setup Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ValueAggregatorCombiner public ValueAggregatorCombiner() Method Detail reduce public void reduce(Text key,           Iterable<Text> values,           org.apache.hadoop.mapreduce.Reducer.Context context)             throws IOException,                    InterruptedException Combines values for a given key. Overrides: reduce in class Reducer<Text,Text,Text,Text> Parameters:key - the key is expected to be a Text object, whose prefix indicates  the type of aggregation to aggregate the values.values - the values to combinecontext - to collect combined values Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ValueAggregatorDescriptor (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ValueAggregatorDescriptor (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Interface ValueAggregatorDescriptor All Known Subinterfaces: ValueAggregatorDescriptor All Known Implementing Classes: UserDefinedValueAggregatorDescriptor, UserDefinedValueAggregatorDescriptor, ValueAggregatorBaseDescriptor, ValueAggregatorBaseDescriptor @InterfaceAudience.Public @InterfaceStability.Stable public interface ValueAggregatorDescriptor This interface defines the contract a value aggregator descriptor must  support. Such a descriptor can be configured with a Configuration  object. Its main function is to generate a list of aggregation-id/value   pairs. An aggregation id encodes an aggregation type which is used to   guide the way to aggregate the value in the reduce/combiner phrase of an  Aggregate based job.   The mapper in an Aggregate based map/reduce job may create one or more of  ValueAggregatorDescriptor objects at configuration time. For each input  key/value pair, the mapper will use those objects to create aggregation  id/value pairs. Field Summary Fields  Modifier and Type Field and Description static Text ONE  static String TYPE_SEPARATOR  Method Summary Methods  Modifier and Type Method and Description void configure(Configuration conf) Configure the object ArrayList<Map.Entry<Text,Text>> generateKeyValPairs(Object key,                                       Object val) Generate a list of aggregation-id/value pairs for   the given key/value pair. Field Detail TYPE_SEPARATOR static final String TYPE_SEPARATOR See Also:Constant Field Values ONE static final Text ONE Method Detail generateKeyValPairs ArrayList<Map.Entry<Text,Text>> generateKeyValPairs(Object key,                                                   Object val) Generate a list of aggregation-id/value pairs for   the given key/value pair.  This function is usually called by the mapper of an Aggregate based job. Parameters:key - input keyval - input value Returns:a list of aggregation id/value pairs. An aggregation id encodes an          aggregation type which is used to guide the way to aggregate the          value in the reduce/combiner phrase of an Aggregate based job. configure void configure(Configuration conf) Configure the object Parameters:conf - a Configuration object that may contain the information            that can be used to configure the object. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ValueAggregatorJob (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ValueAggregatorJob (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class ValueAggregatorJob java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob @InterfaceAudience.Public @InterfaceStability.Stable public class ValueAggregatorJob extends Object This is the main class for creating a map/reduce job using Aggregate  framework. The Aggregate is a specialization of map/reduce framework,  specializing for performing various simple aggregations.    Generally speaking, in order to implement an application using Map/Reduce  model, the developer is to implement Map and Reduce functions (and possibly  combine function). However, a lot of applications related to counting and  statistics computing have very similar characteristics. Aggregate abstracts  out the general patterns of these functions and implementing those patterns.  In particular, the package provides generic mapper/redducer/combiner   classes, and a set of built-in value aggregators, and a generic utility   class that helps user create map/reduce jobs using the generic class.   The built-in aggregators include:    sum over numeric values count the number of distinct values compute the  histogram of values compute the minimum, maximum, media,average, standard  deviation of numeric values    The developer using Aggregate will need only to provide a plugin class  conforming to the following interface:    public interface ValueAggregatorDescriptor { public ArrayList<Entry>  generateKeyValPairs(Object key, Object value); public void  configure(Configuration conf); }    The package also provides a base class, ValueAggregatorBaseDescriptor,  implementing the above interface. The user can extend the base class and  implement generateKeyValPairs accordingly.    The primary work of generateKeyValPairs is to emit one or more key/value  pairs based on the input key/value pair. The key in an output key/value pair  encode two pieces of information: aggregation type and aggregation id. The  value will be aggregated onto the aggregation id according the aggregation  type.    This class offers a function to generate a map/reduce job using Aggregate  framework. The function takes the following parameters: input directory spec  input format (text or sequence file) output directory a file specifying the  user plugin class Constructor Summary Constructors  Constructor and Description ValueAggregatorJob()  Method Summary Methods  Modifier and Type Method and Description static Job createValueAggregatorJob(Configuration conf,                                                 String[] args) Create an Aggregate based map/reduce job. static Job createValueAggregatorJob(String[] args,                                                 Class<? extends ValueAggregatorDescriptor>[] descriptors)  static JobControl createValueAggregatorJobs(String[] args)  static JobControl createValueAggregatorJobs(String[] args,                                                   Class<? extends ValueAggregatorDescriptor>[] descriptors)  static void main(String[] args) create and run an Aggregate based map/reduce job. static Configuration setAggregatorDescriptors(Class<? extends ValueAggregatorDescriptor>[] descriptors)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ValueAggregatorJob public ValueAggregatorJob() Method Detail createValueAggregatorJobs public static JobControl createValueAggregatorJobs(String[] args,                                    Class<? extends ValueAggregatorDescriptor>[] descriptors)                                             throws IOException Throws: IOException createValueAggregatorJobs public static JobControl createValueAggregatorJobs(String[] args)                                             throws IOException Throws: IOException createValueAggregatorJob public static Job createValueAggregatorJob(Configuration conf,                            String[] args)                                     throws IOException Create an Aggregate based map/reduce job. Parameters:conf - The configuration for jobargs - the arguments used for job creation. Generic hadoop  arguments are accepted. Returns:a Job object ready for submission. Throws: IOExceptionSee Also:GenericOptionsParser createValueAggregatorJob public static Job createValueAggregatorJob(String[] args,                            Class<? extends ValueAggregatorDescriptor>[] descriptors)                                     throws IOException Throws: IOException setAggregatorDescriptors public static Configuration setAggregatorDescriptors(Class<? extends ValueAggregatorDescriptor>[] descriptors) main public static void main(String[] args)                  throws IOException,                         InterruptedException,                         ClassNotFoundException create and run an Aggregate based map/reduce job. Parameters:args - the arguments used for job creation Throws: IOException InterruptedException ClassNotFoundException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ValueAggregatorJobBase (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ValueAggregatorJobBase (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class ValueAggregatorJobBase<K1 extends WritableComparable<?>,V1 extends Writable> java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase<K1,V1> @InterfaceAudience.Public @InterfaceStability.Stable public class ValueAggregatorJobBase<K1 extends WritableComparable<?>,V1 extends Writable> extends Object This abstract class implements some common functionalities of the  the generic mapper, reducer and combiner classes of Aggregate. Field Summary Fields  Modifier and Type Field and Description protected static ArrayList<ValueAggregatorDescriptor> aggregatorDescriptorList  static String DESCRIPTOR  static String DESCRIPTOR_NUM  static String USER_JAR  Constructor Summary Constructors  Constructor and Description ValueAggregatorJobBase()  Method Summary Methods  Modifier and Type Method and Description protected static ArrayList<ValueAggregatorDescriptor> getAggregatorDescriptors(Configuration conf)  protected static ValueAggregatorDescriptor getValueAggregatorDescriptor(String spec,                                                         Configuration conf)  protected static void logSpec()  static void setup(Configuration job)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Field Detail DESCRIPTOR public static final String DESCRIPTOR See Also:Constant Field Values DESCRIPTOR_NUM public static final String DESCRIPTOR_NUM See Also:Constant Field Values USER_JAR public static final String USER_JAR See Also:Constant Field Values aggregatorDescriptorList protected static ArrayList<ValueAggregatorDescriptor> aggregatorDescriptorList Constructor Detail ValueAggregatorJobBase public ValueAggregatorJobBase() Method Detail setup public static void setup(Configuration job) getValueAggregatorDescriptor protected static ValueAggregatorDescriptor getValueAggregatorDescriptor(String spec,                                                      Configuration conf) getAggregatorDescriptors protected static ArrayList<ValueAggregatorDescriptor> getAggregatorDescriptors(Configuration conf) logSpec protected static void logSpec() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ValueAggregatorMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ValueAggregatorMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class ValueAggregatorMapper<K1 extends WritableComparable<?>,V1 extends Writable> java.lang.Object org.apache.hadoop.mapreduce.Mapper<K1,V1,Text,Text> org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorMapper<K1,V1> @InterfaceAudience.Public @InterfaceStability.Stable public class ValueAggregatorMapper<K1 extends WritableComparable<?>,V1 extends Writable> extends Mapper<K1,V1,Text,Text> This class implements the generic mapper of Aggregate. Constructor Summary Constructors  Constructor and Description ValueAggregatorMapper()  Method Summary Methods  Modifier and Type Method and Description void map(K1 key,       V1 value,       org.apache.hadoop.mapreduce.Mapper.Context context) the map function. void setup(org.apache.hadoop.mapreduce.Mapper.Context context) Called once at the beginning of the task. Methods inherited from class org.apache.hadoop.mapreduce.Mapper cleanup, run Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ValueAggregatorMapper public ValueAggregatorMapper() Method Detail setup public void setup(org.apache.hadoop.mapreduce.Mapper.Context context)            throws IOException,                   InterruptedException Description copied from class: Mapper Called once at the beginning of the task. Overrides: setup in class Mapper<K1 extends WritableComparable<?>,V1 extends Writable,Text,Text> Throws: IOException InterruptedException map public void map(K1 key,        V1 value,        org.apache.hadoop.mapreduce.Mapper.Context context)          throws IOException,                 InterruptedException the map function. It iterates through the value aggregator descriptor    list to generate aggregation id/value pairs and emit them. Overrides: map in class Mapper<K1 extends WritableComparable<?>,V1 extends Writable,Text,Text> Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ValueAggregatorReducer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ValueAggregatorReducer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class ValueAggregatorReducer<K1 extends WritableComparable<?>,V1 extends Writable> java.lang.Object org.apache.hadoop.mapreduce.Reducer<Text,Text,Text,Text> org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorReducer<K1,V1> @InterfaceAudience.Public @InterfaceStability.Stable public class ValueAggregatorReducer<K1 extends WritableComparable<?>,V1 extends Writable> extends Reducer<Text,Text,Text,Text> This class implements the generic reducer of Aggregate. Constructor Summary Constructors  Constructor and Description ValueAggregatorReducer()  Method Summary Methods  Modifier and Type Method and Description void reduce(Text key,             Iterable<Text> values,             org.apache.hadoop.mapreduce.Reducer.Context context) This method is called once for each key. void setup(org.apache.hadoop.mapreduce.Reducer.Context context) Called once at the start of the task. Methods inherited from class org.apache.hadoop.mapreduce.Reducer cleanup, run Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ValueAggregatorReducer public ValueAggregatorReducer() Method Detail setup public void setup(org.apache.hadoop.mapreduce.Reducer.Context context)            throws IOException,                   InterruptedException Description copied from class: Reducer Called once at the start of the task. Overrides: setup in class Reducer<Text,Text,Text,Text> Throws: IOException InterruptedException reduce public void reduce(Text key,           Iterable<Text> values,           org.apache.hadoop.mapreduce.Reducer.Context context)             throws IOException,                    InterruptedException Description copied from class: Reducer This method is called once for each key. Most applications will define  their reduce class by overriding this method. The default implementation  is an identity function. Overrides: reduce in class Reducer<Text,Text,Text,Text> Parameters:key - the key is expected to be a Text object, whose prefix indicates         the type of aggregation to aggregate the values. In effect, data         driven computing is achieved. It is assumed that each aggregator's         getReport method emits appropriate output for the aggregator. This         may be further customized.values - the values to be aggregatedcontext -  Throws: IOException InterruptedException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ValueHistogram (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ValueHistogram (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.aggregate Class ValueHistogram java.lang.Object org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram All Implemented Interfaces: ValueAggregator<String> Direct Known Subclasses: ValueHistogram @InterfaceAudience.Public @InterfaceStability.Stable public class ValueHistogram extends Object implements ValueAggregator<String> This class implements a value aggregator that computes the   histogram of a sequence of strings. Constructor Summary Constructors  Constructor and Description ValueHistogram()  Method Summary Methods  Modifier and Type Method and Description void addNextValue(Object val) add the given val to the aggregator. ArrayList<String> getCombinerOutput()  String getReport()  String getReportDetails()  TreeMap<Object,Object> getReportItems()  void reset() reset the aggregator Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ValueHistogram public ValueHistogram() Method Detail addNextValue public void addNextValue(Object val) add the given val to the aggregator. Specified by: addNextValue in interface ValueAggregator<String> Parameters:val - the value to be added. It is expected to be a string  in the form of xxxx\tnum, meaning xxxx has num occurrences. getReport public String getReport() Specified by: getReport in interface ValueAggregator<String> Returns:the string representation of this aggregator.  It includes the following basic statistics of the histogram:     the number of unique values     the minimum value     the media value     the maximum value     the average value     the standard deviation getReportDetails public String getReportDetails() Returns:a string representation of the list of value/frequence pairs of   the histogram getCombinerOutput public ArrayList<String> getCombinerOutput() Specified by: getCombinerOutput in interface ValueAggregator<String> Returns:a list value/frequence pairs.   The return value is expected to be used by the reducer. getReportItems public TreeMap<Object,Object> getReportItems() Returns:a TreeMap representation of the histogram reset public void reset() reset the aggregator Specified by: reset in interface ValueAggregator<String> Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  VectorTypeID (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="VectorTypeID (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record.meta Class VectorTypeID java.lang.Object org.apache.hadoop.record.meta.TypeID org.apache.hadoop.record.meta.VectorTypeID Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class VectorTypeID extends TypeID Represents typeID for vector. Field Summary Fields inherited from class org.apache.hadoop.record.meta.TypeID BoolTypeID, BufferTypeID, ByteTypeID, DoubleTypeID, FloatTypeID, IntTypeID, LongTypeID, StringTypeID, typeVal Constructor Summary Constructors  Constructor and Description VectorTypeID(TypeID typeIDElement) Deprecated.    Method Summary Methods  Modifier and Type Method and Description boolean equals(Object o) Deprecated.  Two vector typeIDs are equal if their constituent elements have the   same type TypeID getElementTypeID() Deprecated.    int hashCode() Deprecated.  We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Methods inherited from class org.apache.hadoop.record.meta.TypeID getTypeVal Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail VectorTypeID public VectorTypeID(TypeID typeIDElement) Deprecated.  Method Detail getElementTypeID public TypeID getElementTypeID() Deprecated.  equals public boolean equals(Object o) Deprecated.  Two vector typeIDs are equal if their constituent elements have the   same type Overrides: equals in class TypeID hashCode public int hashCode() Deprecated.  We use a basic hashcode implementation, since this class will likely not  be used as a hashmap key Overrides: hashCode in class TypeID Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  VersionMismatchException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="VersionMismatchException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class VersionMismatchException java.lang.Object java.lang.Throwable java.lang.Exception java.io.IOException org.apache.hadoop.io.VersionMismatchException All Implemented Interfaces: Serializable @InterfaceAudience.Public @InterfaceStability.Stable public class VersionMismatchException extends IOException Thrown by VersionedWritable.readFields(DataInput) when the  version of an object being read does not match the current implementation  version as returned by VersionedWritable.getVersion(). See Also:Serialized Form Constructor Summary Constructors  Constructor and Description VersionMismatchException(byte expectedVersionIn,                                                 byte foundVersionIn)  Method Summary Methods  Modifier and Type Method and Description String toString() Returns a string representation of this object. Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail VersionMismatchException public VersionMismatchException(byte expectedVersionIn,                         byte foundVersionIn) Method Detail toString public String toString() Returns a string representation of this object. Overrides: toString in class Throwable Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  VersionedWritable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="VersionedWritable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class VersionedWritable java.lang.Object org.apache.hadoop.io.VersionedWritable All Implemented Interfaces: Writable @InterfaceAudience.Public @InterfaceStability.Stable public abstract class VersionedWritable extends Object implements Writable A base class for Writables that provides version checking.  This is useful when a class may evolve, so that instances written by the  old version of the class may still be processed by the new version.  To  handle this situation, readFields(DataInput)  implementations should catch VersionMismatchException. Constructor Summary Constructors  Constructor and Description VersionedWritable()  Method Summary Methods  Modifier and Type Method and Description abstract byte getVersion() Return the version number of the current implementation. void readFields(DataInput in) Deserialize the fields of this object from in. void write(DataOutput out) Serialize the fields of this object to out. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail VersionedWritable public VersionedWritable() Method Detail getVersion public abstract byte getVersion() Return the version number of the current implementation. write public void write(DataOutput out)            throws IOException Description copied from interface: Writable Serialize the fields of this object to out. Specified by: write in interface Writable Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields public void readFields(DataInput in)                 throws IOException Description copied from interface: Writable Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Specified by: readFields in interface Writable Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ViewFileSystem (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ViewFileSystem (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.viewfs Class ViewFileSystem java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.FileSystem org.apache.hadoop.fs.viewfs.ViewFileSystem All Implemented Interfaces: Closeable, AutoCloseable, Configurable @InterfaceAudience.Public @InterfaceStability.Evolving public class ViewFileSystem extends FileSystem ViewFileSystem (extends the FileSystem interface) implements a client-side  mount table. Its spec and implementation is identical to ViewFs. Field Summary Fields inherited from class org.apache.hadoop.fs.FileSystem DEFAULT_FS, FS_DEFAULT_NAME_KEY, LOG, SHUTDOWN_HOOK_PRIORITY, statistics Constructor Summary Constructors  Constructor and Description ViewFileSystem() This is the  constructor with the signature needed by  FileSystem.createFileSystem(URI, Configuration)    After this constructor is called initialize() is called. ViewFileSystem(Configuration conf) Convenience Constructor for apps to call directly Method Summary Methods  Modifier and Type Method and Description void access(Path path,             FsAction mode) Checks if the user can access a path. FSDataOutputStream append(Path f,             int bufferSize,             Progressable progress) Append to an existing file (optional operation). FSDataOutputStream create(Path f,             FsPermission permission,             boolean overwrite,             int bufferSize,             short replication,             long blockSize,             Progressable progress) Create an FSDataOutputStream at the indicated Path with write-progress  reporting. FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     EnumSet<CreateFlag> flags,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress) Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. boolean delete(Path f) Delete a file boolean delete(Path f,             boolean recursive) Delete a file. AclStatus getAclStatus(Path path) Gets the ACL of a file or directory. FileSystem[] getChildFileSystems() Get all the immediate child FileSystems embedded in this FileSystem. ContentSummary getContentSummary(Path f) Return the ContentSummary of a given Path. long getDefaultBlockSize() Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. long getDefaultBlockSize(Path f) Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. short getDefaultReplication() Get the default replication. short getDefaultReplication(Path f) Get the default replication for a path. BlockLocation[] getFileBlockLocations(FileStatus fs,                                           long start,                                           long len) Return an array containing hostnames, offset and size of   portions of the given file. FileChecksum getFileChecksum(Path f) Get the checksum of a file. FileStatus getFileStatus(Path f) Return a file status object that represents the path. Path getHomeDirectory() Return the current user's home directory in this filesystem. org.apache.hadoop.fs.viewfs.ViewFileSystem.MountPoint[] getMountPoints()  String getScheme() Return the protocol scheme for the FileSystem. FsServerDefaults getServerDefaults() Return a set of server default configuration values FsServerDefaults getServerDefaults(Path f) Return a set of server default configuration values Path getTrashCanLocation(Path f)  URI getUri() Returns a URI whose scheme and authority identify this FileSystem. Path getWorkingDirectory() Get the current working directory for the given file system byte[] getXAttr(Path path,                 String name) Get an xattr name and value for a file or directory. Map<String,byte[]> getXAttrs(Path path) Get all of the xattr name/value pairs for a file or directory. Map<String,byte[]> getXAttrs(Path path,                   List<String> names) Get all of the xattrs name/value pairs for a file or directory. void initialize(URI theUri,                     Configuration conf) Called after a new FileSystem instance is constructed. org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f,                                   PathFilter filter) Listing a directory  The returned results include its block location if it is a file  The results are filtered by the given path filter FileStatus[] listStatus(Path f) List the statuses of the files/directories in the given path if the path is  a directory. List<String> listXAttrs(Path path) Get all of the xattr names for a file or directory. boolean mkdirs(Path dir,             FsPermission permission) Make the given file and all non-existent parents into  directories. void modifyAclEntries(Path path,                                 List<AclEntry> aclSpec) Modifies ACL entries of files and directories. FSDataInputStream open(Path f,         int bufferSize) Opens an FSDataInputStream at the indicated Path. void removeAcl(Path path) Removes all but the base ACL entries of files and directories. void removeAclEntries(Path path,                                 List<AclEntry> aclSpec) Removes ACL entries from files and directories. void removeDefaultAcl(Path path) Removes all default ACL entries from files and directories. void removeXAttr(Path path,                       String name) Remove an xattr of a file or directory. boolean rename(Path src,             Path dst) Renames Path src to Path dst. Path resolvePath(Path f) Return the fully-qualified path of path f resolving the path  through any symlinks or mount point void setAcl(Path path,             List<AclEntry> aclSpec) Fully replaces ACL of files and directories, discarding all existing  entries. void setOwner(Path f,                 String username,                 String groupname) Set owner of a path (i.e. void setPermission(Path f,                           FsPermission permission) Set permission of a path. boolean setReplication(Path f,                             short replication) Set replication for an existing file. void setTimes(Path f,                 long mtime,                 long atime) Set access time of a file void setVerifyChecksum(boolean verifyChecksum) Set the verify checksum flag. void setWorkingDirectory(Path new_dir) Set the current working directory for the given file system. void setWriteChecksum(boolean writeChecksum) Set the write checksum flag. void setXAttr(Path path,                 String name,                 byte[] value,                 EnumSet<XAttrSetFlag> flag) Set an xattr of a file or directory. boolean truncate(Path f,                 long newLength) Truncate the file in the indicated path to the indicated size. Methods inherited from class org.apache.hadoop.fs.FileSystem append, append, areSymlinksEnabled, cancelDeleteOnExit, canonicalizeUri, checkPath, clearStatistics, close, closeAll, closeAllForUGI, completeLocalOutput, concat, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyFromLocalFile, copyToLocalFile, copyToLocalFile, copyToLocalFile, create, create, create, create, create, create, create, create, create, create, create, create, createNewFile, createNonRecursive, createNonRecursive, createSnapshot, createSnapshot, createSymlink, deleteOnExit, deleteSnapshot, enableSymlinks, exists, fixRelativePart, get, get, get, getAllStatistics, getBlockSize, getCanonicalUri, getDefaultPort, getDefaultUri, getFileBlockLocations, getFileChecksum, getFileLinkStatus, getFileSystemClass, getFSofPath, getInitialWorkingDirectory, getLength, getLinkTarget, getLocal, getName, getNamed, getReplication, getStatistics, getStatistics, getStatus, getStatus, getUsed, globStatus, globStatus, isDirectory, isFile, listCorruptFileBlocks, listFiles, listLocatedStatus, listStatus, listStatus, listStatus, listStatusIterator, makeQualified, mkdirs, mkdirs, moveFromLocalFile, moveFromLocalFile, moveToLocalFile, newInstance, newInstance, newInstance, newInstanceLocal, open, primitiveCreate, primitiveMkdir, primitiveMkdir, printStatistics, processDeleteOnExit, rename, renameSnapshot, resolveLink, setDefaultUri, setDefaultUri, setXAttr, startLocalOutput, supportsSymlinks Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail ViewFileSystem public ViewFileSystem()                throws IOException This is the  constructor with the signature needed by  FileSystem.createFileSystem(URI, Configuration)    After this constructor is called initialize() is called. Throws: IOException ViewFileSystem public ViewFileSystem(Configuration conf)                throws IOException Convenience Constructor for apps to call directly Parameters:conf -  Throws: IOException Method Detail getScheme public String getScheme() Return the protocol scheme for the FileSystem.   Overrides: getScheme in class FileSystem Returns:viewfs initialize public void initialize(URI theUri,               Configuration conf)                 throws IOException Called after a new FileSystem instance is constructed. Overrides: initialize in class FileSystem Parameters:theUri - a uri whose authority section names the host, port, etc. for           this FileSystemconf - the configuration Throws: IOException getTrashCanLocation public Path getTrashCanLocation(Path f)                          throws FileNotFoundException Throws: FileNotFoundException getUri public URI getUri() Description copied from class: FileSystem Returns a URI whose scheme and authority identify this FileSystem. Specified by: getUri in class FileSystem resolvePath public Path resolvePath(Path f)                  throws IOException Description copied from class: FileSystem Return the fully-qualified path of path f resolving the path  through any symlinks or mount point Overrides: resolvePath in class FileSystem Parameters:f - path to be resolved Returns:fully qualified path Throws: FileNotFoundException IOException getHomeDirectory public Path getHomeDirectory() Description copied from class: FileSystem Return the current user's home directory in this filesystem.  The default implementation returns "/user/$USER/". Overrides: getHomeDirectory in class FileSystem getWorkingDirectory public Path getWorkingDirectory() Description copied from class: FileSystem Get the current working directory for the given file system Specified by: getWorkingDirectory in class FileSystem Returns:the directory pathname setWorkingDirectory public void setWorkingDirectory(Path new_dir) Description copied from class: FileSystem Set the current working directory for the given file system. All relative  paths will be resolved relative to it. Specified by: setWorkingDirectory in class FileSystem append public FSDataOutputStream append(Path f,                         int bufferSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Append to an existing file (optional operation). Specified by: append in class FileSystem Parameters:f - the existing file to be appended.bufferSize - the size of the buffer to be used.progress - for reporting progress if it is not null. Throws: IOException createNonRecursive public FSDataOutputStream createNonRecursive(Path f,                                     FsPermission permission,                                     EnumSet<CreateFlag> flags,                                     int bufferSize,                                     short replication,                                     long blockSize,                                     Progressable progress)                                       throws IOException Description copied from class: FileSystem Opens an FSDataOutputStream at the indicated Path with write-progress  reporting. Same as create(), except fails if parent directory doesn't  already exist. Overrides: createNonRecursive in class FileSystem Parameters:f - the file name to openflags - CreateFlags to use for this stream.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) create public FSDataOutputStream create(Path f,                         FsPermission permission,                         boolean overwrite,                         int bufferSize,                         short replication,                         long blockSize,                         Progressable progress)                           throws IOException Description copied from class: FileSystem Create an FSDataOutputStream at the indicated Path with write-progress  reporting. Specified by: create in class FileSystem Parameters:f - the file name to openoverwrite - if a file with this name already exists, then if true,    the file will be overwritten, and if false an error will be thrown.bufferSize - the size of the buffer to be used.replication - required block replication for the file. Throws: IOExceptionSee Also:FileSystem.setPermission(Path, FsPermission) delete public boolean delete(Path f,              boolean recursive)                throws org.apache.hadoop.security.AccessControlException,                       FileNotFoundException,                       IOException Description copied from class: FileSystem Delete a file. Specified by: delete in class FileSystem Parameters:f - the path to delete.recursive - if path is a directory and set to   true, the directory is deleted else throws an exception. In  case of a file the recursive can be set to either true or false. Returns:true if delete is successful else false. Throws: IOException org.apache.hadoop.security.AccessControlException FileNotFoundException delete public boolean delete(Path f)                throws org.apache.hadoop.security.AccessControlException,                       FileNotFoundException,                       IOException Description copied from class: FileSystem Delete a file Overrides: delete in class FileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException IOException getFileBlockLocations public BlockLocation[] getFileBlockLocations(FileStatus fs,                                     long start,                                     long len)                                       throws IOException Description copied from class: FileSystem Return an array containing hostnames, offset and size of   portions of the given file.  For a nonexistent   file or regions, null will be returned.  This call is most helpful with DFS, where it returns   hostnames of machines that contain the given file.  The FileSystem will simply return an elt containing 'localhost'. Overrides: getFileBlockLocations in class FileSystem Parameters:fs - FilesStatus to get data fromstart - offset into the given filelen - length for which to get locations for Throws: IOException getFileChecksum public FileChecksum getFileChecksum(Path f)                              throws org.apache.hadoop.security.AccessControlException,                                     FileNotFoundException,                                     IOException Description copied from class: FileSystem Get the checksum of a file. Overrides: getFileChecksum in class FileSystem Parameters:f - The file path Returns:The file checksum.  The default return value is null,   which indicates that no checksum algorithm is implemented   in the corresponding FileSystem. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException IOException getFileStatus public FileStatus getFileStatus(Path f)                          throws org.apache.hadoop.security.AccessControlException,                                 FileNotFoundException,                                 IOException Description copied from class: FileSystem Return a file status object that represents the path. Specified by: getFileStatus in class FileSystem Parameters:f - The path we want information from Returns:a FileStatus object Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation org.apache.hadoop.security.AccessControlException IOException access public void access(Path path,           FsAction mode)             throws org.apache.hadoop.security.AccessControlException,                    FileNotFoundException,                    IOException Description copied from class: FileSystem Checks if the user can access a path.  The mode specifies which access  checks to perform.  If the requested permissions are granted, then the  method returns normally.  If access is denied, then the method throws an  AccessControlException.    The default implementation of this method calls FileSystem.getFileStatus(Path)  and checks the returned permissions against the requested permissions.  Note that the getFileStatus call will be subject to authorization checks.  Typically, this requires search (execute) permissions on each directory in  the path's prefix, but this is implementation-defined.  Any file system  that provides a richer authorization model (such as ACLs) may override the  default implementation so that it checks against that model instead.    In general, applications should avoid using this method, due to the risk of  time-of-check/time-of-use race conditions.  The permissions on a file may  change immediately after the access call returns.  Most applications should  prefer running specific file system actions as the desired user represented  by a UserGroupInformation. Parameters:path - Path to checkmode - type of access to check Throws: org.apache.hadoop.security.AccessControlException - if access is denied FileNotFoundException - if the path does not exist IOException - see specific implementation listStatus public FileStatus[] listStatus(Path f)                         throws org.apache.hadoop.security.AccessControlException,                                FileNotFoundException,                                IOException Description copied from class: FileSystem List the statuses of the files/directories in the given path if the path is  a directory. Specified by: listStatus in class FileSystem Parameters:f - given path Returns:the statuses of the files/directories in the given patch Throws: FileNotFoundException - when the path does not exist;          IOException see specific implementation org.apache.hadoop.security.AccessControlException IOException listLocatedStatus public org.apache.hadoop.fs.RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f,                                                                        PathFilter filter)                                                                          throws FileNotFoundException,                                                                                 IOException Description copied from class: FileSystem Listing a directory  The returned results include its block location if it is a file  The results are filtered by the given path filter Overrides: listLocatedStatus in class FileSystem Parameters:f - a pathfilter - a path filter Returns:an iterator that traverses statuses of the files/directories           in the given path Throws: FileNotFoundException - if f does not exist IOException - if any I/O error occurred mkdirs public boolean mkdirs(Path dir,              FsPermission permission)                throws IOException Description copied from class: FileSystem Make the given file and all non-existent parents into  directories. Has the semantics of Unix 'mkdir -p'.  Existence of the directory hierarchy is not an error. Specified by: mkdirs in class FileSystem Parameters:dir - path to createpermission - to apply to f Throws: IOException open public FSDataInputStream open(Path f,                      int bufferSize)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               IOException Description copied from class: FileSystem Opens an FSDataInputStream at the indicated Path. Specified by: open in class FileSystem Parameters:f - the file name to openbufferSize - the size of the buffer to be used. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException IOException rename public boolean rename(Path src,              Path dst)                throws IOException Description copied from class: FileSystem Renames Path src to Path dst.  Can take place on local fs  or remote DFS. Specified by: rename in class FileSystem Parameters:src - path to be renameddst - new path after rename Returns:true if rename is successful Throws: IOException - on failure truncate public boolean truncate(Path f,                long newLength)                  throws IOException Description copied from class: FileSystem Truncate the file in the indicated path to the indicated size.    Fails if path is a directory.  Fails if path does not exist.  Fails if path is not closed.  Fails if new size is greater than current size.   Overrides: truncate in class FileSystem Parameters:f - The path to the file to be truncatednewLength - The size the file is to be truncated to Returns:true if the file has been truncated to the desired  newLength and is immediately available to be reused for  write operations such as append, or  false if a background process of adjusting the length of  the last block has been started, and clients should wait for it to  complete before proceeding with further file updates. Throws: IOException setOwner public void setOwner(Path f,             String username,             String groupname)               throws org.apache.hadoop.security.AccessControlException,                      FileNotFoundException,                      IOException Description copied from class: FileSystem Set owner of a path (i.e. a file or a directory).  The parameters username and groupname cannot both be null. Overrides: setOwner in class FileSystem Parameters:f - The pathusername - If it is null, the original username remains unchanged.groupname - If it is null, the original groupname remains unchanged. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException IOException setPermission public void setPermission(Path f,                  FsPermission permission)                    throws org.apache.hadoop.security.AccessControlException,                           FileNotFoundException,                           IOException Description copied from class: FileSystem Set permission of a path. Overrides: setPermission in class FileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException IOException setReplication public boolean setReplication(Path f,                      short replication)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               IOException Description copied from class: FileSystem Set replication for an existing file. Overrides: setReplication in class FileSystem Parameters:f - file namereplication - new replication Returns:true if successful;          false if file does not exist or is a directory Throws: IOException org.apache.hadoop.security.AccessControlException FileNotFoundException setTimes public void setTimes(Path f,             long mtime,             long atime)               throws org.apache.hadoop.security.AccessControlException,                      FileNotFoundException,                      IOException Description copied from class: FileSystem Set access time of a file Overrides: setTimes in class FileSystem Parameters:f - The pathmtime - Set the modification time of this file.               The number of milliseconds since Jan 1, 1970.                A value of -1 means that this call should not set modification time.atime - Set the access time of this file.               The number of milliseconds since Jan 1, 1970.                A value of -1 means that this call should not set access time. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException IOException modifyAclEntries public void modifyAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Description copied from class: FileSystem Modifies ACL entries of files and directories.  This method can add new ACL  entries or modify the permissions on existing ACL entries.  All existing  ACL entries that are not specified in this call are retained without  changes.  (Modifications are merged into the current ACL.) Overrides: modifyAclEntries in class FileSystem Parameters:path - Path to modifyaclSpec - List describing modifications Throws: IOException - if an ACL could not be modified removeAclEntries public void removeAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Description copied from class: FileSystem Removes ACL entries from files and directories.  Other ACL entries are  retained. Overrides: removeAclEntries in class FileSystem Parameters:path - Path to modifyaclSpec - List describing entries to remove Throws: IOException - if an ACL could not be modified removeDefaultAcl public void removeDefaultAcl(Path path)                       throws IOException Description copied from class: FileSystem Removes all default ACL entries from files and directories. Overrides: removeDefaultAcl in class FileSystem Parameters:path - Path to modify Throws: IOException - if an ACL could not be modified removeAcl public void removeAcl(Path path)                throws IOException Description copied from class: FileSystem Removes all but the base ACL entries of files and directories.  The entries  for user, group, and others are retained for compatibility with permission  bits. Overrides: removeAcl in class FileSystem Parameters:path - Path to modify Throws: IOException - if an ACL could not be removed setAcl public void setAcl(Path path,           List<AclEntry> aclSpec)             throws IOException Description copied from class: FileSystem Fully replaces ACL of files and directories, discarding all existing  entries. Overrides: setAcl in class FileSystem Parameters:path - Path to modifyaclSpec - List describing modifications, must include entries    for user, group, and others for compatibility with permission bits. Throws: IOException - if an ACL could not be modified getAclStatus public AclStatus getAclStatus(Path path)                        throws IOException Description copied from class: FileSystem Gets the ACL of a file or directory. Overrides: getAclStatus in class FileSystem Parameters:path - Path to get Returns:AclStatus describing the ACL of the file or directory Throws: IOException - if an ACL could not be read setXAttr public void setXAttr(Path path,             String name,             byte[] value,             EnumSet<XAttrSetFlag> flag)               throws IOException Description copied from class: FileSystem Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: setXAttr in class FileSystem Parameters:path - Path to modifyname - xattr name.value - xattr value.flag - xattr set flag Throws: IOException getXAttr public byte[] getXAttr(Path path,               String name)                 throws IOException Description copied from class: FileSystem Get an xattr name and value for a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: getXAttr in class FileSystem Parameters:path - Path to get extended attributename - xattr name. Returns:byte[] xattr value. Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path)                              throws IOException Description copied from class: FileSystem Get all of the xattr name/value pairs for a file or directory.  Only those xattrs which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Overrides: getXAttrs in class FileSystem Parameters:path - Path to get extended attributes Returns:Map describing the XAttrs of the file or directory Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path,                            List<String> names)                              throws IOException Description copied from class: FileSystem Get all of the xattrs name/value pairs for a file or directory.  Only those xattrs which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Overrides: getXAttrs in class FileSystem Parameters:path - Path to get extended attributesnames - XAttr names. Returns:Map describing the XAttrs of the file or directory Throws: IOException listXAttrs public List<String> listXAttrs(Path path)                         throws IOException Description copied from class: FileSystem Get all of the xattr names for a file or directory.  Only those xattr names which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Overrides: listXAttrs in class FileSystem Parameters:path - Path to get extended attributes Returns:List of the XAttr names of the file or directory Throws: IOException removeXAttr public void removeXAttr(Path path,                String name)                  throws IOException Description copied from class: FileSystem Remove an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: removeXAttr in class FileSystem Parameters:path - Path to remove extended attributename - xattr name Throws: IOException setVerifyChecksum public void setVerifyChecksum(boolean verifyChecksum) Description copied from class: FileSystem Set the verify checksum flag. This is only applicable if the   corresponding FileSystem supports checksum. By default doesn't do anything. Overrides: setVerifyChecksum in class FileSystem getDefaultBlockSize public long getDefaultBlockSize() Description copied from class: FileSystem Return the number of bytes that large input files should be optimally  be split into to minimize i/o time. Overrides: getDefaultBlockSize in class FileSystem getDefaultReplication public short getDefaultReplication() Description copied from class: FileSystem Get the default replication. Overrides: getDefaultReplication in class FileSystem getServerDefaults public FsServerDefaults getServerDefaults()                                    throws IOException Description copied from class: FileSystem Return a set of server default configuration values Overrides: getServerDefaults in class FileSystem Returns:server default configuration values Throws: IOException getDefaultBlockSize public long getDefaultBlockSize(Path f) Description copied from class: FileSystem Return the number of bytes that large input files should be optimally  be split into to minimize i/o time.  The given path will be used to  locate the actual filesystem.  The full path does not have to exist. Overrides: getDefaultBlockSize in class FileSystem Parameters:f - path of file Returns:the default block size for the path's filesystem getDefaultReplication public short getDefaultReplication(Path f) Description copied from class: FileSystem Get the default replication for a path.   The given path will be used to  locate the actual filesystem.  The full path does not have to exist. Overrides: getDefaultReplication in class FileSystem Parameters:f - of the file Returns:default replication for the path's filesystem getServerDefaults public FsServerDefaults getServerDefaults(Path f)                                    throws IOException Description copied from class: FileSystem Return a set of server default configuration values Overrides: getServerDefaults in class FileSystem Parameters:f - path is used to identify an FS since an FS could have           another FS that it could be delegating the call to Returns:server default configuration values Throws: IOException getContentSummary public ContentSummary getContentSummary(Path f)                                  throws IOException Description copied from class: FileSystem Return the ContentSummary of a given Path. Overrides: getContentSummary in class FileSystem Parameters:f - path to use Throws: IOException setWriteChecksum public void setWriteChecksum(boolean writeChecksum) Description copied from class: FileSystem Set the write checksum flag. This is only applicable if the   corresponding FileSystem supports checksum. By default doesn't do anything. Overrides: setWriteChecksum in class FileSystem getChildFileSystems public FileSystem[] getChildFileSystems() Description copied from class: FileSystem Get all the immediate child FileSystems embedded in this FileSystem.  It does not recurse and get grand children.  If a FileSystem  has multiple child FileSystems, then it should return a unique list  of those FileSystems.  Default is to return null to signify no children. Returns:FileSystems used by this FileSystem getMountPoints public org.apache.hadoop.fs.viewfs.ViewFileSystem.MountPoint[] getMountPoints() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ViewFs (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ViewFs (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.viewfs Class ViewFs java.lang.Object org.apache.hadoop.fs.AbstractFileSystem org.apache.hadoop.fs.viewfs.ViewFs @InterfaceAudience.Public @InterfaceStability.Evolving public class ViewFs extends AbstractFileSystem ViewFs (extends the AbstractFileSystem interface) implements a client-side  mount table. The viewFs file system is implemented completely in memory on  the client side. The client-side mount table allows a client to provide a   customized view of a file system namespace that is composed from   one or more individual file systems (a localFs or Hdfs, S3fs, etc).  For example one could have a mount table that provides links such as      /user          -> hdfs://nnContainingUserDir/user    /project/foo   -> hdfs://nnProject1/projects/foo    /project/bar   -> hdfs://nnProject2/projects/bar    /tmp           -> hdfs://nnTmp/privateTmpForUserXXX       ViewFs is specified with the following URI: viewfs:///     To use viewfs one would typically set the default file system in the  config  (i.e. fs.default.name< = viewfs:///) along with the  mount table config variables as described below.        ** Config variables to specify the mount table entries **       The file system is initialized from the standard Hadoop config through  config variables.  See FsConstants for URI and Scheme constants;   See Constants for config var constants;   see ConfigUtil for convenient lib.      All the mount table config entries for view fs are prefixed by   fs.viewfs.mounttable.  For example the above example can be specified with the following   config variables:       fs.viewfs.mounttable.default.link./user=   hdfs://nnContainingUserDir/user    fs.viewfs.mounttable.default.link./project/foo=   hdfs://nnProject1/projects/foo    fs.viewfs.mounttable.default.link./project/bar=   hdfs://nnProject2/projects/bar    fs.viewfs.mounttable.default.link./tmp=   hdfs://nnTmp/privateTmpForUserXXX        The default mount table (when no authority is specified) is   from config variables prefixed by fs.viewFs.mounttable.default   The authority component of a URI can be used to specify a different mount  table. For example,      viewfs://sanjayMountable/    is initialized from fs.viewFs.mounttable.sanjayMountable.* config variables.          **** Merge Mounts **** (NOTE: merge mounts are not implemented yet.)          One can also use "MergeMounts" to merge several directories (this is    sometimes  called union-mounts or junction-mounts in the literature.    For example of the home directories are stored on say two file systems    (because they do not fit on one) then one could specify a mount    entry such as following merges two dirs:         /user -> hdfs://nnUser1/user,hdfs://nnUser2/user       Such a mergeLink can be specified with the following config var where ","   is used as the separator for each of links to be merged:       fs.viewfs.mounttable.default.linkMerge./user=   hdfs://nnUser1/user,hdfs://nnUser1/user       A special case of the merge mount is where mount table's root is merged    with the root (slash) of another file system:            fs.viewfs.mounttable.default.linkMergeSlash=hdfs://nn99/        In this cases the root of the mount table is merged with the root of             hdfs://nn99/  Field Summary Fields inherited from class org.apache.hadoop.fs.AbstractFileSystem statistics Constructor Summary Constructors  Constructor and Description ViewFs(Configuration conf)  Method Summary Methods  Modifier and Type Method and Description void access(Path path,             FsAction mode) The specification of this method matches that of  FileContext.access(Path, FsAction)  except that an UnresolvedLinkException may be thrown if a symlink is  encountered in the path. FSDataOutputStream createInternal(Path f,                             EnumSet<CreateFlag> flag,                             FsPermission absolutePermission,                             int bufferSize,                             short replication,                             long blockSize,                             Progressable progress,                             org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt,                             boolean createParent) The specification of this method matches that of  AbstractFileSystem.create(Path, EnumSet, Options.CreateOpts...) except that the opts  have been declared explicitly. void createSymlink(Path target,                           Path link,                           boolean createParent) The specification of this method matches that of    FileContext.createSymlink(Path, Path, boolean); boolean delete(Path f,             boolean recursive) The specification of this method matches that of  FileContext.delete(Path, boolean) except that Path f must be for  this file system. AclStatus getAclStatus(Path path) Gets the ACLs of files and directories. List<org.apache.hadoop.security.token.Token<?>> getDelegationTokens(String renewer) Get one or more delegation tokens associated with the filesystem. BlockLocation[] getFileBlockLocations(Path f,                                           long start,                                           long len) The specification of this method matches that of  FileContext.getFileBlockLocations(Path, long, long) except that  Path f must be for this file system. FileChecksum getFileChecksum(Path f) The specification of this method matches that of  FileContext.getFileChecksum(Path) except that Path f must be for  this file system. FileStatus getFileLinkStatus(Path f) The specification of this method matches that of  FileContext.getFileLinkStatus(Path)  except that an UnresolvedLinkException may be thrown if a symlink is    encountered in the path leading up to the final path component. FileStatus getFileStatus(Path f) The specification of this method matches that of  FileContext.getFileStatus(Path)   except that an UnresolvedLinkException may be thrown if a symlink is   encountered in the path. FsStatus getFsStatus() The specification of this method matches that of  FileContext.getFsStatus(Path). Path getHomeDirectory() Return the current user's home directory in this file system. Path getLinkTarget(Path f) Partially resolves the path. org.apache.hadoop.fs.viewfs.ViewFs.MountPoint[] getMountPoints()  FsServerDefaults getServerDefaults() Return a set of server default configuration values. int getUriDefaultPort() The default port of this file system. byte[] getXAttr(Path path,                 String name) Get an xattr for a file or directory. Map<String,byte[]> getXAttrs(Path path) Get all of the xattrs for a file or directory. Map<String,byte[]> getXAttrs(Path path,                   List<String> names) Get all of the xattrs for a file or directory. boolean isValidName(String src) Returns true if the specified string is considered valid in the path part  of a URI by this file system. FileStatus[] listStatus(Path f) The specification of this method matches that of  FileContext.Util.listStatus(Path) except that Path f must be   for this file system. org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatusIterator(Path f) The specification of this method matches that of  FileContext.listStatus(Path) except that Path f must be for this  file system. List<String> listXAttrs(Path path) Get all of the xattr names for a file or directory. void mkdir(Path dir,           FsPermission permission,           boolean createParent) The specification of this method matches that of  FileContext.mkdir(Path, FsPermission, boolean) except that the Path  f must be fully qualified and the permission is absolute (i.e. void modifyAclEntries(Path path,                                 List<AclEntry> aclSpec) Modifies ACL entries of files and directories. FSDataInputStream open(Path f,         int bufferSize) The specification of this method matches that of  FileContext.open(Path, int) except that Path f must be for this  file system. void removeAcl(Path path) Removes all but the base ACL entries of files and directories. void removeAclEntries(Path path,                                 List<AclEntry> aclSpec) Removes ACL entries from files and directories. void removeDefaultAcl(Path path) Removes all default ACL entries from files and directories. void removeXAttr(Path path,                       String name) Remove an xattr of a file or directory. void renameInternal(Path src,                             Path dst) The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system and NO OVERWRITE is performed. void renameInternal(Path src,                             Path dst,                             boolean overwrite) The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system. Path resolvePath(Path f) Return the fully-qualified path of path f resolving the path  through any internal symlinks or mount point void setAcl(Path path,             List<AclEntry> aclSpec) Fully replaces ACL of files and directories, discarding all existing  entries. void setOwner(Path f,                 String username,                 String groupname) The specification of this method matches that of  FileContext.setOwner(Path, String, String) except that Path f must  be for this file system. void setPermission(Path f,                           FsPermission permission) The specification of this method matches that of  FileContext.setPermission(Path, FsPermission) except that Path f  must be for this file system. boolean setReplication(Path f,                             short replication) The specification of this method matches that of  FileContext.setReplication(Path, short) except that Path f must be  for this file system. void setTimes(Path f,                 long mtime,                 long atime) The specification of this method matches that of  FileContext.setTimes(Path, long, long) except that Path f must be  for this file system. void setVerifyChecksum(boolean verifyChecksum) The specification of this method matches that of  FileContext.setVerifyChecksum(boolean, Path) except that Path f  must be for this file system. void setXAttr(Path path,                 String name,                 byte[] value,                 EnumSet<XAttrSetFlag> flag) Set an xattr of a file or directory. boolean supportsSymlinks() Returns true if the file system supports symlinks, false otherwise. boolean truncate(Path f,                 long newLength) The specification of this method matches that of  FileContext.truncate(Path, long) except that Path f must be for  this file system. Methods inherited from class org.apache.hadoop.fs.AbstractFileSystem checkPath, checkScheme, clearStatistics, create, createFileSystem, equals, get, getAllStatistics, getCanonicalServiceName, getFsStatus, getInitialWorkingDirectory, getStatistics, getStatistics, getUri, getUriPath, hashCode, listCorruptFileBlocks, listLocatedStatus, makeQualified, open, printStatistics, rename, setXAttr Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Constructor Detail ViewFs public ViewFs(Configuration conf)        throws IOException,               URISyntaxException Throws: IOException URISyntaxException Method Detail getServerDefaults public FsServerDefaults getServerDefaults()                                    throws IOException Description copied from class: AbstractFileSystem Return a set of server default configuration values. Specified by: getServerDefaults in class AbstractFileSystem Returns:server default configuration values Throws: IOException - an I/O error occurred getUriDefaultPort public int getUriDefaultPort() Description copied from class: AbstractFileSystem The default port of this file system. Specified by: getUriDefaultPort in class AbstractFileSystem Returns:default port of this file system's Uri scheme          A uri with a port of -1 => default port; getHomeDirectory public Path getHomeDirectory() Description copied from class: AbstractFileSystem Return the current user's home directory in this file system.  The default implementation returns "/user/$USER/". Overrides: getHomeDirectory in class AbstractFileSystem Returns:current user's home directory. resolvePath public Path resolvePath(Path f)                  throws FileNotFoundException,                         org.apache.hadoop.security.AccessControlException,                         org.apache.hadoop.fs.UnresolvedLinkException,                         IOException Description copied from class: AbstractFileSystem Return the fully-qualified path of path f resolving the path  through any internal symlinks or mount point Overrides: resolvePath in class AbstractFileSystem Parameters:f - path to be resolved Returns:fully qualified path Throws: FileNotFoundException org.apache.hadoop.security.AccessControlException org.apache.hadoop.fs.UnresolvedLinkException IOException createInternal public FSDataOutputStream createInternal(Path f,                                 EnumSet<CreateFlag> flag,                                 FsPermission absolutePermission,                                 int bufferSize,                                 short replication,                                 long blockSize,                                 Progressable progress,                                 org.apache.hadoop.fs.Options.ChecksumOpt checksumOpt,                                 boolean createParent)                                   throws org.apache.hadoop.security.AccessControlException,                                          FileAlreadyExistsException,                                          FileNotFoundException,                                          ParentNotDirectoryException,                                          UnsupportedFileSystemException,                                          org.apache.hadoop.fs.UnresolvedLinkException,                                          IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  AbstractFileSystem.create(Path, EnumSet, Options.CreateOpts...) except that the opts  have been declared explicitly. Specified by: createInternal in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException ParentNotDirectoryException UnsupportedFileSystemException org.apache.hadoop.fs.UnresolvedLinkException IOException delete public boolean delete(Path f,              boolean recursive)                throws org.apache.hadoop.security.AccessControlException,                       FileNotFoundException,                       org.apache.hadoop.fs.UnresolvedLinkException,                       IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.delete(Path, boolean) except that Path f must be for  this file system. Specified by: delete in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException getFileBlockLocations public BlockLocation[] getFileBlockLocations(Path f,                                     long start,                                     long len)                                       throws org.apache.hadoop.security.AccessControlException,                                              FileNotFoundException,                                              org.apache.hadoop.fs.UnresolvedLinkException,                                              IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.getFileBlockLocations(Path, long, long) except that  Path f must be for this file system. Specified by: getFileBlockLocations in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException getFileChecksum public FileChecksum getFileChecksum(Path f)                              throws org.apache.hadoop.security.AccessControlException,                                     FileNotFoundException,                                     org.apache.hadoop.fs.UnresolvedLinkException,                                     IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.getFileChecksum(Path) except that Path f must be for  this file system. Specified by: getFileChecksum in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException getFileStatus public FileStatus getFileStatus(Path f)                          throws org.apache.hadoop.security.AccessControlException,                                 FileNotFoundException,                                 org.apache.hadoop.fs.UnresolvedLinkException,                                 IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.getFileStatus(Path)   except that an UnresolvedLinkException may be thrown if a symlink is   encountered in the path. Specified by: getFileStatus in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException access public void access(Path path,           FsAction mode)             throws org.apache.hadoop.security.AccessControlException,                    FileNotFoundException,                    org.apache.hadoop.fs.UnresolvedLinkException,                    IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.access(Path, FsAction)  except that an UnresolvedLinkException may be thrown if a symlink is  encountered in the path. Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException getFileLinkStatus public FileStatus getFileLinkStatus(Path f)                              throws org.apache.hadoop.security.AccessControlException,                                     FileNotFoundException,                                     UnsupportedFileSystemException,                                     IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.getFileLinkStatus(Path)  except that an UnresolvedLinkException may be thrown if a symlink is    encountered in the path leading up to the final path component.  If the file system does not support symlinks then the behavior is  equivalent to AbstractFileSystem.getFileStatus(Path). Overrides: getFileLinkStatus in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException UnsupportedFileSystemException IOException getFsStatus public FsStatus getFsStatus()                      throws org.apache.hadoop.security.AccessControlException,                             FileNotFoundException,                             IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.getFsStatus(Path). Specified by: getFsStatus in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException IOException listStatusIterator public org.apache.hadoop.fs.RemoteIterator<FileStatus> listStatusIterator(Path f)                                                                    throws org.apache.hadoop.security.AccessControlException,                                                                           FileNotFoundException,                                                                           org.apache.hadoop.fs.UnresolvedLinkException,                                                                           IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.listStatus(Path) except that Path f must be for this  file system. Overrides: listStatusIterator in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException listStatus public FileStatus[] listStatus(Path f)                         throws org.apache.hadoop.security.AccessControlException,                                FileNotFoundException,                                org.apache.hadoop.fs.UnresolvedLinkException,                                IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.Util.listStatus(Path) except that Path f must be   for this file system. Specified by: listStatus in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException mkdir public void mkdir(Path dir,          FsPermission permission,          boolean createParent)            throws org.apache.hadoop.security.AccessControlException,                   FileAlreadyExistsException,                   FileNotFoundException,                   org.apache.hadoop.fs.UnresolvedLinkException,                   IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.mkdir(Path, FsPermission, boolean) except that the Path  f must be fully qualified and the permission is absolute (i.e.   umask has been applied). Specified by: mkdir in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException open public FSDataInputStream open(Path f,                      int bufferSize)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               org.apache.hadoop.fs.UnresolvedLinkException,                               IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.open(Path, int) except that Path f must be for this  file system. Specified by: open in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException truncate public boolean truncate(Path f,                long newLength)                  throws org.apache.hadoop.security.AccessControlException,                         FileNotFoundException,                         org.apache.hadoop.fs.UnresolvedLinkException,                         IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.truncate(Path, long) except that Path f must be for  this file system. Overrides: truncate in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException renameInternal public void renameInternal(Path src,                   Path dst,                   boolean overwrite)                     throws IOException,                            org.apache.hadoop.fs.UnresolvedLinkException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system. Overrides: renameInternal in class AbstractFileSystem Throws: IOException org.apache.hadoop.fs.UnresolvedLinkException renameInternal public void renameInternal(Path src,                   Path dst)                     throws org.apache.hadoop.security.AccessControlException,                            FileAlreadyExistsException,                            FileNotFoundException,                            ParentNotDirectoryException,                            org.apache.hadoop.fs.UnresolvedLinkException,                            IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.rename(Path, Path, Options.Rename...) except that Path  f must be for this file system and NO OVERWRITE is performed.    File systems that do not have a built in overwrite need implement only this  method and can take advantage of the default impl of the other  AbstractFileSystem.renameInternal(Path, Path, boolean) Specified by: renameInternal in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileAlreadyExistsException FileNotFoundException ParentNotDirectoryException org.apache.hadoop.fs.UnresolvedLinkException IOException supportsSymlinks public boolean supportsSymlinks() Description copied from class: AbstractFileSystem Returns true if the file system supports symlinks, false otherwise. Overrides: supportsSymlinks in class AbstractFileSystem Returns:true if filesystem supports symlinks createSymlink public void createSymlink(Path target,                  Path link,                  boolean createParent)                    throws IOException,                           org.apache.hadoop.fs.UnresolvedLinkException Description copied from class: AbstractFileSystem The specification of this method matches that of    FileContext.createSymlink(Path, Path, boolean); Overrides: createSymlink in class AbstractFileSystem Throws: IOException org.apache.hadoop.fs.UnresolvedLinkException getLinkTarget public Path getLinkTarget(Path f)                    throws IOException Description copied from class: AbstractFileSystem Partially resolves the path. This is used during symlink resolution in  FSLinkResolver, and differs from the similarly named method  FileContext.getLinkTarget(Path). Overrides: getLinkTarget in class AbstractFileSystem Throws: IOException - subclass implementations may throw IOException setOwner public void setOwner(Path f,             String username,             String groupname)               throws org.apache.hadoop.security.AccessControlException,                      FileNotFoundException,                      org.apache.hadoop.fs.UnresolvedLinkException,                      IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.setOwner(Path, String, String) except that Path f must  be for this file system. Specified by: setOwner in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException setPermission public void setPermission(Path f,                  FsPermission permission)                    throws org.apache.hadoop.security.AccessControlException,                           FileNotFoundException,                           org.apache.hadoop.fs.UnresolvedLinkException,                           IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.setPermission(Path, FsPermission) except that Path f  must be for this file system. Specified by: setPermission in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException setReplication public boolean setReplication(Path f,                      short replication)                        throws org.apache.hadoop.security.AccessControlException,                               FileNotFoundException,                               org.apache.hadoop.fs.UnresolvedLinkException,                               IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.setReplication(Path, short) except that Path f must be  for this file system. Specified by: setReplication in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException setTimes public void setTimes(Path f,             long mtime,             long atime)               throws org.apache.hadoop.security.AccessControlException,                      FileNotFoundException,                      org.apache.hadoop.fs.UnresolvedLinkException,                      IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.setTimes(Path, long, long) except that Path f must be  for this file system. Specified by: setTimes in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException FileNotFoundException org.apache.hadoop.fs.UnresolvedLinkException IOException setVerifyChecksum public void setVerifyChecksum(boolean verifyChecksum)                        throws org.apache.hadoop.security.AccessControlException,                               IOException Description copied from class: AbstractFileSystem The specification of this method matches that of  FileContext.setVerifyChecksum(boolean, Path) except that Path f  must be for this file system. Specified by: setVerifyChecksum in class AbstractFileSystem Throws: org.apache.hadoop.security.AccessControlException IOException getMountPoints public org.apache.hadoop.fs.viewfs.ViewFs.MountPoint[] getMountPoints() getDelegationTokens public List<org.apache.hadoop.security.token.Token<?>> getDelegationTokens(String renewer)                                                                     throws IOException Description copied from class: AbstractFileSystem Get one or more delegation tokens associated with the filesystem. Normally  a file system returns a single delegation token. A file system that manages  multiple file systems underneath, could return set of delegation tokens for  all the file systems it manages Parameters:renewer - the account name that is allowed to renew the token. Returns:List of delegation tokens.    If delegation tokens not supported then return a list of size zero. Throws: IOException isValidName public boolean isValidName(String src) Description copied from class: AbstractFileSystem Returns true if the specified string is considered valid in the path part  of a URI by this file system.  The default implementation enforces the rules  of HDFS, but subclasses may override this method to implement specific  validation rules for specific file systems. Overrides: isValidName in class AbstractFileSystem Parameters:src - String source filename to check, path part of the URI Returns:boolean true if the specified string is considered valid modifyAclEntries public void modifyAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Description copied from class: AbstractFileSystem Modifies ACL entries of files and directories.  This method can add new ACL  entries or modify the permissions on existing ACL entries.  All existing  ACL entries that are not specified in this call are retained without  changes.  (Modifications are merged into the current ACL.) Overrides: modifyAclEntries in class AbstractFileSystem Parameters:path - Path to modifyaclSpec - List describing modifications Throws: IOException - if an ACL could not be modified removeAclEntries public void removeAclEntries(Path path,                     List<AclEntry> aclSpec)                       throws IOException Description copied from class: AbstractFileSystem Removes ACL entries from files and directories.  Other ACL entries are  retained. Overrides: removeAclEntries in class AbstractFileSystem Parameters:path - Path to modifyaclSpec - List describing entries to remove Throws: IOException - if an ACL could not be modified removeDefaultAcl public void removeDefaultAcl(Path path)                       throws IOException Description copied from class: AbstractFileSystem Removes all default ACL entries from files and directories. Overrides: removeDefaultAcl in class AbstractFileSystem Parameters:path - Path to modify Throws: IOException - if an ACL could not be modified removeAcl public void removeAcl(Path path)                throws IOException Description copied from class: AbstractFileSystem Removes all but the base ACL entries of files and directories.  The entries  for user, group, and others are retained for compatibility with permission  bits. Overrides: removeAcl in class AbstractFileSystem Parameters:path - Path to modify Throws: IOException - if an ACL could not be removed setAcl public void setAcl(Path path,           List<AclEntry> aclSpec)             throws IOException Description copied from class: AbstractFileSystem Fully replaces ACL of files and directories, discarding all existing  entries. Overrides: setAcl in class AbstractFileSystem Parameters:path - Path to modifyaclSpec - List describing modifications, must include entries    for user, group, and others for compatibility with permission bits. Throws: IOException - if an ACL could not be modified getAclStatus public AclStatus getAclStatus(Path path)                        throws IOException Description copied from class: AbstractFileSystem Gets the ACLs of files and directories. Overrides: getAclStatus in class AbstractFileSystem Parameters:path - Path to get Returns:RemoteIterator which returns each AclStatus Throws: IOException - if an ACL could not be read setXAttr public void setXAttr(Path path,             String name,             byte[] value,             EnumSet<XAttrSetFlag> flag)               throws IOException Description copied from class: AbstractFileSystem Set an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: setXAttr in class AbstractFileSystem Parameters:path - Path to modifyname - xattr name.value - xattr value.flag - xattr set flag Throws: IOException getXAttr public byte[] getXAttr(Path path,               String name)                 throws IOException Description copied from class: AbstractFileSystem Get an xattr for a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: getXAttr in class AbstractFileSystem Parameters:path - Path to get extended attributename - xattr name. Returns:byte[] xattr value. Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path)                              throws IOException Description copied from class: AbstractFileSystem Get all of the xattrs for a file or directory.  Only those xattrs for which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Overrides: getXAttrs in class AbstractFileSystem Parameters:path - Path to get extended attributes Returns:Map describing the XAttrs of the file or directory Throws: IOException getXAttrs public Map<String,byte[]> getXAttrs(Path path,                            List<String> names)                              throws IOException Description copied from class: AbstractFileSystem Get all of the xattrs for a file or directory.  Only those xattrs for which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Overrides: getXAttrs in class AbstractFileSystem Parameters:path - Path to get extended attributesnames - XAttr names. Returns:Map describing the XAttrs of the file or directory Throws: IOException listXAttrs public List<String> listXAttrs(Path path)                         throws IOException Description copied from class: AbstractFileSystem Get all of the xattr names for a file or directory.  Only the xattr names for which the logged-in user has permissions to view  are returned.    Refer to the HDFS extended attributes user documentation for details. Overrides: listXAttrs in class AbstractFileSystem Parameters:path - Path to get extended attributes Returns:Map describing the XAttrs of the file or directory Throws: IOException removeXAttr public void removeXAttr(Path path,                String name)                  throws IOException Description copied from class: AbstractFileSystem Remove an xattr of a file or directory.  The name must be prefixed with the namespace followed by ".". For example,  "user.attr".    Refer to the HDFS extended attributes user documentation for details. Overrides: removeXAttr in class AbstractFileSystem Parameters:path - Path to remove extended attributename - xattr name Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  VolumeId (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="VolumeId (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs Interface VolumeId All Superinterfaces: Comparable<VolumeId> All Known Implementing Classes: HdfsVolumeId @InterfaceStability.Unstable @InterfaceAudience.Public public interface VolumeId extends Comparable<VolumeId> Opaque interface that identifies a disk location. Subclasses  should implement Comparable and override both equals and hashCode. Method Summary Methods  Modifier and Type Method and Description int compareTo(VolumeId arg0)  boolean equals(Object obj)  int hashCode()  Method Detail compareTo int compareTo(VolumeId arg0) Specified by: compareTo in interface Comparable<VolumeId> hashCode int hashCode() Overrides: hashCode in class Object equals boolean equals(Object obj) Overrides: equals in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Wasb (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Wasb (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.azure Class Wasb java.lang.Object org.apache.hadoop.fs.AbstractFileSystem org.apache.hadoop.fs.DelegateToFileSystem org.apache.hadoop.fs.azure.Wasb @InterfaceAudience.Public @InterfaceStability.Evolving public class Wasb extends org.apache.hadoop.fs.DelegateToFileSystem WASB implementation of AbstractFileSystem.  This impl delegates to the old FileSystem Field Summary Fields inherited from class org.apache.hadoop.fs.DelegateToFileSystem fsImpl Fields inherited from class org.apache.hadoop.fs.AbstractFileSystem statistics Method Summary Methods  Modifier and Type Method and Description int getUriDefaultPort() The default port of this file system. Methods inherited from class org.apache.hadoop.fs.DelegateToFileSystem createInternal, createSymlink, delete, getCanonicalServiceName, getDelegationTokens, getFileBlockLocations, getFileChecksum, getFileLinkStatus, getFileStatus, getFsStatus, getFsStatus, getHomeDirectory, getInitialWorkingDirectory, getLinkTarget, getServerDefaults, listStatus, mkdir, open, renameInternal, setOwner, setPermission, setReplication, setTimes, setVerifyChecksum, supportsSymlinks, truncate Methods inherited from class org.apache.hadoop.fs.AbstractFileSystem checkPath, checkScheme, clearStatistics, create, createFileSystem, equals, get, getAclStatus, getAllStatistics, getStatistics, getStatistics, getUri, getUriPath, getXAttr, getXAttrs, getXAttrs, hashCode, isValidName, listCorruptFileBlocks, listLocatedStatus, listStatusIterator, listXAttrs, makeQualified, modifyAclEntries, open, printStatistics, removeAcl, removeAclEntries, removeDefaultAcl, removeXAttr, rename, renameInternal, resolvePath, setAcl, setXAttr, setXAttr Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Method Detail getUriDefaultPort public int getUriDefaultPort() Description copied from class: AbstractFileSystem The default port of this file system. Overrides: getUriDefaultPort in class org.apache.hadoop.fs.DelegateToFileSystem Returns:default port of this file system's Uri scheme          A uri with a port of -1 => default port; Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WasbFsck (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WasbFsck (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.fs.azure Class WasbFsck java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.fs.azure.WasbFsck All Implemented Interfaces: Configurable, Tool @InterfaceAudience.Public @InterfaceStability.Evolving public class WasbFsck extends Configured implements Tool An fsck tool implementation for WASB that does various admin/cleanup/recovery  tasks on the WASB file system. Constructor Summary Constructors  Constructor and Description WasbFsck(Configuration conf)  Method Summary Methods  Modifier and Type Method and Description boolean getPathNameWarning()  static void main(String[] args)  int run(String[] args) Execute the command with the given arguments. void setMockFileSystemForTesting(FileSystem fileSystem) For testing purposes, set the file system to use here instead of relying on  getting it from the FileSystem class based on the URI. Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface org.apache.hadoop.conf.Configurable getConf, setConf Constructor Detail WasbFsck public WasbFsck(Configuration conf) Method Detail setMockFileSystemForTesting public void setMockFileSystemForTesting(FileSystem fileSystem) For testing purposes, set the file system to use here instead of relying on  getting it from the FileSystem class based on the URI. Parameters:fileSystem - The file system to use. run public int run(String[] args)         throws Exception Description copied from interface: Tool Execute the command with the given arguments. Specified by: run in interface Tool Parameters:args - command specific arguments. Returns:exit code. Throws: Exception getPathNameWarning public boolean getPathNameWarning() main public static void main(String[] args)                  throws Exception Throws: Exception Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WrappedMapper (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WrappedMapper (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.map Class WrappedMapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> java.lang.Object org.apache.hadoop.mapreduce.Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> org.apache.hadoop.mapreduce.lib.map.WrappedMapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Evolving public class WrappedMapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> A Mapper which wraps a given one to allow custom   Mapper.Context implementations. Constructor Summary Constructors  Constructor and Description WrappedMapper()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.mapreduce.Mapper.Context getMapContext(MapContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> mapContext) Get a wrapped Mapper.Context for custom implementations. Methods inherited from class org.apache.hadoop.mapreduce.Mapper cleanup, map, run, setup Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail WrappedMapper public WrappedMapper() Method Detail getMapContext public org.apache.hadoop.mapreduce.Mapper.Context getMapContext(MapContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> mapContext) Get a wrapped Mapper.Context for custom implementations. Parameters:mapContext - MapContext to be wrapped Returns:a wrapped Mapper.Context for custom implementations Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WrappedRecordReader (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WrappedRecordReader (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.join Class WrappedRecordReader<K extends WritableComparable<?>,U extends Writable> java.lang.Object org.apache.hadoop.mapreduce.RecordReader<K,V> org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader<K,U> org.apache.hadoop.mapreduce.lib.join.WrappedRecordReader<K,U> All Implemented Interfaces: Closeable, AutoCloseable, Comparable<ComposableRecordReader<K,?>> @InterfaceAudience.Public @InterfaceStability.Stable public class WrappedRecordReader<K extends WritableComparable<?>,U extends Writable> extends ComposableRecordReader<K,U> Proxy class for a RecordReader participating in the join framework.    This class keeps track of the "head" key-value pair for the  provided RecordReader and keeps a store of values matching a key when  this source is participating in a join. Field Summary Fields  Modifier and Type Field and Description protected WritableComparator cmp  protected boolean empty  Constructor Summary Constructors  Modifier Constructor and Description protected  WrappedRecordReader(int id)  Method Summary Methods  Modifier and Type Method and Description void accept(org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector i,             K key) Add an iterator to the collector at the position occupied by this  RecordReader over the values in this stream paired with the key  provided (ie register a stream of values from this source matching K  with a collector). void close() Forward close request to proxied RR. int compareTo(ComposableRecordReader<K,?> other) Implement Comparable contract (compare key at head of proxied RR  with that of another). K createKey() Request new key from proxied RR. U createValue() Create instance of value. boolean equals(Object other) Return true iff compareTo(other) retn true. K getCurrentKey() Get current key U getCurrentValue() Get current value float getProgress() Request progress from proxied RR. int hashCode()  boolean hasNext() Return true if the RR- including the k,v pair stored in this object-  is exhausted. int id() Return the position in the collector this class occupies. void initialize(InputSplit split,                     TaskAttemptContext context) Called once at initialization. K key() Return the key at the head of this RR. void key(K qkey) Clone the key at the head of this RR into the object supplied. boolean nextKeyValue() Read the next k,v pair into the head of this object; return true iff  the RR and this are exhausted. void skip(K key) Skip key-value pairs with keys less than or equal to the key provided. Methods inherited from class java.lang.Object clone, finalize, getClass, notify, notifyAll, toString, wait, wait, wait Field Detail empty protected boolean empty cmp protected WritableComparator cmp Constructor Detail WrappedRecordReader protected WrappedRecordReader(int id) Method Detail initialize public void initialize(InputSplit split,               TaskAttemptContext context)                 throws IOException,                        InterruptedException Description copied from class: RecordReader Called once at initialization. Specified by: initialize in class RecordReader<K extends WritableComparable<?>,U extends Writable> Parameters:split - the split that defines the range of records to readcontext - the information about the task Throws: IOException InterruptedException createKey public K createKey() Request new key from proxied RR. createValue public U createValue() Description copied from class: ComposableRecordReader Create instance of value. id public int id() Return the position in the collector this class occupies. key public K key() Return the key at the head of this RR. key public void key(K qkey)          throws IOException Clone the key at the head of this RR into the object supplied. Throws: IOException hasNext public boolean hasNext() Return true if the RR- including the k,v pair stored in this object-  is exhausted. skip public void skip(K key)           throws IOException,                  InterruptedException Skip key-value pairs with keys less than or equal to the key provided. Throws: IOException InterruptedException accept public void accept(org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector i,           K key)             throws IOException,                    InterruptedException Add an iterator to the collector at the position occupied by this  RecordReader over the values in this stream paired with the key  provided (ie register a stream of values from this source matching K  with a collector). Throws: IOException InterruptedException nextKeyValue public boolean nextKeyValue()                      throws IOException,                             InterruptedException Read the next k,v pair into the head of this object; return true iff  the RR and this are exhausted. Specified by: nextKeyValue in class RecordReader<K extends WritableComparable<?>,U extends Writable> Returns:true if a key/value pair was read Throws: IOException InterruptedException getCurrentKey public K getCurrentKey()                                               throws IOException,                                                      InterruptedException Get current key Specified by: getCurrentKey in class RecordReader<K extends WritableComparable<?>,U extends Writable> Returns:the current key or null if there is no current key Throws: IOException InterruptedException getCurrentValue public U getCurrentValue()                                    throws IOException,                                           InterruptedException Get current value Specified by: getCurrentValue in class RecordReader<K extends WritableComparable<?>,U extends Writable> Returns:the object that was read Throws: IOException InterruptedException getProgress public float getProgress()                   throws IOException,                          InterruptedException Request progress from proxied RR. Specified by: getProgress in class RecordReader<K extends WritableComparable<?>,U extends Writable> Returns:a number between 0.0 and 1.0 that is the fraction of the data read Throws: IOException InterruptedException close public void close()            throws IOException Forward close request to proxied RR. Specified by: close in interface Closeable Specified by: close in interface AutoCloseable Specified by: close in class RecordReader<K extends WritableComparable<?>,U extends Writable> Throws: IOException compareTo public int compareTo(ComposableRecordReader<K,?> other) Implement Comparable contract (compare key at head of proxied RR  with that of another). equals public boolean equals(Object other) Return true iff compareTo(other) retn true. Overrides: equals in class Object hashCode public int hashCode() Overrides: hashCode in class Object Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WrappedReducer (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WrappedReducer (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.mapreduce.lib.reduce Class WrappedReducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> java.lang.Object org.apache.hadoop.mapreduce.Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> @InterfaceAudience.Public @InterfaceStability.Evolving public class WrappedReducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> extends Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> A Reducer which wraps a given one to allow for custom   Reducer.Context implementations. Constructor Summary Constructors  Constructor and Description WrappedReducer()  Method Summary Methods  Modifier and Type Method and Description org.apache.hadoop.mapreduce.Reducer.Context getReducerContext(ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> reduceContext) A a wrapped Reducer.Context for custom implementations. Methods inherited from class org.apache.hadoop.mapreduce.Reducer cleanup, reduce, run, setup Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail WrappedReducer public WrappedReducer() Method Detail getReducerContext public org.apache.hadoop.mapreduce.Reducer.Context getReducerContext(ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> reduceContext) A a wrapped Reducer.Context for custom implementations. Parameters:reduceContext - ReduceContext to be wrapped Returns:a wrapped Reducer.Context for custom implementations Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  Writable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="Writable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Interface Writable All Known Subinterfaces: Counter, CounterGroup, CounterGroupBase<T>, InputSplit, InputSplitWithLocationInfo, WritableComparable<T> All Known Implementing Classes: AbstractCounters, org.apache.hadoop.security.token.delegation.AbstractDelegationTokenIdentifier, AbstractMapWritable, AccessControlList, AggregatedLogFormat.LogKey, AMRMTokenIdentifier, ArrayPrimitiveWritable, ArrayWritable, BloomFilter, BooleanWritable, BytesWritable, ByteWritable, ClientToAMTokenIdentifier, ClusterMetrics, ClusterStatus, CombineFileSplit, CombineFileSplit, CompositeInputSplit, CompositeInputSplit, CompressedWritable, Configuration, ContainerTokenIdentifier, ContentSummary, Counters, Counters, Counters.Counter, Counters.Group, CountingBloomFilter, DoubleWritable, DynamicBloomFilter, EnumSetWritable, FileChecksum, FileSplit, FileSplit, FileStatus, org.apache.hadoop.util.bloom.Filter, FloatWritable, FsPermission, FsServerDefaults, FsStatus, GenericWritable, ID, ID, IntWritable, JobConf, JobID, JobID, JobQueueInfo, JobStatus, JobStatus, LocatedFileStatus, LongWritable, MapWritable, MD5Hash, MultiFileSplit, NMTokenIdentifier, NullWritable, ObjectWritable, QueueAclsInfo, QueueInfo, Record, RecordTypeInfo, RetouchedBloomFilter, RMDelegationTokenIdentifier, ShortWritable, SortedMapWritable, TaskAttemptID, TaskAttemptID, TaskCompletionEvent, TaskCompletionEvent, TaskID, TaskID, org.apache.hadoop.mapreduce.TaskReport, TaskReport, TaskTrackerInfo, Text, TimelineDelegationTokenIdentifier, org.apache.hadoop.security.token.TokenIdentifier, TupleWritable, TupleWritable, TwoDArrayWritable, VersionedWritable, VIntWritable, VLongWritable, YarnConfiguration, org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier @InterfaceAudience.Public @InterfaceStability.Stable public interface Writable A serializable object which implements a simple, efficient, serialization   protocol, based on DataInput and DataOutput.  Any key or value type in the Hadoop Map-Reduce  framework implements this interface.    Implementations typically implement a static read(DataInput)  method which constructs a new instance, calls readFields(DataInput)   and returns the instance.    Example:        public class MyWritable implements Writable {        // Some data             private int counter;        private long timestamp;                public void write(DataOutput out) throws IOException {          out.writeInt(counter);          out.writeLong(timestamp);        }                public void readFields(DataInput in) throws IOException {          counter = in.readInt();          timestamp = in.readLong();        }                public static MyWritable read(DataInput in) throws IOException {          MyWritable w = new MyWritable();          w.readFields(in);          return w;        }      }   Method Summary Methods  Modifier and Type Method and Description void readFields(DataInput in) Deserialize the fields of this object from in. void write(DataOutput out) Serialize the fields of this object to out. Method Detail write void write(DataOutput out)            throws IOException Serialize the fields of this object to out. Parameters:out - DataOuput to serialize this object into. Throws: IOException readFields void readFields(DataInput in)                 throws IOException Deserialize the fields of this object from in.      For efficiency, implementations should attempt to re-use storage in the   existing object where possible. Parameters:in - DataInput to deseriablize this object from. Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WritableComparable (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WritableComparable (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Interface WritableComparable<T> All Superinterfaces: Comparable<T>, Writable All Known Implementing Classes: BooleanWritable, BytesWritable, ByteWritable, DoubleWritable, FloatWritable, ID, ID, IntWritable, JobID, JobID, LongWritable, MD5Hash, NullWritable, Record, RecordTypeInfo, ShortWritable, TaskAttemptID, TaskAttemptID, TaskID, TaskID, Text, VIntWritable, VLongWritable @InterfaceAudience.Public @InterfaceStability.Stable public interface WritableComparable<T> extends Writable, Comparable<T> A Writable which is also Comparable.   WritableComparables can be compared to each other, typically   via Comparators. Any type which is to be used as a   key in the Hadoop Map-Reduce framework should implement this  interface.  Note that hashCode() is frequently used in Hadoop to partition  keys. It's important that your implementation of hashCode() returns the same   result across different instances of the JVM. Note also that the default   hashCode() implementation in Object does not  satisfy this property.     Example:        public class MyWritableComparable implements WritableComparable {        // Some data        private int counter;        private long timestamp;                public void write(DataOutput out) throws IOException {          out.writeInt(counter);          out.writeLong(timestamp);        }                public void readFields(DataInput in) throws IOException {          counter = in.readInt();          timestamp = in.readLong();        }                public int compareTo(MyWritableComparable o) {          int thisValue = this.value;          int thatValue = o.value;          return (thisValue < thatValue ? -1 : (thisValue==thatValue ? 0 : 1));        }        public int hashCode() {          final int prime = 31;          int result = 1;          result = prime * result + counter;          result = prime * result + (int) (timestamp ^ (timestamp >>> 32));          return result        }      }   Method Summary Methods inherited from interface org.apache.hadoop.io.Writable readFields, write Methods inherited from interface java.lang.Comparable compareTo Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WritableComparator (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WritableComparator (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class WritableComparator java.lang.Object org.apache.hadoop.io.WritableComparator All Implemented Interfaces: Comparator, Configurable, RawComparator Direct Known Subclasses: KeyFieldBasedComparator, RecordComparator @InterfaceAudience.Public @InterfaceStability.Stable public class WritableComparator extends Object implements RawComparator, Configurable A Comparator for WritableComparables.  This base implemenation uses the natural ordering.  To define alternate  orderings, override compare(WritableComparable,WritableComparable).  One may optimize compare-intensive operations by overriding  compare(byte[],int,int,byte[],int,int).  Static utility methods are  provided to assist in optimized implementations of this method. Constructor Summary Constructors  Modifier Constructor and Description protected  WritableComparator()  protected  WritableComparator(Class<? extends WritableComparable> keyClass) Construct for a WritableComparable implementation. protected  WritableComparator(Class<? extends WritableComparable> keyClass,                                     boolean createInstances)  protected  WritableComparator(Class<? extends WritableComparable> keyClass,                                     Configuration conf,                                     boolean createInstances)  Method Summary Methods  Modifier and Type Method and Description int compare(byte[] b1,               int s1,               int l1,               byte[] b2,               int s2,               int l2) Optimization hook. int compare(Object a,               Object b)  int compare(WritableComparable a,               WritableComparable b) Compare two WritableComparables. static int compareBytes(byte[] b1,                         int s1,                         int l1,                         byte[] b2,                         int s2,                         int l2) Lexicographic order of binary data. static void define(Class c,             WritableComparator comparator) Register an optimized comparator for a WritableComparable  implementation. static WritableComparator get(Class<? extends WritableComparable> c) For backwards compatibility. static WritableComparator get(Class<? extends WritableComparable> c,       Configuration conf) Get a comparator for a WritableComparable implementation. Configuration getConf() Return the configuration used by this object. Class<? extends WritableComparable> getKeyClass() Returns the WritableComparable implementation class. static int hashBytes(byte[] bytes,                   int length) Compute hash for binary data. static int hashBytes(byte[] bytes,                   int offset,                   int length) Compute hash for binary data. WritableComparable newKey() Construct a new WritableComparable instance. static double readDouble(byte[] bytes,                     int start) Parse a double from a byte array. static float readFloat(byte[] bytes,                   int start) Parse a float from a byte array. static int readInt(byte[] bytes,               int start) Parse an integer from a byte array. static long readLong(byte[] bytes,                 int start) Parse a long from a byte array. static int readUnsignedShort(byte[] bytes,                                   int start) Parse an unsigned short from a byte array. static int readVInt(byte[] bytes,                 int start) Reads a zero-compressed encoded integer from a byte array and returns it. static long readVLong(byte[] bytes,                   int start) Reads a zero-compressed encoded long from a byte array and returns it. void setConf(Configuration conf) Set the configuration to be used by this object. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Methods inherited from interface java.util.Comparator equals Constructor Detail WritableComparator protected WritableComparator() WritableComparator protected WritableComparator(Class<? extends WritableComparable> keyClass) Construct for a WritableComparable implementation. WritableComparator protected WritableComparator(Class<? extends WritableComparable> keyClass,                   boolean createInstances) WritableComparator protected WritableComparator(Class<? extends WritableComparable> keyClass,                   Configuration conf,                   boolean createInstances) Method Detail get public static WritableComparator get(Class<? extends WritableComparable> c) For backwards compatibility. get public static WritableComparator get(Class<? extends WritableComparable> c,                      Configuration conf) Get a comparator for a WritableComparable implementation. setConf public void setConf(Configuration conf) Description copied from interface: Configurable Set the configuration to be used by this object. Specified by: setConf in interface Configurable getConf public Configuration getConf() Description copied from interface: Configurable Return the configuration used by this object. Specified by: getConf in interface Configurable define public static void define(Class c,           WritableComparator comparator) Register an optimized comparator for a WritableComparable  implementation. Comparators registered with this method must be  thread-safe. getKeyClass public Class<? extends WritableComparable> getKeyClass() Returns the WritableComparable implementation class. newKey public WritableComparable newKey() Construct a new WritableComparable instance. compare public int compare(byte[] b1,           int s1,           int l1,           byte[] b2,           int s2,           int l2) Optimization hook.  Override this to make SequenceFile.Sorter's scream.  The default implementation reads the data into two WritableComparables (using Writable.readFields(DataInput), then calls compare(WritableComparable,WritableComparable). Specified by: compare in interface RawComparator Parameters:b1 - The first byte array.s1 - The position index in b1. The object under comparison's starting index.l1 - The length of the object in b1.b2 - The second byte array.s2 - The position index in b2. The object under comparison's starting index.l2 - The length of the object under comparison in b2. Returns:An integer result of the comparison. compare public int compare(WritableComparable a,           WritableComparable b) Compare two WritableComparables.   The default implementation uses the natural ordering, calling Comparable.compareTo(Object). compare public int compare(Object a,           Object b) Specified by: compare in interface Comparator compareBytes public static int compareBytes(byte[] b1,                int s1,                int l1,                byte[] b2,                int s2,                int l2) Lexicographic order of binary data. hashBytes public static int hashBytes(byte[] bytes,             int offset,             int length) Compute hash for binary data. hashBytes public static int hashBytes(byte[] bytes,             int length) Compute hash for binary data. readUnsignedShort public static int readUnsignedShort(byte[] bytes,                     int start) Parse an unsigned short from a byte array. readInt public static int readInt(byte[] bytes,           int start) Parse an integer from a byte array. readFloat public static float readFloat(byte[] bytes,               int start) Parse a float from a byte array. readLong public static long readLong(byte[] bytes,             int start) Parse a long from a byte array. readDouble public static double readDouble(byte[] bytes,                 int start) Parse a double from a byte array. readVLong public static long readVLong(byte[] bytes,              int start)                       throws IOException Reads a zero-compressed encoded long from a byte array and returns it. Parameters:bytes - byte array with decode longstart - starting index Returns:deserialized long Throws: IOException readVInt public static int readVInt(byte[] bytes,            int start)                     throws IOException Reads a zero-compressed encoded integer from a byte array and returns it. Parameters:bytes - byte array with the encoded integerstart - start index Returns:deserialized integer Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WritableFactories (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WritableFactories (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class WritableFactories java.lang.Object org.apache.hadoop.io.WritableFactories @InterfaceAudience.Public @InterfaceStability.Stable public class WritableFactories extends Object Factories for non-public writables.  Defining a factory permits ObjectWritable to be able to construct instances of non-public classes. Method Summary Methods  Modifier and Type Method and Description static WritableFactory getFactory(Class c) Define a factory for a class. static Writable newInstance(Class<? extends Writable> c) Create a new instance of a class with a defined factory. static Writable newInstance(Class<? extends Writable> c,                       Configuration conf) Create a new instance of a class with a defined factory. static void setFactory(Class c,                     WritableFactory factory) Define a factory for a class. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Method Detail setFactory public static void setFactory(Class c,               WritableFactory factory) Define a factory for a class. getFactory public static WritableFactory getFactory(Class c) Define a factory for a class. newInstance public static Writable newInstance(Class<? extends Writable> c,                    Configuration conf) Create a new instance of a class with a defined factory. newInstance public static Writable newInstance(Class<? extends Writable> c) Create a new instance of a class with a defined factory. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WritableFactory (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WritableFactory (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Interface WritableFactory @InterfaceAudience.Public @InterfaceStability.Stable public interface WritableFactory A factory for a class of Writable. See Also:WritableFactories Method Summary Methods  Modifier and Type Method and Description Writable newInstance() Return a new instance. Method Detail newInstance Writable newInstance() Return a new instance. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WritableSerialization (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WritableSerialization (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io.serializer Class WritableSerialization java.lang.Object org.apache.hadoop.conf.Configured org.apache.hadoop.io.serializer.WritableSerialization All Implemented Interfaces: Configurable, org.apache.hadoop.io.serializer.Serialization<Writable> @InterfaceAudience.Public @InterfaceStability.Evolving public class WritableSerialization extends Configured implements org.apache.hadoop.io.serializer.Serialization<Writable> A Serialization for Writables that delegates to  Writable.write(java.io.DataOutput) and  Writable.readFields(java.io.DataInput). Constructor Summary Constructors  Constructor and Description WritableSerialization()  Method Summary Methods inherited from class org.apache.hadoop.conf.Configured getConf, setConf Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail WritableSerialization public WritableSerialization() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  WritableUtils (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="WritableUtils (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.io Class WritableUtils java.lang.Object org.apache.hadoop.io.WritableUtils @InterfaceAudience.Public @InterfaceStability.Stable public final class WritableUtils extends Object Constructor Summary Constructors  Constructor and Description WritableUtils()  Method Summary Methods  Modifier and Type Method and Description static <T extends Writable> T clone(T orig,           Configuration conf) Make a copy of a writable object using serialization to a buffer. static void cloneInto(Writable dst,                   Writable src) Deprecated.  use ReflectionUtils.cloneInto instead. static int decodeVIntSize(byte value) Parse the first byte of a vint/vlong to determine the number of bytes static void displayByteArray(byte[] record)  static int getVIntSize(long i) Get the encoded length if an integer is stored in a variable-length format static boolean isNegativeVInt(byte value) Given the first byte of a vint/vlong, determine the sign static byte[] readCompressedByteArray(DataInput in)  static String readCompressedString(DataInput in)  static String[] readCompressedStringArray(DataInput in)  static <T extends Enum<T>> T readEnum(DataInput in,                 Class<T> enumType) Read an Enum value from DataInput, Enums are read and written   using String values. static String readString(DataInput in)  static String[] readStringArray(DataInput in)  static String readStringSafely(DataInput in,                                 int maxLength) Read a string, but check it for sanity. static int readVInt(DataInput stream) Reads a zero-compressed encoded integer from input stream and returns it. static int readVIntInRange(DataInput stream,                               int lower,                               int upper) Reads an integer from the input stream and returns it. static long readVLong(DataInput stream) Reads a zero-compressed encoded long from input stream and returns it. static void skipCompressedByteArray(DataInput in)  static void skipFully(DataInput in,                   int len) Skip len number of bytes in input streamin static byte[] toByteArray(Writable... writables) Convert writables to a byte array static int writeCompressedByteArray(DataOutput out,                                                 byte[] bytes)  static int writeCompressedString(DataOutput out,                                           String s)  static void writeCompressedStringArray(DataOutput out,                                                     String[] s)  static void writeEnum(DataOutput out,                   Enum<?> enumVal) writes String value of enum to DataOutput. static void writeString(DataOutput out,                       String s)  static void writeStringArray(DataOutput out,                                 String[] s)  static void writeVInt(DataOutput stream,                   int i) Serializes an integer to a binary stream with zero-compressed encoding. static void writeVLong(DataOutput stream,                     long i) Serializes a long to a binary stream with zero-compressed encoding. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail WritableUtils public WritableUtils() Method Detail readCompressedByteArray public static byte[] readCompressedByteArray(DataInput in)                                       throws IOException Throws: IOException skipCompressedByteArray public static void skipCompressedByteArray(DataInput in)                                     throws IOException Throws: IOException writeCompressedByteArray public static int writeCompressedByteArray(DataOutput out,                            byte[] bytes)                                     throws IOException Throws: IOException readCompressedString public static String readCompressedString(DataInput in)                                    throws IOException Throws: IOException writeCompressedString public static int writeCompressedString(DataOutput out,                         String s)                                  throws IOException Throws: IOException writeString public static void writeString(DataOutput out,                String s)                         throws IOException Throws: IOException readString public static String readString(DataInput in)                          throws IOException Throws: IOException writeStringArray public static void writeStringArray(DataOutput out,                     String[] s)                              throws IOException Throws: IOException writeCompressedStringArray public static void writeCompressedStringArray(DataOutput out,                               String[] s)                                        throws IOException Throws: IOException readStringArray public static String[] readStringArray(DataInput in)                                 throws IOException Throws: IOException readCompressedStringArray public static String[] readCompressedStringArray(DataInput in)                                           throws IOException Throws: IOException displayByteArray public static void displayByteArray(byte[] record) clone public static <T extends Writable> T clone(T orig,                            Configuration conf) Make a copy of a writable object using serialization to a buffer. Parameters:orig - The object to copy Returns:The copied object cloneInto @Deprecated public static void cloneInto(Writable dst,                         Writable src)                       throws IOException Deprecated. use ReflectionUtils.cloneInto instead. Make a copy of the writable object using serialiation to a buffer Parameters:dst - the object to copy fromsrc - the object to copy into, which is destroyed Throws: IOException writeVInt public static void writeVInt(DataOutput stream,              int i)                       throws IOException Serializes an integer to a binary stream with zero-compressed encoding.  For -112 <= i <= 127, only one byte is used with the actual value.  For other values of i, the first byte value indicates whether the  integer is positive or negative, and the number of bytes that follow.  If the first byte value v is between -113 and -116, the following integer  is positive, with number of bytes that follow are -(v+112).  If the first byte value v is between -121 and -124, the following integer  is negative, with number of bytes that follow are -(v+120). Bytes are  stored in the high-non-zero-byte-first order. Parameters:stream - Binary output streami - Integer to be serialized Throws: IOException writeVLong public static void writeVLong(DataOutput stream,               long i)                        throws IOException Serializes a long to a binary stream with zero-compressed encoding.  For -112 <= i <= 127, only one byte is used with the actual value.  For other values of i, the first byte value indicates whether the  long is positive or negative, and the number of bytes that follow.  If the first byte value v is between -113 and -120, the following long  is positive, with number of bytes that follow are -(v+112).  If the first byte value v is between -121 and -128, the following long  is negative, with number of bytes that follow are -(v+120). Bytes are  stored in the high-non-zero-byte-first order. Parameters:stream - Binary output streami - Long to be serialized Throws: IOException readVLong public static long readVLong(DataInput stream)                       throws IOException Reads a zero-compressed encoded long from input stream and returns it. Parameters:stream - Binary input stream Returns:deserialized long from stream. Throws: IOException readVInt public static int readVInt(DataInput stream)                     throws IOException Reads a zero-compressed encoded integer from input stream and returns it. Parameters:stream - Binary input stream Returns:deserialized integer from stream. Throws: IOException readVIntInRange public static int readVIntInRange(DataInput stream,                   int lower,                   int upper)                            throws IOException Reads an integer from the input stream and returns it.  This function validates that the integer is between [lower, upper],  inclusive. Parameters:stream - Binary input stream Returns:deserialized integer from stream Throws: IOException isNegativeVInt public static boolean isNegativeVInt(byte value) Given the first byte of a vint/vlong, determine the sign Parameters:value - the first byte Returns:is the value negative decodeVIntSize public static int decodeVIntSize(byte value) Parse the first byte of a vint/vlong to determine the number of bytes Parameters:value - the first byte of the vint/vlong Returns:the total number of bytes (1 to 9) getVIntSize public static int getVIntSize(long i) Get the encoded length if an integer is stored in a variable-length format Returns:the encoded length readEnum public static <T extends Enum<T>> T readEnum(DataInput in,                              Class<T> enumType)                                throws IOException Read an Enum value from DataInput, Enums are read and written   using String values. Type Parameters:T - Enum typeParameters:in - DataInput to read fromenumType - Class type of Enum Returns:Enum represented by String read from DataInput Throws: IOException writeEnum public static void writeEnum(DataOutput out,              Enum<?> enumVal)                       throws IOException writes String value of enum to DataOutput. Parameters:out - Dataoutput streamenumVal - enum value Throws: IOException skipFully public static void skipFully(DataInput in,              int len)                       throws IOException Skip len number of bytes in input streamin Parameters:in - input streamlen - number of bytes to skip Throws: IOException - when skipped less number of bytes toByteArray public static byte[] toByteArray(Writable... writables) Convert writables to a byte array readStringSafely public static String readStringSafely(DataInput in,                       int maxLength)                                throws IOException,                                       IllegalArgumentException Read a string, but check it for sanity. The format consists of a vint  followed by the given number of bytes. Parameters:in - the stream to read frommaxLength - the largest acceptable length of the encoded string Returns:the bytes as a string Throws: IOException - if reading from the DataInput fails IllegalArgumentException - if the encoded byte size for string               is negative or larger than maxSize. Only the vint is read. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  XAttrCodec (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="XAttrCodec (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.fs Enum XAttrCodec java.lang.Object java.lang.Enum<XAttrCodec> org.apache.hadoop.fs.XAttrCodec All Implemented Interfaces: Serializable, Comparable<XAttrCodec> @InterfaceAudience.Public @InterfaceStability.Stable public enum XAttrCodec extends Enum<XAttrCodec> The value of XAttr is byte[], this class is to   covert byte[] to some kind of string representation or convert back.  String representation is convenient for display and input. For example  display in screen as shell response and json response, input as http  or shell parameter. Enum Constant Summary Enum Constants  Enum Constant and Description BASE64 Value encoded as base64 string   is prefixed with 0s. HEX Value encoded as hexadecimal string   is prefixed with 0x. TEXT Value encoded as text   string is enclosed in double quotes (\"). Method Summary Methods  Modifier and Type Method and Description static byte[] decodeValue(String value) Decode string representation of a value and check whether it's   encoded. static String encodeValue(byte[] value,                       XAttrCodec encoding) Encode byte[] value to string representation with encoding. static XAttrCodec valueOf(String name) Returns the enum constant of this type with the specified name. static XAttrCodec[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail TEXT public static final XAttrCodec TEXT Value encoded as text   string is enclosed in double quotes (\"). HEX public static final XAttrCodec HEX Value encoded as hexadecimal string   is prefixed with 0x. BASE64 public static final XAttrCodec BASE64 Value encoded as base64 string   is prefixed with 0s. Method Detail values public static XAttrCodec[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (XAttrCodec c : XAttrCodec.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static XAttrCodec valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null decodeValue public static byte[] decodeValue(String value)                           throws IOException Decode string representation of a value and check whether it's   encoded. If the given string begins with 0x or 0X, it expresses  a hexadecimal number. If the given string begins with 0s or 0S,  base64 encoding is expected. If the given string is enclosed in   double quotes, the inner string is treated as text. Otherwise   the given string is treated as text. Parameters:value - string representation of the value. Returns:byte[] the value Throws: IOException encodeValue public static String encodeValue(byte[] value,                  XAttrCodec encoding)                           throws IOException Encode byte[] value to string representation with encoding.   Values encoded as text strings are enclosed in double quotes (\"),   while strings encoded as hexadecimal and base64 are prefixed with   0x and 0s, respectively. Parameters:value - byte[] valueencoding -  Returns:String string representation of value Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  XAttrSetFlag (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="XAttrSetFlag (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.fs Enum XAttrSetFlag java.lang.Object java.lang.Enum<XAttrSetFlag> org.apache.hadoop.fs.XAttrSetFlag All Implemented Interfaces: Serializable, Comparable<XAttrSetFlag> @InterfaceAudience.Public @InterfaceStability.Stable public enum XAttrSetFlag extends Enum<XAttrSetFlag> Enum Constant Summary Enum Constants  Enum Constant and Description CREATE Create a new xattr. REPLACE Replace a existing xattr. Method Summary Methods  Modifier and Type Method and Description static void validate(String xAttrName,                 boolean xAttrExists,                 EnumSet<XAttrSetFlag> flag)  static XAttrSetFlag valueOf(String name) Returns the enum constant of this type with the specified name. static XAttrSetFlag[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail CREATE public static final XAttrSetFlag CREATE Create a new xattr.  If the xattr exists already, exception will be thrown. REPLACE public static final XAttrSetFlag REPLACE Replace a existing xattr.  If the xattr does not exist, exception will be thrown. Method Detail values public static XAttrSetFlag[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (XAttrSetFlag c : XAttrSetFlag.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static XAttrSetFlag valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null validate public static void validate(String xAttrName,             boolean xAttrExists,             EnumSet<XAttrSetFlag> flag)                      throws IOException Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  XmlRecordInput (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="XmlRecordInput (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class XmlRecordInput java.lang.Object org.apache.hadoop.record.XmlRecordInput All Implemented Interfaces: RecordInput Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class XmlRecordInput extends Object implements RecordInput XML Deserializer. Constructor Summary Constructors  Constructor and Description XmlRecordInput(InputStream in) Deprecated.  Creates a new instance of XmlRecordInput Method Summary Methods  Modifier and Type Method and Description void endMap(String tag) Deprecated.  Check the mark for end of the serialized map. void endRecord(String tag) Deprecated.  Check the mark for end of the serialized record. void endVector(String tag) Deprecated.  Check the mark for end of the serialized vector. boolean readBool(String tag) Deprecated.  Read a boolean from serialized record. Buffer readBuffer(String tag) Deprecated.  Read byte array from serialized record. byte readByte(String tag) Deprecated.  Read a byte from serialized record. double readDouble(String tag) Deprecated.  Read a double-precision number from serialized record. float readFloat(String tag) Deprecated.  Read a single-precision float from serialized record. int readInt(String tag) Deprecated.  Read an integer from serialized record. long readLong(String tag) Deprecated.  Read a long integer from serialized record. String readString(String tag) Deprecated.  Read a UTF-8 encoded string from serialized record. Index startMap(String tag) Deprecated.  Check the mark for start of the serialized map. void startRecord(String tag) Deprecated.  Check the mark for start of the serialized record. Index startVector(String tag) Deprecated.  Check the mark for start of the serialized vector. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail XmlRecordInput public XmlRecordInput(InputStream in) Deprecated.  Creates a new instance of XmlRecordInput Method Detail readByte public byte readByte(String tag)               throws IOException Deprecated.  Description copied from interface: RecordInput Read a byte from serialized record. Specified by: readByte in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readBool public boolean readBool(String tag)                  throws IOException Deprecated.  Description copied from interface: RecordInput Read a boolean from serialized record. Specified by: readBool in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readInt public int readInt(String tag)             throws IOException Deprecated.  Description copied from interface: RecordInput Read an integer from serialized record. Specified by: readInt in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readLong public long readLong(String tag)               throws IOException Deprecated.  Description copied from interface: RecordInput Read a long integer from serialized record. Specified by: readLong in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readFloat public float readFloat(String tag)                 throws IOException Deprecated.  Description copied from interface: RecordInput Read a single-precision float from serialized record. Specified by: readFloat in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readDouble public double readDouble(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Read a double-precision number from serialized record. Specified by: readDouble in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readString public String readString(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Read a UTF-8 encoded string from serialized record. Specified by: readString in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException readBuffer public Buffer readBuffer(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Read byte array from serialized record. Specified by: readBuffer in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:value read from serialized record. Throws: IOException startRecord public void startRecord(String tag)                  throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for start of the serialized record. Specified by: startRecord in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException endRecord public void endRecord(String tag)                throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for end of the serialized record. Specified by: endRecord in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException startVector public Index startVector(String tag)                   throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for start of the serialized vector. Specified by: startVector in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:Index that is used to count the number of elements. Throws: IOException endVector public void endVector(String tag)                throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for end of the serialized vector. Specified by: endVector in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException startMap public Index startMap(String tag)                throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for start of the serialized map. Specified by: startMap in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Returns:Index that is used to count the number of map entries. Throws: IOException endMap public void endMap(String tag)             throws IOException Deprecated.  Description copied from interface: RecordInput Check the mark for end of the serialized map. Specified by: endMap in interface RecordInput Parameters:tag - Used by tagged serialization formats (such as XML) Throws: IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  XmlRecordOutput (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="XmlRecordOutput (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.record Class XmlRecordOutput java.lang.Object org.apache.hadoop.record.XmlRecordOutput All Implemented Interfaces: RecordOutput Deprecated.  Replaced by Avro. @Deprecated @InterfaceAudience.Public @InterfaceStability.Stable public class XmlRecordOutput extends Object implements RecordOutput XML Serializer. Constructor Summary Constructors  Constructor and Description XmlRecordOutput(OutputStream out) Deprecated.  Creates a new instance of XmlRecordOutput Method Summary Methods  Modifier and Type Method and Description void endMap(TreeMap v,             String tag) Deprecated.  Mark the end of a serialized map. void endRecord(Record r,                   String tag) Deprecated.  Mark the end of a serialized record. void endVector(ArrayList v,                   String tag) Deprecated.  Mark the end of a serialized vector. void startMap(TreeMap v,                 String tag) Deprecated.  Mark the start of a map to be serialized. void startRecord(Record r,                       String tag) Deprecated.  Mark the start of a record to be serialized. void startVector(ArrayList v,                       String tag) Deprecated.  Mark the start of a vector to be serialized. void writeBool(boolean b,                   String tag) Deprecated.  Write a boolean to serialized record. void writeBuffer(Buffer buf,                       String tag) Deprecated.  Write a buffer to serialized record. void writeByte(byte b,                   String tag) Deprecated.  Write a byte to serialized record. void writeDouble(double d,                       String tag) Deprecated.  Write a double precision floating point number to serialized record. void writeFloat(float f,                     String tag) Deprecated.  Write a single-precision float to serialized record. void writeInt(int i,                 String tag) Deprecated.  Write an integer to serialized record. void writeLong(long l,                   String tag) Deprecated.  Write a long integer to serialized record. void writeString(String s,                       String tag) Deprecated.  Write a unicode string to serialized record. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail XmlRecordOutput public XmlRecordOutput(OutputStream out) Deprecated.  Creates a new instance of XmlRecordOutput Method Detail writeByte public void writeByte(byte b,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Write a byte to serialized record. Specified by: writeByte in interface RecordOutput Parameters:b - Byte to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeBool public void writeBool(boolean b,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Write a boolean to serialized record. Specified by: writeBool in interface RecordOutput Parameters:b - Boolean to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeInt public void writeInt(int i,             String tag)               throws IOException Deprecated.  Description copied from interface: RecordOutput Write an integer to serialized record. Specified by: writeInt in interface RecordOutput Parameters:i - Integer to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeLong public void writeLong(long l,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Write a long integer to serialized record. Specified by: writeLong in interface RecordOutput Parameters:l - Long to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeFloat public void writeFloat(float f,               String tag)                 throws IOException Deprecated.  Description copied from interface: RecordOutput Write a single-precision float to serialized record. Specified by: writeFloat in interface RecordOutput Parameters:f - Float to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeDouble public void writeDouble(double d,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Write a double precision floating point number to serialized record. Specified by: writeDouble in interface RecordOutput Parameters:d - Double to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeString public void writeString(String s,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Write a unicode string to serialized record. Specified by: writeString in interface RecordOutput Parameters:s - String to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization writeBuffer public void writeBuffer(Buffer buf,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Write a buffer to serialized record. Specified by: writeBuffer in interface RecordOutput Parameters:buf - Buffer to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startRecord public void startRecord(Record r,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the start of a record to be serialized. Specified by: startRecord in interface RecordOutput Parameters:r - Record to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endRecord public void endRecord(Record r,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the end of a serialized record. Specified by: endRecord in interface RecordOutput Parameters:r - Record to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startVector public void startVector(ArrayList v,                String tag)                  throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the start of a vector to be serialized. Specified by: startVector in interface RecordOutput Parameters:v - Vector to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endVector public void endVector(ArrayList v,              String tag)                throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the end of a serialized vector. Specified by: endVector in interface RecordOutput Parameters:v - Vector to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization startMap public void startMap(TreeMap v,             String tag)               throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the start of a map to be serialized. Specified by: startMap in interface RecordOutput Parameters:v - Map to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization endMap public void endMap(TreeMap v,           String tag)             throws IOException Deprecated.  Description copied from interface: RecordOutput Mark the end of a serialized map. Specified by: endMap in interface RecordOutput Parameters:v - Map to be serializedtag - Used by tagged serialization formats (such as XML) Throws: IOException - Indicates error in serialization Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  YarnApplicationAttemptState (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="YarnApplicationAttemptState (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum YarnApplicationAttemptState java.lang.Object java.lang.Enum<YarnApplicationAttemptState> org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState All Implemented Interfaces: Serializable, Comparable<YarnApplicationAttemptState> @InterfaceAudience.Public @InterfaceStability.Stable public enum YarnApplicationAttemptState extends Enum<YarnApplicationAttemptState> Enumeration of various states of a RMAppAttempt. Enum Constant Summary Enum Constants  Enum Constant and Description ALLOCATED AppAttempt Data was saved ALLOCATED_SAVING Acquired AM Container from Scheduler and Saving AppAttempt Data FAILED AppAttempt failed. FINISHED AppAttempt finished successfully. FINISHING AppAttempt is finishing. KILLED AppAttempt was terminated by a user or admin. LAUNCHED AppAttempt was launched NEW AppAttempt was just created. RUNNING AppAttempt is currently running. SCHEDULED AppAttempt was scheduled SUBMITTED AppAttempt has been submitted. Method Summary Methods  Modifier and Type Method and Description static YarnApplicationAttemptState valueOf(String name) Returns the enum constant of this type with the specified name. static YarnApplicationAttemptState[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail NEW public static final YarnApplicationAttemptState NEW AppAttempt was just created. SUBMITTED public static final YarnApplicationAttemptState SUBMITTED AppAttempt has been submitted. SCHEDULED public static final YarnApplicationAttemptState SCHEDULED AppAttempt was scheduled ALLOCATED_SAVING public static final YarnApplicationAttemptState ALLOCATED_SAVING Acquired AM Container from Scheduler and Saving AppAttempt Data ALLOCATED public static final YarnApplicationAttemptState ALLOCATED AppAttempt Data was saved LAUNCHED public static final YarnApplicationAttemptState LAUNCHED AppAttempt was launched FAILED public static final YarnApplicationAttemptState FAILED AppAttempt failed. RUNNING public static final YarnApplicationAttemptState RUNNING AppAttempt is currently running. FINISHING public static final YarnApplicationAttemptState FINISHING AppAttempt is finishing. FINISHED public static final YarnApplicationAttemptState FINISHED AppAttempt finished successfully. KILLED public static final YarnApplicationAttemptState KILLED AppAttempt was terminated by a user or admin. Method Detail values public static YarnApplicationAttemptState[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (YarnApplicationAttemptState c : YarnApplicationAttemptState.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static YarnApplicationAttemptState valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  YarnApplicationState (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="YarnApplicationState (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method org.apache.hadoop.yarn.api.records Enum YarnApplicationState java.lang.Object java.lang.Enum<YarnApplicationState> org.apache.hadoop.yarn.api.records.YarnApplicationState All Implemented Interfaces: Serializable, Comparable<YarnApplicationState> @InterfaceAudience.Public @InterfaceStability.Stable public enum YarnApplicationState extends Enum<YarnApplicationState> Enumeration of various states of an ApplicationMaster. Enum Constant Summary Enum Constants  Enum Constant and Description ACCEPTED Application has been accepted by the scheduler FAILED Application which failed. FINISHED Application which finished successfully. KILLED Application which was terminated by a user or admin. NEW Application which was just created. NEW_SAVING Application which is being saved. RUNNING Application which is currently running. SUBMITTED Application which has been submitted. Method Summary Methods  Modifier and Type Method and Description static YarnApplicationState valueOf(String name) Returns the enum constant of this type with the specified name. static YarnApplicationState[] values() Returns an array containing the constants of this enum type, in the order they are declared. Methods inherited from class java.lang.Enum clone, compareTo, equals, finalize, getDeclaringClass, hashCode, name, ordinal, toString, valueOf Methods inherited from class java.lang.Object getClass, notify, notifyAll, wait, wait, wait Enum Constant Detail NEW public static final YarnApplicationState NEW Application which was just created. NEW_SAVING public static final YarnApplicationState NEW_SAVING Application which is being saved. SUBMITTED public static final YarnApplicationState SUBMITTED Application which has been submitted. ACCEPTED public static final YarnApplicationState ACCEPTED Application has been accepted by the scheduler RUNNING public static final YarnApplicationState RUNNING Application which is currently running. FINISHED public static final YarnApplicationState FINISHED Application which finished successfully. FAILED public static final YarnApplicationState FAILED Application which failed. KILLED public static final YarnApplicationState KILLED Application which was terminated by a user or admin. Method Detail values public static YarnApplicationState[] values() Returns an array containing the constants of this enum type, in the order they are declared.  This method may be used to iterate over the constants as follows: for (YarnApplicationState c : YarnApplicationState.values())     System.out.println(c); Returns:an array containing the constants of this enum type, in the order they are declared valueOf public static YarnApplicationState valueOf(String name) Returns the enum constant of this type with the specified name. The string must match exactly an identifier used to declare an enum constant in this type.  (Extraneous whitespace characters are  not permitted.) Parameters:name - the name of the enum constant to be returned. Returns:the enum constant with the specified name Throws: IllegalArgumentException - if this enum type has no constant with the specified name NullPointerException - if the argument is null Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Enum Constants |  Field |  Method Detail:  Enum Constants |  Field |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  YarnClient (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="YarnClient (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api Class YarnClient java.lang.Object org.apache.hadoop.service.AbstractService org.apache.hadoop.yarn.client.api.YarnClient All Implemented Interfaces: Closeable, AutoCloseable, Service @InterfaceAudience.Public @InterfaceStability.Stable public abstract class YarnClient extends AbstractService Constructor Summary Constructors  Modifier Constructor and Description protected  YarnClient(String name)  Method Summary Methods  Modifier and Type Method and Description abstract YarnClientApplication createApplication()  Obtain a YarnClientApplication for a new application,  which in turn contains the ApplicationSubmissionContext and  GetNewApplicationResponse  objects. static YarnClient createYarnClient() Create a new instance of YarnClient. abstract ReservationDeleteResponse deleteReservation(ReservationDeleteRequest request)  The interface used by clients to remove an existing Reservation. abstract List<QueueInfo> getAllQueues()  Get information (QueueInfo) about all queues, recursively if there  is a hierarchy abstract org.apache.hadoop.security.token.Token<AMRMTokenIdentifier> getAMRMToken(ApplicationId appId) Get the AMRM token of the application. abstract ApplicationAttemptReport getApplicationAttemptReport(ApplicationAttemptId applicationAttemptId)  Get a report of the given ApplicationAttempt. abstract List<ApplicationAttemptReport> getApplicationAttempts(ApplicationId applicationId)  Get a report of all (ApplicationAttempts) of Application in the cluster. abstract ApplicationReport getApplicationReport(ApplicationId appId)  Get a report of the given Application. abstract List<ApplicationReport> getApplications()  Get a report (ApplicationReport) of all Applications in the cluster. abstract List<ApplicationReport> getApplications(EnumSet<YarnApplicationState> applicationStates)  Get a report (ApplicationReport) of Applications matching the given  application states in the cluster. abstract List<ApplicationReport> getApplications(Set<String> applicationTypes)  Get a report (ApplicationReport) of Applications  matching the given application types in the cluster. abstract List<ApplicationReport> getApplications(Set<String> applicationTypes,                               EnumSet<YarnApplicationState> applicationStates)  Get a report (ApplicationReport) of Applications matching the given  application types and application states in the cluster. abstract List<QueueInfo> getChildQueueInfos(String parent)  Get information (QueueInfo) about all the immediate children queues  of the given queue abstract Set<String> getClusterNodeLabels()  The interface used by client to get node labels in the cluster abstract ContainerReport getContainerReport(ContainerId containerId)  Get a report of the given Container. abstract List<ContainerReport> getContainers(ApplicationAttemptId applicationAttemptId)  Get a report of all (Containers) of ApplicationAttempt in the cluster. abstract Map<String,Set<NodeId>> getLabelsToNodes()  The interface used by client to get labels to nodes mapping  in existing cluster abstract Map<String,Set<NodeId>> getLabelsToNodes(Set<String> labels)  The interface used by client to get labels to nodes mapping  for specified labels in existing cluster abstract List<NodeReport> getNodeReports(NodeState... states)  Get a report of nodes (NodeReport) in the cluster. abstract Map<NodeId,Set<String>> getNodeToLabels()  The interface used by client to get node to labels mappings in existing cluster abstract List<QueueUserACLInfo> getQueueAclsInfo()  Get information about acls for current user on all the  existing queues. abstract QueueInfo getQueueInfo(String queueName)  Get information (QueueInfo) about a given queue. abstract Token getRMDelegationToken(Text renewer)  Get a delegation token so as to be able to talk to YARN using those tokens. abstract List<QueueInfo> getRootQueueInfos()  Get information (QueueInfo) about top level queues. abstract YarnClusterMetrics getYarnClusterMetrics()  Get metrics (YarnClusterMetrics) about the cluster. abstract void killApplication(ApplicationId applicationId)  Kill an application identified by given ID. abstract void moveApplicationAcrossQueues(ApplicationId appId,                                                       String queue)  Attempts to move the given application to the given queue. abstract ApplicationId submitApplication(ApplicationSubmissionContext appContext)  Submit a new application to YARN. It is a blocking call - it  will not return ApplicationId until the submitted application is  submitted successfully and accepted by the ResourceManager. abstract ReservationSubmissionResponse submitReservation(ReservationSubmissionRequest request)  The interface used by clients to submit a new reservation to the  ResourceManager. abstract ReservationUpdateResponse updateReservation(ReservationUpdateRequest request)  The interface used by clients to update an existing Reservation. Methods inherited from class org.apache.hadoop.service.AbstractService close, getBlockers, getConfig, getFailureCause, getFailureState, getLifecycleHistory, getName, getServiceState, getStartTime, init, isInState, noteFailure, putBlocker, registerGlobalListener, registerServiceListener, removeBlocker, serviceInit, serviceStart, serviceStop, setConfig, start, stop, toString, unregisterGlobalListener, unregisterServiceListener, waitForServiceToStop Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail YarnClient @InterfaceAudience.Private protected YarnClient(String name) Method Detail createYarnClient @InterfaceAudience.Public public static YarnClient createYarnClient() Create a new instance of YarnClient. createApplication public abstract YarnClientApplication createApplication()                                                  throws YarnException,                                                         IOException  Obtain a YarnClientApplication for a new application,  which in turn contains the ApplicationSubmissionContext and  GetNewApplicationResponse  objects.   Returns:YarnClientApplication built for a new application Throws: YarnException IOException submitApplication public abstract ApplicationId submitApplication(ApplicationSubmissionContext appContext)                                          throws YarnException,                                                 IOException  Submit a new application to YARN. It is a blocking call - it  will not return ApplicationId until the submitted application is  submitted successfully and accepted by the ResourceManager.        Users should provide an ApplicationId as part of the parameter  ApplicationSubmissionContext when submitting a new application,  otherwise it will throw the ApplicationIdNotProvidedException.    This internally calls (SubmitApplicationRequest), and after that, it internally invokes  (GetApplicationReportRequest) and waits till it can make sure that the  application gets properly submitted. If RM fails over or RM restart  happens before ResourceManager saves the application's state,  #getApplicationReport(GetApplicationReportRequest) will throw  the ApplicationNotFoundException. This API automatically resubmits  the application with the same ApplicationSubmissionContext when it  catches the ApplicationNotFoundException Parameters:appContext - ApplicationSubmissionContext containing all the details           needed to submit a new application Returns:ApplicationId of the accepted application Throws: YarnException IOExceptionSee Also:createApplication() killApplication public abstract void killApplication(ApplicationId applicationId)                               throws YarnException,                                      IOException  Kill an application identified by given ID.   Parameters:applicationId - ApplicationId of the application that needs to be killed Throws: YarnException - in case of errors or if YARN rejects the request due to            access-control restrictions. IOExceptionSee Also:getQueueAclsInfo() getApplicationReport public abstract ApplicationReport getApplicationReport(ApplicationId appId)                                                 throws YarnException,                                                        IOException  Get a report of the given Application.        In secure mode, YARN verifies access to the application, queue  etc. before accepting the request.        If the user does not have VIEW_APP access then the following  fields in the report will be set to stubbed values:    host - set to "N/A"  RPC port - set to -1  client token - set to "N/A"  diagnostics - set to "N/A"  tracking URL - set to "N/A"  original tracking URL - set to "N/A"  resource usage report - all values are -1   Parameters:appId - ApplicationId of the application that needs a report Returns:application report Throws: YarnException IOException getAMRMToken public abstract org.apache.hadoop.security.token.Token<AMRMTokenIdentifier> getAMRMToken(ApplicationId appId)                                                                                   throws YarnException,                                                                                          IOException Get the AMRM token of the application.    The AMRM token is required for AM to RM scheduling operations. For   managed Application Masters Yarn takes care of injecting it. For unmanaged  Applications Masters, the token must be obtained via this method and set  in the UserGroupInformation of the  current user.    The AMRM token will be returned only if all the following conditions are  met:      the requester is the owner of the ApplicationMaster    the application master is an unmanaged ApplicationMaster    the application master is in ACCEPTED state    Else this method returns NULL. Parameters:appId - ApplicationId of the application to get the AMRM token Returns:the AMRM token if available Throws: YarnException IOException getApplications public abstract List<ApplicationReport> getApplications()                                                  throws YarnException,                                                         IOException  Get a report (ApplicationReport) of all Applications in the cluster.      If the user does not have VIEW_APP access for an application  then the corresponding report will be filtered as described in  getApplicationReport(ApplicationId).   Returns:a list of reports of all running applications Throws: YarnException IOException getApplications public abstract List<ApplicationReport> getApplications(Set<String> applicationTypes)                                                  throws YarnException,                                                         IOException  Get a report (ApplicationReport) of Applications  matching the given application types in the cluster.      If the user does not have VIEW_APP access for an application  then the corresponding report will be filtered as described in  getApplicationReport(ApplicationId).   Parameters:applicationTypes -  Returns:a list of reports of applications Throws: YarnException IOException getApplications public abstract List<ApplicationReport> getApplications(EnumSet<YarnApplicationState> applicationStates)                                                  throws YarnException,                                                         IOException  Get a report (ApplicationReport) of Applications matching the given  application states in the cluster.      If the user does not have VIEW_APP access for an application  then the corresponding report will be filtered as described in  getApplicationReport(ApplicationId).   Parameters:applicationStates -  Returns:a list of reports of applications Throws: YarnException IOException getApplications public abstract List<ApplicationReport> getApplications(Set<String> applicationTypes,                                       EnumSet<YarnApplicationState> applicationStates)                                                  throws YarnException,                                                         IOException  Get a report (ApplicationReport) of Applications matching the given  application types and application states in the cluster.      If the user does not have VIEW_APP access for an application  then the corresponding report will be filtered as described in  getApplicationReport(ApplicationId).   Parameters:applicationTypes - applicationStates -  Returns:a list of reports of applications Throws: YarnException IOException getYarnClusterMetrics public abstract YarnClusterMetrics getYarnClusterMetrics()                                                   throws YarnException,                                                          IOException  Get metrics (YarnClusterMetrics) about the cluster.   Returns:cluster metrics Throws: YarnException IOException getNodeReports public abstract List<NodeReport> getNodeReports(NodeState... states)                                          throws YarnException,                                                 IOException  Get a report of nodes (NodeReport) in the cluster.   Parameters:states - The NodeStates to filter on. If no filter states are           given, nodes in all states will be returned. Returns:A list of node reports Throws: YarnException IOException getRMDelegationToken public abstract Token getRMDelegationToken(Text renewer)                                     throws YarnException,                                            IOException  Get a delegation token so as to be able to talk to YARN using those tokens. Parameters:renewer - Address of the renewer who can renew these tokens when needed by           securely talking to YARN. Returns:a delegation token (Token) that can be used to          talk to YARN Throws: YarnException IOException getQueueInfo public abstract QueueInfo getQueueInfo(String queueName)                                 throws YarnException,                                        IOException  Get information (QueueInfo) about a given queue.   Parameters:queueName - Name of the queue whose information is needed Returns:queue information Throws: YarnException - in case of errors or if YARN rejects the request due to            access-control restrictions. IOException getAllQueues public abstract List<QueueInfo> getAllQueues()                                       throws YarnException,                                              IOException  Get information (QueueInfo) about all queues, recursively if there  is a hierarchy   Returns:a list of queue-information for all queues Throws: YarnException IOException getRootQueueInfos public abstract List<QueueInfo> getRootQueueInfos()                                            throws YarnException,                                                   IOException  Get information (QueueInfo) about top level queues.   Returns:a list of queue-information for all the top-level queues Throws: YarnException IOException getChildQueueInfos public abstract List<QueueInfo> getChildQueueInfos(String parent)                                             throws YarnException,                                                    IOException  Get information (QueueInfo) about all the immediate children queues  of the given queue   Parameters:parent - Name of the queue whose child-queues' information is needed Returns:a list of queue-information for all queues who are direct children          of the given parent queue. Throws: YarnException IOException getQueueAclsInfo public abstract List<QueueUserACLInfo> getQueueAclsInfo()                                                  throws YarnException,                                                         IOException  Get information about acls for current user on all the  existing queues.   Returns:a list of queue acls (QueueUserACLInfo) for          current user Throws: YarnException IOException getApplicationAttemptReport public abstract ApplicationAttemptReport getApplicationAttemptReport(ApplicationAttemptId applicationAttemptId)                                                               throws YarnException,                                                                      IOException  Get a report of the given ApplicationAttempt.        In secure mode, YARN verifies access to the application, queue  etc. before accepting the request.   Parameters:applicationAttemptId - ApplicationAttemptId of the application attempt that needs           a report Returns:application attempt report Throws: YarnException ApplicationAttemptNotFoundException - if application attempt          not found IOException getApplicationAttempts public abstract List<ApplicationAttemptReport> getApplicationAttempts(ApplicationId applicationId)                                                                throws YarnException,                                                                       IOException  Get a report of all (ApplicationAttempts) of Application in the cluster.   Parameters:applicationId -  Returns:a list of reports for all application attempts for specified          application. Throws: YarnException IOException getContainerReport public abstract ContainerReport getContainerReport(ContainerId containerId)                                             throws YarnException,                                                    IOException  Get a report of the given Container.        In secure mode, YARN verifies access to the application, queue  etc. before accepting the request.   Parameters:containerId - ContainerId of the container that needs a report Returns:container report Throws: YarnException ContainerNotFoundException - if container not found. IOException getContainers public abstract List<ContainerReport> getContainers(ApplicationAttemptId applicationAttemptId)                                              throws YarnException,                                                     IOException  Get a report of all (Containers) of ApplicationAttempt in the cluster.   Parameters:applicationAttemptId -  Returns:a list of reports of all containers for specified application          attempts Throws: YarnException IOException moveApplicationAcrossQueues public abstract void moveApplicationAcrossQueues(ApplicationId appId,                                String queue)                                           throws YarnException,                                                  IOException  Attempts to move the given application to the given queue.   Parameters:appId - Application to move.queue - Queue to place it in to. Throws: YarnException IOException submitReservation @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationSubmissionResponse submitReservation(ReservationSubmissionRequest request)                                                          throws YarnException,                                                                 IOException  The interface used by clients to submit a new reservation to the  ResourceManager.        The client packages all details of its request in a  ReservationSubmissionRequest object. This contains information  about the amount of capacity, temporal constraints, and gang needs.  Furthermore, the reservation might be composed of multiple stages, with  ordering dependencies among them.        In order to respond, a new admission control component in the  ResourceManager performs an analysis of the resources that have  been committed over the period of time the user is requesting, verify that  the user requests can be fulfilled, and that it respect a sharing policy  (e.g., CapacityOverTimePolicy). Once it has positively determined  that the ReservationRequest is satisfiable the ResourceManager  answers with a ReservationSubmissionResponse that includes a  ReservationId. Upon failure to find a valid allocation the response  is an exception with the message detailing the reason of failure.        The semantics guarantees that the ReservationId returned,  corresponds to a valid reservation existing in the time-range request by  the user. The amount of capacity dedicated to such reservation can vary  overtime, depending of the allocation that has been determined. But it is  guaranteed to satisfy all the constraint expressed by the user in the  ReservationDefinition   Parameters:request - request to submit a new Reservation Returns:response contains the ReservationId on accepting the          submission Throws: YarnException - if the reservation cannot be created successfully IOException updateReservation @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationUpdateResponse updateReservation(ReservationUpdateRequest request)                                                      throws YarnException,                                                             IOException  The interface used by clients to update an existing Reservation. This is  referred to as a re-negotiation process, in which a user that has  previously submitted a Reservation.        The allocation is attempted by virtually substituting all previous  allocations related to this Reservation with new ones, that satisfy the new  ReservationDefinition. Upon success the previous allocation is  atomically substituted by the new one, and on failure (i.e., if the system  cannot find a valid allocation for the updated request), the previous  allocation remains valid.   Parameters:request - to update an existing Reservation (the           ReservationUpdateRequest should refer to an existing valid           ReservationId) Returns:response empty on successfully updating the existing reservation Throws: YarnException - if the request is invalid or reservation cannot be            updated successfully IOException deleteReservation @InterfaceAudience.Public @InterfaceStability.Unstable public abstract ReservationDeleteResponse deleteReservation(ReservationDeleteRequest request)                                                      throws YarnException,                                                             IOException  The interface used by clients to remove an existing Reservation.   Parameters:request - to remove an existing Reservation (the           ReservationDeleteRequest should refer to an existing valid           ReservationId) Returns:response empty on successfully deleting the existing reservation Throws: YarnException - if the request is invalid or reservation cannot be            deleted successfully IOException getNodeToLabels @InterfaceAudience.Public @InterfaceStability.Unstable public abstract Map<NodeId,Set<String>> getNodeToLabels()                                                  throws YarnException,                                                         IOException  The interface used by client to get node to labels mappings in existing cluster   Returns:node to labels mappings Throws: YarnException IOException getLabelsToNodes @InterfaceAudience.Public @InterfaceStability.Unstable public abstract Map<String,Set<NodeId>> getLabelsToNodes()                                                   throws YarnException,                                                          IOException  The interface used by client to get labels to nodes mapping  in existing cluster   Returns:node to labels mappings Throws: YarnException IOException getLabelsToNodes @InterfaceAudience.Public @InterfaceStability.Unstable public abstract Map<String,Set<NodeId>> getLabelsToNodes(Set<String> labels)                                                   throws YarnException,                                                          IOException  The interface used by client to get labels to nodes mapping  for specified labels in existing cluster   Parameters:labels - labels for which labels to nodes mapping has to be retrieved Returns:labels to nodes mappings for specific labels Throws: YarnException IOException getClusterNodeLabels @InterfaceAudience.Public @InterfaceStability.Unstable public abstract Set<String> getClusterNodeLabels()                                           throws YarnException,                                                  IOException  The interface used by client to get node labels in the cluster   Returns:cluster node labels collection Throws: YarnException IOException Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  YarnClientApplication (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="YarnClientApplication (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.client.api Class YarnClientApplication java.lang.Object org.apache.hadoop.yarn.client.api.YarnClientApplication @InterfaceAudience.Public @InterfaceStability.Stable public class YarnClientApplication extends Object Constructor Summary Constructors  Constructor and Description YarnClientApplication(GetNewApplicationResponse newAppResponse,                                           ApplicationSubmissionContext appContext)  Method Summary Methods  Modifier and Type Method and Description ApplicationSubmissionContext getApplicationSubmissionContext()  GetNewApplicationResponse getNewApplicationResponse()  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail YarnClientApplication public YarnClientApplication(GetNewApplicationResponse newAppResponse,                      ApplicationSubmissionContext appContext) Method Detail getNewApplicationResponse public GetNewApplicationResponse getNewApplicationResponse() getApplicationSubmissionContext public ApplicationSubmissionContext getApplicationSubmissionContext() Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  YarnClusterMetrics (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="YarnClusterMetrics (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.api.records Class YarnClusterMetrics java.lang.Object org.apache.hadoop.yarn.api.records.YarnClusterMetrics @InterfaceAudience.Public @InterfaceStability.Stable public abstract class YarnClusterMetrics extends Object YarnClusterMetrics represents cluster metrics.    Currently only number of NodeManagers is provided. Constructor Summary Constructors  Constructor and Description YarnClusterMetrics()  Method Summary Methods  Modifier and Type Method and Description abstract int getNumNodeManagers() Get the number of NodeManagers in the cluster. Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail YarnClusterMetrics public YarnClusterMetrics() Method Detail getNumNodeManagers @InterfaceAudience.Public @InterfaceStability.Stable public abstract int getNumNodeManagers() Get the number of NodeManagers in the cluster. Returns:number of NodeManagers in the cluster Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  YarnConfiguration (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="YarnConfiguration (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.conf Class YarnConfiguration java.lang.Object org.apache.hadoop.conf.Configuration org.apache.hadoop.yarn.conf.YarnConfiguration All Implemented Interfaces: Iterable<Map.Entry<String,String>>, Writable @InterfaceAudience.Public @InterfaceStability.Evolving public class YarnConfiguration extends Configuration Field Summary Fields  Modifier and Type Field and Description static String APPLICATION_HISTORY_MAX_APPS Defines the max number of applications could be fetched using  REST API or application history protocol and shown in timeline  server web ui. static int APPLICATION_MAX_TAG_LENGTH  static int APPLICATION_MAX_TAGS  static int APPLICATION_TYPE_LENGTH Default application type length static String AUTO_FAILOVER_EMBEDDED  static String AUTO_FAILOVER_ENABLED  static String AUTO_FAILOVER_PREFIX  static String AUTO_FAILOVER_ZK_BASE_PATH  static String CLIENT_FAILOVER_MAX_ATTEMPTS  static String CLIENT_FAILOVER_PREFIX  static String CLIENT_FAILOVER_PROXY_PROVIDER  static String CLIENT_FAILOVER_RETRIES  static String CLIENT_FAILOVER_RETRIES_ON_SOCKET_TIMEOUTS  static String CLIENT_FAILOVER_SLEEPTIME_BASE_MS  static String CLIENT_FAILOVER_SLEEPTIME_MAX_MS  static String CLIENT_NM_CONNECT_MAX_WAIT_MS Max time to wait to establish a connection to NM static String CLIENT_NM_CONNECT_RETRY_INTERVAL_MS Time interval between each attempt to connect to NM static String DEBUG_NM_DELETE_DELAY_SEC Delay before deleting resource to ease debugging of NM issues static long DEFAULT_APPLICATION_HISTORY_MAX_APPS  static String DEFAULT_APPLICATION_NAME Default application name static String DEFAULT_APPLICATION_TYPE Default application type static boolean DEFAULT_AUTO_FAILOVER_EMBEDDED  static boolean DEFAULT_AUTO_FAILOVER_ENABLED  static String DEFAULT_AUTO_FAILOVER_ZK_BASE_PATH  static String DEFAULT_CLIENT_FAILOVER_PROXY_PROVIDER  static int DEFAULT_CLIENT_FAILOVER_RETRIES  static int DEFAULT_CLIENT_FAILOVER_RETRIES_ON_SOCKET_TIMEOUTS  static long DEFAULT_CLIENT_NM_CONNECT_MAX_WAIT_MS  static long DEFAULT_CLIENT_NM_CONNECT_RETRY_INTERVAL_MS  static String DEFAULT_CONTAINER_TEMP_DIR Container temp directory static long DEFAULT_DISPATCHER_DRAIN_EVENTS_TIMEOUT  static String DEFAULT_FS_BASED_RM_CONF_STORE  static String DEFAULT_FS_NODE_LABELS_STORE_RETRY_POLICY_SPEC  static int DEFAULT_FS_RM_STATE_STORE_NUM_RETRIES  static long DEFAULT_FS_RM_STATE_STORE_RETRY_INTERVAL_MS  static String DEFAULT_FS_RM_STATE_STORE_RETRY_POLICY_SPEC  static int DEFAULT_IN_MEMORY_CHECK_PERIOD_MINS  static int DEFAULT_IN_MEMORY_INITIAL_DELAY_MINS  static int DEFAULT_IN_MEMORY_STALENESS_PERIOD_MINS  static String DEFAULT_IPC_CLIENT_FACTORY_CLASS  static String DEFAULT_IPC_RECORD_FACTORY_CLASS  static String DEFAULT_IPC_RPC_IMPL  static String DEFAULT_IPC_SERVER_FACTORY_CLASS  static boolean DEFAULT_LOG_AGGREGATION_ENABLED  static long DEFAULT_LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS  static long DEFAULT_LOG_AGGREGATION_RETAIN_SECONDS  static String DEFAULT_NM_ADDRESS  static String DEFAULT_NM_ADMIN_USER_ENV  static int DEFAULT_NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE  static int DEFAULT_NM_CLIENT_MAX_NM_PROXIES  static int DEFAULT_NM_CONTAINER_EXECUTOR_SCHED_PRIORITY  static int DEFAULT_NM_CONTAINER_MGR_THREAD_COUNT  static int DEFAULT_NM_CONTAINER_MON_INTERVAL_MS  static int DEFAULT_NM_DELETE_THREAD_COUNT  static long DEFAULT_NM_DISK_HEALTH_CHECK_INTERVAL_MS By default, disks' health is checked every 2 minutes. static String DEFAULT_NM_ENV_WHITELIST  static long DEFAULT_NM_HEALTH_CHECK_INTERVAL_MS  static long DEFAULT_NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS  static long DEFAULT_NM_LINUX_CONTAINER_CGROUPS_DELETE_DELAY  static long DEFAULT_NM_LINUX_CONTAINER_CGROUPS_DELETE_TIMEOUT  static boolean DEFAULT_NM_LINUX_CONTAINER_CGROUPS_STRICT_RESOURCE_USAGE  static int DEFAULT_NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY  static String DEFAULT_NM_LOCAL_DIRS  static String DEFAULT_NM_LOCALIZER_ADDRESS  static long DEFAULT_NM_LOCALIZER_CACHE_CLEANUP_INTERVAL_MS  static long DEFAULT_NM_LOCALIZER_CACHE_TARGET_SIZE_MB  static int DEFAULT_NM_LOCALIZER_CLIENT_THREAD_COUNT  static int DEFAULT_NM_LOCALIZER_FETCH_THREAD_COUNT  static int DEFAULT_NM_LOCALIZER_PORT  static String DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE  static long DEFAULT_NM_LOG_AGGREGATION_ROLL_MONITORING_INTERVAL_SECONDS  static int DEFAULT_NM_LOG_DELETE_THREAD_COUNT  static String DEFAULT_NM_LOG_DIRS  static long DEFAULT_NM_LOG_RETAIN_SECONDS  static float DEFAULT_NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE By default, 90% of the disk can be used before it is marked as offline. static float DEFAULT_NM_MIN_HEALTHY_DISKS_FRACTION By default, at least 25% of disks are to be healthy to say that the node is  healthy in terms of disks. static long DEFAULT_NM_MIN_PER_DISK_FREE_SPACE_MB By default, all of the disk can be used before it is marked as offline. static boolean DEFAULT_NM_NONSECURE_MODE_LIMIT_USERS  static String DEFAULT_NM_NONSECURE_MODE_LOCAL_USER  static String DEFAULT_NM_NONSECURE_MODE_USER_PATTERN  static boolean DEFAULT_NM_PMEM_CHECK_ENABLED  static int DEFAULT_NM_PMEM_MB  static int DEFAULT_NM_PORT  static long DEFAULT_NM_PROCESS_KILL_WAIT_MS  static boolean DEFAULT_NM_RECOVERY_ENABLED  static String DEFAULT_NM_REMOTE_APP_LOG_DIR  static String DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX  static int DEFAULT_NM_RESOURCE_PERCENTAGE_PHYSICAL_CPU_LIMIT  static String DEFAULT_NM_RESOURCEMANAGER_MINIMUM_VERSION  static long DEFAULT_NM_SLEEP_DELAY_BEFORE_SIGKILL_MS  static String DEFAULT_NM_USER_HOME_DIR  static int DEFAULT_NM_VCORES  static boolean DEFAULT_NM_VMEM_CHECK_ENABLED  static float DEFAULT_NM_VMEM_PMEM_RATIO  static String DEFAULT_NM_WEBAPP_ADDRESS  static boolean DEFAULT_NM_WEBAPP_ENABLE_CORS_FILTER  static String DEFAULT_NM_WEBAPP_HTTPS_ADDRESS  static int DEFAULT_NM_WEBAPP_HTTPS_PORT  static int DEFAULT_NM_WEBAPP_PORT  static boolean DEFAULT_NM_WINDOWS_CONTAINER_CPU_LIMIT_ENABLED  static boolean DEFAULT_NM_WINDOWS_CONTAINER_MEMORY_LIMIT_ENABLED  static boolean DEFAULT_NODE_LABELS_ENABLED  static boolean DEFAULT_PROCFS_USE_SMAPS_BASED_RSS_ENABLED  static String DEFAULT_PROXY_ADDRESS  static int DEFAULT_PROXY_PORT  static String DEFAULT_QUEUE_NAME Default queue name static long DEFAULT_RESOURCEMANAGER_CONNECT_MAX_WAIT_MS  static long DEFAULT_RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS  static String DEFAULT_RM_ADDRESS  static String DEFAULT_RM_ADMIN_ADDRESS  static int DEFAULT_RM_ADMIN_CLIENT_THREAD_COUNT  static int DEFAULT_RM_ADMIN_PORT  static int DEFAULT_RM_AM_EXPIRY_INTERVAL_MS  static int DEFAULT_RM_AM_MAX_ATTEMPTS  static int DEFAULT_RM_AMLAUNCHER_THREAD_COUNT  static long DEFAULT_RM_AMRM_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS  static int DEFAULT_RM_CLIENT_THREAD_COUNT  static String DEFAULT_RM_CONFIGURATION_PROVIDER_CLASS  static int DEFAULT_RM_CONTAINER_ALLOC_EXPIRY_INTERVAL_MS  static long DEFAULT_RM_CONTAINER_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS  static long DEFAULT_RM_DELAYED_DELEGATION_TOKEN_REMOVAL_INTERVAL_MS  static int DEFAULT_RM_DELEGATION_TOKEN_RENEWER_THREAD_COUNT  static boolean DEFAULT_RM_HA_ENABLED  static int DEFAULT_RM_HISTORY_WRITER_MULTI_THREADED_DISPATCHER_POOL_SIZE  static int DEFAULT_RM_MAX_COMPLETED_APPLICATIONS  static String DEFAULT_RM_METRICS_RUNTIME_BUCKETS Default sizes of the runtime metric buckets in minutes. static int DEFAULT_RM_NM_EXPIRY_INTERVAL_MS  static long DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MS  static long DEFAULT_RM_NMTOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS  static int DEFAULT_RM_NODEMANAGER_CONNECT_RETIRES  static String DEFAULT_RM_NODEMANAGER_MINIMUM_VERSION  static String DEFAULT_RM_NODES_EXCLUDE_FILE_PATH  static String DEFAULT_RM_NODES_INCLUDE_FILE_PATH  static int DEFAULT_RM_PORT  static boolean DEFAULT_RM_PROXY_USER_PRIVILEGES_ENABLED  static boolean DEFAULT_RM_RECOVERY_ENABLED  static boolean DEFAULT_RM_RESERVATION_SYSTEM_ENABLE  static long DEFAULT_RM_RESERVATION_SYSTEM_PLAN_FOLLOWER_TIME_STEP  static String DEFAULT_RM_RESOURCE_TRACKER_ADDRESS  static int DEFAULT_RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT  static int DEFAULT_RM_RESOURCE_TRACKER_PORT  static String DEFAULT_RM_SCHEDULER  static String DEFAULT_RM_SCHEDULER_ADDRESS  static int DEFAULT_RM_SCHEDULER_CLIENT_THREAD_COUNT  static boolean DEFAULT_RM_SCHEDULER_ENABLE_MONITORS  static int DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_MB  static int DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES  static int DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MB  static int DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES  static int DEFAULT_RM_SCHEDULER_PORT  static boolean DEFAULT_RM_SCHEDULER_USE_PORT_FOR_NODE_NAME  static int DEFAULT_RM_STATE_STORE_MAX_COMPLETED_APPLICATIONS  static int DEFAULT_RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE  static boolean DEFAULT_RM_SYSTEM_METRICS_PUBLISHER_ENABLED  static String DEFAULT_RM_WEBAPP_ADDRESS  static boolean DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER  static boolean DEFAULT_RM_WEBAPP_ENABLE_CORS_FILTER  static String DEFAULT_RM_WEBAPP_HTTPS_ADDRESS  static int DEFAULT_RM_WEBAPP_HTTPS_PORT  static int DEFAULT_RM_WEBAPP_PORT  static boolean DEFAULT_RM_WEBAPP_UI_ACTIONS_ENABLED  static long DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS  static String DEFAULT_RM_ZK_ACL  static long DEFAULT_RM_ZK_RETRY_INTERVAL_MS  static int DEFAULT_RM_ZK_TIMEOUT_MS  static String DEFAULT_SCM_ADMIN_ADDRESS  static int DEFAULT_SCM_ADMIN_CLIENT_THREAD_COUNT  static int DEFAULT_SCM_ADMIN_PORT  static String DEFAULT_SCM_APP_CHECKER_CLASS  static int DEFAULT_SCM_CLEANER_INITIAL_DELAY_MINS  static int DEFAULT_SCM_CLEANER_PERIOD_MINS  static long DEFAULT_SCM_CLEANER_RESOURCE_SLEEP_MS  static String DEFAULT_SCM_CLIENT_SERVER_ADDRESS  static int DEFAULT_SCM_CLIENT_SERVER_PORT  static int DEFAULT_SCM_CLIENT_SERVER_THREAD_COUNT  static String DEFAULT_SCM_STORE_CLASS  static String DEFAULT_SCM_UPLOADER_SERVER_ADDRESS  static int DEFAULT_SCM_UPLOADER_SERVER_PORT  static int DEFAULT_SCM_UPLOADER_SERVER_THREAD_COUNT  static String DEFAULT_SCM_WEBAPP_ADDRESS  static int DEFAULT_SCM_WEBAPP_PORT  static String DEFAULT_SHARED_CACHE_CHECKSUM_ALGO_IMPL  static boolean DEFAULT_SHARED_CACHE_ENABLED  static int DEFAULT_SHARED_CACHE_NESTED_LEVEL  static int DEFAULT_SHARED_CACHE_NM_UPLOADER_REPLICATION_FACTOR  static int DEFAULT_SHARED_CACHE_NM_UPLOADER_THREAD_COUNT  static String DEFAULT_SHARED_CACHE_ROOT  static long DEFAULT_TIMELINE_DELEGATION_KEY_UPDATE_INTERVAL  static long DEFAULT_TIMELINE_DELEGATION_TOKEN_MAX_LIFETIME  static long DEFAULT_TIMELINE_DELEGATION_TOKEN_RENEW_INTERVAL  static String DEFAULT_TIMELINE_SERVICE_ADDRESS  static boolean DEFAULT_TIMELINE_SERVICE_CLIENT_BEST_EFFORT  static int DEFAULT_TIMELINE_SERVICE_CLIENT_MAX_RETRIES  static long DEFAULT_TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS  static int DEFAULT_TIMELINE_SERVICE_CLIENT_THREAD_COUNT  static boolean DEFAULT_TIMELINE_SERVICE_ENABLED  static long DEFAULT_TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE  static int DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE  static int DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE  static long DEFAULT_TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS  static int DEFAULT_TIMELINE_SERVICE_PORT  static boolean DEFAULT_TIMELINE_SERVICE_RECOVERY_ENABLED  static long DEFAULT_TIMELINE_SERVICE_TTL_MS  static String DEFAULT_TIMELINE_SERVICE_WEBAPP_ADDRESS  static String DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS  static int DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_PORT  static int DEFAULT_TIMELINE_SERVICE_WEBAPP_PORT  static boolean DEFAULT_YARN_ACL_ENABLE  static String DEFAULT_YARN_ADMIN_ACL  static String DEFAULT_YARN_APP_ACL ACL used in case none is found. static String[] DEFAULT_YARN_APPLICATION_CLASSPATH  Default platform-specific CLASSPATH for YARN applications. static long DEFAULT_YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS  static long DEFAULT_YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_TIMEOUT_MS  static String[] DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH Default platform-agnostic CLASSPATH for YARN applications. static boolean DEFAULT_YARN_FAIL_FAST  static boolean DEFAULT_YARN_MINICLUSTER_CONTROL_RESOURCE_MONITORING  static boolean DEFAULT_YARN_MINICLUSTER_FIXED_PORTS Default is false to be able to run tests concurrently without port  conflicts. static int DEFAULT_YARN_MINICLUSTER_NM_PMEM_MB  static boolean DEFAULT_YARN_MINICLUSTER_USE_RPC  static int DEFAULT_ZK_RM_NUM_RETRIES  static String DEFAULT_ZK_RM_STATE_STORE_PARENT_PATH  static String DISPATCHER_DRAIN_EVENTS_TIMEOUT  static String FS_BASED_RM_CONF_STORE Store the related configuration files in File System static String FS_NODE_LABELS_STORE_RETRY_POLICY_SPEC  static String FS_NODE_LABELS_STORE_ROOT_DIR URI for NodeLabelManager static String FS_RM_STATE_STORE_NUM_RETRIES  static String FS_RM_STATE_STORE_RETRY_INTERVAL_MS  static String FS_RM_STATE_STORE_RETRY_POLICY_SPEC  static String FS_RM_STATE_STORE_URI URI for FileSystemRMStateStore static String IN_MEMORY_CHECK_PERIOD_MINS The frequency at which the in-memory store checks to remove dead initial  applications. static String IN_MEMORY_INITIAL_DELAY_MINS Initial delay before the in-memory store runs its first check to remove  dead initial applications. static String IN_MEMORY_STALENESS_PERIOD_MINS A resource in the InMemorySCMStore is considered stale if the time since  the last reference exceeds the staleness period. static String IN_MEMORY_STORE_PREFIX  static String IPC_CLIENT_FACTORY_CLASS Factory to create client IPC classes. static String IPC_PREFIX  static String IPC_RECORD_FACTORY_CLASS Factory to create serializeable records. static String IPC_RPC_IMPL RPC class implementation static String IPC_SERVER_FACTORY_CLASS Factory to create server IPC classes. static String IS_MINI_YARN_CLUSTER  static String LOG_AGGREGATION_ENABLED Whether to enable log aggregation static String LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS How long to wait between aggregated log retention checks. static String LOG_AGGREGATION_RETAIN_SECONDS How long to wait before deleting aggregated logs, -1 disables. static String NM_ADDRESS address of node manager IPC. static String NM_ADMIN_USER_ENV Environment variables that will be sent to containers. static String NM_AUX_SERVICE_FMT  static String NM_AUX_SERVICES  static String NM_BIND_HOST The actual bind address or the NM. static String NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE Max number of threads in NMClientAsync to process container management  events static String NM_CLIENT_MAX_NM_PROXIES Maximum number of proxy connections to cache for node managers. static String NM_CONTAINER_EXECUTOR who will execute(launch) the containers. static String NM_CONTAINER_EXECUTOR_SCHED_PRIORITY Adjustment to make to the container os scheduling priority. static String NM_CONTAINER_MGR_THREAD_COUNT Number of threads container manager uses. static String NM_CONTAINER_MON_INTERVAL_MS How often to monitor containers. static String NM_CONTAINER_MON_PROCESS_TREE Class that calculates process tree resource utilization. static String NM_CONTAINER_MON_RESOURCE_CALCULATOR Class that calculates containers current resource utilization. static String NM_DEFAULT_DOCKER_CONTAINER_EXECUTOR_EXEC_NAME The default docker executor (For DockerContainerExecutor). static String NM_DELETE_THREAD_COUNT Number of threads used in cleanup. static String NM_DISK_HEALTH_CHECK_ENABLE Enable/Disable disks' health checker. static String NM_DISK_HEALTH_CHECK_INTERVAL_MS Frequency of running disks' health checker. static String NM_DOCKER_CONTAINER_EXECUTOR_EXEC_NAME The name of the docker executor (For DockerContainerExecutor). static String NM_DOCKER_CONTAINER_EXECUTOR_IMAGE_NAME The Docker image name(For DockerContainerExecutor). static String NM_ENV_WHITELIST Environment variables that containers may override rather than use NodeManager's default. static String NM_HEALTH_CHECK_INTERVAL_MS Frequency of running node health script. static String NM_HEALTH_CHECK_SCRIPT_OPTS The arguments to pass to the health check script. static String NM_HEALTH_CHECK_SCRIPT_PATH The health check script to run. static String NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS Health check script time out period. static String NM_KEYTAB Keytab for NM. static String NM_LINUX_CONTAINER_CGROUPS_DELETE_DELAY Delay between attempts to remove linux cgroup. static String NM_LINUX_CONTAINER_CGROUPS_DELETE_TIMEOUT Interval of time the linux container executor should try cleaning up  cgroups entry when cleaning up a container. static String NM_LINUX_CONTAINER_CGROUPS_HIERARCHY The path the linux container executor should use for cgroups static String NM_LINUX_CONTAINER_CGROUPS_MOUNT Whether the linux container executor should mount cgroups if not found static String NM_LINUX_CONTAINER_CGROUPS_MOUNT_PATH Where the linux container executor should mount cgroups if not found static String NM_LINUX_CONTAINER_CGROUPS_STRICT_RESOURCE_USAGE Whether the apps should run in strict resource usage mode(not allowed to  use spare CPU) static String NM_LINUX_CONTAINER_EXECUTOR_PATH The path to the Linux container executor. static String NM_LINUX_CONTAINER_GROUP The UNIX group that the linux-container-executor should run as. static String NM_LINUX_CONTAINER_RESOURCES_HANDLER The type of resource enforcement to use with the   linux container executor. static String NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY Number of files in each localized directories  Avoid tuning this too low. static String NM_LOCAL_DIRS List of directories to store localized files in. static String NM_LOCALIZER_ADDRESS Address where the localizer IPC is. static String NM_LOCALIZER_CACHE_CLEANUP_INTERVAL_MS Interval in between cache cleanups. static String NM_LOCALIZER_CACHE_TARGET_SIZE_MB Target size of localizer cache in MB, per nodemanager. static String NM_LOCALIZER_CLIENT_THREAD_COUNT Number of threads to handle localization requests. static String NM_LOCALIZER_FETCH_THREAD_COUNT Number of threads to use for localization fetching. static String NM_LOG_AGG_COMPRESSION_TYPE T-file compression types used to compress aggregated logs. static String NM_LOG_AGGREGATION_ROLL_MONITORING_INTERVAL_SECONDS Define how often NMs wake up and upload log files static String NM_LOG_DELETION_THREADS_COUNT Number of threads used in log cleanup. static String NM_LOG_DIRS Where to store container logs. static String NM_LOG_RETAIN_SECONDS Number of seconds to retain logs on the NodeManager. static String NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE The maximum percentage of disk space that can be used after which a disk is  marked as offline. static String NM_MIN_HEALTHY_DISKS_FRACTION The minimum fraction of number of disks to be healthy for the nodemanager  to launch new containers. static String NM_MIN_PER_DISK_FREE_SPACE_MB The minimum space that must be available on a local dir for it to be used. static String NM_NONSECURE_MODE_LIMIT_USERS If linux-container-executor should limit itself to one user  when running in non-secure mode. static String NM_NONSECURE_MODE_LOCAL_USER_KEY The UNIX user that containers will run as when Linux-container-executor  is used in nonsecure mode (a use case for this is using cgroups). static String NM_NONSECURE_MODE_USER_PATTERN_KEY The allowed pattern for UNIX user names enforced by   Linux-container-executor when used in nonsecure mode (use case for this   is using cgroups). static String NM_PMEM_CHECK_ENABLED Specifies whether physical memory check is enabled. static String NM_PMEM_MB Amount of memory in GB that can be allocated for containers. static String NM_PREFIX Prefix for all node manager configs. static String NM_PRINCIPAL The kerberos principal for the node manager. static String NM_PROCESS_KILL_WAIT_MS Max time to wait for a process to come up when trying to cleanup  container resources static String NM_RECOVERY_DIR  static String NM_RECOVERY_ENABLED  static String NM_RECOVERY_PREFIX  static String NM_REMOTE_APP_LOG_DIR Where to aggregate logs to. static String NM_REMOTE_APP_LOG_DIR_SUFFIX The remote log dir will be created at  NM_REMOTE_APP_LOG_DIR/${user}/NM_REMOTE_APP_LOG_DIR_SUFFIX/${appId} static String NM_RESOURCE_PERCENTAGE_PHYSICAL_CPU_LIMIT Percentage of overall CPU which can be allocated for containers. static String NM_RESOURCEMANAGER_MINIMUM_VERSION  static String NM_SLEEP_DELAY_BEFORE_SIGKILL_MS No. static String NM_USER_HOME_DIR  static String NM_VCORES Number of Virtual CPU Cores which can be allocated for containers. static String NM_VMEM_CHECK_ENABLED Specifies whether physical memory check is enabled. static String NM_VMEM_PMEM_RATIO Conversion ratio for physical memory to virtual memory. static String NM_WEBAPP_ADDRESS NM Webapp address. static String NM_WEBAPP_ENABLE_CORS_FILTER Enable/disable CORS filter. static String NM_WEBAPP_HTTPS_ADDRESS NM Webapp https address. static String NM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY The kerberos keytab to be used for spnego filter for NM. static String NM_WEBAPP_SPNEGO_USER_NAME_KEY The kerberos principal to be used for spnego filter for NM. static String NM_WINDOWS_CONTAINER_CPU_LIMIT_ENABLED  static String NM_WINDOWS_CONTAINER_MEMORY_LIMIT_ENABLED Indicates if memory and CPU limits will be set for the Windows Job  Object for the containers launched by the default container executor. static String NM_WINDOWS_SECURE_CONTAINER_GROUP /* The Windows group that the windows-secure-container-executor should run as. static String NODE_LABELS_ENABLED Flag to indicate if the node labels feature enabled, by default it's  disabled static String NODE_LABELS_PREFIX Node-labels configurations static String PROCFS_USE_SMAPS_BASED_RSS_ENABLED  static String PROXY_ADDRESS The address for the web proxy. static String PROXY_KEYTAB Keytab for Proxy. static String PROXY_PREFIX  static String PROXY_PRINCIPAL The kerberos principal for the proxy. static String RECOVERY_ENABLED  static String RESOURCEMANAGER_CONNECT_MAX_WAIT_MS Max time to wait to establish a connection to RM static String RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS Time interval between each attempt to connect to RM static String RM_ADDRESS The address of the applications manager interface in the RM. static String RM_ADMIN_ADDRESS The address of the RM admin interface. static String RM_ADMIN_CLIENT_THREAD_COUNT Number of threads used to handle RM admin interface. static String RM_AM_EXPIRY_INTERVAL_MS The expiry interval for application master reporting. static String RM_AM_MAX_ATTEMPTS The maximum number of application attempts. static String RM_AMLAUNCHER_THREAD_COUNT Number of threads used to launch/cleanup AM. static String RM_AMRM_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS  static String RM_BIND_HOST The actual bind address for the RM. static String RM_CLIENT_THREAD_COUNT The number of threads used to handle applications manager requests. static String RM_CLUSTER_ID  static String RM_CONFIGURATION_PROVIDER_CLASS  static String RM_CONTAINER_ALLOC_EXPIRY_INTERVAL_MS How long to wait until a container is considered dead. static String RM_CONTAINER_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS  static String RM_DELAYED_DELEGATION_TOKEN_REMOVAL_INTERVAL_MS Interval at which the delayed token removal thread runs static long RM_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT  static String RM_DELEGATION_KEY_UPDATE_INTERVAL_KEY  static long RM_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT  static String RM_DELEGATION_TOKEN_MAX_LIFETIME_KEY  static long RM_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT  static String RM_DELEGATION_TOKEN_RENEW_INTERVAL_KEY  static String RM_DELEGATION_TOKEN_RENEWER_THREAD_COUNT Delegation Token renewer thread count static String RM_FAIL_FAST  static String RM_HA_ENABLED  static String RM_HA_ID  static String RM_HA_IDS  static String RM_HA_PREFIX HA related configs static String RM_HISTORY_WRITER_MULTI_THREADED_DISPATCHER_POOL_SIZE Number of worker threads that write the history data. static String RM_HOSTNAME  static String RM_KEYTAB The keytab for the resource manager. static String RM_LEVELDB_STORE_PATH  static String RM_MAX_COMPLETED_APPLICATIONS The maximum number of completed applications RM keeps. static String RM_METRICS_RUNTIME_BUCKETS Buckets (in minutes) for the number of apps running in each queue. static String RM_NM_EXPIRY_INTERVAL_MS How long to wait until a node manager is considered dead. static String RM_NM_HEARTBEAT_INTERVAL_MS RM set next Heartbeat interval for NM static String RM_NMTOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS  static String RM_NODEMANAGER_CONNECT_RETIRES Retry times to connect with NM. static String RM_NODEMANAGER_MINIMUM_VERSION  static String RM_NODES_EXCLUDE_FILE_PATH Path to file with nodes to exclude. static String RM_NODES_INCLUDE_FILE_PATH Path to file with nodes to include. static String RM_PREFIX  static String RM_PRINCIPAL The Kerberos principal for the resource manager. static String RM_PROXY_USER_PREFIX RM proxy users' prefix static String RM_PROXY_USER_PRIVILEGES_ENABLED  static String RM_RESERVATION_SYSTEM_CLASS The class to use as the Reservation System. static String RM_RESERVATION_SYSTEM_ENABLE Whether the RM should enable Reservation System static String RM_RESERVATION_SYSTEM_PLAN_FOLLOWER The PlanFollower for the Reservation System. static String RM_RESERVATION_SYSTEM_PLAN_FOLLOWER_TIME_STEP The step size of the Reservation System. static String RM_RESOURCE_TRACKER_ADDRESS  static String RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT Number of threads to handle resource tracker calls. static String RM_SCHEDULER The class to use as the resource scheduler. static String RM_SCHEDULER_ADDRESS The address of the scheduler interface. static String RM_SCHEDULER_CLIENT_THREAD_COUNT Number of threads to handle scheduler interface. static String RM_SCHEDULER_ENABLE_MONITORS Enable periodic monitor threads. static String RM_SCHEDULER_INCLUDE_PORT_IN_NODE_NAME If the port should be included or not in the node name. static String RM_SCHEDULER_MAXIMUM_ALLOCATION_MB Maximum request grant-able by the RM scheduler. static String RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES  static String RM_SCHEDULER_MINIMUM_ALLOCATION_MB Miniumum request grant-able by the RM scheduler. static String RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES  static String RM_SCHEDULER_MONITOR_POLICIES List of SchedulingEditPolicy classes affecting the scheduler. static String RM_STATE_STORE_MAX_COMPLETED_APPLICATIONS The maximum number of completed applications RM state store keeps, by  default equals to DEFAULT_RM_MAX_COMPLETED_APPLICATIONS static String RM_STORE The class to use as the persistent store. static String RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE  static String RM_SYSTEM_METRICS_PUBLISHER_ENABLED The setting that controls whether yarn system metrics is published on the   timeline server or not by RM. static String RM_WEBAPP_ADDRESS The address of the RM web application. static String RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER Flag to enable override of the default kerberos authentication filter with  the RM authentication filter to allow authentication using delegation  tokens(fallback to kerberos if the tokens are missing). static String RM_WEBAPP_ENABLE_CORS_FILTER Enable cross origin (CORS) support. static String RM_WEBAPP_HTTPS_ADDRESS The https address of the RM web application. static String RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY The kerberos keytab to be used for spnego filter for RM. static String RM_WEBAPP_SPNEGO_USER_NAME_KEY The kerberos principal to be used for spnego filter for RM. static String RM_WEBAPP_UI_ACTIONS_ENABLED Enable Resource Manager webapp ui actions static String RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS  static String RM_ZK_ACL  static String RM_ZK_ADDRESS  static String RM_ZK_AUTH  static String RM_ZK_NUM_RETRIES  static String RM_ZK_PREFIX Zookeeper interaction configs static String RM_ZK_RETRY_INTERVAL_MS  static String RM_ZK_TIMEOUT_MS  static String SCM_ADMIN_ADDRESS The address of the SCM admin interface. static String SCM_ADMIN_CLIENT_THREAD_COUNT Number of threads used to handle SCM admin interface. static String SCM_APP_CHECKER_CLASS  static String SCM_CLEANER_INITIAL_DELAY_MINS Initial delay before the first cleaner task is scheduled. static String SCM_CLEANER_PERIOD_MINS The frequency at which a cleaner task runs. static String SCM_CLEANER_RESOURCE_SLEEP_MS The time to sleep between processing each shared cache resource. static String SCM_CLIENT_SERVER_ADDRESS The address of the client interface in the SCM. static String SCM_CLIENT_SERVER_THREAD_COUNT The number of threads used to handle shared cache manager requests. static String SCM_STORE_CLASS  static String SCM_STORE_PREFIX  static String SCM_UPLOADER_SERVER_ADDRESS The address of the node manager interface in the SCM. static String SCM_UPLOADER_SERVER_THREAD_COUNT The number of SCM threads used to handle notify requests from the node  manager. static String SCM_WEBAPP_ADDRESS The address of the SCM web application. static String SHARED_CACHE_CHECKSUM_ALGO_IMPL the checksum algorithm implementation static String SHARED_CACHE_ENABLED whether the shared cache is enabled/disabled static String SHARED_CACHE_NESTED_LEVEL The config key for the level of nested directories before getting to the  checksum directory. static String SHARED_CACHE_NM_UPLOADER_REPLICATION_FACTOR The replication factor for the node manager uploader for the shared cache. static String SHARED_CACHE_NM_UPLOADER_THREAD_COUNT  static String SHARED_CACHE_PREFIX  static String SHARED_CACHE_ROOT The config key for the shared cache root directory. static String TIMELINE_DELEGATION_KEY_UPDATE_INTERVAL  static String TIMELINE_DELEGATION_TOKEN_MAX_LIFETIME  static String TIMELINE_DELEGATION_TOKEN_RENEW_INTERVAL  static String TIMELINE_SERVICE_ADDRESS host:port address for timeline service RPC APIs. static String TIMELINE_SERVICE_BIND_HOST The listening endpoint for the timeline service application. static String TIMELINE_SERVICE_CLIENT_BEST_EFFORT Timeline client policy for whether connections are fatal static String TIMELINE_SERVICE_CLIENT_MAX_RETRIES Timeline client call, max retries (-1 means no limit) static String TIMELINE_SERVICE_CLIENT_PREFIX Timeline client settings static String TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS Timeline client call, retry interval static String TIMELINE_SERVICE_ENABLED The setting that controls whether timeline service is enabled or not. static String TIMELINE_SERVICE_HANDLER_THREAD_COUNT The number of threads to handle client RPC API requests. static String TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED Enables cross origin support for timeline server. static boolean TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED_DEFAULT Default value for cross origin support for timeline server. static String TIMELINE_SERVICE_KEYTAB The Kerberos keytab for the timeline server. static String TIMELINE_SERVICE_LEVELDB_PATH Timeline service leveldb path static String TIMELINE_SERVICE_LEVELDB_PREFIX  static String TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE Timeline service leveldb read cache (uncompressed blocks) static String TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE Timeline service leveldb start time read cache (number of entities) static String TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE Timeline service leveldb start time write cache (number of entities) static String TIMELINE_SERVICE_LEVELDB_STATE_STORE_PATH Timeline service state store leveldb path static String TIMELINE_SERVICE_LEVELDB_STATE_STORE_PREFIX  static String TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS Timeline service leveldb interval to wait between deletion rounds static String TIMELINE_SERVICE_PREFIX  static String TIMELINE_SERVICE_PRINCIPAL The Kerberos principal for the timeline server. static String TIMELINE_SERVICE_RECOVERY_ENABLED Flag to enable recovery of timeline service static String TIMELINE_SERVICE_STATE_STORE_CLASS Timeline service state store class static String TIMELINE_SERVICE_STORE Timeline service store class static String TIMELINE_SERVICE_TTL_ENABLE Timeline service enable data age off static String TIMELINE_SERVICE_TTL_MS Timeline service length of time to retain data static String TIMELINE_SERVICE_UI_NAMES Comma seperated list of names for UIs hosted in the timeline server  (For pluggable UIs). static String TIMELINE_SERVICE_UI_ON_DISK_PATH_PREFIX Path to war file or static content directory for this UI  (For pluggable UIs). static String TIMELINE_SERVICE_UI_WEB_PATH_PREFIX Relative web path that will serve up this UI (For pluggable UIs). static String TIMELINE_SERVICE_WEBAPP_ADDRESS The address of the timeline service web application. static String TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS The https address of the timeline service web application. static String YARN_ACL_ENABLE Are acls enabled. static String YARN_ADMIN_ACL ACL of who can be admin of YARN cluster. static String YARN_APP_CONTAINER_LOG_BACKUPS  static String YARN_APP_CONTAINER_LOG_DIR The log directory for the containers static String YARN_APP_CONTAINER_LOG_SIZE  static String YARN_APPLICATION_CLASSPATH CLASSPATH for YARN applications. static String YARN_AUTHORIZATION_PROVIDER  static String YARN_CLIENT_APP_SUBMISSION_POLL_INTERVAL_MS Deprecated.  static String YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS The interval that the yarn client library uses to poll the completion  status of the asynchronous API of application client protocol. static String YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_TIMEOUT_MS The duration that the yarn client library waits, cumulatively across polls,  for an expected state change to occur. static String YARN_FAIL_FAST  static String YARN_HTTP_POLICY_DEFAULT  static String YARN_HTTP_POLICY_KEY  static String YARN_LOG_SERVER_URL  static String YARN_MC_PREFIX  static String YARN_MINICLUSTER_CONTROL_RESOURCE_MONITORING Whether users are explicitly trying to control resource monitoring  configuration for the MiniYARNCluster. static String YARN_MINICLUSTER_FIXED_PORTS Whether to use fixed ports with the minicluster. static String YARN_MINICLUSTER_NM_PMEM_MB Allow changing the memory for the NodeManager in the MiniYARNCluster static String YARN_MINICLUSTER_USE_RPC Whether the NM should use RPC to connect to the RM. static String YARN_PREFIX  static String YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONCLIENT_PROTOCOL  static String YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONHISTORY_PROTOCOL  static String YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONMASTER_PROTOCOL  static String YARN_SECURITY_SERVICE_AUTHORIZATION_CONTAINER_MANAGEMENT_PROTOCOL  static String YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCE_LOCALIZER  static String YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCEMANAGER_ADMINISTRATION_PROTOCOL  static String YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCETRACKER_PROTOCOL YARN Service Level Authorization static boolean YARN_SSL_CLIENT_HTTPS_NEED_AUTH_DEFAULT  static String YARN_SSL_SERVER_RESOURCE_DEFAULT  static String YARN_TRACKING_URL_GENERATOR  static String ZK_RM_STATE_STORE_PARENT_PATH Parent znode path under which ZKRMStateStore will create znodes static String ZK_RM_STATE_STORE_ROOT_NODE_ACL Root node ACLs for fencing static String ZK_STATE_STORE_PREFIX  Constructor Summary Constructors  Constructor and Description YarnConfiguration()  YarnConfiguration(Configuration conf)  Method Summary Methods  Modifier and Type Method and Description InetSocketAddress getSocketAddr(String name,                           String defaultAddress,                           int defaultPort) Get the socket address for name property as a  InetSocketAddress. static boolean shouldRMFailFast(Configuration conf)  InetSocketAddress updateConnectAddr(String name,                                   InetSocketAddress addr) Set the socket address a client can use to connect for the  name property as a host:port. static boolean useHttps(Configuration conf)  Methods inherited from class org.apache.hadoop.conf.Configuration addDefaultResource, addDeprecation, addDeprecation, addDeprecation, addDeprecation, addDeprecations, addResource, addResource, addResource, addResource, addResource, addResource, clear, dumpConfiguration, dumpDeprecatedKeys, get, get, getBoolean, getClass, getClass, getClassByName, getClassByNameOrNull, getClasses, getClassLoader, getConfResourceAsInputStream, getConfResourceAsReader, getDouble, getEnum, getFile, getFinalParameters, getFloat, getInstances, getInt, getInts, getLocalPath, getLong, getLongBytes, getPassword, getPasswordFromConfig, getPasswordFromCredentialProviders, getPattern, getPropertySources, getProps, getRange, getRaw, getResource, getSocketAddr, getStringCollection, getStrings, getStrings, getTimeDuration, getTrimmed, getTrimmed, getTrimmedStringCollection, getTrimmedStrings, getTrimmedStrings, getValByRegex, hasWarnedDeprecation, isDeprecated, iterator, main, onlyKeyExists, readFields, reloadConfiguration, set, set, setAllowNullValueProperties, setBoolean, setBooleanIfUnset, setClass, setClassLoader, setDeprecatedProperties, setDouble, setEnum, setFloat, setIfUnset, setInt, setLong, setPattern, setQuietMode, setSocketAddr, setStrings, setTimeDuration, size, toString, unset, updateConnectAddr, write, writeXml, writeXml Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Field Detail APPLICATION_MAX_TAGS @InterfaceStability.Evolving public static final int APPLICATION_MAX_TAGS See Also:Constant Field Values APPLICATION_MAX_TAG_LENGTH @InterfaceStability.Evolving public static final int APPLICATION_MAX_TAG_LENGTH See Also:Constant Field Values YARN_PREFIX public static final String YARN_PREFIX See Also:Constant Field Values DEBUG_NM_DELETE_DELAY_SEC public static final String DEBUG_NM_DELETE_DELAY_SEC Delay before deleting resource to ease debugging of NM issues See Also:Constant Field Values IPC_PREFIX public static final String IPC_PREFIX See Also:Constant Field Values IPC_CLIENT_FACTORY_CLASS public static final String IPC_CLIENT_FACTORY_CLASS Factory to create client IPC classes. See Also:Constant Field Values DEFAULT_IPC_CLIENT_FACTORY_CLASS public static final String DEFAULT_IPC_CLIENT_FACTORY_CLASS See Also:Constant Field Values IPC_SERVER_FACTORY_CLASS public static final String IPC_SERVER_FACTORY_CLASS Factory to create server IPC classes. See Also:Constant Field Values DEFAULT_IPC_SERVER_FACTORY_CLASS public static final String DEFAULT_IPC_SERVER_FACTORY_CLASS See Also:Constant Field Values IPC_RECORD_FACTORY_CLASS public static final String IPC_RECORD_FACTORY_CLASS Factory to create serializeable records. See Also:Constant Field Values DEFAULT_IPC_RECORD_FACTORY_CLASS public static final String DEFAULT_IPC_RECORD_FACTORY_CLASS See Also:Constant Field Values IPC_RPC_IMPL public static final String IPC_RPC_IMPL RPC class implementation See Also:Constant Field Values DEFAULT_IPC_RPC_IMPL public static final String DEFAULT_IPC_RPC_IMPL See Also:Constant Field Values RM_PREFIX public static final String RM_PREFIX See Also:Constant Field Values RM_CLUSTER_ID public static final String RM_CLUSTER_ID See Also:Constant Field Values RM_HOSTNAME public static final String RM_HOSTNAME See Also:Constant Field Values RM_ADDRESS public static final String RM_ADDRESS The address of the applications manager interface in the RM. See Also:Constant Field Values DEFAULT_RM_PORT public static final int DEFAULT_RM_PORT See Also:Constant Field Values DEFAULT_RM_ADDRESS public static final String DEFAULT_RM_ADDRESS See Also:Constant Field Values RM_BIND_HOST public static final String RM_BIND_HOST The actual bind address for the RM. See Also:Constant Field Values RM_CLIENT_THREAD_COUNT public static final String RM_CLIENT_THREAD_COUNT The number of threads used to handle applications manager requests. See Also:Constant Field Values DEFAULT_RM_CLIENT_THREAD_COUNT public static final int DEFAULT_RM_CLIENT_THREAD_COUNT See Also:Constant Field Values RM_AMLAUNCHER_THREAD_COUNT public static final String RM_AMLAUNCHER_THREAD_COUNT Number of threads used to launch/cleanup AM. See Also:Constant Field Values DEFAULT_RM_AMLAUNCHER_THREAD_COUNT public static final int DEFAULT_RM_AMLAUNCHER_THREAD_COUNT See Also:Constant Field Values RM_NODEMANAGER_CONNECT_RETIRES public static final String RM_NODEMANAGER_CONNECT_RETIRES Retry times to connect with NM. See Also:Constant Field Values DEFAULT_RM_NODEMANAGER_CONNECT_RETIRES public static final int DEFAULT_RM_NODEMANAGER_CONNECT_RETIRES See Also:Constant Field Values RM_PRINCIPAL public static final String RM_PRINCIPAL The Kerberos principal for the resource manager. See Also:Constant Field Values RM_SCHEDULER_ADDRESS public static final String RM_SCHEDULER_ADDRESS The address of the scheduler interface. See Also:Constant Field Values DEFAULT_RM_SCHEDULER_PORT public static final int DEFAULT_RM_SCHEDULER_PORT See Also:Constant Field Values DEFAULT_RM_SCHEDULER_ADDRESS public static final String DEFAULT_RM_SCHEDULER_ADDRESS See Also:Constant Field Values RM_SCHEDULER_MINIMUM_ALLOCATION_MB public static final String RM_SCHEDULER_MINIMUM_ALLOCATION_MB Miniumum request grant-able by the RM scheduler. See Also:Constant Field Values DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MB public static final int DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MB See Also:Constant Field Values RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES public static final String RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES See Also:Constant Field Values DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES public static final int DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES See Also:Constant Field Values RM_SCHEDULER_MAXIMUM_ALLOCATION_MB public static final String RM_SCHEDULER_MAXIMUM_ALLOCATION_MB Maximum request grant-able by the RM scheduler. See Also:Constant Field Values DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_MB public static final int DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_MB See Also:Constant Field Values RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES public static final String RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES See Also:Constant Field Values DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES public static final int DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES See Also:Constant Field Values RM_SCHEDULER_CLIENT_THREAD_COUNT public static final String RM_SCHEDULER_CLIENT_THREAD_COUNT Number of threads to handle scheduler interface. See Also:Constant Field Values DEFAULT_RM_SCHEDULER_CLIENT_THREAD_COUNT public static final int DEFAULT_RM_SCHEDULER_CLIENT_THREAD_COUNT See Also:Constant Field Values RM_SCHEDULER_INCLUDE_PORT_IN_NODE_NAME public static final String RM_SCHEDULER_INCLUDE_PORT_IN_NODE_NAME If the port should be included or not in the node name. The node name  is used by the scheduler for resource requests allocation location   matching. Typically this is just the hostname, using the port is needed  when using minicluster and specific NM are required. See Also:Constant Field Values DEFAULT_RM_SCHEDULER_USE_PORT_FOR_NODE_NAME public static final boolean DEFAULT_RM_SCHEDULER_USE_PORT_FOR_NODE_NAME See Also:Constant Field Values RM_WEBAPP_UI_ACTIONS_ENABLED public static final String RM_WEBAPP_UI_ACTIONS_ENABLED Enable Resource Manager webapp ui actions See Also:Constant Field Values DEFAULT_RM_WEBAPP_UI_ACTIONS_ENABLED public static final boolean DEFAULT_RM_WEBAPP_UI_ACTIONS_ENABLED See Also:Constant Field Values RM_RESERVATION_SYSTEM_ENABLE public static final String RM_RESERVATION_SYSTEM_ENABLE Whether the RM should enable Reservation System See Also:Constant Field Values DEFAULT_RM_RESERVATION_SYSTEM_ENABLE public static final boolean DEFAULT_RM_RESERVATION_SYSTEM_ENABLE See Also:Constant Field Values RM_RESERVATION_SYSTEM_CLASS public static final String RM_RESERVATION_SYSTEM_CLASS The class to use as the Reservation System. See Also:Constant Field Values RM_RESERVATION_SYSTEM_PLAN_FOLLOWER public static final String RM_RESERVATION_SYSTEM_PLAN_FOLLOWER The PlanFollower for the Reservation System. See Also:Constant Field Values RM_RESERVATION_SYSTEM_PLAN_FOLLOWER_TIME_STEP public static final String RM_RESERVATION_SYSTEM_PLAN_FOLLOWER_TIME_STEP The step size of the Reservation System. See Also:Constant Field Values DEFAULT_RM_RESERVATION_SYSTEM_PLAN_FOLLOWER_TIME_STEP public static final long DEFAULT_RM_RESERVATION_SYSTEM_PLAN_FOLLOWER_TIME_STEP See Also:Constant Field Values RM_SCHEDULER_ENABLE_MONITORS public static final String RM_SCHEDULER_ENABLE_MONITORS Enable periodic monitor threads. See Also:RM_SCHEDULER_MONITOR_POLICIES,  Constant Field Values DEFAULT_RM_SCHEDULER_ENABLE_MONITORS public static final boolean DEFAULT_RM_SCHEDULER_ENABLE_MONITORS See Also:Constant Field Values RM_SCHEDULER_MONITOR_POLICIES public static final String RM_SCHEDULER_MONITOR_POLICIES List of SchedulingEditPolicy classes affecting the scheduler. See Also:Constant Field Values RM_WEBAPP_ADDRESS public static final String RM_WEBAPP_ADDRESS The address of the RM web application. See Also:Constant Field Values DEFAULT_RM_WEBAPP_PORT public static final int DEFAULT_RM_WEBAPP_PORT See Also:Constant Field Values DEFAULT_RM_WEBAPP_ADDRESS public static final String DEFAULT_RM_WEBAPP_ADDRESS See Also:Constant Field Values RM_WEBAPP_HTTPS_ADDRESS public static final String RM_WEBAPP_HTTPS_ADDRESS The https address of the RM web application. See Also:Constant Field Values YARN_SSL_CLIENT_HTTPS_NEED_AUTH_DEFAULT public static final boolean YARN_SSL_CLIENT_HTTPS_NEED_AUTH_DEFAULT See Also:Constant Field Values YARN_SSL_SERVER_RESOURCE_DEFAULT public static final String YARN_SSL_SERVER_RESOURCE_DEFAULT See Also:Constant Field Values DEFAULT_RM_WEBAPP_HTTPS_PORT public static final int DEFAULT_RM_WEBAPP_HTTPS_PORT See Also:Constant Field Values DEFAULT_RM_WEBAPP_HTTPS_ADDRESS public static final String DEFAULT_RM_WEBAPP_HTTPS_ADDRESS See Also:Constant Field Values RM_RESOURCE_TRACKER_ADDRESS public static final String RM_RESOURCE_TRACKER_ADDRESS See Also:Constant Field Values DEFAULT_RM_RESOURCE_TRACKER_PORT public static final int DEFAULT_RM_RESOURCE_TRACKER_PORT See Also:Constant Field Values DEFAULT_RM_RESOURCE_TRACKER_ADDRESS public static final String DEFAULT_RM_RESOURCE_TRACKER_ADDRESS See Also:Constant Field Values RM_AM_EXPIRY_INTERVAL_MS public static final String RM_AM_EXPIRY_INTERVAL_MS The expiry interval for application master reporting. See Also:Constant Field Values DEFAULT_RM_AM_EXPIRY_INTERVAL_MS public static final int DEFAULT_RM_AM_EXPIRY_INTERVAL_MS See Also:Constant Field Values RM_NM_EXPIRY_INTERVAL_MS public static final String RM_NM_EXPIRY_INTERVAL_MS How long to wait until a node manager is considered dead. See Also:Constant Field Values DEFAULT_RM_NM_EXPIRY_INTERVAL_MS public static final int DEFAULT_RM_NM_EXPIRY_INTERVAL_MS See Also:Constant Field Values YARN_ACL_ENABLE public static final String YARN_ACL_ENABLE Are acls enabled. See Also:Constant Field Values DEFAULT_YARN_ACL_ENABLE public static final boolean DEFAULT_YARN_ACL_ENABLE See Also:Constant Field Values YARN_ADMIN_ACL public static final String YARN_ADMIN_ACL ACL of who can be admin of YARN cluster. See Also:Constant Field Values DEFAULT_YARN_ADMIN_ACL public static final String DEFAULT_YARN_ADMIN_ACL See Also:Constant Field Values DEFAULT_YARN_APP_ACL public static final String DEFAULT_YARN_APP_ACL ACL used in case none is found. Allows nothing. See Also:Constant Field Values RM_ADMIN_ADDRESS public static final String RM_ADMIN_ADDRESS The address of the RM admin interface. See Also:Constant Field Values DEFAULT_RM_ADMIN_PORT public static final int DEFAULT_RM_ADMIN_PORT See Also:Constant Field Values DEFAULT_RM_ADMIN_ADDRESS public static final String DEFAULT_RM_ADMIN_ADDRESS See Also:Constant Field Values RM_ADMIN_CLIENT_THREAD_COUNT public static final String RM_ADMIN_CLIENT_THREAD_COUNT Number of threads used to handle RM admin interface. See Also:Constant Field Values DEFAULT_RM_ADMIN_CLIENT_THREAD_COUNT public static final int DEFAULT_RM_ADMIN_CLIENT_THREAD_COUNT See Also:Constant Field Values RM_AM_MAX_ATTEMPTS public static final String RM_AM_MAX_ATTEMPTS The maximum number of application attempts.  It's a global setting for all application masters. See Also:Constant Field Values DEFAULT_RM_AM_MAX_ATTEMPTS public static final int DEFAULT_RM_AM_MAX_ATTEMPTS See Also:Constant Field Values RM_KEYTAB public static final String RM_KEYTAB The keytab for the resource manager. See Also:Constant Field Values RM_WEBAPP_SPNEGO_USER_NAME_KEY public static final String RM_WEBAPP_SPNEGO_USER_NAME_KEY The kerberos principal to be used for spnego filter for RM. See Also:Constant Field Values RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY public static final String RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY The kerberos keytab to be used for spnego filter for RM. See Also:Constant Field Values RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER public static final String RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER Flag to enable override of the default kerberos authentication filter with  the RM authentication filter to allow authentication using delegation  tokens(fallback to kerberos if the tokens are missing). Only applicable  when the http authentication type is kerberos. See Also:Constant Field Values DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER public static final boolean DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER See Also:Constant Field Values RM_WEBAPP_ENABLE_CORS_FILTER public static final String RM_WEBAPP_ENABLE_CORS_FILTER Enable cross origin (CORS) support. See Also:Constant Field Values DEFAULT_RM_WEBAPP_ENABLE_CORS_FILTER public static final boolean DEFAULT_RM_WEBAPP_ENABLE_CORS_FILTER See Also:Constant Field Values RM_CONTAINER_ALLOC_EXPIRY_INTERVAL_MS public static final String RM_CONTAINER_ALLOC_EXPIRY_INTERVAL_MS How long to wait until a container is considered dead. See Also:Constant Field Values DEFAULT_RM_CONTAINER_ALLOC_EXPIRY_INTERVAL_MS public static final int DEFAULT_RM_CONTAINER_ALLOC_EXPIRY_INTERVAL_MS See Also:Constant Field Values RM_NODES_INCLUDE_FILE_PATH public static final String RM_NODES_INCLUDE_FILE_PATH Path to file with nodes to include. See Also:Constant Field Values DEFAULT_RM_NODES_INCLUDE_FILE_PATH public static final String DEFAULT_RM_NODES_INCLUDE_FILE_PATH See Also:Constant Field Values RM_NODES_EXCLUDE_FILE_PATH public static final String RM_NODES_EXCLUDE_FILE_PATH Path to file with nodes to exclude. See Also:Constant Field Values DEFAULT_RM_NODES_EXCLUDE_FILE_PATH public static final String DEFAULT_RM_NODES_EXCLUDE_FILE_PATH See Also:Constant Field Values RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT public static final String RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT Number of threads to handle resource tracker calls. See Also:Constant Field Values DEFAULT_RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT public static final int DEFAULT_RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT See Also:Constant Field Values RM_SCHEDULER public static final String RM_SCHEDULER The class to use as the resource scheduler. See Also:Constant Field Values DEFAULT_RM_SCHEDULER public static final String DEFAULT_RM_SCHEDULER See Also:Constant Field Values RM_NM_HEARTBEAT_INTERVAL_MS public static final String RM_NM_HEARTBEAT_INTERVAL_MS RM set next Heartbeat interval for NM See Also:Constant Field Values DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MS public static final long DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MS See Also:Constant Field Values RM_HISTORY_WRITER_MULTI_THREADED_DISPATCHER_POOL_SIZE public static final String RM_HISTORY_WRITER_MULTI_THREADED_DISPATCHER_POOL_SIZE Number of worker threads that write the history data. See Also:Constant Field Values DEFAULT_RM_HISTORY_WRITER_MULTI_THREADED_DISPATCHER_POOL_SIZE public static final int DEFAULT_RM_HISTORY_WRITER_MULTI_THREADED_DISPATCHER_POOL_SIZE See Also:Constant Field Values RM_SYSTEM_METRICS_PUBLISHER_ENABLED public static final String RM_SYSTEM_METRICS_PUBLISHER_ENABLED The setting that controls whether yarn system metrics is published on the   timeline server or not by RM. See Also:Constant Field Values DEFAULT_RM_SYSTEM_METRICS_PUBLISHER_ENABLED public static final boolean DEFAULT_RM_SYSTEM_METRICS_PUBLISHER_ENABLED See Also:Constant Field Values RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE public static final String RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE See Also:Constant Field Values DEFAULT_RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE public static final int DEFAULT_RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE See Also:Constant Field Values RM_DELEGATION_KEY_UPDATE_INTERVAL_KEY public static final String RM_DELEGATION_KEY_UPDATE_INTERVAL_KEY See Also:Constant Field Values RM_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT public static final long RM_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT See Also:Constant Field Values RM_DELEGATION_TOKEN_RENEW_INTERVAL_KEY public static final String RM_DELEGATION_TOKEN_RENEW_INTERVAL_KEY See Also:Constant Field Values RM_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT public static final long RM_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT See Also:Constant Field Values RM_DELEGATION_TOKEN_MAX_LIFETIME_KEY public static final String RM_DELEGATION_TOKEN_MAX_LIFETIME_KEY See Also:Constant Field Values RM_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT public static final long RM_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT See Also:Constant Field Values RECOVERY_ENABLED public static final String RECOVERY_ENABLED See Also:Constant Field Values DEFAULT_RM_RECOVERY_ENABLED public static final boolean DEFAULT_RM_RECOVERY_ENABLED See Also:Constant Field Values YARN_FAIL_FAST public static final String YARN_FAIL_FAST See Also:Constant Field Values DEFAULT_YARN_FAIL_FAST public static final boolean DEFAULT_YARN_FAIL_FAST See Also:Constant Field Values RM_FAIL_FAST public static final String RM_FAIL_FAST See Also:Constant Field Values RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS public static final String RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS See Also:Constant Field Values DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS public static final long DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS See Also:Constant Field Values RM_ZK_PREFIX public static final String RM_ZK_PREFIX Zookeeper interaction configs See Also:Constant Field Values RM_ZK_ADDRESS public static final String RM_ZK_ADDRESS See Also:Constant Field Values RM_ZK_NUM_RETRIES public static final String RM_ZK_NUM_RETRIES See Also:Constant Field Values DEFAULT_ZK_RM_NUM_RETRIES public static final int DEFAULT_ZK_RM_NUM_RETRIES See Also:Constant Field Values RM_ZK_RETRY_INTERVAL_MS public static final String RM_ZK_RETRY_INTERVAL_MS See Also:Constant Field Values DEFAULT_RM_ZK_RETRY_INTERVAL_MS public static final long DEFAULT_RM_ZK_RETRY_INTERVAL_MS See Also:Constant Field Values RM_ZK_TIMEOUT_MS public static final String RM_ZK_TIMEOUT_MS See Also:Constant Field Values DEFAULT_RM_ZK_TIMEOUT_MS public static final int DEFAULT_RM_ZK_TIMEOUT_MS See Also:Constant Field Values RM_ZK_ACL public static final String RM_ZK_ACL See Also:Constant Field Values DEFAULT_RM_ZK_ACL public static final String DEFAULT_RM_ZK_ACL See Also:Constant Field Values RM_ZK_AUTH public static final String RM_ZK_AUTH See Also:Constant Field Values ZK_STATE_STORE_PREFIX public static final String ZK_STATE_STORE_PREFIX See Also:Constant Field Values ZK_RM_STATE_STORE_PARENT_PATH public static final String ZK_RM_STATE_STORE_PARENT_PATH Parent znode path under which ZKRMStateStore will create znodes See Also:Constant Field Values DEFAULT_ZK_RM_STATE_STORE_PARENT_PATH public static final String DEFAULT_ZK_RM_STATE_STORE_PARENT_PATH See Also:Constant Field Values ZK_RM_STATE_STORE_ROOT_NODE_ACL public static final String ZK_RM_STATE_STORE_ROOT_NODE_ACL Root node ACLs for fencing See Also:Constant Field Values RM_HA_PREFIX public static final String RM_HA_PREFIX HA related configs See Also:Constant Field Values RM_HA_ENABLED public static final String RM_HA_ENABLED See Also:Constant Field Values DEFAULT_RM_HA_ENABLED public static final boolean DEFAULT_RM_HA_ENABLED See Also:Constant Field Values RM_HA_IDS public static final String RM_HA_IDS See Also:Constant Field Values RM_HA_ID public static final String RM_HA_ID See Also:Constant Field Values FS_BASED_RM_CONF_STORE public static final String FS_BASED_RM_CONF_STORE Store the related configuration files in File System See Also:Constant Field Values DEFAULT_FS_BASED_RM_CONF_STORE public static final String DEFAULT_FS_BASED_RM_CONF_STORE See Also:Constant Field Values RM_CONFIGURATION_PROVIDER_CLASS public static final String RM_CONFIGURATION_PROVIDER_CLASS See Also:Constant Field Values DEFAULT_RM_CONFIGURATION_PROVIDER_CLASS public static final String DEFAULT_RM_CONFIGURATION_PROVIDER_CLASS See Also:Constant Field Values YARN_AUTHORIZATION_PROVIDER public static final String YARN_AUTHORIZATION_PROVIDER See Also:Constant Field Values AUTO_FAILOVER_PREFIX public static final String AUTO_FAILOVER_PREFIX See Also:Constant Field Values AUTO_FAILOVER_ENABLED public static final String AUTO_FAILOVER_ENABLED See Also:Constant Field Values DEFAULT_AUTO_FAILOVER_ENABLED public static final boolean DEFAULT_AUTO_FAILOVER_ENABLED See Also:Constant Field Values AUTO_FAILOVER_EMBEDDED public static final String AUTO_FAILOVER_EMBEDDED See Also:Constant Field Values DEFAULT_AUTO_FAILOVER_EMBEDDED public static final boolean DEFAULT_AUTO_FAILOVER_EMBEDDED See Also:Constant Field Values AUTO_FAILOVER_ZK_BASE_PATH public static final String AUTO_FAILOVER_ZK_BASE_PATH See Also:Constant Field Values DEFAULT_AUTO_FAILOVER_ZK_BASE_PATH public static final String DEFAULT_AUTO_FAILOVER_ZK_BASE_PATH See Also:Constant Field Values CLIENT_FAILOVER_PREFIX public static final String CLIENT_FAILOVER_PREFIX See Also:Constant Field Values CLIENT_FAILOVER_PROXY_PROVIDER public static final String CLIENT_FAILOVER_PROXY_PROVIDER See Also:Constant Field Values DEFAULT_CLIENT_FAILOVER_PROXY_PROVIDER public static final String DEFAULT_CLIENT_FAILOVER_PROXY_PROVIDER See Also:Constant Field Values CLIENT_FAILOVER_MAX_ATTEMPTS public static final String CLIENT_FAILOVER_MAX_ATTEMPTS See Also:Constant Field Values CLIENT_FAILOVER_SLEEPTIME_BASE_MS public static final String CLIENT_FAILOVER_SLEEPTIME_BASE_MS See Also:Constant Field Values CLIENT_FAILOVER_SLEEPTIME_MAX_MS public static final String CLIENT_FAILOVER_SLEEPTIME_MAX_MS See Also:Constant Field Values CLIENT_FAILOVER_RETRIES public static final String CLIENT_FAILOVER_RETRIES See Also:Constant Field Values DEFAULT_CLIENT_FAILOVER_RETRIES public static final int DEFAULT_CLIENT_FAILOVER_RETRIES See Also:Constant Field Values CLIENT_FAILOVER_RETRIES_ON_SOCKET_TIMEOUTS public static final String CLIENT_FAILOVER_RETRIES_ON_SOCKET_TIMEOUTS See Also:Constant Field Values DEFAULT_CLIENT_FAILOVER_RETRIES_ON_SOCKET_TIMEOUTS public static final int DEFAULT_CLIENT_FAILOVER_RETRIES_ON_SOCKET_TIMEOUTS See Also:Constant Field Values RM_STORE public static final String RM_STORE The class to use as the persistent store. See Also:Constant Field Values FS_RM_STATE_STORE_URI public static final String FS_RM_STATE_STORE_URI URI for FileSystemRMStateStore See Also:Constant Field Values FS_RM_STATE_STORE_RETRY_POLICY_SPEC public static final String FS_RM_STATE_STORE_RETRY_POLICY_SPEC See Also:Constant Field Values DEFAULT_FS_RM_STATE_STORE_RETRY_POLICY_SPEC public static final String DEFAULT_FS_RM_STATE_STORE_RETRY_POLICY_SPEC See Also:Constant Field Values FS_RM_STATE_STORE_NUM_RETRIES public static final String FS_RM_STATE_STORE_NUM_RETRIES See Also:Constant Field Values DEFAULT_FS_RM_STATE_STORE_NUM_RETRIES public static final int DEFAULT_FS_RM_STATE_STORE_NUM_RETRIES See Also:Constant Field Values FS_RM_STATE_STORE_RETRY_INTERVAL_MS public static final String FS_RM_STATE_STORE_RETRY_INTERVAL_MS See Also:Constant Field Values DEFAULT_FS_RM_STATE_STORE_RETRY_INTERVAL_MS public static final long DEFAULT_FS_RM_STATE_STORE_RETRY_INTERVAL_MS See Also:Constant Field Values RM_LEVELDB_STORE_PATH public static final String RM_LEVELDB_STORE_PATH See Also:Constant Field Values RM_MAX_COMPLETED_APPLICATIONS public static final String RM_MAX_COMPLETED_APPLICATIONS The maximum number of completed applications RM keeps. See Also:Constant Field Values DEFAULT_RM_MAX_COMPLETED_APPLICATIONS public static final int DEFAULT_RM_MAX_COMPLETED_APPLICATIONS See Also:Constant Field Values RM_STATE_STORE_MAX_COMPLETED_APPLICATIONS public static final String RM_STATE_STORE_MAX_COMPLETED_APPLICATIONS The maximum number of completed applications RM state store keeps, by  default equals to DEFAULT_RM_MAX_COMPLETED_APPLICATIONS See Also:Constant Field Values DEFAULT_RM_STATE_STORE_MAX_COMPLETED_APPLICATIONS public static final int DEFAULT_RM_STATE_STORE_MAX_COMPLETED_APPLICATIONS See Also:Constant Field Values DEFAULT_APPLICATION_NAME public static final String DEFAULT_APPLICATION_NAME Default application name See Also:Constant Field Values DEFAULT_APPLICATION_TYPE public static final String DEFAULT_APPLICATION_TYPE Default application type See Also:Constant Field Values APPLICATION_TYPE_LENGTH public static final int APPLICATION_TYPE_LENGTH Default application type length See Also:Constant Field Values DEFAULT_QUEUE_NAME public static final String DEFAULT_QUEUE_NAME Default queue name See Also:Constant Field Values RM_METRICS_RUNTIME_BUCKETS public static final String RM_METRICS_RUNTIME_BUCKETS Buckets (in minutes) for the number of apps running in each queue. See Also:Constant Field Values DEFAULT_RM_METRICS_RUNTIME_BUCKETS public static final String DEFAULT_RM_METRICS_RUNTIME_BUCKETS Default sizes of the runtime metric buckets in minutes. See Also:Constant Field Values RM_AMRM_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS public static final String RM_AMRM_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS See Also:Constant Field Values DEFAULT_RM_AMRM_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS public static final long DEFAULT_RM_AMRM_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS See Also:Constant Field Values RM_CONTAINER_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS public static final String RM_CONTAINER_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS See Also:Constant Field Values DEFAULT_RM_CONTAINER_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS public static final long DEFAULT_RM_CONTAINER_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS See Also:Constant Field Values RM_NMTOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS public static final String RM_NMTOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS See Also:Constant Field Values DEFAULT_RM_NMTOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS public static final long DEFAULT_RM_NMTOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS See Also:Constant Field Values RM_NODEMANAGER_MINIMUM_VERSION public static final String RM_NODEMANAGER_MINIMUM_VERSION See Also:Constant Field Values DEFAULT_RM_NODEMANAGER_MINIMUM_VERSION public static final String DEFAULT_RM_NODEMANAGER_MINIMUM_VERSION See Also:Constant Field Values RM_PROXY_USER_PREFIX public static final String RM_PROXY_USER_PREFIX RM proxy users' prefix See Also:Constant Field Values NM_PREFIX public static final String NM_PREFIX Prefix for all node manager configs. See Also:Constant Field Values NM_ADMIN_USER_ENV public static final String NM_ADMIN_USER_ENV Environment variables that will be sent to containers. See Also:Constant Field Values DEFAULT_NM_ADMIN_USER_ENV public static final String DEFAULT_NM_ADMIN_USER_ENV See Also:Constant Field Values NM_ENV_WHITELIST public static final String NM_ENV_WHITELIST Environment variables that containers may override rather than use NodeManager's default. See Also:Constant Field Values DEFAULT_NM_ENV_WHITELIST public static final String DEFAULT_NM_ENV_WHITELIST NM_ADDRESS public static final String NM_ADDRESS address of node manager IPC. See Also:Constant Field Values DEFAULT_NM_PORT public static final int DEFAULT_NM_PORT See Also:Constant Field Values DEFAULT_NM_ADDRESS public static final String DEFAULT_NM_ADDRESS See Also:Constant Field Values NM_BIND_HOST public static final String NM_BIND_HOST The actual bind address or the NM. See Also:Constant Field Values NM_CONTAINER_EXECUTOR public static final String NM_CONTAINER_EXECUTOR who will execute(launch) the containers. See Also:Constant Field Values NM_CONTAINER_EXECUTOR_SCHED_PRIORITY public static final String NM_CONTAINER_EXECUTOR_SCHED_PRIORITY Adjustment to make to the container os scheduling priority.  The valid values for this could vary depending on the platform.  On Linux, higher values mean run the containers at a less   favorable priority than the NM.   The value specified is an int. See Also:Constant Field Values DEFAULT_NM_CONTAINER_EXECUTOR_SCHED_PRIORITY public static final int DEFAULT_NM_CONTAINER_EXECUTOR_SCHED_PRIORITY See Also:Constant Field Values NM_CONTAINER_MGR_THREAD_COUNT public static final String NM_CONTAINER_MGR_THREAD_COUNT Number of threads container manager uses. See Also:Constant Field Values DEFAULT_NM_CONTAINER_MGR_THREAD_COUNT public static final int DEFAULT_NM_CONTAINER_MGR_THREAD_COUNT See Also:Constant Field Values NM_DELETE_THREAD_COUNT public static final String NM_DELETE_THREAD_COUNT Number of threads used in cleanup. See Also:Constant Field Values DEFAULT_NM_DELETE_THREAD_COUNT public static final int DEFAULT_NM_DELETE_THREAD_COUNT See Also:Constant Field Values NM_KEYTAB public static final String NM_KEYTAB Keytab for NM. See Also:Constant Field Values NM_LOCAL_DIRS public static final String NM_LOCAL_DIRS List of directories to store localized files in. See Also:Constant Field Values DEFAULT_NM_LOCAL_DIRS public static final String DEFAULT_NM_LOCAL_DIRS See Also:Constant Field Values NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY public static final String NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY Number of files in each localized directories  Avoid tuning this too low. See Also:Constant Field Values DEFAULT_NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY public static final int DEFAULT_NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY See Also:Constant Field Values NM_LOCALIZER_ADDRESS public static final String NM_LOCALIZER_ADDRESS Address where the localizer IPC is. See Also:Constant Field Values DEFAULT_NM_LOCALIZER_PORT public static final int DEFAULT_NM_LOCALIZER_PORT See Also:Constant Field Values DEFAULT_NM_LOCALIZER_ADDRESS public static final String DEFAULT_NM_LOCALIZER_ADDRESS See Also:Constant Field Values NM_LOCALIZER_CACHE_CLEANUP_INTERVAL_MS public static final String NM_LOCALIZER_CACHE_CLEANUP_INTERVAL_MS Interval in between cache cleanups. See Also:Constant Field Values DEFAULT_NM_LOCALIZER_CACHE_CLEANUP_INTERVAL_MS public static final long DEFAULT_NM_LOCALIZER_CACHE_CLEANUP_INTERVAL_MS See Also:Constant Field Values NM_LOCALIZER_CACHE_TARGET_SIZE_MB public static final String NM_LOCALIZER_CACHE_TARGET_SIZE_MB Target size of localizer cache in MB, per nodemanager. It is a target  retention size that only includes resources with PUBLIC and PRIVATE  visibility and excludes resources with APPLICATION visibility See Also:Constant Field Values DEFAULT_NM_LOCALIZER_CACHE_TARGET_SIZE_MB public static final long DEFAULT_NM_LOCALIZER_CACHE_TARGET_SIZE_MB See Also:Constant Field Values NM_LOCALIZER_CLIENT_THREAD_COUNT public static final String NM_LOCALIZER_CLIENT_THREAD_COUNT Number of threads to handle localization requests. See Also:Constant Field Values DEFAULT_NM_LOCALIZER_CLIENT_THREAD_COUNT public static final int DEFAULT_NM_LOCALIZER_CLIENT_THREAD_COUNT See Also:Constant Field Values NM_LOCALIZER_FETCH_THREAD_COUNT public static final String NM_LOCALIZER_FETCH_THREAD_COUNT Number of threads to use for localization fetching. See Also:Constant Field Values DEFAULT_NM_LOCALIZER_FETCH_THREAD_COUNT public static final int DEFAULT_NM_LOCALIZER_FETCH_THREAD_COUNT See Also:Constant Field Values NM_LOG_DIRS public static final String NM_LOG_DIRS Where to store container logs. See Also:Constant Field Values DEFAULT_NM_LOG_DIRS public static final String DEFAULT_NM_LOG_DIRS See Also:Constant Field Values NM_RESOURCEMANAGER_MINIMUM_VERSION public static final String NM_RESOURCEMANAGER_MINIMUM_VERSION See Also:Constant Field Values DEFAULT_NM_RESOURCEMANAGER_MINIMUM_VERSION public static final String DEFAULT_NM_RESOURCEMANAGER_MINIMUM_VERSION See Also:Constant Field Values RM_DELAYED_DELEGATION_TOKEN_REMOVAL_INTERVAL_MS public static final String RM_DELAYED_DELEGATION_TOKEN_REMOVAL_INTERVAL_MS Interval at which the delayed token removal thread runs See Also:Constant Field Values DEFAULT_RM_DELAYED_DELEGATION_TOKEN_REMOVAL_INTERVAL_MS public static final long DEFAULT_RM_DELAYED_DELEGATION_TOKEN_REMOVAL_INTERVAL_MS See Also:Constant Field Values RM_DELEGATION_TOKEN_RENEWER_THREAD_COUNT public static final String RM_DELEGATION_TOKEN_RENEWER_THREAD_COUNT Delegation Token renewer thread count See Also:Constant Field Values DEFAULT_RM_DELEGATION_TOKEN_RENEWER_THREAD_COUNT public static final int DEFAULT_RM_DELEGATION_TOKEN_RENEWER_THREAD_COUNT See Also:Constant Field Values RM_PROXY_USER_PRIVILEGES_ENABLED public static final String RM_PROXY_USER_PRIVILEGES_ENABLED See Also:Constant Field Values DEFAULT_RM_PROXY_USER_PRIVILEGES_ENABLED public static boolean DEFAULT_RM_PROXY_USER_PRIVILEGES_ENABLED LOG_AGGREGATION_ENABLED public static final String LOG_AGGREGATION_ENABLED Whether to enable log aggregation See Also:Constant Field Values DEFAULT_LOG_AGGREGATION_ENABLED public static final boolean DEFAULT_LOG_AGGREGATION_ENABLED See Also:Constant Field Values LOG_AGGREGATION_RETAIN_SECONDS public static final String LOG_AGGREGATION_RETAIN_SECONDS How long to wait before deleting aggregated logs, -1 disables.  Be careful set this too small and you will spam the name node. See Also:Constant Field Values DEFAULT_LOG_AGGREGATION_RETAIN_SECONDS public static final long DEFAULT_LOG_AGGREGATION_RETAIN_SECONDS See Also:Constant Field Values LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS public static final String LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS How long to wait between aggregated log retention checks. If set to  a value <= 0 then the value is computed as one-tenth of the  log retention setting. Be careful set this too small and you will spam  the name node. See Also:Constant Field Values DEFAULT_LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS public static final long DEFAULT_LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS See Also:Constant Field Values NM_LOG_RETAIN_SECONDS public static final String NM_LOG_RETAIN_SECONDS Number of seconds to retain logs on the NodeManager. Only applicable if Log  aggregation is disabled See Also:Constant Field Values DEFAULT_NM_LOG_RETAIN_SECONDS public static final long DEFAULT_NM_LOG_RETAIN_SECONDS See Also:Constant Field Values NM_LOG_AGGREGATION_ROLL_MONITORING_INTERVAL_SECONDS public static final String NM_LOG_AGGREGATION_ROLL_MONITORING_INTERVAL_SECONDS Define how often NMs wake up and upload log files See Also:Constant Field Values DEFAULT_NM_LOG_AGGREGATION_ROLL_MONITORING_INTERVAL_SECONDS public static final long DEFAULT_NM_LOG_AGGREGATION_ROLL_MONITORING_INTERVAL_SECONDS See Also:Constant Field Values NM_LOG_DELETION_THREADS_COUNT public static final String NM_LOG_DELETION_THREADS_COUNT Number of threads used in log cleanup. Only applicable if Log aggregation  is disabled See Also:Constant Field Values DEFAULT_NM_LOG_DELETE_THREAD_COUNT public static final int DEFAULT_NM_LOG_DELETE_THREAD_COUNT See Also:Constant Field Values NM_REMOTE_APP_LOG_DIR public static final String NM_REMOTE_APP_LOG_DIR Where to aggregate logs to. See Also:Constant Field Values DEFAULT_NM_REMOTE_APP_LOG_DIR public static final String DEFAULT_NM_REMOTE_APP_LOG_DIR See Also:Constant Field Values NM_REMOTE_APP_LOG_DIR_SUFFIX public static final String NM_REMOTE_APP_LOG_DIR_SUFFIX The remote log dir will be created at  NM_REMOTE_APP_LOG_DIR/${user}/NM_REMOTE_APP_LOG_DIR_SUFFIX/${appId} See Also:Constant Field Values DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX public static final String DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX See Also:Constant Field Values YARN_LOG_SERVER_URL public static final String YARN_LOG_SERVER_URL See Also:Constant Field Values YARN_TRACKING_URL_GENERATOR public static final String YARN_TRACKING_URL_GENERATOR See Also:Constant Field Values NM_PMEM_MB public static final String NM_PMEM_MB Amount of memory in GB that can be allocated for containers. See Also:Constant Field Values DEFAULT_NM_PMEM_MB public static final int DEFAULT_NM_PMEM_MB See Also:Constant Field Values NM_PMEM_CHECK_ENABLED public static final String NM_PMEM_CHECK_ENABLED Specifies whether physical memory check is enabled. See Also:Constant Field Values DEFAULT_NM_PMEM_CHECK_ENABLED public static final boolean DEFAULT_NM_PMEM_CHECK_ENABLED See Also:Constant Field Values NM_VMEM_CHECK_ENABLED public static final String NM_VMEM_CHECK_ENABLED Specifies whether physical memory check is enabled. See Also:Constant Field Values DEFAULT_NM_VMEM_CHECK_ENABLED public static final boolean DEFAULT_NM_VMEM_CHECK_ENABLED See Also:Constant Field Values NM_VMEM_PMEM_RATIO public static final String NM_VMEM_PMEM_RATIO Conversion ratio for physical memory to virtual memory. See Also:Constant Field Values DEFAULT_NM_VMEM_PMEM_RATIO public static final float DEFAULT_NM_VMEM_PMEM_RATIO See Also:Constant Field Values NM_VCORES public static final String NM_VCORES Number of Virtual CPU Cores which can be allocated for containers. See Also:Constant Field Values DEFAULT_NM_VCORES public static final int DEFAULT_NM_VCORES See Also:Constant Field Values NM_RESOURCE_PERCENTAGE_PHYSICAL_CPU_LIMIT public static final String NM_RESOURCE_PERCENTAGE_PHYSICAL_CPU_LIMIT Percentage of overall CPU which can be allocated for containers. See Also:Constant Field Values DEFAULT_NM_RESOURCE_PERCENTAGE_PHYSICAL_CPU_LIMIT public static final int DEFAULT_NM_RESOURCE_PERCENTAGE_PHYSICAL_CPU_LIMIT See Also:Constant Field Values NM_WEBAPP_ADDRESS public static final String NM_WEBAPP_ADDRESS NM Webapp address. See Also:Constant Field Values DEFAULT_NM_WEBAPP_PORT public static final int DEFAULT_NM_WEBAPP_PORT See Also:Constant Field Values DEFAULT_NM_WEBAPP_ADDRESS public static final String DEFAULT_NM_WEBAPP_ADDRESS See Also:Constant Field Values NM_WEBAPP_HTTPS_ADDRESS public static final String NM_WEBAPP_HTTPS_ADDRESS NM Webapp https address. See Also:Constant Field Values DEFAULT_NM_WEBAPP_HTTPS_PORT public static final int DEFAULT_NM_WEBAPP_HTTPS_PORT See Also:Constant Field Values DEFAULT_NM_WEBAPP_HTTPS_ADDRESS public static final String DEFAULT_NM_WEBAPP_HTTPS_ADDRESS See Also:Constant Field Values NM_WEBAPP_ENABLE_CORS_FILTER public static final String NM_WEBAPP_ENABLE_CORS_FILTER Enable/disable CORS filter. See Also:Constant Field Values DEFAULT_NM_WEBAPP_ENABLE_CORS_FILTER public static final boolean DEFAULT_NM_WEBAPP_ENABLE_CORS_FILTER See Also:Constant Field Values NM_CONTAINER_MON_INTERVAL_MS public static final String NM_CONTAINER_MON_INTERVAL_MS How often to monitor containers. See Also:Constant Field Values DEFAULT_NM_CONTAINER_MON_INTERVAL_MS public static final int DEFAULT_NM_CONTAINER_MON_INTERVAL_MS See Also:Constant Field Values NM_CONTAINER_MON_RESOURCE_CALCULATOR public static final String NM_CONTAINER_MON_RESOURCE_CALCULATOR Class that calculates containers current resource utilization. See Also:Constant Field Values NM_CONTAINER_MON_PROCESS_TREE public static final String NM_CONTAINER_MON_PROCESS_TREE Class that calculates process tree resource utilization. See Also:Constant Field Values PROCFS_USE_SMAPS_BASED_RSS_ENABLED public static final String PROCFS_USE_SMAPS_BASED_RSS_ENABLED See Also:Constant Field Values DEFAULT_PROCFS_USE_SMAPS_BASED_RSS_ENABLED public static final boolean DEFAULT_PROCFS_USE_SMAPS_BASED_RSS_ENABLED See Also:Constant Field Values NM_DISK_HEALTH_CHECK_ENABLE public static final String NM_DISK_HEALTH_CHECK_ENABLE Enable/Disable disks' health checker. Default is true. An expert level  configuration property. See Also:Constant Field Values NM_DISK_HEALTH_CHECK_INTERVAL_MS public static final String NM_DISK_HEALTH_CHECK_INTERVAL_MS Frequency of running disks' health checker. See Also:Constant Field Values DEFAULT_NM_DISK_HEALTH_CHECK_INTERVAL_MS public static final long DEFAULT_NM_DISK_HEALTH_CHECK_INTERVAL_MS By default, disks' health is checked every 2 minutes. See Also:Constant Field Values NM_MIN_HEALTHY_DISKS_FRACTION public static final String NM_MIN_HEALTHY_DISKS_FRACTION The minimum fraction of number of disks to be healthy for the nodemanager  to launch new containers. This applies to nm-local-dirs and nm-log-dirs. See Also:Constant Field Values DEFAULT_NM_MIN_HEALTHY_DISKS_FRACTION public static final float DEFAULT_NM_MIN_HEALTHY_DISKS_FRACTION By default, at least 25% of disks are to be healthy to say that the node is  healthy in terms of disks. See Also:Constant Field Values NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE public static final String NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE The maximum percentage of disk space that can be used after which a disk is  marked as offline. Values can range from 0.0 to 100.0. If the value is  greater than or equal to 100, NM will check for full disk. This applies to  nm-local-dirs and nm-log-dirs. See Also:Constant Field Values DEFAULT_NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE public static final float DEFAULT_NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE By default, 90% of the disk can be used before it is marked as offline. See Also:Constant Field Values NM_MIN_PER_DISK_FREE_SPACE_MB public static final String NM_MIN_PER_DISK_FREE_SPACE_MB The minimum space that must be available on a local dir for it to be used.  This applies to nm-local-dirs and nm-log-dirs. See Also:Constant Field Values DEFAULT_NM_MIN_PER_DISK_FREE_SPACE_MB public static final long DEFAULT_NM_MIN_PER_DISK_FREE_SPACE_MB By default, all of the disk can be used before it is marked as offline. See Also:Constant Field Values NM_HEALTH_CHECK_INTERVAL_MS public static final String NM_HEALTH_CHECK_INTERVAL_MS Frequency of running node health script. See Also:Constant Field Values DEFAULT_NM_HEALTH_CHECK_INTERVAL_MS public static final long DEFAULT_NM_HEALTH_CHECK_INTERVAL_MS See Also:Constant Field Values NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS public static final String NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS Health check script time out period. See Also:Constant Field Values DEFAULT_NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS public static final long DEFAULT_NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS See Also:Constant Field Values NM_HEALTH_CHECK_SCRIPT_PATH public static final String NM_HEALTH_CHECK_SCRIPT_PATH The health check script to run. See Also:Constant Field Values NM_HEALTH_CHECK_SCRIPT_OPTS public static final String NM_HEALTH_CHECK_SCRIPT_OPTS The arguments to pass to the health check script. See Also:Constant Field Values NM_DOCKER_CONTAINER_EXECUTOR_IMAGE_NAME public static final String NM_DOCKER_CONTAINER_EXECUTOR_IMAGE_NAME The Docker image name(For DockerContainerExecutor). See Also:Constant Field Values NM_DOCKER_CONTAINER_EXECUTOR_EXEC_NAME public static final String NM_DOCKER_CONTAINER_EXECUTOR_EXEC_NAME The name of the docker executor (For DockerContainerExecutor). See Also:Constant Field Values NM_DEFAULT_DOCKER_CONTAINER_EXECUTOR_EXEC_NAME public static final String NM_DEFAULT_DOCKER_CONTAINER_EXECUTOR_EXEC_NAME The default docker executor (For DockerContainerExecutor). See Also:Constant Field Values NM_LINUX_CONTAINER_EXECUTOR_PATH public static final String NM_LINUX_CONTAINER_EXECUTOR_PATH The path to the Linux container executor. See Also:Constant Field Values NM_LINUX_CONTAINER_GROUP public static final String NM_LINUX_CONTAINER_GROUP The UNIX group that the linux-container-executor should run as.  This is intended to be set as part of container-executor.cfg. See Also:Constant Field Values NM_NONSECURE_MODE_LIMIT_USERS public static final String NM_NONSECURE_MODE_LIMIT_USERS If linux-container-executor should limit itself to one user  when running in non-secure mode. See Also:Constant Field Values DEFAULT_NM_NONSECURE_MODE_LIMIT_USERS public static final boolean DEFAULT_NM_NONSECURE_MODE_LIMIT_USERS See Also:Constant Field Values NM_NONSECURE_MODE_LOCAL_USER_KEY public static final String NM_NONSECURE_MODE_LOCAL_USER_KEY The UNIX user that containers will run as when Linux-container-executor  is used in nonsecure mode (a use case for this is using cgroups). See Also:Constant Field Values DEFAULT_NM_NONSECURE_MODE_LOCAL_USER public static final String DEFAULT_NM_NONSECURE_MODE_LOCAL_USER See Also:Constant Field Values NM_NONSECURE_MODE_USER_PATTERN_KEY public static final String NM_NONSECURE_MODE_USER_PATTERN_KEY The allowed pattern for UNIX user names enforced by   Linux-container-executor when used in nonsecure mode (use case for this   is using cgroups). The default value is taken from /usr/sbin/adduser See Also:Constant Field Values DEFAULT_NM_NONSECURE_MODE_USER_PATTERN public static final String DEFAULT_NM_NONSECURE_MODE_USER_PATTERN See Also:Constant Field Values NM_LINUX_CONTAINER_RESOURCES_HANDLER public static final String NM_LINUX_CONTAINER_RESOURCES_HANDLER The type of resource enforcement to use with the   linux container executor. See Also:Constant Field Values NM_LINUX_CONTAINER_CGROUPS_HIERARCHY public static final String NM_LINUX_CONTAINER_CGROUPS_HIERARCHY The path the linux container executor should use for cgroups See Also:Constant Field Values NM_LINUX_CONTAINER_CGROUPS_MOUNT public static final String NM_LINUX_CONTAINER_CGROUPS_MOUNT Whether the linux container executor should mount cgroups if not found See Also:Constant Field Values NM_LINUX_CONTAINER_CGROUPS_MOUNT_PATH public static final String NM_LINUX_CONTAINER_CGROUPS_MOUNT_PATH Where the linux container executor should mount cgroups if not found See Also:Constant Field Values NM_LINUX_CONTAINER_CGROUPS_STRICT_RESOURCE_USAGE public static final String NM_LINUX_CONTAINER_CGROUPS_STRICT_RESOURCE_USAGE Whether the apps should run in strict resource usage mode(not allowed to  use spare CPU) See Also:Constant Field Values DEFAULT_NM_LINUX_CONTAINER_CGROUPS_STRICT_RESOURCE_USAGE public static final boolean DEFAULT_NM_LINUX_CONTAINER_CGROUPS_STRICT_RESOURCE_USAGE See Also:Constant Field Values NM_LINUX_CONTAINER_CGROUPS_DELETE_TIMEOUT public static final String NM_LINUX_CONTAINER_CGROUPS_DELETE_TIMEOUT Interval of time the linux container executor should try cleaning up  cgroups entry when cleaning up a container. This is required due to what   it seems a race condition because the SIGTERM/SIGKILL is asynch. See Also:Constant Field Values DEFAULT_NM_LINUX_CONTAINER_CGROUPS_DELETE_TIMEOUT public static final long DEFAULT_NM_LINUX_CONTAINER_CGROUPS_DELETE_TIMEOUT See Also:Constant Field Values NM_LINUX_CONTAINER_CGROUPS_DELETE_DELAY public static final String NM_LINUX_CONTAINER_CGROUPS_DELETE_DELAY Delay between attempts to remove linux cgroup. See Also:Constant Field Values DEFAULT_NM_LINUX_CONTAINER_CGROUPS_DELETE_DELAY public static final long DEFAULT_NM_LINUX_CONTAINER_CGROUPS_DELETE_DELAY See Also:Constant Field Values NM_WINDOWS_CONTAINER_MEMORY_LIMIT_ENABLED public static final String NM_WINDOWS_CONTAINER_MEMORY_LIMIT_ENABLED Indicates if memory and CPU limits will be set for the Windows Job  Object for the containers launched by the default container executor. See Also:Constant Field Values DEFAULT_NM_WINDOWS_CONTAINER_MEMORY_LIMIT_ENABLED public static final boolean DEFAULT_NM_WINDOWS_CONTAINER_MEMORY_LIMIT_ENABLED See Also:Constant Field Values NM_WINDOWS_CONTAINER_CPU_LIMIT_ENABLED public static final String NM_WINDOWS_CONTAINER_CPU_LIMIT_ENABLED See Also:Constant Field Values DEFAULT_NM_WINDOWS_CONTAINER_CPU_LIMIT_ENABLED public static final boolean DEFAULT_NM_WINDOWS_CONTAINER_CPU_LIMIT_ENABLED See Also:Constant Field Values NM_WINDOWS_SECURE_CONTAINER_GROUP public static final String NM_WINDOWS_SECURE_CONTAINER_GROUP /* The Windows group that the windows-secure-container-executor should run as. See Also:Constant Field Values NM_LOG_AGG_COMPRESSION_TYPE public static final String NM_LOG_AGG_COMPRESSION_TYPE T-file compression types used to compress aggregated logs. See Also:Constant Field Values DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE public static final String DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE See Also:Constant Field Values NM_PRINCIPAL public static final String NM_PRINCIPAL The kerberos principal for the node manager. See Also:Constant Field Values NM_AUX_SERVICES public static final String NM_AUX_SERVICES See Also:Constant Field Values NM_AUX_SERVICE_FMT public static final String NM_AUX_SERVICE_FMT See Also:Constant Field Values NM_USER_HOME_DIR public static final String NM_USER_HOME_DIR See Also:Constant Field Values NM_WEBAPP_SPNEGO_USER_NAME_KEY public static final String NM_WEBAPP_SPNEGO_USER_NAME_KEY The kerberos principal to be used for spnego filter for NM. See Also:Constant Field Values NM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY public static final String NM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY The kerberos keytab to be used for spnego filter for NM. See Also:Constant Field Values DEFAULT_NM_USER_HOME_DIR public static final String DEFAULT_NM_USER_HOME_DIR See Also:Constant Field Values NM_RECOVERY_PREFIX public static final String NM_RECOVERY_PREFIX See Also:Constant Field Values NM_RECOVERY_ENABLED public static final String NM_RECOVERY_ENABLED See Also:Constant Field Values DEFAULT_NM_RECOVERY_ENABLED public static final boolean DEFAULT_NM_RECOVERY_ENABLED See Also:Constant Field Values NM_RECOVERY_DIR public static final String NM_RECOVERY_DIR See Also:Constant Field Values PROXY_PREFIX public static final String PROXY_PREFIX See Also:Constant Field Values PROXY_PRINCIPAL public static final String PROXY_PRINCIPAL The kerberos principal for the proxy. See Also:Constant Field Values PROXY_KEYTAB public static final String PROXY_KEYTAB Keytab for Proxy. See Also:Constant Field Values PROXY_ADDRESS public static final String PROXY_ADDRESS The address for the web proxy. See Also:Constant Field Values DEFAULT_PROXY_PORT public static final int DEFAULT_PROXY_PORT See Also:Constant Field Values DEFAULT_PROXY_ADDRESS public static final String DEFAULT_PROXY_ADDRESS See Also:Constant Field Values YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCETRACKER_PROTOCOL public static final String YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCETRACKER_PROTOCOL YARN Service Level Authorization See Also:Constant Field Values YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONCLIENT_PROTOCOL public static final String YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONCLIENT_PROTOCOL See Also:Constant Field Values YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCEMANAGER_ADMINISTRATION_PROTOCOL public static final String YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCEMANAGER_ADMINISTRATION_PROTOCOL See Also:Constant Field Values YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONMASTER_PROTOCOL public static final String YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONMASTER_PROTOCOL See Also:Constant Field Values YARN_SECURITY_SERVICE_AUTHORIZATION_CONTAINER_MANAGEMENT_PROTOCOL public static final String YARN_SECURITY_SERVICE_AUTHORIZATION_CONTAINER_MANAGEMENT_PROTOCOL See Also:Constant Field Values YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCE_LOCALIZER public static final String YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCE_LOCALIZER See Also:Constant Field Values YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONHISTORY_PROTOCOL public static final String YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONHISTORY_PROTOCOL See Also:Constant Field Values NM_SLEEP_DELAY_BEFORE_SIGKILL_MS public static final String NM_SLEEP_DELAY_BEFORE_SIGKILL_MS No. of milliseconds to wait between sending a SIGTERM and SIGKILL  to a running container See Also:Constant Field Values DEFAULT_NM_SLEEP_DELAY_BEFORE_SIGKILL_MS public static final long DEFAULT_NM_SLEEP_DELAY_BEFORE_SIGKILL_MS See Also:Constant Field Values NM_PROCESS_KILL_WAIT_MS public static final String NM_PROCESS_KILL_WAIT_MS Max time to wait for a process to come up when trying to cleanup  container resources See Also:Constant Field Values DEFAULT_NM_PROCESS_KILL_WAIT_MS public static final long DEFAULT_NM_PROCESS_KILL_WAIT_MS See Also:Constant Field Values RESOURCEMANAGER_CONNECT_MAX_WAIT_MS public static final String RESOURCEMANAGER_CONNECT_MAX_WAIT_MS Max time to wait to establish a connection to RM See Also:Constant Field Values DEFAULT_RESOURCEMANAGER_CONNECT_MAX_WAIT_MS public static final long DEFAULT_RESOURCEMANAGER_CONNECT_MAX_WAIT_MS See Also:Constant Field Values RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS public static final String RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS Time interval between each attempt to connect to RM See Also:Constant Field Values DEFAULT_RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS public static final long DEFAULT_RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS See Also:Constant Field Values DISPATCHER_DRAIN_EVENTS_TIMEOUT public static final String DISPATCHER_DRAIN_EVENTS_TIMEOUT See Also:Constant Field Values DEFAULT_DISPATCHER_DRAIN_EVENTS_TIMEOUT public static final long DEFAULT_DISPATCHER_DRAIN_EVENTS_TIMEOUT See Also:Constant Field Values YARN_APPLICATION_CLASSPATH public static final String YARN_APPLICATION_CLASSPATH CLASSPATH for YARN applications. A comma-separated list of CLASSPATH  entries See Also:Constant Field Values DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH @InterfaceAudience.Public @InterfaceStability.Unstable public static final String[] DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH Default platform-agnostic CLASSPATH for YARN applications. A  comma-separated list of CLASSPATH entries. The parameter expansion marker  will be replaced with real parameter expansion marker ('%' for Windows and  '$' for Linux) by NodeManager on container launch. For example: {{VAR}}  will be replaced as $VAR on Linux, and %VAR% on Windows. DEFAULT_YARN_APPLICATION_CLASSPATH public static final String[] DEFAULT_YARN_APPLICATION_CLASSPATH  Default platform-specific CLASSPATH for YARN applications. A  comma-separated list of CLASSPATH entries constructed based on the client  OS environment expansion syntax.      Note: Use DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH for  cross-platform practice i.e. submit an application from a Windows client to  a Linux/Unix server or vice versa.   DEFAULT_CONTAINER_TEMP_DIR public static final String DEFAULT_CONTAINER_TEMP_DIR Container temp directory See Also:Constant Field Values IS_MINI_YARN_CLUSTER public static final String IS_MINI_YARN_CLUSTER See Also:Constant Field Values YARN_MC_PREFIX public static final String YARN_MC_PREFIX See Also:Constant Field Values YARN_MINICLUSTER_FIXED_PORTS public static final String YARN_MINICLUSTER_FIXED_PORTS Whether to use fixed ports with the minicluster. See Also:Constant Field Values DEFAULT_YARN_MINICLUSTER_FIXED_PORTS public static final boolean DEFAULT_YARN_MINICLUSTER_FIXED_PORTS Default is false to be able to run tests concurrently without port  conflicts. See Also:Constant Field Values YARN_MINICLUSTER_USE_RPC public static final String YARN_MINICLUSTER_USE_RPC Whether the NM should use RPC to connect to the RM. Default is false.  Can be set to true only when using fixed ports. See Also:Constant Field Values DEFAULT_YARN_MINICLUSTER_USE_RPC public static final boolean DEFAULT_YARN_MINICLUSTER_USE_RPC See Also:Constant Field Values YARN_MINICLUSTER_CONTROL_RESOURCE_MONITORING public static final String YARN_MINICLUSTER_CONTROL_RESOURCE_MONITORING Whether users are explicitly trying to control resource monitoring  configuration for the MiniYARNCluster. Disabled by default. See Also:Constant Field Values DEFAULT_YARN_MINICLUSTER_CONTROL_RESOURCE_MONITORING public static final boolean DEFAULT_YARN_MINICLUSTER_CONTROL_RESOURCE_MONITORING See Also:Constant Field Values YARN_MINICLUSTER_NM_PMEM_MB public static final String YARN_MINICLUSTER_NM_PMEM_MB Allow changing the memory for the NodeManager in the MiniYARNCluster See Also:Constant Field Values DEFAULT_YARN_MINICLUSTER_NM_PMEM_MB public static final int DEFAULT_YARN_MINICLUSTER_NM_PMEM_MB See Also:Constant Field Values YARN_APP_CONTAINER_LOG_DIR public static final String YARN_APP_CONTAINER_LOG_DIR The log directory for the containers See Also:Constant Field Values YARN_APP_CONTAINER_LOG_SIZE public static final String YARN_APP_CONTAINER_LOG_SIZE See Also:Constant Field Values YARN_APP_CONTAINER_LOG_BACKUPS public static final String YARN_APP_CONTAINER_LOG_BACKUPS See Also:Constant Field Values TIMELINE_SERVICE_PREFIX public static final String TIMELINE_SERVICE_PREFIX See Also:Constant Field Values TIMELINE_SERVICE_UI_NAMES public static final String TIMELINE_SERVICE_UI_NAMES Comma seperated list of names for UIs hosted in the timeline server  (For pluggable UIs). See Also:Constant Field Values TIMELINE_SERVICE_UI_WEB_PATH_PREFIX public static final String TIMELINE_SERVICE_UI_WEB_PATH_PREFIX Relative web path that will serve up this UI (For pluggable UIs). See Also:Constant Field Values TIMELINE_SERVICE_UI_ON_DISK_PATH_PREFIX public static final String TIMELINE_SERVICE_UI_ON_DISK_PATH_PREFIX Path to war file or static content directory for this UI  (For pluggable UIs). See Also:Constant Field Values TIMELINE_SERVICE_ENABLED public static final String TIMELINE_SERVICE_ENABLED The setting that controls whether timeline service is enabled or not. See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_ENABLED public static final boolean DEFAULT_TIMELINE_SERVICE_ENABLED See Also:Constant Field Values TIMELINE_SERVICE_ADDRESS public static final String TIMELINE_SERVICE_ADDRESS host:port address for timeline service RPC APIs. See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_PORT public static final int DEFAULT_TIMELINE_SERVICE_PORT See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_ADDRESS public static final String DEFAULT_TIMELINE_SERVICE_ADDRESS See Also:Constant Field Values TIMELINE_SERVICE_BIND_HOST public static final String TIMELINE_SERVICE_BIND_HOST The listening endpoint for the timeline service application. See Also:Constant Field Values TIMELINE_SERVICE_HANDLER_THREAD_COUNT public static final String TIMELINE_SERVICE_HANDLER_THREAD_COUNT The number of threads to handle client RPC API requests. See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_CLIENT_THREAD_COUNT public static final int DEFAULT_TIMELINE_SERVICE_CLIENT_THREAD_COUNT See Also:Constant Field Values TIMELINE_SERVICE_WEBAPP_ADDRESS public static final String TIMELINE_SERVICE_WEBAPP_ADDRESS The address of the timeline service web application. See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_WEBAPP_PORT public static final int DEFAULT_TIMELINE_SERVICE_WEBAPP_PORT See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_WEBAPP_ADDRESS public static final String DEFAULT_TIMELINE_SERVICE_WEBAPP_ADDRESS See Also:Constant Field Values TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS public static final String TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS The https address of the timeline service web application. See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_PORT public static final int DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_PORT See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS public static final String DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS See Also:Constant Field Values APPLICATION_HISTORY_MAX_APPS public static final String APPLICATION_HISTORY_MAX_APPS Defines the max number of applications could be fetched using  REST API or application history protocol and shown in timeline  server web ui. See Also:Constant Field Values DEFAULT_APPLICATION_HISTORY_MAX_APPS public static final long DEFAULT_APPLICATION_HISTORY_MAX_APPS See Also:Constant Field Values TIMELINE_SERVICE_STORE public static final String TIMELINE_SERVICE_STORE Timeline service store class See Also:Constant Field Values TIMELINE_SERVICE_TTL_ENABLE public static final String TIMELINE_SERVICE_TTL_ENABLE Timeline service enable data age off See Also:Constant Field Values TIMELINE_SERVICE_TTL_MS public static final String TIMELINE_SERVICE_TTL_MS Timeline service length of time to retain data See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_TTL_MS public static final long DEFAULT_TIMELINE_SERVICE_TTL_MS See Also:Constant Field Values TIMELINE_SERVICE_LEVELDB_PREFIX public static final String TIMELINE_SERVICE_LEVELDB_PREFIX See Also:Constant Field Values TIMELINE_SERVICE_LEVELDB_PATH public static final String TIMELINE_SERVICE_LEVELDB_PATH Timeline service leveldb path See Also:Constant Field Values TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE public static final String TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE Timeline service leveldb read cache (uncompressed blocks) See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE public static final long DEFAULT_TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE See Also:Constant Field Values TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE public static final String TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE Timeline service leveldb start time read cache (number of entities) See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE public static final int DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE See Also:Constant Field Values TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE public static final String TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE Timeline service leveldb start time write cache (number of entities) See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE public static final int DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE See Also:Constant Field Values TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS public static final String TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS Timeline service leveldb interval to wait between deletion rounds See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS public static final long DEFAULT_TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS See Also:Constant Field Values TIMELINE_SERVICE_PRINCIPAL public static final String TIMELINE_SERVICE_PRINCIPAL The Kerberos principal for the timeline server. See Also:Constant Field Values TIMELINE_SERVICE_KEYTAB public static final String TIMELINE_SERVICE_KEYTAB The Kerberos keytab for the timeline server. See Also:Constant Field Values TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED public static final String TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED Enables cross origin support for timeline server. See Also:Constant Field Values TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED_DEFAULT public static final boolean TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED_DEFAULT Default value for cross origin support for timeline server. See Also:Constant Field Values TIMELINE_SERVICE_CLIENT_PREFIX public static final String TIMELINE_SERVICE_CLIENT_PREFIX Timeline client settings See Also:Constant Field Values TIMELINE_SERVICE_CLIENT_MAX_RETRIES public static final String TIMELINE_SERVICE_CLIENT_MAX_RETRIES Timeline client call, max retries (-1 means no limit) See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_CLIENT_MAX_RETRIES public static final int DEFAULT_TIMELINE_SERVICE_CLIENT_MAX_RETRIES See Also:Constant Field Values TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS public static final String TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS Timeline client call, retry interval See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS public static final long DEFAULT_TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS See Also:Constant Field Values TIMELINE_SERVICE_CLIENT_BEST_EFFORT public static final String TIMELINE_SERVICE_CLIENT_BEST_EFFORT Timeline client policy for whether connections are fatal See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_CLIENT_BEST_EFFORT public static final boolean DEFAULT_TIMELINE_SERVICE_CLIENT_BEST_EFFORT See Also:Constant Field Values TIMELINE_SERVICE_RECOVERY_ENABLED public static final String TIMELINE_SERVICE_RECOVERY_ENABLED Flag to enable recovery of timeline service See Also:Constant Field Values DEFAULT_TIMELINE_SERVICE_RECOVERY_ENABLED public static final boolean DEFAULT_TIMELINE_SERVICE_RECOVERY_ENABLED See Also:Constant Field Values TIMELINE_SERVICE_STATE_STORE_CLASS public static final String TIMELINE_SERVICE_STATE_STORE_CLASS Timeline service state store class See Also:Constant Field Values TIMELINE_SERVICE_LEVELDB_STATE_STORE_PREFIX public static final String TIMELINE_SERVICE_LEVELDB_STATE_STORE_PREFIX See Also:Constant Field Values TIMELINE_SERVICE_LEVELDB_STATE_STORE_PATH public static final String TIMELINE_SERVICE_LEVELDB_STATE_STORE_PATH Timeline service state store leveldb path See Also:Constant Field Values TIMELINE_DELEGATION_KEY_UPDATE_INTERVAL public static final String TIMELINE_DELEGATION_KEY_UPDATE_INTERVAL See Also:Constant Field Values DEFAULT_TIMELINE_DELEGATION_KEY_UPDATE_INTERVAL public static final long DEFAULT_TIMELINE_DELEGATION_KEY_UPDATE_INTERVAL See Also:Constant Field Values TIMELINE_DELEGATION_TOKEN_RENEW_INTERVAL public static final String TIMELINE_DELEGATION_TOKEN_RENEW_INTERVAL See Also:Constant Field Values DEFAULT_TIMELINE_DELEGATION_TOKEN_RENEW_INTERVAL public static final long DEFAULT_TIMELINE_DELEGATION_TOKEN_RENEW_INTERVAL See Also:Constant Field Values TIMELINE_DELEGATION_TOKEN_MAX_LIFETIME public static final String TIMELINE_DELEGATION_TOKEN_MAX_LIFETIME See Also:Constant Field Values DEFAULT_TIMELINE_DELEGATION_TOKEN_MAX_LIFETIME public static final long DEFAULT_TIMELINE_DELEGATION_TOKEN_MAX_LIFETIME See Also:Constant Field Values SHARED_CACHE_PREFIX public static final String SHARED_CACHE_PREFIX See Also:Constant Field Values SHARED_CACHE_ENABLED public static final String SHARED_CACHE_ENABLED whether the shared cache is enabled/disabled See Also:Constant Field Values DEFAULT_SHARED_CACHE_ENABLED public static final boolean DEFAULT_SHARED_CACHE_ENABLED See Also:Constant Field Values SHARED_CACHE_ROOT public static final String SHARED_CACHE_ROOT The config key for the shared cache root directory. See Also:Constant Field Values DEFAULT_SHARED_CACHE_ROOT public static final String DEFAULT_SHARED_CACHE_ROOT See Also:Constant Field Values SHARED_CACHE_NESTED_LEVEL public static final String SHARED_CACHE_NESTED_LEVEL The config key for the level of nested directories before getting to the  checksum directory. See Also:Constant Field Values DEFAULT_SHARED_CACHE_NESTED_LEVEL public static final int DEFAULT_SHARED_CACHE_NESTED_LEVEL See Also:Constant Field Values SCM_STORE_PREFIX public static final String SCM_STORE_PREFIX See Also:Constant Field Values SCM_STORE_CLASS public static final String SCM_STORE_CLASS See Also:Constant Field Values DEFAULT_SCM_STORE_CLASS public static final String DEFAULT_SCM_STORE_CLASS See Also:Constant Field Values SCM_APP_CHECKER_CLASS public static final String SCM_APP_CHECKER_CLASS See Also:Constant Field Values DEFAULT_SCM_APP_CHECKER_CLASS public static final String DEFAULT_SCM_APP_CHECKER_CLASS See Also:Constant Field Values SCM_ADMIN_ADDRESS public static final String SCM_ADMIN_ADDRESS The address of the SCM admin interface. See Also:Constant Field Values DEFAULT_SCM_ADMIN_PORT public static final int DEFAULT_SCM_ADMIN_PORT See Also:Constant Field Values DEFAULT_SCM_ADMIN_ADDRESS public static final String DEFAULT_SCM_ADMIN_ADDRESS See Also:Constant Field Values SCM_ADMIN_CLIENT_THREAD_COUNT public static final String SCM_ADMIN_CLIENT_THREAD_COUNT Number of threads used to handle SCM admin interface. See Also:Constant Field Values DEFAULT_SCM_ADMIN_CLIENT_THREAD_COUNT public static final int DEFAULT_SCM_ADMIN_CLIENT_THREAD_COUNT See Also:Constant Field Values SCM_WEBAPP_ADDRESS public static final String SCM_WEBAPP_ADDRESS The address of the SCM web application. See Also:Constant Field Values DEFAULT_SCM_WEBAPP_PORT public static final int DEFAULT_SCM_WEBAPP_PORT See Also:Constant Field Values DEFAULT_SCM_WEBAPP_ADDRESS public static final String DEFAULT_SCM_WEBAPP_ADDRESS See Also:Constant Field Values IN_MEMORY_STORE_PREFIX public static final String IN_MEMORY_STORE_PREFIX See Also:Constant Field Values IN_MEMORY_STALENESS_PERIOD_MINS public static final String IN_MEMORY_STALENESS_PERIOD_MINS A resource in the InMemorySCMStore is considered stale if the time since  the last reference exceeds the staleness period. This value is specified in  minutes. See Also:Constant Field Values DEFAULT_IN_MEMORY_STALENESS_PERIOD_MINS public static final int DEFAULT_IN_MEMORY_STALENESS_PERIOD_MINS See Also:Constant Field Values IN_MEMORY_INITIAL_DELAY_MINS public static final String IN_MEMORY_INITIAL_DELAY_MINS Initial delay before the in-memory store runs its first check to remove  dead initial applications. Specified in minutes. See Also:Constant Field Values DEFAULT_IN_MEMORY_INITIAL_DELAY_MINS public static final int DEFAULT_IN_MEMORY_INITIAL_DELAY_MINS See Also:Constant Field Values IN_MEMORY_CHECK_PERIOD_MINS public static final String IN_MEMORY_CHECK_PERIOD_MINS The frequency at which the in-memory store checks to remove dead initial  applications. Specified in minutes. See Also:Constant Field Values DEFAULT_IN_MEMORY_CHECK_PERIOD_MINS public static final int DEFAULT_IN_MEMORY_CHECK_PERIOD_MINS See Also:Constant Field Values SCM_CLEANER_PERIOD_MINS public static final String SCM_CLEANER_PERIOD_MINS The frequency at which a cleaner task runs. Specified in minutes. See Also:Constant Field Values DEFAULT_SCM_CLEANER_PERIOD_MINS public static final int DEFAULT_SCM_CLEANER_PERIOD_MINS See Also:Constant Field Values SCM_CLEANER_INITIAL_DELAY_MINS public static final String SCM_CLEANER_INITIAL_DELAY_MINS Initial delay before the first cleaner task is scheduled. Specified in  minutes. See Also:Constant Field Values DEFAULT_SCM_CLEANER_INITIAL_DELAY_MINS public static final int DEFAULT_SCM_CLEANER_INITIAL_DELAY_MINS See Also:Constant Field Values SCM_CLEANER_RESOURCE_SLEEP_MS public static final String SCM_CLEANER_RESOURCE_SLEEP_MS The time to sleep between processing each shared cache resource. Specified  in milliseconds. See Also:Constant Field Values DEFAULT_SCM_CLEANER_RESOURCE_SLEEP_MS public static final long DEFAULT_SCM_CLEANER_RESOURCE_SLEEP_MS See Also:Constant Field Values SCM_UPLOADER_SERVER_ADDRESS public static final String SCM_UPLOADER_SERVER_ADDRESS The address of the node manager interface in the SCM. See Also:Constant Field Values DEFAULT_SCM_UPLOADER_SERVER_PORT public static final int DEFAULT_SCM_UPLOADER_SERVER_PORT See Also:Constant Field Values DEFAULT_SCM_UPLOADER_SERVER_ADDRESS public static final String DEFAULT_SCM_UPLOADER_SERVER_ADDRESS See Also:Constant Field Values SCM_UPLOADER_SERVER_THREAD_COUNT public static final String SCM_UPLOADER_SERVER_THREAD_COUNT The number of SCM threads used to handle notify requests from the node  manager. See Also:Constant Field Values DEFAULT_SCM_UPLOADER_SERVER_THREAD_COUNT public static final int DEFAULT_SCM_UPLOADER_SERVER_THREAD_COUNT See Also:Constant Field Values SCM_CLIENT_SERVER_ADDRESS public static final String SCM_CLIENT_SERVER_ADDRESS The address of the client interface in the SCM. See Also:Constant Field Values DEFAULT_SCM_CLIENT_SERVER_PORT public static final int DEFAULT_SCM_CLIENT_SERVER_PORT See Also:Constant Field Values DEFAULT_SCM_CLIENT_SERVER_ADDRESS public static final String DEFAULT_SCM_CLIENT_SERVER_ADDRESS See Also:Constant Field Values SCM_CLIENT_SERVER_THREAD_COUNT public static final String SCM_CLIENT_SERVER_THREAD_COUNT The number of threads used to handle shared cache manager requests. See Also:Constant Field Values DEFAULT_SCM_CLIENT_SERVER_THREAD_COUNT public static final int DEFAULT_SCM_CLIENT_SERVER_THREAD_COUNT See Also:Constant Field Values SHARED_CACHE_CHECKSUM_ALGO_IMPL public static final String SHARED_CACHE_CHECKSUM_ALGO_IMPL the checksum algorithm implementation See Also:Constant Field Values DEFAULT_SHARED_CACHE_CHECKSUM_ALGO_IMPL public static final String DEFAULT_SHARED_CACHE_CHECKSUM_ALGO_IMPL See Also:Constant Field Values SHARED_CACHE_NM_UPLOADER_REPLICATION_FACTOR public static final String SHARED_CACHE_NM_UPLOADER_REPLICATION_FACTOR The replication factor for the node manager uploader for the shared cache. See Also:Constant Field Values DEFAULT_SHARED_CACHE_NM_UPLOADER_REPLICATION_FACTOR public static final int DEFAULT_SHARED_CACHE_NM_UPLOADER_REPLICATION_FACTOR See Also:Constant Field Values SHARED_CACHE_NM_UPLOADER_THREAD_COUNT public static final String SHARED_CACHE_NM_UPLOADER_THREAD_COUNT See Also:Constant Field Values DEFAULT_SHARED_CACHE_NM_UPLOADER_THREAD_COUNT public static final int DEFAULT_SHARED_CACHE_NM_UPLOADER_THREAD_COUNT See Also:Constant Field Values YARN_CLIENT_APP_SUBMISSION_POLL_INTERVAL_MS @Deprecated public static final String YARN_CLIENT_APP_SUBMISSION_POLL_INTERVAL_MS Deprecated.  Use YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS instead.  The interval of the yarn client's querying application state after  application submission. The unit is millisecond. See Also:Constant Field Values YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS public static final String YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS The interval that the yarn client library uses to poll the completion  status of the asynchronous API of application client protocol. See Also:Constant Field Values DEFAULT_YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS public static final long DEFAULT_YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS See Also:Constant Field Values YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_TIMEOUT_MS public static final String YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_TIMEOUT_MS The duration that the yarn client library waits, cumulatively across polls,  for an expected state change to occur. Defaults to -1, which indicates no  limit. See Also:Constant Field Values DEFAULT_YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_TIMEOUT_MS public static final long DEFAULT_YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_TIMEOUT_MS See Also:Constant Field Values NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE public static final String NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE Max number of threads in NMClientAsync to process container management  events See Also:Constant Field Values DEFAULT_NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE public static final int DEFAULT_NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE See Also:Constant Field Values NM_CLIENT_MAX_NM_PROXIES public static final String NM_CLIENT_MAX_NM_PROXIES Maximum number of proxy connections to cache for node managers. If set  to a value greater than zero then the cache is enabled and the NMClient  and MRAppMaster will cache the specified number of node manager proxies.  There will be at max one proxy per node manager. Ex. configuring it to a  value of 5 will make sure that client will at max have 5 proxies cached  with 5 different node managers. These connections for these proxies will  be timed out if idle for more than the system wide idle timeout period.  Note that this could cause issues on large clusters as many connections  could linger simultaneously and lead to a large number of connection  threads. The token used for authentication will be used only at  connection creation time. If a new token is received then the earlier  connection should be closed in order to use the new token. This and  NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE are related  and should be in sync (no need for them to be equal).  If the value of this property is zero then the connection cache is  disabled and connections will use a zero idle timeout to prevent too  many connection threads on large clusters. See Also:Constant Field Values DEFAULT_NM_CLIENT_MAX_NM_PROXIES public static final int DEFAULT_NM_CLIENT_MAX_NM_PROXIES See Also:Constant Field Values CLIENT_NM_CONNECT_MAX_WAIT_MS public static final String CLIENT_NM_CONNECT_MAX_WAIT_MS Max time to wait to establish a connection to NM See Also:Constant Field Values DEFAULT_CLIENT_NM_CONNECT_MAX_WAIT_MS public static final long DEFAULT_CLIENT_NM_CONNECT_MAX_WAIT_MS See Also:Constant Field Values CLIENT_NM_CONNECT_RETRY_INTERVAL_MS public static final String CLIENT_NM_CONNECT_RETRY_INTERVAL_MS Time interval between each attempt to connect to NM See Also:Constant Field Values DEFAULT_CLIENT_NM_CONNECT_RETRY_INTERVAL_MS public static final long DEFAULT_CLIENT_NM_CONNECT_RETRY_INTERVAL_MS See Also:Constant Field Values YARN_HTTP_POLICY_KEY public static final String YARN_HTTP_POLICY_KEY See Also:Constant Field Values YARN_HTTP_POLICY_DEFAULT public static final String YARN_HTTP_POLICY_DEFAULT NODE_LABELS_PREFIX public static final String NODE_LABELS_PREFIX Node-labels configurations See Also:Constant Field Values FS_NODE_LABELS_STORE_ROOT_DIR public static final String FS_NODE_LABELS_STORE_ROOT_DIR URI for NodeLabelManager See Also:Constant Field Values FS_NODE_LABELS_STORE_RETRY_POLICY_SPEC public static final String FS_NODE_LABELS_STORE_RETRY_POLICY_SPEC See Also:Constant Field Values DEFAULT_FS_NODE_LABELS_STORE_RETRY_POLICY_SPEC public static final String DEFAULT_FS_NODE_LABELS_STORE_RETRY_POLICY_SPEC See Also:Constant Field Values NODE_LABELS_ENABLED public static final String NODE_LABELS_ENABLED Flag to indicate if the node labels feature enabled, by default it's  disabled See Also:Constant Field Values DEFAULT_NODE_LABELS_ENABLED public static final boolean DEFAULT_NODE_LABELS_ENABLED See Also:Constant Field Values Constructor Detail YarnConfiguration public YarnConfiguration() YarnConfiguration public YarnConfiguration(Configuration conf) Method Detail getSocketAddr public InetSocketAddress getSocketAddr(String name,                               String defaultAddress,                               int defaultPort) Get the socket address for name property as a  InetSocketAddress. On a HA cluster,  this fetches the address corresponding to the RM identified by  RM_HA_ID. Overrides: getSocketAddr in class Configuration Parameters:name - property name.defaultAddress - the default valuedefaultPort - the default port Returns:InetSocketAddress updateConnectAddr public InetSocketAddress updateConnectAddr(String name,                                   InetSocketAddress addr) Description copied from class: Configuration Set the socket address a client can use to connect for the  name property as a host:port.  The wildcard  address is replaced with the local host's address. Overrides: updateConnectAddr in class Configuration Parameters:name - property name.addr - InetSocketAddress of a listener to store in the given property Returns:InetSocketAddress for clients to connect useHttps public static boolean useHttps(Configuration conf) shouldRMFailFast public static boolean shouldRMFailFast(Configuration conf) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  YarnException (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="YarnException (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn.exceptions Class YarnException java.lang.Object java.lang.Throwable java.lang.Exception org.apache.hadoop.yarn.exceptions.YarnException All Implemented Interfaces: Serializable Direct Known Subclasses: ApplicationAttemptNotFoundException, ApplicationIdNotProvidedException, ApplicationNotFoundException, ContainerNotFoundException @InterfaceAudience.Public @InterfaceStability.Stable public class YarnException extends Exception YarnException indicates exceptions from yarn servers. On the other hand,  IOExceptions indicates exceptions from RPC layer. See Also:Serialized Form Constructor Summary Constructors  Constructor and Description YarnException()  YarnException(String message)  YarnException(String message,                           Throwable cause)  YarnException(Throwable cause)  Method Summary Methods inherited from class java.lang.Throwable addSuppressed, fillInStackTrace, getCause, getLocalizedMessage, getMessage, getStackTrace, getSuppressed, initCause, printStackTrace, printStackTrace, printStackTrace, setStackTrace, toString Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, wait, wait, wait Constructor Detail YarnException public YarnException() YarnException public YarnException(String message) YarnException public YarnException(Throwable cause) YarnException public YarnException(String message,              Throwable cause) Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  YarnUncaughtExceptionHandler (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="YarnUncaughtExceptionHandler (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.yarn Class YarnUncaughtExceptionHandler java.lang.Object org.apache.hadoop.yarn.YarnUncaughtExceptionHandler All Implemented Interfaces: Thread.UncaughtExceptionHandler @InterfaceAudience.Public @InterfaceStability.Evolving public class YarnUncaughtExceptionHandler extends Object implements Thread.UncaughtExceptionHandler This class is intended to be installed by calling   Thread.setDefaultUncaughtExceptionHandler(UncaughtExceptionHandler)  In the main entry point.  It is intended to try and cleanly shut down  programs using the Yarn Event framework.    Note: Right now it only will shut down the program if a Error is caught, but  not any other exception.  Anything else is just logged. Constructor Summary Constructors  Constructor and Description YarnUncaughtExceptionHandler()  Method Summary Methods  Modifier and Type Method and Description void uncaughtException(Thread t,                                   Throwable e)  Methods inherited from class java.lang.Object clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait Constructor Detail YarnUncaughtExceptionHandler public YarnUncaughtExceptionHandler() Method Detail uncaughtException public void uncaughtException(Thread t,                      Throwable e) Specified by: uncaughtException in interface Thread.UncaughtExceptionHandler Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved.  ZKFCProtocolPB (Apache Hadoop Main 2.7.2 API) <!--     if (location.href.indexOf('is-external=true') == -1) {         parent.document.title="ZKFCProtocolPB (Apache Hadoop Main 2.7.2 API)";     } //--> JavaScript is disabled on your browser. Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_top");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method org.apache.hadoop.ha.protocolPB Interface ZKFCProtocolPB All Superinterfaces: org.apache.hadoop.ipc.VersionedProtocol, org.apache.hadoop.ha.proto.ZKFCProtocolProtos.ZKFCProtocolService.BlockingInterface @InterfaceAudience.Public @InterfaceStability.Evolving public interface ZKFCProtocolPB extends org.apache.hadoop.ha.proto.ZKFCProtocolProtos.ZKFCProtocolService.BlockingInterface, org.apache.hadoop.ipc.VersionedProtocol Method Summary Methods inherited from interface org.apache.hadoop.ha.proto.ZKFCProtocolProtos.ZKFCProtocolService.BlockingInterface cedeActive, gracefulFailover Methods inherited from interface org.apache.hadoop.ipc.VersionedProtocol getProtocolSignature, getProtocolVersion Overview Package Class Use Tree Deprecated Index Help Prev Class Next Class Frames No Frames All Classes <!--   allClassesLink = document.getElementById("allclasses_navbar_bottom");   if(window==top) {     allClassesLink.style.display = "block";   }   else {     allClassesLink.style.display = "none";   }   //--> Summary:  Nested |  Field |  Constr |  Method Detail:  Field |  Constr |  Method Copyright © 2016 Apache Software Foundation. All rights reserved. 